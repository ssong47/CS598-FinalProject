{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(x_train.dtype)\n",
    "print(y_train.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions, returning logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7574823   0.40195763 -0.19585942  0.47278902 -0.15115862 -0.08864196\n",
      "   0.28004393 -0.271615   -0.35497454 -0.4060803 ]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18905489, 0.13249074, 0.07287136, 0.1422156 , 0.07620267,\n",
       "        0.08111867, 0.11728409, 0.06755486, 0.06215185, 0.05905534]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to softmax. \n",
    "tf.nn.softmax(predictions).numpy()\n",
    "\n",
    "# Note that it's not recommended to put softmax as last layer b/c impossible to provide exact and numerically stable loss calculation for all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute loss using sparse categorical cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# The losses.SparseCategoricalCrossentropy loss takes a vector of logits and a True index and returns a scalar loss for each example.\n",
    "# This loss is equal to the negative log probability of the true class: It is zero if the model is sure of the correct class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5118423"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(loss_fn(y_train[:1], predictions).numpy())\n",
    "print()\n",
    "# This untrained model should give probability close to random (1/10 for each class) , so the initial loss should be ~tf.log(1/10) ~= 2,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model using the optimizer, loss function and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.4841 - accuracy: 0.85 - 1s 638us/step - loss: 0.4794 - accuracy: 0.8610\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 656us/step - loss: 0.1590 - accuracy: 0.9541\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 658us/step - loss: 0.1112 - accuracy: 0.9653\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 675us/step - loss: 0.0866 - accuracy: 0.9723\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 652us/step - loss: 0.0733 - accuracy: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13b69117358>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0740 - accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0740356296300888, 0.9775999784469604]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)\n",
    "# Make sure the trained model works for validation or test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return probablity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.9712282e-07, 3.6487595e-09, 1.5694095e-05, 9.9794415e-05,\n",
       "        2.3483321e-10, 5.1303329e-07, 8.0362163e-14, 9.9987435e-01,\n",
       "        5.6426131e-07, 8.7411790e-06],\n",
       "       [7.0113691e-07, 1.6030492e-04, 9.9971873e-01, 1.0946670e-04,\n",
       "        9.2107235e-15, 6.3925845e-06, 1.0855697e-07, 4.5965705e-13,\n",
       "        4.1810795e-06, 1.6208323e-11],\n",
       "       [1.7864748e-07, 9.9972337e-01, 5.2863397e-05, 1.3593894e-05,\n",
       "        2.5864128e-05, 5.8707483e-06, 6.7855131e-06, 8.2485552e-05,\n",
       "        8.7939836e-05, 1.0368002e-06],\n",
       "       [9.9992621e-01, 1.0704584e-08, 2.4439641e-05, 7.5949015e-07,\n",
       "        5.0569820e-06, 2.7772865e-06, 3.0540232e-05, 1.8572230e-07,\n",
       "        2.8287906e-07, 9.9068147e-06],\n",
       "       [2.7675680e-06, 3.2633019e-07, 3.3358037e-06, 5.1699992e-08,\n",
       "        9.9830866e-01, 9.9775832e-07, 2.3970661e-06, 3.5246470e-05,\n",
       "        2.5950405e-07, 1.6461656e-03]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:5]).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing results from raw model, probability model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-14.007774   -5.3724833  -8.441552   -3.0162597   2.0305045  -7.5744143\n",
      "  -12.416223   -1.8851573  -1.0188295   9.887919 ]]\n",
      "[[4.1884291e-11 2.3567354e-07 1.0950429e-08 2.4866001e-06 3.8671185e-04\n",
      "  2.6062997e-08 2.0570920e-10 7.7061441e-06 1.8326466e-05 9.9958450e-01]]\n",
      "[9]\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "predictions = model(x_train[i-1:i]).numpy()\n",
    "prob_pred = probability_model(x_train[i-1:i]).numpy()\n",
    "print(predictions)\n",
    "print(prob_pred)\n",
    "print(y_train[i-1:i])\n",
    "print(np.argmax(predictions[0]))\n",
    "print(np.argmax(prob_pred[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4615047"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 2\n",
    "predictions = model(x_train[i-1:i]).numpy()\n",
    "prob_pred = probability_model(x_train[i-1:i]).numpy()\n",
    "\n",
    "loss_fn(y_train[i-1:i], prob_pred).numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
