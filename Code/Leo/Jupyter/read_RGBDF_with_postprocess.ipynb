{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this script is to log the RGB Camera, Depth Camera, and Force Data at the same sampling rate and time via the serial port. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import serial\n",
    "import time \n",
    "\n",
    "# Setup:\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "\n",
    "# Create an object to read  \n",
    "# from camera \n",
    "video = cv2.VideoCapture(0) \n",
    "   \n",
    "# We need to check if camera \n",
    "# is opened previously or not \n",
    "if (video.isOpened() == False):  \n",
    "    print(\"Error reading video file\") \n",
    "    \n",
    "# We need to set resolutions. \n",
    "# so, convert them from float to integer. \n",
    "frame_width = int(video.get(3)) \n",
    "frame_height = int(video.get(4)) \n",
    "   \n",
    "size = (frame_width, frame_height) \n",
    "\n",
    "\n",
    "\n",
    "# Below VideoWriter object will create \n",
    "# a frame of above defined The output  \n",
    "# is stored in 'filename.avi' file. \n",
    "colorizer = rs.colorizer()\n",
    "colorizer.set_option(rs.option.color_scheme, 3)\n",
    "mag_deci = 4\n",
    "decimation = rs.decimation_filter(mag_deci)\n",
    "threshold = rs.threshold_filter(0.15, 1.6)\n",
    "\n",
    "n_trial = 30\n",
    "depthwriter = cv2.VideoWriter('fcss_leo_depth_test'+str(n_trial)+'.avi',  \n",
    "                         cv2.VideoWriter_fourcc(*'DIVX'), \n",
    "                         30, (int(frame_width/mag_deci), int(frame_height/mag_deci)), 0) \n",
    "\n",
    "\n",
    "print(\"type anything to start\")\n",
    "start_test = input()\n",
    "\n",
    "\n",
    "addr = \"COM4\" ## serial port to read data from\n",
    "baud = 115200 ## baud rate for instrument\n",
    "\n",
    "ser = serial.Serial(\n",
    "    port = addr,\\\n",
    "    baudrate = baud)\n",
    "\n",
    "fcss_filename = \"fcss_leo_load_test\"+str(n_trial)+\".csv\"\n",
    "datafile = open(fcss_filename, 'a')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Start streaming\n",
    "pipe.start(cfg)\n",
    "start_time = cv2.getTickCount()\n",
    "prev_time = 0\n",
    "count = 0\n",
    "count_total = 0 \n",
    "try:\n",
    "    while ((cv2.getTickCount() - start_time)/cv2.getTickFrequency() < 15):\n",
    "        try:\n",
    "            prev_time = cv2.getTickCount()\n",
    "            ser_bytes = ser.readline()\n",
    "            decoded_bytes = (ser_bytes[0:len(ser_bytes)-2].decode(\"utf-8\").split(\",\"))\n",
    "\n",
    "#             print(decoded_bytes)\n",
    "\n",
    "            write_line = \",\".join(decoded_bytes) + str(\"\\n\")\n",
    "            datafile.write(write_line)\n",
    "            \n",
    "            \n",
    "            # Wait for a coherent pair of frames: depth and color\n",
    "            frames = pipe.wait_for_frames()\n",
    "            depth_frame = frames.get_depth_frame()\n",
    "            \n",
    "            if not depth_frame:\n",
    "                continue\n",
    "            \n",
    "            # Decimation \n",
    "            depth_frame = decimation.process(depth_frame)\n",
    "\n",
    "            # Thresholding\n",
    "            depth_frame = threshold.process(depth_frame)\n",
    "        \n",
    "            # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "            depth_colormap = np.asanyarray(colorizer.colorize(depth_frame).get_data())     \n",
    "            key = cv2.waitKey(1)\n",
    "            \n",
    "            # Resize the CV frame to fit the decimated frame\n",
    "            depth_save = cv2.resize(depth_colormap, (int(frame_width/mag_deci), int(frame_height/mag_deci)))\n",
    "            \n",
    "            \n",
    " \n",
    "            # Save depth camera frame \n",
    "            depthwriter.write(depth_save)\n",
    "            \n",
    "            # Show depth camera \n",
    "            cv2.imshow('Depth', depth_save)\n",
    "\n",
    "            # Press esc or 'q' to close the image window\n",
    "            if key & 0xFF == ord('q') or key == 27:\n",
    "                cv2.destroyAllWindows()\n",
    "                video.release() \n",
    "                depthwriter.release()\n",
    "                break \n",
    "            count_total = count_total+ 1\n",
    "            \n",
    "            el_t = (cv2.getTickCount() - prev_time)/cv2.getTickFrequency()\n",
    "            \n",
    "            if el_t > 0.04:\n",
    "                count = count + 1\n",
    "                print(el_t)\n",
    "            prev_time = cv2.getTickCount()\n",
    "            \n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    ser.close()\n",
    "    datafile.close()\n",
    "    pipe.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release() \n",
    "    depthwriter.release()\n",
    "    print(count/count_total * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "# config.enable_record_to_file('object_detection.bag')\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "e1 = cv2.getTickCount()\n",
    "\n",
    "\n",
    "count = 0\n",
    "count_total = 0 \n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        e11 = cv2.getTickCount()\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not color_frame or not depth_frame:\n",
    "            continue\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # Apply colormap on depth image (image must be converted to8-bit per pixel first)\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Stack both images horizontally\n",
    "        images = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        # Show images\n",
    "        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RealSense', images)\n",
    "        cv2.waitKey(1)\n",
    "        e2 = cv2.getTickCount()\n",
    "        t = (e2 - e1) / cv2.getTickFrequency()\n",
    "        t1 = (e2 - e11) / cv2.getTickFrequency()\n",
    "\n",
    "        count_total = count_total+ 1\n",
    "        if t1 > 0.033:\n",
    "            count = count + 1\n",
    "        if t > 10: # change it to record what length of video you are interested in\n",
    "            print('Done')\n",
    "            break\n",
    "\n",
    "finally:\n",
    "\n",
    "    # Stop streaming\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(count/count_total*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import serial\n",
    "\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "\n",
    "# Convert to black-to-white color scheme\n",
    "colorizer = rs.colorizer()\n",
    "colorizer.set_option(rs.option.color_scheme, 3)\n",
    "\n",
    "\n",
    "# Filter parameters\n",
    "mag_deci = 4\n",
    "decimation = rs.decimation_filter(mag_deci)\n",
    "threshold = rs.threshold_filter(0.15, 1.6)\n",
    "\n",
    "\n",
    "\n",
    "# Create an object to read from camera \n",
    "video = cv2.VideoCapture(0) \n",
    "   \n",
    "# We need to check if camera is opened previously or not \n",
    "if (video.isOpened() == False):  \n",
    "    print(\"Error reading video file\") \n",
    "    \n",
    "# We need to set resolutions. so, convert them from float to integer. \n",
    "frame_width = int(video.get(3)) \n",
    "frame_height = int(video.get(4)) \n",
    "size = (frame_width, frame_height) \n",
    "\n",
    "\n",
    "# Save Video\n",
    "n_trial = 30\n",
    "depthwriter = cv2.VideoWriter('fcss_leo_depth_test'+str(n_trial)+'.avi',  \n",
    "                         cv2.VideoWriter_fourcc(*'DIVX'), \n",
    "                         30, (int(frame_width/mag_deci), int(frame_height/mag_deci)), 0) \n",
    "\n",
    "\n",
    "\n",
    "# arduino_port = \"COM4\" #serial port of Arduino\n",
    "# baud = 115200 #arduino uno runs at 9600 baud\n",
    "# fileName=\"test_1.csv\" #name of the CSV file generated\n",
    "# ser = serial.Serial(arduino_port, baud)\n",
    "# print(\"Connected to Arduino port:\" + arduino_port)\n",
    "# file = open(fileName, \"a\")\n",
    "# print(\"Created file\")\n",
    "\n",
    "# print_labels = False\n",
    "# line = 0 #start at 0 because our header is 0 (not real data)\n",
    "\n",
    "e1 = cv2.getTickCount()\n",
    "\n",
    "count = 0\n",
    "count_total = 0 \n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        e11 = cv2.getTickCount()\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        if not depth_frame:\n",
    "            continue\n",
    "\n",
    "        # Decimation \n",
    "        depth_frame = decimation.process(depth_frame)\n",
    "\n",
    "        # Thresholding\n",
    "        depth_frame = threshold.process(depth_frame)\n",
    "            \n",
    "        # Apply colormap on depth image (image must be converted to8-bit per pixel first)\n",
    "        depth_colormap = np.asanyarray(colorizer.colorize(depth_frame).get_data())  \n",
    "        \n",
    "        # Show images\n",
    "        cv2.imshow('RealSense', depth_colormap)\n",
    "        cv2.waitKey(1)\n",
    "                \n",
    "#         if print_labels:\n",
    "#             if line==0:\n",
    "#                 print(\"Printing Column Headers\")\n",
    "#             else:\n",
    "#                 print(\"Line \" + str(line) + \": writing...\")\n",
    "#         getData=str(ser.readline())\n",
    "#         data=getData[0:][:-2]\n",
    "#         print(data)\n",
    "\n",
    "#         file = open(fileName, \"a\")\n",
    "#         file.write(data + \"\\\\n\") #write data with a newline\n",
    "#         line = line+1\n",
    "        \n",
    "#         key = cv2.waitKey(1)\n",
    "#         if key & 0xFF == ord('q') or key == 27:\n",
    "#                 cv2.destroyAllWindows()\n",
    "#                 video.release() \n",
    "#                 depthwriter.release()\n",
    "#                 break \n",
    "                \n",
    "        e2 = cv2.getTickCount()\n",
    "        t = (e2 - e1) / cv2.getTickFrequency()\n",
    "        t1 = (e2 - e11) / cv2.getTickFrequency()\n",
    "\n",
    "        count_total = count_total+ 1\n",
    "        if t1 > 0.033:\n",
    "            count = count + 1\n",
    "        if t > 5: # change it to record what length of video you are interested in\n",
    "            print('Done')\n",
    "            break\n",
    "\n",
    "finally:\n",
    "\n",
    "    # Stop streaming\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release() \n",
    "    print(\"Data collection complete!\")\n",
    "    ser.close()\n",
    "    file.close()\n",
    "    print(count/count_total * 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import serial \n",
    "\n",
    "n_trial = 31\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "bag_filename = 'bag_test' + str(n_trial) + '.bag'\n",
    "config.enable_record_to_file(bag_filename)\n",
    "\n",
    "# addr = \"COM4\" \n",
    "# baud = 115200 \n",
    "# ser = serial.Serial(\n",
    "#     port = addr,\\\n",
    "#     baudrate = baud)\n",
    "\n",
    "fcss_filename = \"fcss_leo_load_test\"+str(n_trial)+\".csv\"\n",
    "datafile = open(fcss_filename, 'a')\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "count = 0\n",
    "count_total = 0\n",
    "e1 = cv2.getTickCount()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        e11 = cv2.getTickCount()\n",
    "\n",
    "#         ser_bytes = ser.readline()\n",
    "#         decoded_bytes = (ser_bytes[0:len(ser_bytes)-2].decode(\"utf-8\").split(\",\"))\n",
    "#         write_line = \",\".join(decoded_bytes) + str(\"\\n\")\n",
    "#         datafile.write(write_line)\n",
    "        \n",
    "        e2 = cv2.getTickCount()\n",
    "        t = (e2 - e1) / cv2.getTickFrequency()\n",
    "        t1 = (e2 - e11) / cv2.getTickFrequency()\n",
    "        print(t1)\n",
    "        \n",
    "        if t1 > 0.04:\n",
    "            count = count + 1\n",
    "            \n",
    "        count_total = count_total+ 1\n",
    "        \n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "    ser.close()\n",
    "    datafile.close()\n",
    "    print(count/count_total * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "def do_something():\n",
    "    print(\"sleep\")\n",
    "    time.sleep(1)\n",
    "    print(\"done\")\n",
    "    \n",
    "\n",
    "\n",
    "p1 = multiprocessing.Process(target = do_something)\n",
    "p2 = multiprocessing.Process(target = do_something)\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "\n",
    "finish = time.perf_counter()\n",
    "\n",
    "print(f'Finished in {round(finish - start, 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.perf_counter()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import serial\n",
    "import time \n",
    "\n",
    "# Setup Realsense environment\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_stream(rs.stream.depth, 424, 240, rs.format.z16, 30)\n",
    "cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "\n",
    "# Create an object to read from camera \n",
    "video = cv2.VideoCapture(0) \n",
    "   \n",
    "# We need to check if camera is opened previously or not \n",
    "if (video.isOpened() == False):  \n",
    "    print(\"Error reading video file\") \n",
    "    \n",
    "# We need to set resolutions. so, convert them from float to integer. \n",
    "frame_width = int(video.get(3)) \n",
    "frame_height = int(video.get(4)) \n",
    "   \n",
    "size = (frame_width, frame_height) \n",
    "\n",
    "\n",
    "\n",
    "# Changing colormap to \"black-white\" \n",
    "colorizer = rs.colorizer()\n",
    "colorizer.set_option(rs.option.color_scheme, 3)\n",
    "\n",
    "# Applying filters. Decimation filter for smoothening, Thresholding for removing background. \n",
    "mag_deci = 4\n",
    "decimation = rs.decimation_filter(mag_deci) # smoothen using 4x4 kernel. Mean depth is used. \n",
    "threshold = rs.threshold_filter(0.15, 1.6) # allow only objects from 0.15m ~ 1.6m\n",
    "\n",
    "\n",
    "print(\"type anything to start\")\n",
    "start_test = input()\n",
    "\n",
    "# Start streaming\n",
    "pipe.start(cfg)\n",
    "start_time = cv2.getTickCount()\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        try:\n",
    "            \n",
    "            # Wait for a coherent pair of frames: depth and color\n",
    "            frames = pipe.wait_for_frames()\n",
    "            depth_frame = frames.get_depth_frame()\n",
    "            \n",
    "            color_frame = frames.get_color_frame()\n",
    "            if not depth_frame or not color_frame:\n",
    "                continue\n",
    "            \n",
    "            # Decimation \n",
    "            depth_frame = decimation.process(depth_frame)\n",
    "\n",
    "            # Thresholding\n",
    "            depth_frame = threshold.process(depth_frame)\n",
    "        \n",
    "            # Apply colormap on image (image must be converted to 8-bit per pixel first)\n",
    "            depth_colormap = np.asanyarray(colorizer.colorize(depth_frame).get_data())     \n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "            \n",
    "            key = cv2.waitKey(1)\n",
    "            \n",
    "            # Resize the CV frame to fit the decimated frame\n",
    "            depth_display = cv2.resize(depth_colormap, (int(frame_width/mag_deci), int(frame_height/mag_deci)))\n",
    "            \n",
    "            # Show depth camera \n",
    "            cv2.imshow('Depth', depth_display)\n",
    "\n",
    "            # Press esc or 'q' to close the image window\n",
    "            if key & 0xFF == ord('q') or key == 27:\n",
    "                cv2.destroyAllWindows()\n",
    "                video.release() \n",
    "                break \n",
    "   \n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipe.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "\n",
    "# This is for saving the video files. I highly recommend first saving the files into '.bag' file like this and then \n",
    "# post processing it to get .avi files. This is the recommended way outlined by Intel\n",
    "#config.enable_record_to_file('object_detection.bag')\n",
    "\n",
    "\n",
    "# Create an object to read from camera \n",
    "video = cv2.VideoCapture(0) \n",
    "   \n",
    "# We need to check if camera is opened previously or not \n",
    "if (video.isOpened() == False):  \n",
    "    print(\"Error reading video file\") \n",
    "\n",
    "# We need to set resolutions. so, convert them from float to integer. \n",
    "frame_width = int(video.get(3)) \n",
    "frame_height = int(video.get(4)) \n",
    "\n",
    "    \n",
    "# Changing depth colormap to \"black-white\" \n",
    "colorizer = rs.colorizer()\n",
    "colorizer.set_option(rs.option.color_scheme, 3)\n",
    "\n",
    "# Applying filters. Decimation filter for smoothening, Thresholding for removing background. \n",
    "mag_deci = 4\n",
    "decimation = rs.decimation_filter(mag_deci) # smoothen using 4x4 kernel. Mean depth is used. \n",
    "threshold = rs.threshold_filter(0.15, 1.6) # allow only objects from 0.15m ~ 1.6m\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "\n",
    "e1 = cv2.getTickCount()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "    \n",
    "        # Decimation\n",
    "        depth_frame = decimation.process(depth_frame)\n",
    "\n",
    "        # Thresholding\n",
    "        depth_frame = threshold.process(depth_frame)\n",
    "\n",
    "        # Apply colormap on image (image must be converted to 8-bit per pixel first)\n",
    "        depth_final = np.asanyarray(colorizer.colorize(depth_frame).get_data())     \n",
    "        \n",
    "        # Resize rgb color map\n",
    "        color_final = cv2.resize(color_image, (int(frame_width/mag_deci), int(frame_height/mag_deci)))\n",
    "        \n",
    "        # Stack both images horizontally\n",
    "        images = np.hstack((color_final, depth_final))\n",
    "\n",
    "        # Show images\n",
    "        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RealSense', images)\n",
    "        \n",
    "        e2 = cv2.getTickCount()\n",
    "        \n",
    "        t = (e2 - e1) / cv2.getTickFrequency()\n",
    "        if t>30: # change it to record what length of video you are interested in\n",
    "            print(\"Done!\")\n",
    "            break\n",
    "            \n",
    "        \n",
    "        \n",
    "        # Press 'q' or 'ESC' to close the image window\n",
    "        key = cv2.waitKey(1)\n",
    "        if key & 0xFF == ord('q') or key == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            video.release() \n",
    "            break \n",
    "\n",
    "finally:\n",
    "    # Stop streaming\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
