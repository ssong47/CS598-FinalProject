{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import urllib\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test files\n",
    "n_test = [31]\n",
    "date_test = ['11_24_2020']\n",
    "subj_test = ['leo']\n",
    "subjwgt_test = [67]\n",
    "subjht_test = [174]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Depth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading depth camera\n",
    "def read_depth_camera(dcamera_path, show_video, nw_resize=1, nh_resize=1):\n",
    "    video  = cv2.VideoCapture(dcamera_path)\n",
    "    ret, frame = video.read()\n",
    "    # Get total # of frame count \n",
    "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "    frame_height = int(frame.shape[0])\n",
    "    frame_width = int(frame.shape[1])\n",
    "\n",
    "    \n",
    "    depth_frames = np.empty((frame_count, int(frame_height/nh_resize), int(frame_width/nw_resize)))\n",
    "    depth_frames = np.empty((frame_count, int(frame_height/nh_resize), int(frame_width/nw_resize),3))\n",
    "    count = 0\n",
    "    while (video.isOpened()):\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        if ret == True:\n",
    "            gray_frame = frame\n",
    "            gray_frame = cv2.resize(gray_frame, \\\n",
    "                                    (int(frame_width/nw_resize), int(frame_height/nh_resize)),\\\n",
    "                                    interpolation = cv2.INTER_NEAREST)\n",
    "\n",
    "            depth_frames[count] = gray_frame\n",
    "            if show_video == True:\n",
    "                cv2.imshow(\"Depth\", gray_frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            count = count + 1\n",
    "        else: \n",
    "            break\n",
    "            \n",
    "\n",
    "    video.release()\n",
    "    #cv2.destroyAllWindows()\n",
    "    return depth_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_resize = 2 # for reducing width\n",
    "nh_resize = 2 # for reducing height\n",
    "xtemp = {}\n",
    "show_video = 0\n",
    "\n",
    "for i in range(len(n_test)):\n",
    "    test_str = 'test' + str(n_test[i])\n",
    "    data_dir = os.path.join(r'C:\\Users\\77bis\\Box\\CS598 - Final Project\\Preliminary Data V5','Test_Subject_'+subj_test[i],test_str)\n",
    "\n",
    "    train_dcamera_path = os.path.join(data_dir , 'depth_processed_'+subj_test[i]+'_test'+str(n_test[i])+'.avi')\n",
    "    xtemp[i] = read_depth_camera(train_dcamera_path, show_video, nw_resize=nw_resize, nh_resize=nh_resize).astype('uint8')\n",
    "    \n",
    "\n",
    "tlen=0 # total length of training data set\n",
    "for x in range(len(xtemp)):\n",
    "    tlen+= xtemp[x].shape[0]\n",
    "\n",
    "\n",
    "x_test = np.zeros((tlen,xtemp[0].shape[1],xtemp[0].shape[2],xtemp[0].shape[3]),dtype='uint8') # initialize training set data\n",
    "xrun_cum = 0\n",
    "for i in range (len(xtemp)):\n",
    "    xrun_n = len(xtemp[i])\n",
    "    x_test[xrun_cum:xrun_cum+xrun_n,:,:,:] = xtemp[i][:xrun_n,:,:,:] # compiling all the training data into one large array\n",
    "    xrun_cum += xrun_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Force Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfcss_gt = {}\n",
    "yrun = 0\n",
    "\n",
    "for i in range(len(n_test)):\n",
    "    test_str = 'test' + str(n_test[i])\n",
    "    data_dir = os.path.join(r'C:\\Users\\77bis\\Box\\CS598 - Final Project\\Preliminary Data V5','Test_Subject_'+subj_test[i],test_str)\n",
    "    fcss_data_dir = os.path.join(data_dir , 'fcss_processed_'+subj_test[i]+'_' + test_str + '_' + date_test[i] + '.txt')\n",
    "    \n",
    "    xfcss_gttemp = pd.read_csv(fcss_data_dir)\n",
    "    xfcss_gt[i]=xfcss_gttemp\n",
    "    if i == 0:\n",
    "        xfcss_test = xfcss_gttemp\n",
    "    else:\n",
    "        xfcss_test = pd.concat([xfcss_test,xfcss_gt[i]],axis=0)\n",
    "del xfcss_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Qtm Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output_data(qtm_file_data, theta):\n",
    "    if theta=='x':\n",
    "        qtm_data = pd.read_csv(qtm_file_data, usecols = [\"Lean Left/Right Angle (deg)\"])\n",
    "    if theta=='y':\n",
    "        qtm_data = pd.read_csv(qtm_file_data, usecols = [\"Lean Forward/Backwards Angle (deg)\"])\n",
    "    if theta=='z':\n",
    "        qtm_data = pd.read_csv(qtm_file_data, usecols = [\"Torso Twist Angle (deg)\"])\n",
    "        \n",
    "    \n",
    "    return qtm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gt = {}\n",
    "yrun = 0\n",
    "theta_interest = 'z'\n",
    "for i in range(len(n_test)):\n",
    "    test_str = 'test' + str(n_test[i])\n",
    "    data_dir = os.path.join(r'C:\\Users\\77bis\\Box\\CS598 - Final Project\\Preliminary Data V5','Test_Subject_'+subj_test[i],test_str)\n",
    "    qtm_file_data_dir = os.path.join(data_dir , 'qtm_processed_'+subj_test[i]+'_test' + str(n_test[i]) + '_' + date_test[i] + '.txt')\n",
    "    \n",
    "    y_gt[i] = read_output_data(qtm_file_data_dir,theta_interest).values\n",
    "\n",
    "tlen=0\n",
    "for x in range(len(y_gt)):\n",
    "    tlen+= y_gt[x].shape[0]\n",
    "yrun_cum = 0\n",
    "y_test = np.zeros((tlen,1))\n",
    "for i in range (len(y_gt)):\n",
    "    yrun_n = len(y_gt[i])\n",
    "    y_test[yrun_cum:yrun_cum+yrun_n] = y_gt[i][:]\n",
    "    yrun_cum += yrun_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "sc_X2_path = r'C:\\Users\\77bis\\Desktop\\CS598-FinalProject\\Code\\Leo\\Jupyter\\standard_scaler\\std_scaler_X2.pkl'\n",
    "sc_X2 = joblib.load(sc_X2_path)\n",
    "\n",
    "sc_y_path = r'C:\\Users\\77bis\\Desktop\\CS598-FinalProject\\Code\\Leo\\Jupyter\\standard_scaler\\std_scaler_y.pkl'\n",
    "sc_y = joblib.load(sc_y_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_test/255.\n",
    "X2 = sc_X2.transform(xfcss_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = r'C:\\Users\\77bis\\Desktop\\CS598-FinalProject\\Code\\Leo\\Jupyter\\saved_model\\test_cnn3v23_2'\n",
    "new_model = tf.keras.models.load_model(saved_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = new_model.predict([X,X2])\n",
    "y_pred = sc_y.inverse_transform(y_pred)\n",
    "\n",
    "y_new = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(y_new,'k')\n",
    "plt.plot(y_pred,'r--')\n",
    "plt.title('Prediction of Test')\n",
    "#plt.axis([xmin, xmax, ymin, ymax])\n",
    "plt.legend(labels=['Ground Truth','Prediction'])\n",
    "plt.show()\n",
    "\n",
    "# Squared-root of Squared Error\n",
    "\n",
    "test_error = (y_pred - y_new)\n",
    "print('Average error is {:4.2f} degrees'.format(np.sum(test_error)/test_error.shape[0]))\n",
    "rmse = np.sqrt(test_error**2)\n",
    "print('Root Mean Squared Error is {:4.2f} degrees'.format(np.sum(rmse)/test_error.shape[0]))\n",
    "# Mean absolute error\n",
    "print('Mean Absolute Error is {:4.2f} degrees'.format(np.sum(np.abs(test_error))/test_error.shape[0]))\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(rmse,'.')\n",
    "plt.title('Sqrt(Squared Error) of Test Set')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Error (degrees)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(test_error,bins=100)\n",
    "plt.title('Histogram of Residuals in Test Set')\n",
    "plt.xlabel('Angle')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "#plot scatterplot of data\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_pred,y_new,marker='.',color='black')\n",
    "plt.xlabel('Predicted angle (degrees)')\n",
    "plt.ylabel('Ground truth angle (degrees)')\n",
    "plt.title('Ground truth vs predicted angle')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
