{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, LabelBinarizer\n",
    "from sklearn.svm import SVR\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "from scipy import stats\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fix all seeds for random number generators\n",
    "# # Set seed value\n",
    "# seed_value = 9\n",
    "# import os\n",
    "# os.environ['PYTHONHASHSEED']=str(seed_value)# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "# random.seed(seed_value)# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "# np.random.seed(seed_value)\n",
    "# tf.random.set_seed(seed_value)# 5. Configure a new global `tensorflow` session\n",
    "\n",
    "# #TODO need to initiate session here on tensorflow to fix random seeds\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" #use only cpu\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "\n",
    "mdlname = 'saved_model/cnn3v35'\n",
    "mdl_paramsfn = 'depthforcemodelparam_cnn3v35_pb.pkl'\n",
    "# datapath = \"/home/asilador/CS598/CS598-FinalProject/Preliminary Data V5/Test_Subject_Leo\"\n",
    "datapath = r'C:\\Users\\Alex\\Box\\CS598 - Final Project\\Preliminary Data V5\\Test_Subject_Leo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading depth camera\n",
    "def read_depth_camera(dcamera_path, show_video, nw_resize=1, nh_resize=1):\n",
    "    video  = cv2.VideoCapture(dcamera_path)\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    # Get total # of frame count \n",
    "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "    frame_height = int(frame.shape[0])\n",
    "    frame_width = int(frame.shape[1])\n",
    "\n",
    "    \n",
    "    depth_frames = np.empty((frame_count, int(frame_height/nh_resize), int(frame_width/nw_resize)))\n",
    "    depth_frames = np.empty((frame_count, int(frame_height/nh_resize), int(frame_width/nw_resize),3))\n",
    "    count = 0\n",
    "    while (video.isOpened()):\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        if ret == True:\n",
    "#             gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#             gray_frame = frame/np.maximum(np.max(frame),255) keep as int8 for memory savings\n",
    "            gray_frame = frame\n",
    "            gray_frame = cv2.resize(gray_frame, \\\n",
    "                                    (int(frame_width/nw_resize), int(frame_height/nh_resize)),\\\n",
    "                                    interpolation = cv2.INTER_NEAREST)\n",
    "\n",
    "            depth_frames[count] = gray_frame\n",
    "            if show_video == True:\n",
    "                cv2.imshow(\"Depth\", gray_frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            count = count + 1\n",
    "        else: \n",
    "            break\n",
    "            \n",
    "\n",
    "    video.release()\n",
    "    #cv2.destroyAllWindows()\n",
    "    return depth_frames\n",
    "\n",
    "def read_output_data(qtm_file_data, theta):\n",
    "    if theta=='x':\n",
    "        qtm_data = pd.read_csv(qtm_file_data, usecols = [\"Lean Left/Right Angle (deg)\"])\n",
    "    if theta=='y':\n",
    "        qtm_data = pd.read_csv(qtm_file_data, usecols = [\"Lean Forward/Backwards Angle (deg)\"])\n",
    "    if theta=='z':\n",
    "        qtm_data = pd.read_csv(qtm_file_data, usecols = [\"Torso Twist Angle (deg)\"])\n",
    "        \n",
    "    \n",
    "    return qtm_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_test = (61,62,63) #horrible hack\n",
    "nw_resize = 2\n",
    "nh_resize = 2\n",
    "xtemp = {}\n",
    "show_video = 0\n",
    "subj = ['leo','leo','leo']\n",
    "        \n",
    "for i in range(len(n_test)):\n",
    "    test_str = 'test' + str(n_test[i])\n",
    "    \n",
    "#     data_dir = os.path.join('/home/asilador/CS598/CS598-FinalProject/Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "    data_dir = os.path.join(r'C:\\Users\\Alex\\Box\\CS598 - Final Project\\Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "#     train_dcamera_path = data_dir + '/depth_processed_leo_test'+str(n_test[i])+'.avi'\n",
    "    train_dcamera_path = os.path.join(data_dir , 'depth_processed_'+subj[i]+'_test'+str(n_test[i])+'.avi')\n",
    "    xtemp[i] = read_depth_camera(train_dcamera_path, show_video, nw_resize=nw_resize, nh_resize=nh_resize).astype('uint8')\n",
    "\n",
    "tlen=0\n",
    "for x in range(len(xtemp)):\n",
    "    tlen+= xtemp[x].shape[0]\n",
    "xrun_cum = 0\n",
    "x_train = np.zeros((tlen,xtemp[0].shape[1],xtemp[0].shape[2],xtemp[0].shape[3]),dtype='uint8')\n",
    "for i in range (len(xtemp)):\n",
    "    xrun_n = len(xtemp[i])\n",
    "    x_train[xrun_cum:xrun_cum+xrun_n,:,:,:] = xtemp[i][:xrun_n,:,:,:]\n",
    "    xrun_cum += xrun_n\n",
    "    \n",
    "del xtemp\n",
    "\n",
    "## Read Input Data: FCSS\n",
    "n_test = (61,62,63)\n",
    "date = ('01_11_2021','01_11_2021','01_11_2021')\n",
    "subj = ['leo','leo','leo']\n",
    "subjwgt = [67, 67,67]\n",
    "subjht = [174, 174,174]\n",
    "xfcss_gt = {}\n",
    "yrun = 0\n",
    "for i in range(len(n_test)):\n",
    "    test_str = 'test' + str(n_test[i])\n",
    "#     data_dir = os.path.join('/home/asilador/CS598/CS598-FinalProject/Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "    data_dir = os.path.join(r'C:\\Users\\Alex\\Box\\CS598 - Final Project\\Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "    fcss_data_dir = os.path.join(data_dir , 'fcss_processed_'+subj[i]+'_' + test_str + '_' + date[i] + '.txt')\n",
    "    xfcss_gttemp = pd.read_csv(fcss_data_dir)/subjwgt[i]*subjht[i]**2\n",
    "    xfcss_gt[i]=xfcss_gttemp\n",
    "#     xfcss_gt[i]['weight'] = subjwgt[i]# hacky but will work for now\n",
    "#     xfcss_gt[i]['height'] = subjht[i]# hacky but will work for now\n",
    "    if i==0:\n",
    "        xfcss_train=xfcss_gttemp\n",
    "    else:\n",
    "        xfcss_train = pd.concat([xfcss_train,xfcss_gt[i]],axis=0)\n",
    "del xfcss_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in Input Data \n",
    "# #TODO clean up this section of code for easy access from other computers\n",
    "# n_test = (1,2,24,30,31,32,33,35,1,3)\n",
    "# nw_resize = 2\n",
    "# nh_resize = 2\n",
    "# xtemp = {}\n",
    "# show_video = 0\n",
    "# subj = ['cz','cz','leo','leo','leo','leo','leo','leo','yc','yc']\n",
    "        \n",
    "# for i in range(len(n_test)):\n",
    "#     test_str = 'test' + str(n_test[i])\n",
    "    \n",
    "# #     data_dir = os.path.join('/home/asilador/CS598/CS598-FinalProject/Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "#     data_dir = os.path.join(r'C:\\Users\\Alex\\Box\\CS598 - Final Project\\Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "# #     train_dcamera_path = data_dir + '/depth_processed_leo_test'+str(n_test[i])+'.avi'\n",
    "#     train_dcamera_path = os.path.join(data_dir , 'depth_processed_'+subj[i]+'_test'+str(n_test[i])+'.avi')\n",
    "#     xtemp[i] = read_depth_camera(train_dcamera_path, show_video, nw_resize=nw_resize, nh_resize=nh_resize).astype('uint8')\n",
    "\n",
    "# tlen=0\n",
    "# for x in range(len(xtemp)):\n",
    "#     tlen+= xtemp[x].shape[0]\n",
    "# xrun_cum = 0\n",
    "# x_train = np.zeros((tlen,xtemp[0].shape[1],xtemp[0].shape[2],xtemp[0].shape[3]),dtype='uint8')\n",
    "# for i in range (len(xtemp)):\n",
    "#     xrun_n = len(xtemp[i])\n",
    "#     x_train[xrun_cum:xrun_cum+xrun_n,:,:,:] = xtemp[i][:xrun_n,:,:,:]\n",
    "#     xrun_cum += xrun_n\n",
    "    \n",
    "# del xtemp\n",
    "\n",
    "# ## Read Input Data: FCSS\n",
    "# n_test = (1,2,24,30,31,32,33,35,1,3)\n",
    "# date = ('12_2_2020','12_11_2020','11_15_2020','11_24_2020','11_24_2020','11_25_2020','11_25_2020','11_25_2020','12_2_2020','12_11_2020')\n",
    "# subj = ['cz','cz','leo','leo','leo','leo','leo','leo','yc','yc']\n",
    "# subjwgt = [61,61, 67, 67, 67, 67, 67, 67, 70, 70]\n",
    "# subjht = [180, 180, 174, 174, 174, 174, 174, 174, 170, 170]\n",
    "# xfcss_gt = {}\n",
    "# yrun = 0\n",
    "# for i in range(len(n_test)):\n",
    "#     test_str = 'test' + str(n_test[i])\n",
    "# #     data_dir = os.path.join('/home/asilador/CS598/CS598-FinalProject/Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "#     data_dir = os.path.join(r'C:\\Users\\Alex\\Box\\CS598 - Final Project\\Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "#     fcss_data_dir = os.path.join(data_dir , 'fcss_processed_'+subj[i]+'_' + test_str + '_' + date[i] + '.txt')\n",
    "#     xfcss_gttemp = pd.read_csv(fcss_data_dir)/subjwgt[i]*subjht[i]**2\n",
    "#     xfcss_gt[i]=xfcss_gttemp\n",
    "# #     xfcss_gt[i]['weight'] = subjwgt[i]# hacky but will work for now\n",
    "# #     xfcss_gt[i]['height'] = subjht[i]# hacky but will work for now\n",
    "#     if i==0:\n",
    "#         xfcss_train=xfcss_gttemp\n",
    "#     else:\n",
    "#         xfcss_train = pd.concat([xfcss_train,xfcss_gt[i]],axis=0)\n",
    "# del xfcss_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Alex\\\\Box\\\\CS598 - Final Project\\\\Preliminary Data V5\\\\Test_Subject_leo\\\\test63\\\\depth_processed_leo_test63.avi'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dcamera_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Output Data \n",
    "#TODO clean up this section of code for easy access from other computers\n",
    "n_test = (61,62,63)\n",
    "date = ('01_11_2021','01_11_2021','01_11_2021')\n",
    "subj = ['leo','leo','leo']\n",
    "y_gt = {}\n",
    "yrun = 0\n",
    "theta_interest = 'z'\n",
    "for i in range(len(n_test)):\n",
    "    test_str = 'test' + str(n_test[i])\n",
    "#     data_dir = os.path.join('/home/asilador/CS598/CS598-FinalProject/Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "    data_dir = os.path.join(r'C:\\Users\\Alex\\Box\\CS598 - Final Project\\Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "    qtm_file_data_dir = os.path.join(data_dir , 'qtm_processed_'+subj[i]+'_test' + str(n_test[i]) + '_' + date[i] + '.txt')\n",
    "    y_gt[i] = read_output_data(qtm_file_data_dir,theta_interest).values\n",
    "    \n",
    "tlen=0\n",
    "for x in range(len(y_gt)):\n",
    "    tlen+= y_gt[x].shape[0]\n",
    "yrun_cum = 0\n",
    "y_train = np.zeros((tlen,1))\n",
    "for i in range (len(y_gt)):\n",
    "    yrun_n = len(y_gt[i])\n",
    "    y_train[yrun_cum:yrun_cum+yrun_n] = y_gt[i][:]\n",
    "    yrun_cum += yrun_n\n",
    "del y_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in Output Data \n",
    "# #TODO clean up this section of code for easy access from other computers\n",
    "# n_test = (1,2,24,30,31,32,33,35,1,3)\n",
    "# date = ('12_2_2020','12_11_2020','11_15_2020','11_24_2020','11_24_2020','11_25_2020','11_25_2020','11_25_2020','12_2_2020','12_11_2020')\n",
    "# subj = ['cz','cz','leo','leo','leo','leo','leo','leo','yc','yc']\n",
    "# y_gt = {}\n",
    "# yrun = 0\n",
    "# theta_interest = 'z'\n",
    "# for i in range(len(n_test)):\n",
    "#     test_str = 'test' + str(n_test[i])\n",
    "# #     data_dir = os.path.join('/home/asilador/CS598/CS598-FinalProject/Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "#     data_dir = os.path.join(r'C:\\Users\\Alex\\Box\\CS598 - Final Project\\Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "#     qtm_file_data_dir = os.path.join(data_dir , 'qtm_processed_'+subj[i]+'_test' + str(n_test[i]) + '_' + date[i] + '.txt')\n",
    "#     y_gt[i] = read_output_data(qtm_file_data_dir,theta_interest).values\n",
    "    \n",
    "# tlen=0\n",
    "# for x in range(len(y_gt)):\n",
    "#     tlen+= y_gt[x].shape[0]\n",
    "# yrun_cum = 0\n",
    "# y_train = np.zeros((tlen,1))\n",
    "# for i in range (len(y_gt)):\n",
    "#     yrun_n = len(y_gt[i])\n",
    "#     y_train[yrun_cum:yrun_cum+yrun_n] = y_gt[i][:]\n",
    "#     yrun_cum += yrun_n\n",
    "# del y_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saturate output\n",
    "def saturate(theta, min_val, max_val):\n",
    "    for i in range(len(theta)):\n",
    "        if theta[i] < min_val:\n",
    "            theta[i] = min_val\n",
    "            continue\n",
    "        if theta[i] > max_val:\n",
    "            theta[i] = max_val\n",
    "            continue\n",
    "    return theta\n",
    "            \n",
    "min_val = -50\n",
    "max_val = 50\n",
    "    \n",
    "y_train = saturate(y_train, min_val, max_val)\n",
    "\n",
    "\n",
    "def round_of_rating(number):\n",
    "    \"\"\"Round a number to the closest half integer.\n",
    "    >>> round_of_rating(1.3)\n",
    "    1.5\n",
    "    >>> round_of_rating(2.6)\n",
    "    2.5\n",
    "    >>> round_of_rating(3.0)\n",
    "    3.0\n",
    "    >>> round_of_rating(4.1)\n",
    "    4.0\"\"\"\n",
    "\n",
    "    return np.round(number * 2) / 2\n",
    "\n",
    "min_val = -40\n",
    "max_val = 40\n",
    "\n",
    "y_train = round_of_rating(saturate(y_train, min_val, max_val))\n",
    "\n",
    "r_int = 0.5\n",
    "slist = np.arange(min_val,max_val+r_int,r_int)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alex\\.conda\\envs\\cs598env36\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.23.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "c:\\users\\alex\\.conda\\envs\\cs598env36\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MaxAbsScaler from version 0.23.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "load_prevset = 1# (1): load previously trained Nnet Regression Model (0): Create new Nnet Regression Model to train\n",
    "ranold = 0\n",
    "\n",
    "if load_prevset:\n",
    "    \n",
    "    with open(mdl_paramsfn, 'rb') as file:\n",
    "        mdl_prm = pickle.load(file)\n",
    "    \n",
    "    randata=mdl_prm[0]\n",
    "    lb=mdl_prm[1]\n",
    "    sc_X2 = mdl_prm[2]\n",
    "#     modelhistory=mdl_prm[3]\n",
    "    if ranold:\n",
    "        nsamps = randata['nsamps']\n",
    "        n80p = randata['n80p']\n",
    "        rannums = randata['rannums']\n",
    "        test_set = randata['test_set']\n",
    "    else:\n",
    "        nsamps = x_train.shape[0]\n",
    "        n80p = int(np.floor(nsamps*0.8))\n",
    "        rannums = np.array(random.sample(range(1,nsamps,1), n80p))\n",
    "        s_nfiles = np.arange(nsamps)\n",
    "        test_set = np.setdiff1d(s_nfiles,rannums)\n",
    "else:\n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    sc_X2 = MaxAbsScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont randomize and remove duplicate\n",
    "Testset = x_train[:int(len(x_train)),:,:,:]\n",
    "Testset2 = xfcss_train.values[:int(len(xfcss_train)),:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ylabels = lb.transform(y_train*2)#discretize test set. multiply by 2 to get precision of 0.5 deg\n",
    "Testy =ylabels[:int(len(ylabels)),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainset = x_train[rannums,:]\n",
    "# Trainset2 = xfcss_train.values[rannums,:]\n",
    "# Testset = x_train[test_set,:]\n",
    "# Testset2 = xfcss_train.values[test_set,:]\n",
    "# # Trainy= y_gt[rannums,:]\n",
    "# # Testy = y_gt[test_set,:]\n",
    "# Trainy= y_train[rannums,:]\n",
    "# Testy = y_train[test_set,:]\n",
    "# Xtrainz = Trainset\n",
    "# Xtrainz2 = Trainset2\n",
    "# ytrainz = Trainy\n",
    "# X = Xtrainz\n",
    "# X2 = sc_X2.fit_transform(Xtrainz2)\n",
    "# y = sc_y.fit_transform(ytrainz)\n",
    "# Xvalid = Testset\n",
    "# Xvalid2 = sc_X2.transform(Testset2)\n",
    "# y_valid = Testy\n",
    "# y_valid = sc_y.transform(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mdl(mdlname):\n",
    "#     model=create_model()\n",
    "#     modelname = mdlname\n",
    "#     model.load_weights(modelname)\n",
    "    model = tf.keras.models.load_model(mdlname)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_mdl(mdlname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# import pydot\n",
    "# import pydotplus\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "# keras.utils.vis_utils.pydot = pydot\n",
    "# keras.utils.plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model, to_file='model.png',rankdir='TB',show_shapes=False,expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30144.95462687, 14604.78089552, 12756.58925373,  7302.39044776,\n",
       "        7645.81970149,  3438.81134328])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_X2.max_abs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b66f2672e8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(Testy[4000:6000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "Xtest = Testset/255.\n",
    "Xtest2 = sc_X2.transform(Testset2)\n",
    "y_pred = model.predict([Xtest,Xtest2])\n",
    "\n",
    "y_pred = lb.inverse_transform(y_pred)/2\n",
    "# y_pred_sat = saturate(y_pred, min_val, max_val)\n",
    "y_new = lb.inverse_transform(Testy)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error is 2.95 degrees\n",
      "Root Mean Squared Error is 11.84 degrees\n",
      "Mean Absolute Error is 11.84 degrees\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(y_new,'ko',alpha=0.9)\n",
    "plt.plot(y_pred,'r.',alpha=0.9)\n",
    "plt.title('Prediction of Test')\n",
    "#plt.axis([xmin, xmax, ymin, ymax])\n",
    "plt.legend(labels=['Ground Truth','Prediction'])\n",
    "plt.show()\n",
    "# Squared-root of Squared Error\n",
    "\n",
    "test_error = (y_pred - y_new)\n",
    "print('Average error is {:4.2f} degrees'.format(np.sum(test_error)/test_error.shape[0]))\n",
    "rmse = np.sqrt(test_error**2)\n",
    "print('Root Mean Squared Error is {:4.2f} degrees'.format(np.sum(rmse)/test_error.shape[0]))\n",
    "# Mean absolute error\n",
    "print('Mean Absolute Error is {:4.2f} degrees'.format(np.sum(np.abs(test_error))/test_error.shape[0]))\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(rmse,'.')\n",
    "plt.title('Sqrt(Squared Error) of Test Set')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Error (degrees)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(test_error,bins=100)\n",
    "plt.title('Histogram of Residuals in Test Set')\n",
    "plt.xlabel('Angle')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "#plot scatterplot of data\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_pred,y_new,marker='.',color='black')\n",
    "plt.xlabel('Predicted angle (degrees)')\n",
    "plt.ylabel('Ground truth angle (degrees)')\n",
    "plt.title('Ground truth vs predicted angle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858/858 - 19s - loss: 80.1685 - categorical_accuracy: 0.0174\n"
     ]
    }
   ],
   "source": [
    "loss, cls_std = model.evaluate([Xtest,Xtest2], Testy, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(y_new,'k')\n",
    "plt.plot(y_pred*1.5,'r--')\n",
    "plt.title('Prediction of Test')\n",
    "#plt.axis([xmin, xmax, ymin, ymax])\n",
    "plt.legend(labels=['Ground Truth','Prediction'])\n",
    "plt.show()\n",
    "# Squared-root of Squared Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Discretization of output\n",
    "#assume saturation of +-50\n",
    "#max abs of int8 is 128 but use 126 for all \n",
    "# y_train*126/50\n",
    "newy_train = (np.round(y_train*126/50)).astype('int8')\n",
    "plt.plot(newy_train,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
