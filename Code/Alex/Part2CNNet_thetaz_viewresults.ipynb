{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "from scipy import stats\n",
    "import os\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# #fix all seeds for random number generators\n",
    "# # Set seed value\n",
    "# seed_value = 9\n",
    "# import os\n",
    "# os.environ['PYTHONHASHSEED']=str(seed_value)# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "# random.seed(seed_value)# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "# np.random.seed(seed_value)\n",
    "# tf.random.set_seed(seed_value)# 5. Configure a new global `tensorflow` session\n",
    "\n",
    "# #TODO need to initiate session here on tensorflow to fix random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "\n",
    "mdlname = 'depthmodel_cnn3v12.h5'\n",
    "mdl_paramsfn = 'depthmodelparam_cnn3v12.pkl'\n",
    "# datapath = \"/home/asilador/CS598/CS598-FinalProject/Preliminary Data V5/Test_Subject_Leo\"\n",
    "datapath = r'C:\\Users\\Alex\\Box Sync\\CS598 - Final Project\\Preliminary Data V5\\Test_Subject_Leo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    from tensorflow.keras.layers import Bidirectional, Conv2D, MaxPooling2D, \\\n",
    "    Input, Concatenate, AveragePooling2D, BatchNormalization, Dense, Activation, Dropout, Flatten\n",
    "    from tensorflow.keras.models import Model\n",
    "    inputheight = 60\n",
    "    inputwidth = 80\n",
    "    inputchans = 3\n",
    "    model_start = Input(shape=(inputheight,inputwidth,inputchans))\n",
    "    model_cnn = model_start\n",
    "\n",
    "    dropout_rate = 0.2\n",
    "\n",
    "    model_cnn = Conv2D(filters=16, kernel_size=(3, 3),padding='same')(model_cnn)\n",
    "    model_cnn = Activation('relu')(model_cnn)\n",
    "    model_cnn = AveragePooling2D(pool_size=(2, 2))(model_cnn)\n",
    "\n",
    "    model_cnn = Conv2D(filters=32, kernel_size=(3, 3),padding='same')(model_cnn)\n",
    "    model_cnn = Activation('relu')(model_cnn)\n",
    "    model_cnn = AveragePooling2D(pool_size=(2, 2))(model_cnn)\n",
    "    \n",
    "    model_cnn = Conv2D(filters=64, kernel_size=(3, 3),padding='same')(model_cnn)\n",
    "    model_cnn = Activation('relu')(model_cnn)\n",
    "    model_cnn = AveragePooling2D(pool_size=(2, 2))(model_cnn)\n",
    "\n",
    "    model_cnn = Conv2D(filters=96, kernel_size=(3, 3),padding='same')(model_cnn)\n",
    "    model_cnn = Activation('relu')(model_cnn)\n",
    "    model_cnn = AveragePooling2D(pool_size=(2, 2))(model_cnn)\n",
    "\n",
    "    model_cnn = Flatten()(model_cnn)\n",
    "    model_cnn = Activation('relu')(model_cnn)\n",
    "\n",
    "    model_cnn = Dense(128)(model_cnn)\n",
    "    model_cnn = Activation('relu')(model_cnn)\n",
    "    model_cnn = Dropout(dropout_rate)(model_cnn)\n",
    "\n",
    "    output = Dense(1)(model_cnn)\n",
    "    output = Activation('linear', name='thetaz_out')(output)\n",
    "    model = Model(inputs=model_start,outputs=output)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading depth camera\n",
    "def read_depth_camera(dcamera_path, show_video, nw_resize=1, nh_resize=1):\n",
    "    video  = cv2.VideoCapture(dcamera_path)\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    # Get total # of frame count \n",
    "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "    frame_height = int(frame.shape[0])\n",
    "    frame_width = int(frame.shape[1])\n",
    "\n",
    "    depth_frames = np.empty((frame_count, int(frame_height/nh_resize), int(frame_width/nw_resize)))\n",
    "    depth_frames = np.empty((frame_count, int(frame_height/nh_resize), int(frame_width/nw_resize),3))\n",
    "    count = 0\n",
    "    while (video.isOpened()):\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        if ret:\n",
    "            frame = frame/255\n",
    "            frame = cv2.resize(frame, \\\n",
    "                               (int(frame_width/nw_resize), int(frame_height/nh_resize)),\\\n",
    "                               interpolation = cv2.INTER_NEAREST)\n",
    "\n",
    "            depth_frames[count] = frame\n",
    "            \n",
    "            count = count + 1\n",
    "        else: \n",
    "            break\n",
    "    video.release()\n",
    "    #cv2.destroyAllWindows()\n",
    "    return depth_frames\n",
    "\n",
    "def read_output_data(qtm_file_data, theta):\n",
    "    if theta=='x':\n",
    "        qtm_data = pd.read_csv(qtm_file_data, usecols = [\"Lean Left/Right Angle (deg)\"])\n",
    "    if theta=='y':\n",
    "        qtm_data = pd.read_csv(qtm_file_data, usecols = [\"Lean Forward/Backwards Angle (deg)\"])\n",
    "    if theta=='z':\n",
    "        qtm_data = pd.read_csv(qtm_file_data, usecols = [\"Torso Twist Angle (deg)\"])\n",
    "        \n",
    "    \n",
    "    return qtm_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Input Data \n",
    "#TODO clean up this section of code for easy access from other computers\n",
    "n_test = (24,25,30,31)\n",
    "nw_resize = 2\n",
    "nh_resize = 2\n",
    "xtemp = {}\n",
    "show_video = 0\n",
    "for i in range(len(n_test)):\n",
    "    test_str = 'test' + str(n_test[i])\n",
    "    data_dir = os.path.join(datapath, test_str)\n",
    "    train_dcamera_path = os.path.join(data_dir,'depth_processed_leo_test'+str(n_test[i])+'.avi')\n",
    "    x_train = read_depth_camera(train_dcamera_path, show_video, nw_resize=nw_resize, nh_resize=nh_resize)\n",
    "    xtemp[i]=x_train\n",
    "    \n",
    "\n",
    "tlen = len(xtemp[0])-2 +len(xtemp[1])-3+len(xtemp[2])+len(xtemp[3]) #remove 2 samples from 24 and 3 from 25\n",
    "x_train = np.zeros((tlen,xtemp[0].shape[1],xtemp[0].shape[2],xtemp[0].shape[3]))\n",
    "xrun = len(xtemp[0])-2\n",
    "x_train[:xrun,:,:,:] = xtemp[0][:xrun,:,:,:]\n",
    "xrun1 = xrun + len(xtemp[1])-3\n",
    "x_train[xrun:xrun1,:,:,:]=xtemp[1][:xrun1-xrun,:,:,:]\n",
    "xrun2 = xrun1 + len(xtemp[2])\n",
    "x_train[xrun1:xrun2,:,:,:] = xtemp[2][:xrun2-xrun1,:,:,:]\n",
    "xrun3 = xrun2 + len(xtemp[3])\n",
    "x_train[xrun2:xrun3,:,:,:] = xtemp[3][:xrun3-xrun2,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Alex\\\\Box Sync\\\\CS598 - Final Project\\\\Preliminary Data V5\\\\Test_Subject_Leo\\\\test31\\\\depth_processed_leo_test31.avi'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dcamera_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Output Data \n",
    "#TODO clean up this section of code for easy access from other computers\n",
    "n_test = (24,25,30,31)\n",
    "date = ('11_15_2020','11_19_2020','11_24_2020','11_24_2020')\n",
    "y_gt = {}\n",
    "yrun = 0\n",
    "theta_interest = 'z'\n",
    "for i in range(len(n_test)):\n",
    "    test_str = 'test' + str(n_test[i])\n",
    "    data_dir = os.path.join(datapath, test_str)\n",
    "    qtm_file_data_dir = os.path.join(data_dir, 'qtm_processed_leo_test' + str(n_test[i]) + '_' + date[i] + '.txt')\n",
    "    y_gttemp = read_output_data(qtm_file_data_dir,theta_interest).values\n",
    "    y_gt[i]=y_gttemp\n",
    "    \n",
    "tlen = len(y_gt[0])-2 +len(y_gt[1])-3+len(y_gt[2])+len(y_gt[3]) #remove 2 samples from 24 and 3 from 25\n",
    "y_train = np.zeros((tlen,1))\n",
    "xrun = len(y_gt[0])-2\n",
    "y_train[:xrun] = y_gt[0][:xrun]\n",
    "xrun1 = xrun + len(y_gt[1])-3\n",
    "y_train[xrun:xrun1]=y_gt[1][:xrun1-xrun]\n",
    "xrun2 = xrun1 + len(y_gt[2])\n",
    "y_train[xrun1:xrun2] = y_gt[2][:xrun2-xrun1]\n",
    "xrun3 = xrun2 + len(y_gt[3])\n",
    "y_train[xrun2:xrun3] = y_gt[3][:xrun3-xrun2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44276, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_prevset = 1 # (1): load previously trained Nnet Regression Model (0): Create new Nnet Regression Model to train\n",
    "\n",
    "if load_prevset:\n",
    "    \n",
    "    with open(mdl_paramsfn, 'rb') as file:\n",
    "        mdl_prm = pickle.load(file)\n",
    "    \n",
    "    randata=mdl_prm[0]\n",
    "    sc_y=mdl_prm[1]\n",
    "    modelhistory=mdl_prm[2]\n",
    "    \n",
    "    nsamps = randata['nsamps']\n",
    "    n80p = randata['n80p']\n",
    "    rannums = randata['rannums']\n",
    "    test_set = randata['test_set']\n",
    "else:\n",
    "    nsamps = x_train.shape[0]\n",
    "    n80p = int(np.floor(nsamps*0.8))\n",
    "    rannums = np.array(random.sample(range(1,nsamps,1), n80p))\n",
    "    s_nfiles = np.arange(nsamps)\n",
    "    test_set = np.setdiff1d(s_nfiles,rannums)\n",
    "\n",
    "Trainset = x_train[rannums,:]\n",
    "Testset = x_train[test_set,:]\n",
    "Trainy= y_train[rannums,:]\n",
    "Testy = y_train[test_set,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mdl(mdlname):\n",
    "    model=create_model()\n",
    "    modelname = mdlname\n",
    "    model.load_weights(modelname)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_mdl(mdlname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    \n",
    "    v1 = history['mae']*np.sqrt(sc_y.var_)\n",
    "    v2 = history['val_mae']*np.sqrt(sc_y.var_)\n",
    "    fig1 = plt.figure()\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "    ax1.plot(v1, label='mae')\n",
    "    ax1.plot(v2, label='val_mae')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Error [deg]')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    v3 = history['mse']*sc_y.var_\n",
    "    v4 = history['val_mse']*sc_y.var_\n",
    "    fig2 = plt.figure()\n",
    "    ax2 = fig2.add_subplot(111)\n",
    "    ax2.plot(v3, label='mse')\n",
    "    ax2.plot(v4, label='val_mse')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Error [deg^2]')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_loss(modelhistory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error is 0.09 degrees\n",
      "Root Mean Squared Error is 4.04 degrees\n",
      "Mean Absolute Error is 4.04 degrees\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sanity check with 80% data\n",
    "Xtrain = Trainset\n",
    "y_pred = model.predict(Xtrain)\n",
    "#y_pred = sc_y.inverse_transform(y_pred)\n",
    "y_pred = sc_y.inverse_transform(y_pred)\n",
    "y_new = Trainy\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(y_new,'k')\n",
    "plt.plot(y_pred,'r--')\n",
    "plt.title('Prediction of Training Set (Sanity Check)')\n",
    "#plt.axis([xmin, xmax, ymin, ymax])\n",
    "plt.legend(labels=['Ground Truth','Prediction'])\n",
    "plt.show()\n",
    "# Squared-root of Squared Error\n",
    "\n",
    "test_error = (y_pred - y_new)\n",
    "print('Average error is {:4.2f} degrees'.format(np.sum(test_error)/test_error.shape[0]))\n",
    "rmse = np.sqrt(test_error**2)\n",
    "print('Root Mean Squared Error is {:4.2f} degrees'.format(np.sum(rmse)/test_error.shape[0]))\n",
    "# Mean absolute error\n",
    "print('Mean Absolute Error is {:4.2f} degrees'.format(np.sum(np.abs(test_error))/test_error.shape[0]))\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(rmse,'.')\n",
    "plt.title('Sqrt(Squared Error) of Training Set (Sanity Check)')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Error (degrees)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(test_error,bins=100)\n",
    "plt.title('Histogram of Residuals in Training Set')\n",
    "plt.xlabel('Angle')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "#plot scatterplot of data\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_pred,y_new,marker='.',color='black')\n",
    "plt.xlabel('Predicted angle (degrees)')\n",
    "plt.ylabel('Ground truth angle (degrees)')\n",
    "plt.title('Ground truth vs predicted angle of Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error is -0.19 degrees\n",
      "Root Mean Squared Error is 5.77 degrees\n",
      "Mean Absolute Error is 5.77 degrees\n"
     ]
    }
   ],
   "source": [
    "# Redo test set\n",
    "Xtest = Testset\n",
    "y_pred = model.predict(Xtest)\n",
    "#y_pred = sc_y.inverse_transform(y_pred)\n",
    "y_pred = sc_y.inverse_transform(y_pred)\n",
    "y_new = Testy\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(y_new,'k')\n",
    "plt.plot(y_pred,'r--')\n",
    "plt.title('Prediction of Test')\n",
    "#plt.axis([xmin, xmax, ymin, ymax])\n",
    "plt.legend(labels=['Ground Truth','Prediction'])\n",
    "plt.show()\n",
    "\n",
    "# Squared-root of Squared Error\n",
    "\n",
    "test_error = (y_pred - y_new)\n",
    "print('Average error is {:4.2f} degrees'.format(np.sum(test_error)/test_error.shape[0]))\n",
    "rmse = np.sqrt(test_error**2)\n",
    "print('Root Mean Squared Error is {:4.2f} degrees'.format(np.sum(rmse)/test_error.shape[0]))\n",
    "# Mean absolute error\n",
    "print('Mean Absolute Error is {:4.2f} degrees'.format(np.sum(np.abs(test_error))/test_error.shape[0]))\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(rmse,'.')\n",
    "plt.title('Sqrt(Squared Error) of Test Set')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Error (degrees)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(test_error,bins=100)\n",
    "plt.title('Histogram of Residuals in Test Set')\n",
    "plt.xlabel('Angle')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "#plot scatterplot of data\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_pred,y_new,marker='.',color='black')\n",
    "plt.xlabel('Predicted angle (degrees)')\n",
    "plt.ylabel('Ground truth angle (degrees)')\n",
    "plt.title('Ground truth vs predicted angle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
