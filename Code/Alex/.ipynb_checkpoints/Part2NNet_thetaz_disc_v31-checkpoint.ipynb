{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler,MaxAbsScaler, LabelBinarizer, OneHotEncoder\n",
    "from sklearn.svm import SVR\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from scipy import stats\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tensorboard stuff\n",
    "# %load_ext tensorboard\n",
    "# import datetime\n",
    "\n",
    "# !rm -rf ./logs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" #use only cpu\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Depth Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading depth camera\n",
    "def read_depth_camera(dcamera_path, show_video, nw_resize=1, nh_resize=1):\n",
    "    video  = cv2.VideoCapture(dcamera_path)\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    # Get total # of frame count \n",
    "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "    frame_height = int(frame.shape[0])\n",
    "    frame_width = int(frame.shape[1])\n",
    "\n",
    "    \n",
    "    depth_frames = np.empty((frame_count, int(frame_height/nh_resize), int(frame_width/nw_resize)))\n",
    "    depth_frames = np.empty((frame_count, int(frame_height/nh_resize), int(frame_width/nw_resize),3))\n",
    "    count = 0\n",
    "    while (video.isOpened()):\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        if ret == True:\n",
    "#             gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#             gray_frame = frame/np.maximum(np.max(frame),255) keep as int8 for memory savings\n",
    "            gray_frame = frame\n",
    "            gray_frame = cv2.resize(gray_frame, \\\n",
    "                                    (int(frame_width/nw_resize), int(frame_height/nh_resize)),\\\n",
    "                                    interpolation = cv2.INTER_NEAREST)\n",
    "\n",
    "            depth_frames[count] = gray_frame\n",
    "            if show_video == True:\n",
    "                cv2.imshow(\"Depth\", gray_frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            count = count + 1\n",
    "        else: \n",
    "            break\n",
    "            \n",
    "\n",
    "    video.release()\n",
    "    #cv2.destroyAllWindows()\n",
    "    return depth_frames\n",
    "\n",
    "def read_output_data(qtm_file_data, theta):\n",
    "    if theta=='x':\n",
    "        qtm_data = pd.read_csv(qtm_file_data, usecols = [\"Lean Left/Right Angle (deg)\"])\n",
    "    if theta=='y':\n",
    "        qtm_data = pd.read_csv(qtm_file_data, usecols = [\"Lean Forward/Backwards Angle (deg)\"])\n",
    "    if theta=='z':\n",
    "        qtm_data = pd.read_csv(qtm_file_data, usecols = [\"Torso Twist Angle (deg)\"])\n",
    "        \n",
    "    \n",
    "    return qtm_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_video(read_frames):\n",
    "\n",
    "    for i in range(len(read_frames)):\n",
    "        # Capture frame-by-frame\n",
    "        frame = read_frames[i]\n",
    "\n",
    "        # Display the resulting frame\n",
    "        plt.imshow(frame)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frame(read_frames, frame_range):\n",
    "      # Capture frame-by-frame\n",
    "\n",
    "    # Display the resulting frame\n",
    "    for i in frame_range:\n",
    "        fig = plt.figure(figsize=(6,6))        \n",
    "        a = plt.imshow(read_frames[i])\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix this to concatenate everything\n",
    "# n_test = 24\n",
    "# date = '11_15_2020'\n",
    "# test_str = '/test' + str(n_test)\n",
    "# #data_dir = r\"C:\\Users\\77bis\\Box\\CS598 - Final Project\\Preliminary Data V4\\Test_Subject_Leo\" + test_str\n",
    "# data_dir = \"/home/asilador/CS598/CS598-FinalProject/Preliminary Data V4/Test_Subject_Leo\" + test_str\n",
    "# train_dcamera_path = data_dir + '/depth_processed_leo_test'+str(n_test)+'.avi'\n",
    "# show_video = 0\n",
    "# n_resize = 1\n",
    "# x_train = read_depth_camera(train_dcamera_path, show_video, nw_resize=2, nh_resize=3)\n",
    "\n",
    "n_test = (24,30,31,32,33,35)\n",
    "nw_resize = 2\n",
    "nh_resize = 2\n",
    "xtemp = {}\n",
    "show_video = 0\n",
    "\n",
    "subj = ['leo','leo','leo','leo','leo','leo']\n",
    "        \n",
    "for i in range(len(n_test)):\n",
    "    test_str = 'test' + str(n_test[i])\n",
    "    \n",
    "#     data_dir = os.path.join('/home/asilador/CS598/CS598-FinalProject/Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "    data_dir = os.path.join(r'C:\\Users\\Alex\\Box\\CS598 - Final Project\\Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "#     train_dcamera_path = data_dir + '/depth_processed_leo_test'+str(n_test[i])+'.avi'\n",
    "    train_dcamera_path = os.path.join(data_dir , 'depth_processed_'+subj[i]+'_test'+str(n_test[i])+'.avi')\n",
    "    xtemp[i] = read_depth_camera(train_dcamera_path, show_video, nw_resize=nw_resize, nh_resize=nh_resize).astype('uint8')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlen=0\n",
    "for x in range(len(xtemp)):\n",
    "    tlen+= xtemp[x].shape[0]\n",
    "xrun_cum = 0\n",
    "x_train = np.zeros((tlen,xtemp[0].shape[1],xtemp[0].shape[2],xtemp[0].shape[3]),dtype='uint8')\n",
    "for i in range (len(xtemp)):\n",
    "    xrun_n = len(xtemp[i])\n",
    "    x_train[xrun_cum:xrun_cum+xrun_n,:,:,:] = xtemp[i][:xrun_n,:,:,:]\n",
    "    xrun_cum += xrun_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77849, 60, 80, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "del xtemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read fcss data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_test = (24,30,31,32,33,35)\n",
    "date = ('11_15_2020','11_24_2020','11_24_2020','11_25_2020','11_25_2020','11_25_2020')\n",
    "subj = ['leo','leo','leo','leo','leo','leo']\n",
    "subjwgt = [67, 67, 67, 67, 67, 67]\n",
    "subjht = [174, 174, 174, 174, 174, 174]\n",
    "xfcss_gt = {}\n",
    "yrun = 0\n",
    "for i in range(len(n_test)):\n",
    "    test_str = 'test' + str(n_test[i])\n",
    "#     data_dir = os.path.join('/home/asilador/CS598/CS598-FinalProject/Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "    data_dir = os.path.join(r'C:\\Users\\Alex\\Box\\CS598 - Final Project\\Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "    fcss_data_dir = os.path.join(data_dir , 'fcss_processed_'+subj[i]+'_' + test_str + '_' + date[i] + '.txt')\n",
    "    xfcss_gttemp = pd.read_csv(fcss_data_dir)/subjwgt[i]*subjht[i]**2\n",
    "    xfcss_gt[i]=xfcss_gttemp\n",
    "#     xfcss_gt[i]['weight'] = subjwgt[i]# hacky but will work for now\n",
    "#     xfcss_gt[i]['height'] = subjht[i]# hacky but will work for now\n",
    "    if i==0:\n",
    "        xfcss_train=xfcss_gttemp\n",
    "    else:\n",
    "        xfcss_train = pd.concat([xfcss_train,xfcss_gt[i]],axis=0)\n",
    "del xfcss_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Output Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_test = (24,30,31,32,33,35)\n",
    "date = ('11_15_2020','11_24_2020','11_24_2020','11_25_2020','11_25_2020','11_25_2020')\n",
    "subj = ['leo','leo','leo','leo','leo','leo']\n",
    "y_gt = {}\n",
    "yrun = 0\n",
    "theta_interest = 'z'\n",
    "for i in range(len(n_test)):\n",
    "    test_str = 'test' + str(n_test[i])\n",
    "#     data_dir = os.path.join('/home/asilador/CS598/CS598-FinalProject/Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "    data_dir = os.path.join(r'C:\\Users\\Alex\\Box\\CS598 - Final Project\\Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "    qtm_file_data_dir = os.path.join(data_dir , 'qtm_processed_'+subj[i]+'_test' + str(n_test[i]) + '_' + date[i] + '.txt')\n",
    "    y_gt[i] = read_output_data(qtm_file_data_dir,theta_interest).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlen=0\n",
    "for x in range(len(y_gt)):\n",
    "    tlen+= y_gt[x].shape[0]\n",
    "yrun_cum = 0\n",
    "y_train = np.zeros((tlen,1))\n",
    "for i in range (len(y_gt)):\n",
    "    yrun_n = len(y_gt[i])\n",
    "    y_train[yrun_cum:yrun_cum+yrun_n] = y_gt[i][:]\n",
    "    yrun_cum += yrun_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saturate output\n",
    "def saturate(theta, min_val, max_val):\n",
    "    for i in range(len(theta)):\n",
    "        if theta[i] < min_val:\n",
    "            theta[i] = min_val\n",
    "            continue\n",
    "        if theta[i] > max_val:\n",
    "            theta[i] = max_val\n",
    "            continue\n",
    "    return theta\n",
    "\n",
    "def round_of_rating(number):\n",
    "    \"\"\"Round a number to the closest half integer.\n",
    "    >>> round_of_rating(1.3)\n",
    "    1.5\n",
    "    >>> round_of_rating(2.6)\n",
    "    2.5\n",
    "    >>> round_of_rating(3.0)\n",
    "    3.0\n",
    "    >>> round_of_rating(4.1)\n",
    "    4.0\"\"\"\n",
    "\n",
    "    return np.round(number * 2) / 2\n",
    "\n",
    "min_val = -40\n",
    "max_val = 40\n",
    "    \n",
    "y_train = round_of_rating(saturate(y_train, min_val, max_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_int = 0.5\n",
    "slist = np.arange(min_val,max_val+r_int,r_int)*2 #multiply by 2 to allow labelbinarizer to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.fit(slist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylabels = lb.transform(y_train*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77849, 60, 80, 3)\n",
      "(77849, 6)\n",
      "(77849, 161)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(xfcss_train.shape)\n",
    "print(ylabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamps = x_train.shape[0]\n",
    "n80p = int(np.floor(nsamps*0.8))\n",
    "rannums = np.array(random.sample(range(1,nsamps,1), n80p))\n",
    "s_nfiles = np.arange(nsamps)\n",
    "test_set = np.setdiff1d(s_nfiles,rannums)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainset = x_train[rannums,:]\n",
    "Trainset2 = xfcss_train.values[rannums,:]\n",
    "Testset = x_train[test_set,:]\n",
    "Testset2 = xfcss_train.values[test_set,:]\n",
    "# Trainy= y_gt[rannums,:]\n",
    "# Testy = y_gt[test_set,:]\n",
    "Trainy= y_train[rannums,:]\n",
    "Testy = y_train[test_set,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc_X2 = StandardScaler()\n",
    "# sc_y = StandardScaler()\n",
    "\n",
    "sc_X2 = MaxAbsScaler()\n",
    "#sc_y = MaxAbsScaler() #not needed at this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrainz = Trainset\n",
    "Xtrainz2 = Trainset2\n",
    "ytrainz = Trainy\n",
    "X = Xtrainz\n",
    "X2 = sc_X2.fit_transform(Xtrainz2)\n",
    "y = lb.transform(ytrainz*2) #scale output by 2 to allow intervals of 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make validation data available to model.fit\n",
    "Xvalid = Testset\n",
    "Xvalid2 = sc_X2.transform(Testset2)\n",
    "y_valid = Testy\n",
    "y_valid = lb.transform(y_valid*2) #scale output by 2 to allow intervals of 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear up some used variables\n",
    "del Trainset\n",
    "del Trainset2\n",
    "del Testset\n",
    "del Testset2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regress using Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Neural Netowrk\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional, Conv2D, MaxPooling2D, Input, concatenate, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Reshape, Permute, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "# dropout_rate = 0.2\n",
    "\n",
    "model_start = Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))\n",
    "model_start2 = Input(shape=(xfcss_train.shape[1],))\n",
    "model_cnn = model_start\n",
    "model_perc = model_start2\n",
    "\n",
    "model_cnn = Conv2D(filters=8, kernel_size=(3, 3),padding='same',use_bias=False)(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = Conv2D(filters=8, kernel_size=(3, 3),padding='same',use_bias=False)(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = AveragePooling2D(pool_size=(2, 2))(model_cnn)\n",
    "\n",
    "model_perc = Dense(100)(model_perc)\n",
    "model_perc = Activation('relu')(model_perc)\n",
    "\n",
    "model_cnn = Conv2D(filters=16, kernel_size=(3, 3),padding='same',use_bias=False)(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = Conv2D(filters=16, kernel_size=(3, 3),padding='same',use_bias=False)(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = AveragePooling2D(pool_size=(2, 2))(model_cnn)\n",
    "\n",
    "model_perc = Dense(100)(model_perc)\n",
    "model_perc = Activation('relu')(model_perc)\n",
    "\n",
    "model_cnn = Conv2D(filters=32, kernel_size=(3, 3),padding='same',use_bias=False)(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = Conv2D(filters=32, kernel_size=(3, 3),padding='same',use_bias=False)(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = AveragePooling2D(pool_size=(2, 2))(model_cnn)\n",
    "\n",
    "model_cnn = Conv2D(filters=64, kernel_size=(3, 3),padding='same',use_bias=False)(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = Conv2D(filters=64, kernel_size=(3, 3),padding='same',use_bias=False)(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = AveragePooling2D(pool_size=(2, 2))(model_cnn)\n",
    "\n",
    "model_cnn = Flatten()(model_cnn)\n",
    "# model_perc = Flatten()(model_perc)\n",
    "# model_cnn = Activation('relu')(model_cnn)\n",
    "\n",
    "model_cnn = Dense(100)(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "# model_cnn = Dropout(dropout_rate)(model_cnn)\n",
    "\n",
    "model_comb = concatenate([model_cnn,model_perc],axis=-1)\n",
    "\n",
    "#model_comb = Dense(128)(model_comb)\n",
    "# model_comb = BatchNormalization()(model_comb)\n",
    "#model_comb = Activation('relu')(model_comb)\n",
    "# model_comb = Dropout(dropout_rate)(model_comb)\n",
    "\n",
    "output = Dense(y.shape[1])(model_comb)\n",
    "output = Activation('relu', name='thetaz_out')(output)\n",
    "model = Model(inputs=[model_start,model_start2],outputs=output)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50,restore_best_weights=True) #Moving to 1000 patience. \n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50,restore_best_weights=True) #Moving to 1000 patience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 60, 80, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 60, 80, 8)    216         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 60, 80, 8)    32          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 60, 80, 8)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 60, 80, 8)    576         activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 60, 80, 8)    32          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 60, 80, 8)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 30, 40, 8)    0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 30, 40, 16)   1152        average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 30, 40, 16)   64          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 30, 40, 16)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 30, 40, 16)   2304        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 30, 40, 16)   64          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 30, 40, 16)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 15, 20, 16)   0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 15, 20, 32)   4608        average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 15, 20, 32)   128         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 15, 20, 32)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 15, 20, 32)   9216        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 15, 20, 32)   128         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 15, 20, 32)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 7, 10, 32)    0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 10, 64)    18432       average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 10, 64)    256         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 10, 64)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 10, 64)    36864       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 10, 64)    256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 10, 64)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 3, 5, 64)     0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 100)          700         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 960)          0           average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 100)          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 100)          96100       flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 100)          10100       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 100)          0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 100)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 200)          0           activation_43[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 161)          32361       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "thetaz_out (Activation)         (None, 161)          0           dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 213,589\n",
      "Trainable params: 213,109\n",
      "Non-trainable params: 480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "with tf.device('/device:CPU:0'):\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        layers.experimental.preprocessing.RandomRotation(0.05),\n",
    "        layers.experimental.preprocessing.RandomZoom(height_factor = (-0.2,0.2),\n",
    "                                               width_factor = (-0.2,0.2), \n",
    "                                               fill_mode = 'constant'),\n",
    "        ], \n",
    "        name='data_augmentation')\n",
    "\n",
    "# create data generator\n",
    "def get_generator_cyclic(features1, features2, labels, batch_size=256):\n",
    "    while True:\n",
    "        for n in range(int(len(features1)/batch_size)):\n",
    "            X = features1[n*batch_size: (n+1)*batch_size]\n",
    "            with tf.device('/device:CPU:0'): #to prevent hogging limited gpu space\n",
    "                augmented_images = data_augmentation(X)\n",
    "                Xnew =  tf.cast(augmented_images,tf.float64)/255\n",
    "            yield [Xnew, features2[n*batch_size: (n+1)*batch_size], labels[n*batch_size: (n+1)*batch_size]]\n",
    "        permuted = np.random.permutation(len(features1))\n",
    "        features1 = features1[permuted]\n",
    "        features2 = features2[permuted]\n",
    "        labels = labels[permuted]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if e%300 < 200: #very hacky\n",
    "        return 0.001\n",
    "    else:\n",
    "        if e%25==0 & batches==0:\n",
    "            return lr * 0.99\n",
    "        else:\n",
    "            return lr\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Time:  01:47:53\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-137da5c00f8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#         Xtest_1, Xtest_2, ytest_1 =next(test_generator)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#         model.fit([Xtrain_1, Xtrain_2], ytrain_1, callbacks = [callback],validation_data = ([Xtest_1,Xtest_2], ytest_1),batch_size=batch_size,verbose = 0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mXtrain_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtrain_2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "batch_size = 128\n",
    "batch_mult = 4\n",
    "readin = int(batch_size*batch_mult)\n",
    "#epochs = int(1200)\n",
    "epochs = int(5)\n",
    "mae_best = 10000\n",
    "training_generator = get_generator_cyclic(X,X2,y,readin)\n",
    "# test_generator = get_generator_cyclic(Xvalid,Xvalid2,y_valid,readin)\n",
    "for e in range(epochs):\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print('Epoch', e,'Time: ', current_time)\n",
    "    batches = 0\n",
    "    while batches< len(X)/readin:\n",
    "        Xtrain_1, Xtrain_2, ytrain_1 = next(training_generator)\n",
    "#         Xtest_1, Xtest_2, ytest_1 =next(test_generator)\n",
    "#         model.fit([Xtrain_1, Xtrain_2], ytrain_1, callbacks = [callback],validation_data = ([Xtest_1,Xtest_2], ytest_1),batch_size=batch_size,verbose = 0)\n",
    "        model.fit([Xtrain_1, Xtrain_2], ytrain_1, callbacks = [callback],batch_size=batch_size,verbose = 0)\n",
    "        batches += 1\n",
    "    \n",
    "    #calculates and prints the running validation once per epoch\n",
    "    losssc, msesc, maesc = model.evaluate([Xvalid/255.,Xvalid2],y_valid,verbose=0)\n",
    "    mae = sc_y.inverse_transform(np.array(maesc).reshape(1,-1))[0][0]\n",
    "    if mae<mae_best:\n",
    "        modelbest = model\n",
    "        mae_best = mae\n",
    "    print('Mean absolute error at {:4.0f} is: {:4.2f}'.format(e,mae))\n",
    "modelbest.save('cnn3v31')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_notebookparams = 1\n",
    "if save_notebookparams:\n",
    "    pkl_filename = \"depthforcemodelparam_cnn3v31_pb.pkl\"\n",
    "    randata = {}\n",
    "    randata['nsamps']=nsamps\n",
    "    randata['n80p']=n80p\n",
    "    randata['rannums']=rannums\n",
    "    randata['test_set']=test_set\n",
    "#     modelhistory = history.history\n",
    "    \n",
    "    \n",
    "    with open(pkl_filename, 'wb') as file:\n",
    "#         pickle.dump([randata,sc_y,sc_X2,modelhistory], file)\n",
    "          pickle.dump([randata,lb,sc_X2], file)\n",
    "        \n",
    "#     !mkdir -p saved_model\n",
    "#     model.save('saved_model/cnn3v22')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
