{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from scipy import stats\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tensorboard stuff\n",
    "# %load_ext tensorboard\n",
    "# import datetime\n",
    "\n",
    "# !rm -rf ./logs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix all seeds for random number generators\n",
    "# Set seed value\n",
    "seed_value = 9\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "random.seed(seed_value)# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)# 5. Configure a new global `tensorflow` session\n",
    "\n",
    "# TODO need to add session thing for tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Depth Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading depth camera\n",
    "def read_depth_camera(dcamera_path, show_video, nw_resize=1, nh_resize=1):\n",
    "    video  = cv2.VideoCapture(dcamera_path)\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    # Get total # of frame count \n",
    "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "    frame_height = int(frame.shape[0])\n",
    "    frame_width = int(frame.shape[1])\n",
    "\n",
    "    \n",
    "    depth_frames = np.empty((frame_count, int(frame_height/nh_resize), int(frame_width/nw_resize)))\n",
    "    depth_frames = np.empty((frame_count, int(frame_height/nh_resize), int(frame_width/nw_resize),3))\n",
    "    count = 0\n",
    "    while (video.isOpened()):\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        if ret == True:\n",
    "#             gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#             gray_frame = frame/np.maximum(np.max(frame),255) keep as int8 for memory savings\n",
    "            gray_frame = frame\n",
    "            gray_frame = cv2.resize(gray_frame, \\\n",
    "                                    (int(frame_width/nw_resize), int(frame_height/nh_resize)),\\\n",
    "                                    interpolation = cv2.INTER_NEAREST)\n",
    "\n",
    "            depth_frames[count] = gray_frame\n",
    "            if show_video == True:\n",
    "                cv2.imshow(\"Depth\", gray_frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            count = count + 1\n",
    "        else: \n",
    "            break\n",
    "            \n",
    "\n",
    "    video.release()\n",
    "    #cv2.destroyAllWindows()\n",
    "    return depth_frames\n",
    "\n",
    "def read_output_data(qtm_file_data, theta):\n",
    "    if theta=='x':\n",
    "        qtm_data = pd.read_csv(qtm_file_data, usecols = [\"Lean Left/Right Angle (deg)\"])\n",
    "    if theta=='y':\n",
    "        qtm_data = pd.read_csv(qtm_file_data, usecols = [\"Lean Forward/Backwards Angle (deg)\"])\n",
    "    if theta=='z':\n",
    "        qtm_data = pd.read_csv(qtm_file_data, usecols = [\"Torso Twist Angle (deg)\"])\n",
    "        \n",
    "    \n",
    "    return qtm_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_video(read_frames):\n",
    "\n",
    "    for i in range(len(read_frames)):\n",
    "        # Capture frame-by-frame\n",
    "        frame = read_frames[i]\n",
    "\n",
    "        # Display the resulting frame\n",
    "        plt.imshow(frame)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frame(read_frames, frame_range):\n",
    "      # Capture frame-by-frame\n",
    "\n",
    "    # Display the resulting frame\n",
    "    for i in frame_range:\n",
    "        fig = plt.figure(figsize=(6,6))        \n",
    "        a = plt.imshow(read_frames[i])\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix this to concatenate everything\n",
    "# n_test = 24\n",
    "# date = '11_15_2020'\n",
    "# test_str = '/test' + str(n_test)\n",
    "# #data_dir = r\"C:\\Users\\77bis\\Box\\CS598 - Final Project\\Preliminary Data V4\\Test_Subject_Leo\" + test_str\n",
    "# data_dir = \"/home/asilador/CS598/CS598-FinalProject/Preliminary Data V4/Test_Subject_Leo\" + test_str\n",
    "# train_dcamera_path = data_dir + '/depth_processed_leo_test'+str(n_test)+'.avi'\n",
    "# show_video = 0\n",
    "# n_resize = 1\n",
    "# x_train = read_depth_camera(train_dcamera_path, show_video, nw_resize=2, nh_resize=3)\n",
    "\n",
    "n_test = (1,2,24,30,31,32,33,35,1,3)\n",
    "nw_resize = 2\n",
    "nh_resize = 2\n",
    "xtemp = {}\n",
    "show_video = 0\n",
    "\n",
    "subj = ['cz','cz','leo','leo','leo','leo','leo','leo','yc','yc']\n",
    "        \n",
    "for i in range(len(n_test)):\n",
    "    test_str = 'test' + str(n_test[i])\n",
    "    \n",
    "#     data_dir = os.path.join('/home/asilador/CS598/CS598-FinalProject/Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "    data_dir = os.path.join(r'C:\\Users\\Alex\\Box\\CS598 - Final Project\\Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "#     train_dcamera_path = data_dir + '/depth_processed_leo_test'+str(n_test[i])+'.avi'\n",
    "    train_dcamera_path = os.path.join(data_dir , 'depth_processed_'+subj[i]+'_test'+str(n_test[i])+'.avi')\n",
    "    xtemp[i] = read_depth_camera(train_dcamera_path, show_video, nw_resize=nw_resize, nh_resize=nh_resize).astype('uint8')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlen=0\n",
    "for x in range(len(xtemp)):\n",
    "    tlen+= xtemp[x].shape[0]\n",
    "xrun_cum = 0\n",
    "x_train = np.zeros((tlen,xtemp[0].shape[1],xtemp[0].shape[2],xtemp[0].shape[3]),dtype='uint8')\n",
    "for i in range (len(xtemp)):\n",
    "    xrun_n = len(xtemp[i])\n",
    "    x_train[xrun_cum:xrun_cum+xrun_n,:,:,:] = xtemp[i][:xrun_n,:,:,:]\n",
    "    xrun_cum += xrun_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153421, 60, 80, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2222caab2b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[153418])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153421, 60, 80, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "del xtemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read fcss data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_test = (1,2,24,30,31,32,33,35,1,3)\n",
    "date = ('12_2_2020','12_11_2020','11_15_2020','11_24_2020','11_24_2020','11_25_2020','11_25_2020','11_25_2020','12_2_2020','12_11_2020')\n",
    "subj = ['cz','cz','leo','leo','leo','leo','leo','leo','yc','yc']\n",
    "subjwgt = [61,61, 67, 67, 67, 67, 67, 67, 70, 70]\n",
    "subjht = [180, 180, 174, 174, 174, 174, 174, 174, 170, 170]\n",
    "xfcss_gt = {}\n",
    "yrun = 0\n",
    "for i in range(len(n_test)):\n",
    "    test_str = 'test' + str(n_test[i])\n",
    "#     data_dir = os.path.join('/home/asilador/CS598/CS598-FinalProject/Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "    data_dir = os.path.join(r'C:\\Users\\Alex\\Box\\CS598 - Final Project\\Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "    fcss_data_dir = os.path.join(data_dir , 'fcss_processed_'+subj[i]+'_' + test_str + '_' + date[i] + '.txt')\n",
    "    xfcss_gttemp = pd.read_csv(fcss_data_dir)/subjwgt[i]\n",
    "    xfcss_gt[i]=xfcss_gttemp\n",
    "#     xfcss_gt[i]['weight'] = subjwgt[i]# hacky but will work for now\n",
    "#     xfcss_gt[i]['height'] = subjht[i]# hacky but will work for now\n",
    "    if i==0:\n",
    "        xfcss_train=xfcss_gttemp\n",
    "    else:\n",
    "        xfcss_train = pd.concat([xfcss_train,xfcss_gt[i]],axis=0)\n",
    "del xfcss_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fz bottom (kg)</th>\n",
       "      <th>Fz left (kg)</th>\n",
       "      <th>Fz right (kg)</th>\n",
       "      <th>Fx left (kg)</th>\n",
       "      <th>Fx right (kg)</th>\n",
       "      <th>Fy (kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.828197</td>\n",
       "      <td>-0.189016</td>\n",
       "      <td>-0.198197</td>\n",
       "      <td>0.150164</td>\n",
       "      <td>0.196066</td>\n",
       "      <td>0.003934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.824918</td>\n",
       "      <td>-0.189836</td>\n",
       "      <td>-0.200328</td>\n",
       "      <td>0.150164</td>\n",
       "      <td>0.194918</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.822623</td>\n",
       "      <td>-0.191148</td>\n",
       "      <td>-0.202787</td>\n",
       "      <td>0.149836</td>\n",
       "      <td>0.194262</td>\n",
       "      <td>0.002623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.821148</td>\n",
       "      <td>-0.192787</td>\n",
       "      <td>-0.204590</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.194918</td>\n",
       "      <td>0.002295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.821148</td>\n",
       "      <td>-0.194098</td>\n",
       "      <td>-0.206393</td>\n",
       "      <td>0.149836</td>\n",
       "      <td>0.196557</td>\n",
       "      <td>0.002295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23050</th>\n",
       "      <td>-0.710714</td>\n",
       "      <td>-0.272571</td>\n",
       "      <td>-0.248571</td>\n",
       "      <td>0.164429</td>\n",
       "      <td>0.182571</td>\n",
       "      <td>0.005857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23051</th>\n",
       "      <td>-0.711143</td>\n",
       "      <td>-0.269857</td>\n",
       "      <td>-0.248286</td>\n",
       "      <td>0.165571</td>\n",
       "      <td>0.178714</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23052</th>\n",
       "      <td>-0.710714</td>\n",
       "      <td>-0.266286</td>\n",
       "      <td>-0.248429</td>\n",
       "      <td>0.166143</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.007714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23053</th>\n",
       "      <td>-0.710286</td>\n",
       "      <td>-0.263000</td>\n",
       "      <td>-0.248857</td>\n",
       "      <td>0.167143</td>\n",
       "      <td>0.169857</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23054</th>\n",
       "      <td>-0.710429</td>\n",
       "      <td>-0.260143</td>\n",
       "      <td>-0.249143</td>\n",
       "      <td>0.168429</td>\n",
       "      <td>0.165857</td>\n",
       "      <td>0.007429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153421 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fz bottom (kg)  Fz left (kg)  Fz right (kg)  Fx left (kg)  \\\n",
       "0           -0.828197     -0.189016      -0.198197      0.150164   \n",
       "1           -0.824918     -0.189836      -0.200328      0.150164   \n",
       "2           -0.822623     -0.191148      -0.202787      0.149836   \n",
       "3           -0.821148     -0.192787      -0.204590      0.150000   \n",
       "4           -0.821148     -0.194098      -0.206393      0.149836   \n",
       "...               ...           ...            ...           ...   \n",
       "23050       -0.710714     -0.272571      -0.248571      0.164429   \n",
       "23051       -0.711143     -0.269857      -0.248286      0.165571   \n",
       "23052       -0.710714     -0.266286      -0.248429      0.166143   \n",
       "23053       -0.710286     -0.263000      -0.248857      0.167143   \n",
       "23054       -0.710429     -0.260143      -0.249143      0.168429   \n",
       "\n",
       "       Fx right (kg)   Fy (kg)  \n",
       "0           0.196066  0.003934  \n",
       "1           0.194918  0.003115  \n",
       "2           0.194262  0.002623  \n",
       "3           0.194918  0.002295  \n",
       "4           0.196557  0.002295  \n",
       "...              ...       ...  \n",
       "23050       0.182571  0.005857  \n",
       "23051       0.178714  0.007000  \n",
       "23052       0.174000  0.007714  \n",
       "23053       0.169857  0.008000  \n",
       "23054       0.165857  0.007429  \n",
       "\n",
       "[153421 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xfcss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Output Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_test = (1,2,24,30,31,32,33,35,1,3)\n",
    "date = ('12_2_2020','12_11_2020','11_15_2020','11_24_2020','11_24_2020','11_25_2020','11_25_2020','11_25_2020','12_2_2020','12_11_2020')\n",
    "subj = ['cz','cz','leo','leo','leo','leo','leo','leo','yc','yc']\n",
    "y_gt = {}\n",
    "yrun = 0\n",
    "theta_interest = 'z'\n",
    "for i in range(len(n_test)):\n",
    "    test_str = 'test' + str(n_test[i])\n",
    "#     data_dir = os.path.join('/home/asilador/CS598/CS598-FinalProject/Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "    data_dir = os.path.join(r'C:\\Users\\Alex\\Box\\CS598 - Final Project\\Preliminary Data V5','Test_Subject_'+subj[i],test_str)\n",
    "    qtm_file_data_dir = os.path.join(data_dir , 'qtm_processed_'+subj[i]+'_test' + str(n_test[i]) + '_' + date[i] + '.txt')\n",
    "    y_gt[i] = read_output_data(qtm_file_data_dir,theta_interest).values\n",
    "\n",
    "    \n",
    "\n",
    "# tlen = len(y_gt[0])+len(y_gt[1])+len(y_gt[2])+len(y_gt[3])+len(y_gt[4])+len(y_gt[5])\n",
    "# y_train = np.zeros((tlen,1))\n",
    "# xrun = len(y_gt[0])\n",
    "# y_train[:xrun] = y_gt[0][:xrun]\n",
    "# xrun1 = xrun + len(y_gt[1])\n",
    "# y_train[xrun:xrun1]=y_gt[1][:xrun1-xrun]\n",
    "# xrun2 = xrun1 + len(y_gt[2])\n",
    "# y_train[xrun1:xrun2] = y_gt[2][:xrun2-xrun1]\n",
    "# xrun3 = xrun2 + len(y_gt[3])\n",
    "# y_train[xrun2:xrun3] = y_gt[3][:xrun3-xrun2]\n",
    "# xrun4 = xrun3 + len(y_gt[4])\n",
    "# y_train[xrun3:xrun4] = y_gt[4][:xrun4-xrun3]\n",
    "# xrun5 = xrun4 + len(y_gt[5])\n",
    "# y_train[xrun4:xrun5] = y_gt[5][:xrun5-xrun4]\n",
    "# del y_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlen=0\n",
    "for x in range(len(y_gt)):\n",
    "    tlen+= y_gt[x].shape[0]\n",
    "yrun_cum = 0\n",
    "y_train = np.zeros((tlen,1))\n",
    "for i in range (len(y_gt)):\n",
    "    yrun_n = len(y_gt[i])\n",
    "    y_train[yrun_cum:yrun_cum+yrun_n] = y_gt[i][:]\n",
    "    yrun_cum += yrun_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saturate output\n",
    "def saturate(theta, min_val, max_val):\n",
    "    for i in range(len(theta)):\n",
    "        if theta[i] < min_val:\n",
    "            theta[i] = min_val\n",
    "            continue\n",
    "        if theta[i] > max_val:\n",
    "            theta[i] = max_val\n",
    "            continue\n",
    "    return theta\n",
    "            \n",
    "min_val = -50\n",
    "max_val = 50\n",
    "    \n",
    "y_train = saturate(y_train, min_val, max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153421, 60, 80, 3)\n",
      "(153421, 6)\n",
      "(153421, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(xfcss_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamps = x_train.shape[0]\n",
    "n80p = int(np.floor(nsamps*0.8))\n",
    "rannums = np.array(random.sample(range(1,nsamps,1), n80p))\n",
    "s_nfiles = np.arange(nsamps)\n",
    "test_set = np.setdiff1d(s_nfiles,rannums)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainset = x_train[rannums,:]\n",
    "Trainset2 = xfcss_train.values[rannums,:]\n",
    "Testset = x_train[test_set,:]\n",
    "Testset2 = xfcss_train.values[test_set,:]\n",
    "# Trainy= y_gt[rannums,:]\n",
    "# Testy = y_gt[test_set,:]\n",
    "Trainy= y_train[rannums,:]\n",
    "Testy = y_train[test_set,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X2 = StandardScaler()\n",
    "sc_y = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrainz = Trainset\n",
    "Xtrainz2 = Trainset2\n",
    "ytrainz = Trainy\n",
    "X = Xtrainz\n",
    "X2 = sc_X2.fit_transform(Xtrainz2)\n",
    "y = sc_y.fit_transform(ytrainz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make validation data available to model.fit\n",
    "Xvalid = Testset\n",
    "Xvalid2 = sc_X2.transform(Testset2)\n",
    "y_valid = Testy\n",
    "y_valid = sc_y.transform(y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear up some used variables\n",
    "del Trainset\n",
    "del Trainset2\n",
    "del Testset\n",
    "del Testset2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regress using Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153421, 60, 80, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Neural Netowrk\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional, Conv2D, MaxPooling2D, Input, concatenate, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Reshape, Permute, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "dropout_rate = 0.2\n",
    "\n",
    "model_start = Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))\n",
    "model_start2 = Input(shape=(xfcss_train.shape[1],))\n",
    "model_cnn = model_start\n",
    "model_perc = model_start2\n",
    "\n",
    "model_cnn = Conv2D(filters=8, kernel_size=(3, 3),padding='same')(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = Conv2D(filters=8, kernel_size=(3, 3),padding='same')(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = AveragePooling2D(pool_size=(2, 2))(model_cnn)\n",
    "\n",
    "model_perc = Dense(32)(model_perc)\n",
    "model_perc = Activation('relu')(model_perc)\n",
    "\n",
    "model_cnn = Conv2D(filters=16, kernel_size=(3, 3),padding='same')(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = Conv2D(filters=16, kernel_size=(3, 3),padding='same')(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = AveragePooling2D(pool_size=(2, 2))(model_cnn)\n",
    "\n",
    "model_perc = Dense(32)(model_perc)\n",
    "model_perc = Activation('relu')(model_perc)\n",
    "\n",
    "model_cnn = Conv2D(filters=32, kernel_size=(3, 3),padding='same')(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = Conv2D(filters=32, kernel_size=(3, 3),padding='same')(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = AveragePooling2D(pool_size=(2, 2))(model_cnn)\n",
    "\n",
    "model_cnn = Conv2D(filters=64, kernel_size=(3, 3),padding='same')(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = Conv2D(filters=64, kernel_size=(3, 3),padding='same')(model_cnn)\n",
    "model_cnn = BatchNormalization()(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "model_cnn = AveragePooling2D(pool_size=(2, 2))(model_cnn)\n",
    "\n",
    "model_cnn = Flatten()(model_cnn)\n",
    "# model_perc = Flatten()(model_perc)\n",
    "# model_cnn = Activation('relu')(model_cnn)\n",
    "\n",
    "model_cnn = Dense(100)(model_cnn)\n",
    "model_cnn = Activation('relu')(model_cnn)\n",
    "# model_cnn = Dropout(dropout_rate)(model_cnn)\n",
    "\n",
    "model_comb = concatenate([model_cnn,model_perc],axis=-1)\n",
    "\n",
    "model_comb = Dense(256)(model_comb)\n",
    "# model_comb = BatchNormalization()(model_comb)\n",
    "model_comb = Activation('relu')(model_comb)\n",
    "model_comb = Dropout(dropout_rate)(model_comb)\n",
    "\n",
    "output = Dense(1)(model_comb)\n",
    "output = Activation('linear', name='thetaz_out')(output)\n",
    "model = Model(inputs=[model_start,model_start2],outputs=output)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mae',\n",
    "              metrics=['mse','mae'])\n",
    "\n",
    "\n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50,restore_best_weights=True) #Moving to 1000 patience. \n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50,restore_best_weights=True) #Moving to 1000 patience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60, 80, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 60, 80, 8)    224         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 60, 80, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 60, 80, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 60, 80, 8)    584         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 60, 80, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 60, 80, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 30, 40, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 30, 40, 16)   1168        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 30, 40, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 30, 40, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 30, 40, 16)   2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 30, 40, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 30, 40, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 15, 20, 16)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 15, 20, 32)   4640        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 15, 20, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 15, 20, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 15, 20, 32)   9248        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 15, 20, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 15, 20, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 7, 10, 32)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 10, 64)    18496       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 10, 64)    256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 7, 10, 64)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 7, 10, 64)    36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 7, 10, 64)    256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 7, 10, 64)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 3, 5, 64)     0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           224         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 960)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          96100       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           1056        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 132)          0           activation_10[0][0]              \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          34048       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 256)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            257         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "thetaz_out (Activation)         (None, 1)            0           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 206,253\n",
      "Trainable params: 205,773\n",
      "Non-trainable params: 480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "with tf.device('/device:CPU:0'):\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        layers.experimental.preprocessing.RandomZoom(height_factor = (-0.2,0.2),\n",
    "                                               width_factor = (-0.2,0.2), \n",
    "                                               fill_mode = 'constant'),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.05)], \n",
    "        name='data_augmentation')\n",
    "\n",
    "# create data generator\n",
    "def get_generator_cyclic(features1, features2, labels, batch_size=256):\n",
    "    while True:\n",
    "        for n in range(int(len(features1)/batch_size)):\n",
    "            X = features1[n*batch_size: (n+1)*batch_size]\n",
    "            with tf.device('/device:CPU:0'): #to prevent hogging limited gpu space\n",
    "                augmented_images = data_augmentation(X)\n",
    "                Xnew =  tf.cast(augmented_images,tf.float64)/255\n",
    "            yield [Xnew, features2[n*batch_size: (n+1)*batch_size], labels[n*batch_size: (n+1)*batch_size]]\n",
    "        permuted = np.random.permutation(len(features1))\n",
    "        features1 = features1[permuted]\n",
    "        features2 = features2[permuted]\n",
    "        labels = labels[permuted]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if e < 200: #very hacky\n",
    "        return 0.001\n",
    "    else:\n",
    "        if e%10==0:\n",
    "            return lr * 0.9\n",
    "        else:\n",
    "            return lr\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Time:  21:04:35\n",
      "Epoch 1 Time:  21:05:52\n",
      "Epoch 2 Time:  21:07:06\n",
      "Epoch 3 Time:  21:08:20\n",
      "Epoch 4 Time:  21:09:33\n",
      "Epoch 5 Time:  21:10:47\n",
      "Epoch 6 Time:  21:12:01\n",
      "Epoch 7 Time:  21:13:14\n",
      "Epoch 8 Time:  21:14:28\n",
      "Epoch 9 Time:  21:15:41\n",
      "Epoch 10 Time:  21:16:55\n",
      "Epoch 11 Time:  21:18:08\n",
      "Epoch 12 Time:  21:19:22\n",
      "Epoch 13 Time:  21:20:35\n",
      "Epoch 14 Time:  21:21:48\n",
      "Epoch 15 Time:  21:23:02\n",
      "Epoch 16 Time:  21:24:15\n",
      "Epoch 17 Time:  21:25:29\n",
      "Epoch 18 Time:  21:26:42\n",
      "Epoch 19 Time:  21:27:56\n",
      "Epoch 20 Time:  21:29:09\n",
      "Epoch 21 Time:  21:30:23\n",
      "Epoch 22 Time:  21:31:36\n",
      "Epoch 23 Time:  21:32:49\n",
      "Epoch 24 Time:  21:34:02\n",
      "Epoch 25 Time:  21:35:16\n",
      "Epoch 26 Time:  21:36:29\n",
      "Epoch 27 Time:  21:37:43\n",
      "Epoch 28 Time:  21:38:56\n",
      "Epoch 29 Time:  21:40:09\n",
      "Epoch 30 Time:  21:41:23\n",
      "Epoch 31 Time:  21:42:36\n",
      "Epoch 32 Time:  21:43:50\n",
      "Epoch 33 Time:  21:45:03\n",
      "Epoch 34 Time:  21:46:16\n",
      "Epoch 35 Time:  21:47:29\n",
      "Epoch 36 Time:  21:48:43\n",
      "Epoch 37 Time:  21:49:56\n",
      "Epoch 38 Time:  21:51:09\n",
      "Epoch 39 Time:  21:52:23\n",
      "Epoch 40 Time:  21:53:36\n",
      "Epoch 41 Time:  21:54:50\n",
      "Epoch 42 Time:  21:56:03\n",
      "Epoch 43 Time:  21:57:16\n",
      "Epoch 44 Time:  21:58:30\n",
      "Epoch 45 Time:  21:59:43\n",
      "Epoch 46 Time:  22:00:56\n",
      "Epoch 47 Time:  22:02:10\n",
      "Epoch 48 Time:  22:03:23\n",
      "Epoch 49 Time:  22:04:36\n",
      "Epoch 50 Time:  22:05:50\n",
      "Epoch 51 Time:  22:07:03\n",
      "Epoch 52 Time:  22:08:17\n",
      "Epoch 53 Time:  22:09:30\n",
      "Epoch 54 Time:  22:10:43\n",
      "Epoch 55 Time:  22:11:56\n",
      "Epoch 56 Time:  22:13:10\n",
      "Epoch 57 Time:  22:14:23\n",
      "Epoch 58 Time:  22:15:37\n",
      "Epoch 59 Time:  22:16:50\n",
      "Epoch 60 Time:  22:18:03\n",
      "Epoch 61 Time:  22:19:17\n",
      "Epoch 62 Time:  22:20:30\n",
      "Epoch 63 Time:  22:21:44\n",
      "Epoch 64 Time:  22:22:57\n",
      "Epoch 65 Time:  22:24:10\n",
      "Epoch 66 Time:  22:25:24\n",
      "Epoch 67 Time:  22:26:37\n",
      "Epoch 68 Time:  22:27:51\n",
      "Epoch 69 Time:  22:29:04\n",
      "Epoch 70 Time:  22:30:17\n",
      "Epoch 71 Time:  22:31:31\n",
      "Epoch 72 Time:  22:32:44\n",
      "Epoch 73 Time:  22:33:58\n",
      "Epoch 74 Time:  22:35:11\n",
      "Epoch 75 Time:  22:36:24\n",
      "Epoch 76 Time:  22:37:37\n",
      "Epoch 77 Time:  22:38:51\n",
      "Epoch 78 Time:  22:40:04\n",
      "Epoch 79 Time:  22:41:18\n",
      "Epoch 80 Time:  22:42:31\n",
      "Epoch 81 Time:  22:43:45\n",
      "Epoch 82 Time:  22:44:58\n",
      "Epoch 83 Time:  22:46:11\n",
      "Epoch 84 Time:  22:47:25\n",
      "Epoch 85 Time:  22:48:38\n",
      "Epoch 86 Time:  22:49:51\n",
      "Epoch 87 Time:  22:51:04\n",
      "Epoch 88 Time:  22:52:18\n",
      "Epoch 89 Time:  22:53:31\n",
      "Epoch 90 Time:  22:54:45\n",
      "Epoch 91 Time:  22:55:58\n",
      "Epoch 92 Time:  22:57:12\n",
      "Epoch 93 Time:  22:58:25\n",
      "Epoch 94 Time:  22:59:38\n",
      "Epoch 95 Time:  23:00:52\n",
      "Epoch 96 Time:  23:02:05\n",
      "Epoch 97 Time:  23:03:18\n",
      "Epoch 98 Time:  23:04:31\n",
      "Epoch 99 Time:  23:05:45\n",
      "Epoch 100 Time:  23:06:58\n",
      "Epoch 101 Time:  23:08:12\n",
      "Epoch 102 Time:  23:09:25\n",
      "Epoch 103 Time:  23:10:39\n",
      "Epoch 104 Time:  23:11:52\n",
      "Epoch 105 Time:  23:13:05\n",
      "Epoch 106 Time:  23:14:19\n",
      "Epoch 107 Time:  23:15:32\n",
      "Epoch 108 Time:  23:16:45\n",
      "Epoch 109 Time:  23:17:58\n",
      "Epoch 110 Time:  23:19:12\n",
      "Epoch 111 Time:  23:20:25\n",
      "Epoch 112 Time:  23:21:39\n",
      "Epoch 113 Time:  23:22:52\n",
      "Epoch 114 Time:  23:24:06\n",
      "Epoch 115 Time:  23:25:19\n",
      "Epoch 116 Time:  23:26:32\n",
      "Epoch 117 Time:  23:27:45\n",
      "Epoch 118 Time:  23:28:59\n",
      "Epoch 119 Time:  23:30:12\n",
      "Epoch 120 Time:  23:31:25\n",
      "Epoch 121 Time:  23:32:39\n",
      "Epoch 122 Time:  23:33:52\n",
      "Epoch 123 Time:  23:35:05\n",
      "Epoch 124 Time:  23:36:19\n",
      "Epoch 125 Time:  23:37:32\n",
      "Epoch 126 Time:  23:38:46\n",
      "Epoch 127 Time:  23:40:00\n",
      "Epoch 128 Time:  23:41:14\n",
      "Epoch 129 Time:  23:42:27\n",
      "Epoch 130 Time:  23:43:41\n",
      "Epoch 131 Time:  23:44:54\n",
      "Epoch 132 Time:  23:46:07\n",
      "Epoch 133 Time:  23:47:21\n",
      "Epoch 134 Time:  23:48:34\n",
      "Epoch 135 Time:  23:49:48\n",
      "Epoch 136 Time:  23:51:01\n",
      "Epoch 137 Time:  23:52:14\n",
      "Epoch 138 Time:  23:53:27\n",
      "Epoch 139 Time:  23:54:41\n",
      "Epoch 140 Time:  23:55:54\n",
      "Epoch 141 Time:  23:57:08\n",
      "Epoch 142 Time:  23:58:21\n",
      "Epoch 143 Time:  23:59:34\n",
      "Epoch 144 Time:  00:00:48\n",
      "Epoch 145 Time:  00:02:02\n",
      "Epoch 146 Time:  00:03:15\n",
      "Epoch 147 Time:  00:04:29\n",
      "Epoch 148 Time:  00:05:42\n",
      "Epoch 149 Time:  00:06:55\n",
      "Epoch 150 Time:  00:08:08\n",
      "Epoch 151 Time:  00:09:22\n",
      "Epoch 152 Time:  00:10:35\n",
      "Epoch 153 Time:  00:11:49\n",
      "Epoch 154 Time:  00:13:02\n",
      "Epoch 155 Time:  00:14:16\n",
      "Epoch 156 Time:  00:15:29\n",
      "Epoch 157 Time:  00:16:42\n",
      "Epoch 158 Time:  00:17:55\n",
      "Epoch 159 Time:  00:19:09\n",
      "Epoch 160 Time:  00:20:22\n",
      "Epoch 161 Time:  00:21:36\n",
      "Epoch 162 Time:  00:22:49\n",
      "Epoch 163 Time:  00:24:02\n",
      "Epoch 164 Time:  00:25:16\n",
      "Epoch 165 Time:  00:26:29\n",
      "Epoch 166 Time:  00:27:43\n",
      "Epoch 167 Time:  00:28:56\n",
      "Epoch 168 Time:  00:30:09\n",
      "Epoch 169 Time:  00:31:22\n",
      "Epoch 170 Time:  00:32:36\n",
      "Epoch 171 Time:  00:33:49\n",
      "Epoch 172 Time:  00:35:03\n",
      "Epoch 173 Time:  00:36:16\n",
      "Epoch 174 Time:  00:37:30\n",
      "Epoch 175 Time:  00:38:43\n",
      "Epoch 176 Time:  00:39:56\n",
      "Epoch 177 Time:  00:41:10\n",
      "Epoch 178 Time:  00:42:23\n",
      "Epoch 179 Time:  00:43:36\n",
      "Epoch 180 Time:  00:44:50\n",
      "Epoch 181 Time:  00:46:03\n",
      "Epoch 182 Time:  00:47:16\n",
      "Epoch 183 Time:  00:48:30\n",
      "Epoch 184 Time:  00:49:43\n",
      "Epoch 185 Time:  00:50:56\n",
      "Epoch 186 Time:  00:52:10\n",
      "Epoch 187 Time:  00:53:23\n",
      "Epoch 188 Time:  00:54:36\n",
      "Epoch 189 Time:  00:55:49\n",
      "Epoch 190 Time:  00:57:03\n",
      "Epoch 191 Time:  00:58:16\n",
      "Epoch 192 Time:  00:59:30\n",
      "Epoch 193 Time:  01:00:43\n",
      "Epoch 194 Time:  01:01:56\n",
      "Epoch 195 Time:  01:03:10\n",
      "Epoch 196 Time:  01:04:23\n",
      "Epoch 197 Time:  01:05:37\n",
      "Epoch 198 Time:  01:06:50\n",
      "Epoch 199 Time:  01:08:03\n",
      "Epoch 200 Time:  01:09:16\n",
      "Epoch 201 Time:  01:10:30\n",
      "Epoch 202 Time:  01:11:43\n",
      "Epoch 203 Time:  01:12:57\n",
      "Epoch 204 Time:  01:14:10\n",
      "Epoch 205 Time:  01:15:23\n",
      "Epoch 206 Time:  01:16:37\n",
      "Epoch 207 Time:  01:17:50\n",
      "Epoch 208 Time:  01:19:04\n",
      "Epoch 209 Time:  01:20:16\n",
      "Epoch 210 Time:  01:21:30\n",
      "Epoch 211 Time:  01:22:43\n",
      "Epoch 212 Time:  01:23:56\n",
      "Epoch 213 Time:  01:25:10\n",
      "Epoch 214 Time:  01:26:23\n",
      "Epoch 215 Time:  01:27:37\n",
      "Epoch 216 Time:  01:28:50\n",
      "Epoch 217 Time:  01:30:04\n",
      "Epoch 218 Time:  01:31:17\n",
      "Epoch 219 Time:  01:32:30\n",
      "Epoch 220 Time:  01:33:43\n",
      "Epoch 221 Time:  01:34:57\n",
      "Epoch 222 Time:  01:36:10\n",
      "Epoch 223 Time:  01:37:24\n",
      "Epoch 224 Time:  01:38:37\n",
      "Epoch 225 Time:  01:39:51\n",
      "Epoch 226 Time:  01:41:04\n",
      "Epoch 227 Time:  01:42:17\n",
      "Epoch 228 Time:  01:43:31\n",
      "Epoch 229 Time:  01:44:44\n",
      "Epoch 230 Time:  01:45:57\n",
      "Epoch 231 Time:  01:47:10\n",
      "Epoch 232 Time:  01:48:24\n",
      "Epoch 233 Time:  01:49:38\n",
      "Epoch 234 Time:  01:50:51\n",
      "Epoch 235 Time:  01:52:04\n",
      "Epoch 236 Time:  01:53:18\n",
      "Epoch 237 Time:  01:54:31\n",
      "Epoch 238 Time:  01:55:45\n",
      "Epoch 239 Time:  01:56:58\n",
      "Epoch 240 Time:  01:58:11\n",
      "Epoch 241 Time:  01:59:25\n",
      "Epoch 242 Time:  02:00:38\n",
      "Epoch 243 Time:  02:01:52\n",
      "Epoch 244 Time:  02:03:05\n",
      "Epoch 245 Time:  02:04:19\n",
      "Epoch 246 Time:  02:05:32\n",
      "Epoch 247 Time:  02:06:46\n",
      "Epoch 248 Time:  02:08:03\n",
      "Epoch 249 Time:  02:09:17\n",
      "Epoch 250 Time:  02:10:30\n",
      "Epoch 251 Time:  02:11:43\n",
      "Epoch 252 Time:  02:12:57\n",
      "Epoch 253 Time:  02:14:10\n",
      "Epoch 254 Time:  02:15:24\n",
      "Epoch 255 Time:  02:16:38\n",
      "Epoch 256 Time:  02:17:51\n",
      "Epoch 257 Time:  02:19:05\n",
      "Epoch 258 Time:  02:20:18\n",
      "Epoch 259 Time:  02:21:32\n",
      "Epoch 260 Time:  02:22:45\n",
      "Epoch 261 Time:  02:23:58\n",
      "Epoch 262 Time:  02:25:12\n",
      "Epoch 263 Time:  02:26:25\n",
      "Epoch 264 Time:  02:27:39\n",
      "Epoch 265 Time:  02:28:52\n",
      "Epoch 266 Time:  02:30:06\n",
      "Epoch 267 Time:  02:31:19\n",
      "Epoch 268 Time:  02:32:33\n",
      "Epoch 269 Time:  02:33:46\n",
      "Epoch 270 Time:  02:35:00\n",
      "Epoch 271 Time:  02:36:13\n",
      "Epoch 272 Time:  02:37:26\n",
      "Epoch 273 Time:  02:38:40\n",
      "Epoch 274 Time:  02:39:53\n",
      "Epoch 275 Time:  02:41:07\n",
      "Epoch 276 Time:  02:42:20\n",
      "Epoch 277 Time:  02:43:34\n",
      "Epoch 278 Time:  02:44:47\n",
      "Epoch 279 Time:  02:46:01\n",
      "Epoch 280 Time:  02:47:14\n",
      "Epoch 281 Time:  02:48:27\n",
      "Epoch 282 Time:  02:50:03\n",
      "Epoch 283 Time:  02:51:18\n",
      "Epoch 284 Time:  02:52:34\n",
      "Epoch 285 Time:  02:53:50\n",
      "Epoch 286 Time:  02:55:06\n",
      "Epoch 287 Time:  02:56:22\n",
      "Epoch 288 Time:  02:57:37\n",
      "Epoch 289 Time:  02:58:56\n",
      "Epoch 290 Time:  03:00:10\n",
      "Epoch 291 Time:  03:01:23\n",
      "Epoch 292 Time:  03:02:36\n",
      "Epoch 293 Time:  03:03:49\n",
      "Epoch 294 Time:  03:05:03\n",
      "Epoch 295 Time:  03:06:16\n",
      "Epoch 296 Time:  03:07:30\n",
      "Epoch 297 Time:  03:08:43\n",
      "Epoch 298 Time:  03:09:57\n",
      "Epoch 299 Time:  03:11:10\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "batch_size = 32\n",
    "batch_mult = 30\n",
    "readin = int(batch_size*batch_mult)\n",
    "epochs = int(300)\n",
    "training_generator = get_generator_cyclic(X,X2,y,readin)\n",
    "# test_generator = get_generator_cyclic(Xvalid,Xvalid2,y_valid,readin)\n",
    "for e in range(epochs):\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print('Epoch', e,'Time: ', current_time)\n",
    "    batches = 0\n",
    "    while batches<= len(X)/readin:\n",
    "        Xtrain_1, Xtrain_2, ytrain_1 = next(training_generator)\n",
    "#         Xtest_1, Xtest_2, ytest_1 =next(test_generator)\n",
    "#         model.fit([Xtrain_1, Xtrain_2], ytrain_1, callbacks = [callback],validation_data = ([Xtest_1,Xtest_2], ytest_1),batch_size=batch_size,verbose = 0)\n",
    "        model.fit([Xtrain_1, Xtrain_2], ytrain_1, callbacks = [callback],batch_size=batch_size,verbose = 0)\n",
    "        batches += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Time:  03:29:09\n",
      "Epoch 1 Time:  03:30:23\n",
      "Epoch 2 Time:  03:31:40\n",
      "Epoch 3 Time:  03:32:52\n",
      "Epoch 4 Time:  03:34:04\n",
      "Epoch 5 Time:  03:35:21\n",
      "Epoch 6 Time:  03:36:33\n",
      "Epoch 7 Time:  03:37:45\n",
      "Epoch 8 Time:  03:38:57\n",
      "Epoch 9 Time:  03:40:08\n",
      "Epoch 10 Time:  03:41:20\n",
      "Epoch 11 Time:  03:42:31\n",
      "Epoch 12 Time:  03:43:43\n",
      "Epoch 13 Time:  03:44:54\n",
      "Epoch 14 Time:  03:46:06\n",
      "Epoch 15 Time:  03:47:18\n",
      "Epoch 16 Time:  03:48:29\n",
      "Epoch 17 Time:  03:49:41\n",
      "Epoch 18 Time:  03:50:53\n",
      "Epoch 19 Time:  03:52:04\n",
      "Epoch 20 Time:  03:53:15\n",
      "Epoch 21 Time:  03:54:27\n",
      "Epoch 22 Time:  03:55:39\n",
      "Epoch 23 Time:  03:56:50\n",
      "Epoch 24 Time:  03:58:02\n",
      "Epoch 25 Time:  03:59:14\n",
      "Epoch 26 Time:  04:00:25\n",
      "Epoch 27 Time:  04:01:37\n",
      "Epoch 28 Time:  04:02:48\n",
      "Epoch 29 Time:  04:04:00\n",
      "Epoch 30 Time:  04:05:11\n",
      "Epoch 31 Time:  04:06:23\n",
      "Epoch 32 Time:  04:07:35\n",
      "Epoch 33 Time:  04:08:46\n",
      "Epoch 34 Time:  04:09:57\n",
      "Epoch 35 Time:  04:11:09\n",
      "Epoch 36 Time:  04:12:21\n",
      "Epoch 37 Time:  04:13:32\n",
      "Epoch 38 Time:  04:14:44\n",
      "Epoch 39 Time:  04:15:56\n",
      "Epoch 40 Time:  04:17:07\n",
      "Epoch 41 Time:  04:18:19\n",
      "Epoch 42 Time:  04:19:30\n",
      "Epoch 43 Time:  04:20:42\n",
      "Epoch 44 Time:  04:21:53\n",
      "Epoch 45 Time:  04:23:05\n",
      "Epoch 46 Time:  04:24:17\n",
      "Epoch 47 Time:  04:25:28\n",
      "Epoch 48 Time:  04:26:40\n",
      "Epoch 49 Time:  04:27:51\n",
      "Epoch 50 Time:  04:29:03\n",
      "Epoch 51 Time:  04:30:14\n",
      "Epoch 52 Time:  04:31:26\n",
      "Epoch 53 Time:  04:32:37\n",
      "Epoch 54 Time:  04:33:49\n",
      "Epoch 55 Time:  04:35:01\n",
      "Epoch 56 Time:  04:36:12\n",
      "Epoch 57 Time:  04:37:24\n",
      "Epoch 58 Time:  04:38:35\n",
      "Epoch 59 Time:  04:39:47\n",
      "Epoch 60 Time:  04:40:59\n",
      "Epoch 61 Time:  04:42:10\n",
      "Epoch 62 Time:  04:43:22\n",
      "Epoch 63 Time:  04:44:33\n",
      "Epoch 64 Time:  04:45:45\n",
      "Epoch 65 Time:  04:46:56\n",
      "Epoch 66 Time:  04:48:08\n",
      "Epoch 67 Time:  04:49:19\n",
      "Epoch 68 Time:  04:50:31\n",
      "Epoch 69 Time:  04:51:43\n",
      "Epoch 70 Time:  04:52:54\n",
      "Epoch 71 Time:  04:54:06\n",
      "Epoch 72 Time:  04:55:17\n",
      "Epoch 73 Time:  04:56:29\n",
      "Epoch 74 Time:  04:57:40\n",
      "Epoch 75 Time:  04:58:52\n",
      "Epoch 76 Time:  05:00:04\n",
      "Epoch 77 Time:  05:01:15\n",
      "Epoch 78 Time:  05:02:27\n",
      "Epoch 79 Time:  05:03:38\n",
      "Epoch 80 Time:  05:04:49\n",
      "Epoch 81 Time:  05:06:01\n",
      "Epoch 82 Time:  05:07:14\n",
      "Epoch 83 Time:  05:08:25\n",
      "Epoch 84 Time:  05:09:37\n",
      "Epoch 85 Time:  05:10:48\n",
      "Epoch 86 Time:  05:12:00\n",
      "Epoch 87 Time:  05:13:12\n",
      "Epoch 88 Time:  05:14:23\n",
      "Epoch 89 Time:  05:15:34\n",
      "Epoch 90 Time:  05:16:46\n",
      "Epoch 91 Time:  05:17:58\n",
      "Epoch 92 Time:  05:19:09\n",
      "Epoch 93 Time:  05:20:21\n",
      "Epoch 94 Time:  05:21:33\n",
      "Epoch 95 Time:  05:22:44\n",
      "Epoch 96 Time:  05:23:55\n",
      "Epoch 97 Time:  05:25:07\n",
      "Epoch 98 Time:  05:26:18\n",
      "Epoch 99 Time:  05:27:30\n",
      "Epoch 100 Time:  05:28:42\n",
      "Epoch 101 Time:  05:29:53\n",
      "Epoch 102 Time:  05:31:05\n",
      "Epoch 103 Time:  05:32:16\n",
      "Epoch 104 Time:  05:33:28\n",
      "Epoch 105 Time:  05:34:39\n",
      "Epoch 106 Time:  05:35:51\n",
      "Epoch 107 Time:  05:37:03\n",
      "Epoch 108 Time:  05:38:15\n",
      "Epoch 109 Time:  05:39:26\n",
      "Epoch 110 Time:  05:40:38\n",
      "Epoch 111 Time:  05:41:49\n",
      "Epoch 112 Time:  05:43:01\n",
      "Epoch 113 Time:  05:44:12\n",
      "Epoch 114 Time:  05:45:24\n",
      "Epoch 115 Time:  05:46:35\n",
      "Epoch 116 Time:  05:47:47\n",
      "Epoch 117 Time:  05:48:59\n",
      "Epoch 118 Time:  05:50:10\n",
      "Epoch 119 Time:  05:51:21\n",
      "Epoch 120 Time:  05:52:33\n",
      "Epoch 121 Time:  05:53:45\n",
      "Epoch 122 Time:  05:54:56\n",
      "Epoch 123 Time:  05:56:08\n",
      "Epoch 124 Time:  05:57:20\n",
      "Epoch 125 Time:  05:58:31\n",
      "Epoch 126 Time:  05:59:42\n",
      "Epoch 127 Time:  06:00:54\n",
      "Epoch 128 Time:  06:02:06\n",
      "Epoch 129 Time:  06:03:18\n",
      "Epoch 130 Time:  06:04:30\n",
      "Epoch 131 Time:  06:05:41\n",
      "Epoch 132 Time:  06:06:53\n",
      "Epoch 133 Time:  06:08:05\n",
      "Epoch 134 Time:  06:09:16\n",
      "Epoch 135 Time:  06:10:27\n",
      "Epoch 136 Time:  06:11:39\n",
      "Epoch 137 Time:  06:12:51\n",
      "Epoch 138 Time:  06:14:02\n",
      "Epoch 139 Time:  06:15:14\n",
      "Epoch 140 Time:  06:16:26\n",
      "Epoch 141 Time:  06:17:37\n",
      "Epoch 142 Time:  06:18:48\n",
      "Epoch 143 Time:  06:20:00\n",
      "Epoch 144 Time:  06:21:11\n",
      "Epoch 145 Time:  06:22:23\n",
      "Epoch 146 Time:  06:23:35\n",
      "Epoch 147 Time:  06:24:46\n",
      "Epoch 148 Time:  06:25:58\n",
      "Epoch 149 Time:  06:27:09\n",
      "Epoch 150 Time:  06:28:21\n",
      "Epoch 151 Time:  06:29:33\n",
      "Epoch 152 Time:  06:30:44\n",
      "Epoch 153 Time:  06:31:56\n",
      "Epoch 154 Time:  06:33:07\n",
      "Epoch 155 Time:  06:34:19\n",
      "Epoch 156 Time:  06:35:31\n",
      "Epoch 157 Time:  06:36:42\n",
      "Epoch 158 Time:  06:37:54\n",
      "Epoch 159 Time:  06:39:05\n",
      "Epoch 160 Time:  06:40:17\n",
      "Epoch 161 Time:  06:41:28\n",
      "Epoch 162 Time:  06:42:40\n",
      "Epoch 163 Time:  06:43:52\n",
      "Epoch 164 Time:  06:45:03\n",
      "Epoch 165 Time:  06:46:15\n",
      "Epoch 166 Time:  06:47:26\n",
      "Epoch 167 Time:  06:48:38\n",
      "Epoch 168 Time:  06:49:50\n",
      "Epoch 169 Time:  06:51:01\n",
      "Epoch 170 Time:  06:52:13\n",
      "Epoch 171 Time:  06:53:24\n",
      "Epoch 172 Time:  06:54:35\n",
      "Epoch 173 Time:  06:55:47\n",
      "Epoch 174 Time:  06:56:59\n",
      "Epoch 175 Time:  06:58:10\n",
      "Epoch 176 Time:  06:59:22\n",
      "Epoch 177 Time:  07:00:34\n",
      "Epoch 178 Time:  07:01:45\n",
      "Epoch 179 Time:  07:02:57\n",
      "Epoch 180 Time:  07:04:08\n",
      "Epoch 181 Time:  07:05:20\n",
      "Epoch 182 Time:  07:06:31\n",
      "Epoch 183 Time:  07:07:43\n",
      "Epoch 184 Time:  07:08:55\n",
      "Epoch 185 Time:  07:10:06\n",
      "Epoch 186 Time:  07:11:18\n",
      "Epoch 187 Time:  07:12:29\n",
      "Epoch 188 Time:  07:13:41\n",
      "Epoch 189 Time:  07:14:52\n",
      "Epoch 190 Time:  07:16:04\n",
      "Epoch 191 Time:  07:17:15\n",
      "Epoch 192 Time:  07:18:27\n",
      "Epoch 193 Time:  07:19:39\n",
      "Epoch 194 Time:  07:20:50\n",
      "Epoch 195 Time:  07:22:01\n",
      "Epoch 196 Time:  07:23:13\n",
      "Epoch 197 Time:  07:24:25\n",
      "Epoch 198 Time:  07:25:36\n",
      "Epoch 199 Time:  07:26:48\n",
      "Epoch 200 Time:  07:28:00\n",
      "Epoch 201 Time:  07:29:11\n",
      "Epoch 202 Time:  07:30:23\n",
      "Epoch 203 Time:  07:31:34\n",
      "Epoch 204 Time:  07:32:46\n",
      "Epoch 205 Time:  07:33:57\n",
      "Epoch 206 Time:  07:35:09\n",
      "Epoch 207 Time:  07:36:21\n",
      "Epoch 208 Time:  07:37:32\n",
      "Epoch 209 Time:  07:38:44\n",
      "Epoch 210 Time:  07:39:55\n",
      "Epoch 211 Time:  07:41:07\n",
      "Epoch 212 Time:  07:42:18\n",
      "Epoch 213 Time:  07:43:30\n",
      "Epoch 214 Time:  07:44:41\n",
      "Epoch 215 Time:  07:45:53\n",
      "Epoch 216 Time:  07:47:05\n",
      "Epoch 217 Time:  07:48:16\n",
      "Epoch 218 Time:  07:49:27\n",
      "Epoch 219 Time:  07:50:39\n",
      "Epoch 220 Time:  07:51:50\n",
      "Epoch 221 Time:  07:53:02\n",
      "Epoch 222 Time:  07:54:14\n",
      "Epoch 223 Time:  07:55:25\n",
      "Epoch 224 Time:  07:56:37\n",
      "Epoch 225 Time:  07:57:48\n",
      "Epoch 226 Time:  07:59:00\n",
      "Epoch 227 Time:  08:00:11\n",
      "Epoch 228 Time:  08:01:23\n",
      "Epoch 229 Time:  08:02:35\n",
      "Epoch 230 Time:  08:03:47\n",
      "Epoch 231 Time:  08:04:58\n",
      "Epoch 232 Time:  08:06:10\n",
      "Epoch 233 Time:  08:07:21\n",
      "Epoch 234 Time:  08:08:33\n",
      "Epoch 235 Time:  08:09:45\n",
      "Epoch 236 Time:  08:10:56\n",
      "Epoch 237 Time:  08:12:08\n",
      "Epoch 238 Time:  08:13:20\n",
      "Epoch 239 Time:  08:14:31\n",
      "Epoch 240 Time:  08:15:43\n",
      "Epoch 241 Time:  08:16:54\n",
      "Epoch 242 Time:  08:18:06\n",
      "Epoch 243 Time:  08:19:17\n",
      "Epoch 244 Time:  08:20:29\n",
      "Epoch 245 Time:  08:21:41\n",
      "Epoch 246 Time:  08:22:53\n",
      "Epoch 247 Time:  08:24:05\n",
      "Epoch 248 Time:  08:25:16\n",
      "Epoch 249 Time:  08:26:27\n",
      "Epoch 250 Time:  08:27:39\n",
      "Epoch 251 Time:  08:28:51\n",
      "Epoch 252 Time:  08:30:03\n",
      "Epoch 253 Time:  08:31:15\n",
      "Epoch 254 Time:  08:32:26\n",
      "Epoch 255 Time:  08:33:39\n",
      "Epoch 256 Time:  08:34:50\n",
      "Epoch 257 Time:  08:36:02\n",
      "Epoch 258 Time:  08:37:13\n",
      "Epoch 259 Time:  08:38:25\n",
      "Epoch 260 Time:  08:39:37\n",
      "Epoch 261 Time:  08:40:49\n",
      "Epoch 262 Time:  08:42:00\n",
      "Epoch 263 Time:  08:43:12\n",
      "Epoch 264 Time:  08:44:23\n",
      "Epoch 265 Time:  08:45:35\n",
      "Epoch 266 Time:  08:46:47\n",
      "Epoch 267 Time:  08:47:59\n",
      "Epoch 268 Time:  08:49:10\n",
      "Epoch 269 Time:  08:50:22\n",
      "Epoch 270 Time:  08:51:34\n",
      "Epoch 271 Time:  08:52:45\n",
      "Epoch 272 Time:  08:53:57\n",
      "Epoch 273 Time:  08:55:09\n",
      "Epoch 274 Time:  08:56:20\n",
      "Epoch 275 Time:  08:57:32\n",
      "Epoch 276 Time:  08:58:44\n",
      "Epoch 277 Time:  08:59:56\n",
      "Epoch 278 Time:  09:01:07\n",
      "Epoch 279 Time:  09:02:19\n",
      "Epoch 280 Time:  09:03:30\n",
      "Epoch 281 Time:  09:04:42\n",
      "Epoch 282 Time:  09:05:54\n",
      "Epoch 283 Time:  09:07:06\n",
      "Epoch 284 Time:  09:08:18\n",
      "Epoch 285 Time:  09:09:29\n",
      "Epoch 286 Time:  09:10:41\n",
      "Epoch 287 Time:  09:11:52\n",
      "Epoch 288 Time:  09:13:04\n",
      "Epoch 289 Time:  09:14:16\n",
      "Epoch 290 Time:  09:15:28\n",
      "Epoch 291 Time:  09:16:39\n",
      "Epoch 292 Time:  09:17:51\n",
      "Epoch 293 Time:  09:19:03\n",
      "Epoch 294 Time:  09:20:14\n",
      "Epoch 295 Time:  09:21:26\n",
      "Epoch 296 Time:  09:22:38\n",
      "Epoch 297 Time:  09:23:49\n",
      "Epoch 298 Time:  09:25:01\n",
      "Epoch 299 Time:  09:26:13\n"
     ]
    }
   ],
   "source": [
    "# continue training\n",
    "training_generator = get_generator_cyclic(X,X2,y,readin)\n",
    "for e in range(epochs):\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print('Epoch', e,'Time: ', current_time)\n",
    "    batches = 0\n",
    "    while batches<= len(X)/readin:\n",
    "        Xtrain_1, Xtrain_2, ytrain_1 = next(training_generator)\n",
    "#         Xtest_1, Xtest_2, ytest_1 =next(test_generator)\n",
    "#         model.fit([Xtrain_1, Xtrain_2], ytrain_1, callbacks = [callback],validation_data = ([Xtest_1,Xtest_2], ytest_1),batch_size=batch_size,verbose = 0)\n",
    "        model.fit([Xtrain_1, Xtrain_2], ytrain_1, callbacks = [callback],batch_size=batch_size,verbose = 0)\n",
    "        batches += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    \n",
    "    v1 = history.history['mae']*np.sqrt(sc_y.var_)\n",
    "    v2 = history.history['val_mae']*np.sqrt(sc_y.var_)\n",
    "    fig1 = plt.figure()\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "    ax1.plot(v1, label='mae')\n",
    "    ax1.plot(v2, label='val_mae')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Error [deg]')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    v3 = history.history['mse']*sc_y.var_\n",
    "    v4 = history.history['val_mse']*sc_y.var_\n",
    "    fig2 = plt.figure()\n",
    "    ax2 = fig2.add_subplot(111)\n",
    "    ax2.plot(v3, label='mse')\n",
    "    ax2.plot(v4, label='val_mse')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Error [deg^2]')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_loss(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-layer Network: Predict Against Training Data as a Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sanity check with 80% data\n",
    "Xtrainz = Trainset/255.\n",
    "Xtrainz2 = sc_X2.transform(Trainset2)\n",
    "y_pred = model.predict([Xtrainz,Xtrainz2])\n",
    "#y_pred = sc_y.inverse_transform(y_pred)\n",
    "y_pred = sc_y.inverse_transform(y_pred)\n",
    "y_new = Trainy\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(y_new,'k')\n",
    "plt.plot(y_pred,'r--')\n",
    "plt.title('Prediction of Training Set (Sanity Check)')\n",
    "#plt.axis([xmin, xmax, ymin, ymax])\n",
    "plt.legend(labels=['Ground Truth','Prediction'])\n",
    "plt.show()\n",
    "# Squared-root of Squared Error\n",
    "\n",
    "test_error = (y_pred - y_new)\n",
    "print('Average error is {:4.2f} degrees'.format(np.sum(test_error)/test_error.shape[0]))\n",
    "rmse = np.sqrt(test_error**2)\n",
    "print('Root Mean Squared Error is {:4.2f} degrees'.format(np.sum(rmse)/test_error.shape[0]))\n",
    "# Mean absolute error\n",
    "print('Mean Absolute Error is {:4.2f} degrees'.format(np.sum(np.abs(test_error))/test_error.shape[0]))\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(rmse,'.')\n",
    "plt.title('Sqrt(Squared Error) of Training Set (Sanity Check)')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Error (degrees)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(test_error,bins=100)\n",
    "plt.title('Histogram of Residuals in Training Set')\n",
    "plt.xlabel('Angle')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "#plot scatterplot of data\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_pred,y_new,marker='.',color='black')\n",
    "plt.xlabel('Predicted angle (degrees)')\n",
    "plt.ylabel('Ground truth angle (degrees)')\n",
    "plt.title('Ground truth vs predicted angle of Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-layer Neural Network: Predict Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959/959 [==============================] - 5s 5ms/step - loss: 0.1930 - mse: 0.1452 - mae: 0.1930\n",
      "Mean absolute error is: 2.26\n"
     ]
    }
   ],
   "source": [
    "# cheap way to check mse for test set\n",
    "losssc, msesc, maesc = model.evaluate([Xvalid/255.,Xvalid2],y_valid)\n",
    "mae = maesc*(sc_y.var_)**0.5\n",
    "print('Mean absolute error is: {:4.2f}'.format(mae[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959/959 [==============================] - 5s 5ms/step - loss: 0.1790 - mse: 0.1331 - mae: 0.1790\n",
      "Mean absolute error is: 2.10\n"
     ]
    }
   ],
   "source": [
    "losssc, msesc, maesc = model.evaluate([Xvalid/255.,Xvalid2],y_valid)\n",
    "mae = maesc*(sc_y.var_)**0.5\n",
    "print('Mean absolute error is: {:4.2f}'.format(mae[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo test set\n",
    "Xtest = Testset/255.\n",
    "Xtest2 = sc_X2.transform(Testset2)\n",
    "y_pred = model.predict([Xtest,Xtest2])\n",
    "#y_pred = sc_y.inverse_transform(y_pred)\n",
    "y_pred = sc_y.inverse_transform(y_pred)\n",
    "y_new = Testy\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(y_new,'k')\n",
    "plt.plot(y_pred,'r--')\n",
    "plt.title('Prediction of Test')\n",
    "#plt.axis([xmin, xmax, ymin, ymax])\n",
    "plt.legend(labels=['Ground Truth','Prediction'])\n",
    "plt.show()\n",
    "\n",
    "# Squared-root of Squared Error\n",
    "\n",
    "test_error = (y_pred - y_new)\n",
    "print('Average error is {:4.2f} degrees'.format(np.sum(test_error)/test_error.shape[0]))\n",
    "rmse = np.sqrt(test_error**2)\n",
    "print('Root Mean Squared Error is {:4.2f} degrees'.format(np.sum(rmse)/test_error.shape[0]))\n",
    "# Mean absolute error\n",
    "print('Mean Absolute Error is {:4.2f} degrees'.format(np.sum(np.abs(test_error))/test_error.shape[0]))\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(rmse,'.')\n",
    "plt.title('Sqrt(Squared Error) of Test Set')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Error (degrees)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(test_error,bins=100)\n",
    "plt.title('Histogram of Residuals in Test Set')\n",
    "plt.xlabel('Angle')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "#plot scatterplot of data\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_pred,y_new,marker='.',color='black')\n",
    "plt.xlabel('Predicted angle (degrees)')\n",
    "plt.ylabel('Ground truth angle (degrees)')\n",
    "plt.title('Ground truth vs predicted angle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_notebookparams = 1\n",
    "if save_notebookparams:\n",
    "    pkl_filename = \"depthforcemodelparam_cnn3v25_r2_pb.pkl\"\n",
    "    randata = {}\n",
    "    randata['nsamps']=nsamps\n",
    "    randata['n80p']=n80p\n",
    "    randata['rannums']=rannums\n",
    "    randata['test_set']=test_set\n",
    "#     modelhistory = history.history\n",
    "    \n",
    "    \n",
    "    with open(pkl_filename, 'wb') as file:\n",
    "#         pickle.dump([randata,sc_y,sc_X2,modelhistory], file)\n",
    "          pickle.dump([randata,sc_y,sc_X2], file)\n",
    "        \n",
    "#     !mkdir -p saved_model\n",
    "#     model.save('saved_model/cnn3v22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/cnn3v24_r2\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model/cnn3v24_r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
