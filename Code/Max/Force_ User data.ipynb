{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read video frame\n",
    "def dep_cam_reduced(dep_v_name):\n",
    "    dep_v = cv2.VideoCapture(dep_v_name)\n",
    "    ret, frame = dep_v.read()\n",
    "    counter=0\n",
    "\n",
    "    frame_count = int(dep_v.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "#     frame_height = int(frame.shape[0]/5)\n",
    "#     frame_width = int(frame.shape[1]/5)\n",
    "#     frame_height = frame.shape[0]\n",
    "#     frame_width = frame.shape[1]\n",
    "    frame_height = 30\n",
    "    frame_width = 40\n",
    "    depth_frames = np.empty((frame_count, frame_height, frame_width))\n",
    "\n",
    "    while(dep_v.isOpened()):\n",
    "        ret, frame = dep_v.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        if ret == True:\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray_frame = cv2.resize(gray_frame, (frame_width, frame_height), interpolation = cv2.INTER_AREA)\n",
    "            depth_frames[counter] = gray_frame\n",
    "            counter+=1\n",
    "\n",
    "    dep_v.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return depth_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read depth data\n",
    "\n",
    "# # Test subject Leo\n",
    "# foldername = r'Test_Subject_Leo/'\n",
    "# test_folder = ['test24', 'test30', 'test31', 'test32','test33', 'test35' ]\n",
    "# test_num = ['24', '30', '31', '32', '33', '35']\n",
    "# sub_name = foldername + test_folder[0]\n",
    "# dep_name = sub_name + r'/depth_processed_leo_test' + test_num[0] + '.avi';\n",
    "# depth =  dep_cam(dep_name)\n",
    "# for i in range(1, 6):\n",
    "#     subfolder_name = foldername + test_folder[i]\n",
    "#     dep_video_name = subfolder_name + r'/depth_processed_leo_test' + test_num[i] + '.avi'\n",
    "#     #print(dep_video_name)\n",
    "#     dep_v_temp =  dep_cam(dep_video_name)\n",
    "#     depth = np.concatenate((depth, dep_v_temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Force data for each subject\n",
    "# Test subject Leo\n",
    "foldername = r'Test_Subject_Leo/'\n",
    "test_folder = ['test24', 'test30', 'test31', 'test32','test33', 'test35' ]\n",
    "test_num = ['24', '30', '31', '32', '33', '35']\n",
    "subfolder_name = foldername + test_folder[0]\n",
    "force_file_leo = subfolder_name + r'/fcss_processed_leo_test' + test_num[0] + '_' + '11_15_2020' + '.txt'\n",
    "force_leo = pd.read_csv(force_file_leo)\n",
    "force_leo = force_leo.iloc[:,:].values\n",
    "for i in range(1,6):\n",
    "    subfolder_name = foldername + test_folder[i]\n",
    "    if test_folder[i] == 'test30' or test_folder[i] == 'test31':\n",
    "        force_file = subfolder_name + r'/fcss_processed_leo_test' + test_num[i] + '_' + '11_24_2020' + '.txt'\n",
    "    else: \n",
    "        force_file = subfolder_name + r'/fcss_processed_leo_test' + test_num[i] + '_' + '11_25_2020' + '.txt'\n",
    "    dataset_y =  pd.read_csv(force_file)\n",
    "    force_temp = dataset_y.iloc[:,:].values\n",
    "    force_leo = np.concatenate((force_leo, force_temp))\n",
    "    \n",
    "# Test subject cz\n",
    "foldername = r'Test_Subject_cz/'\n",
    "test_folder = ['test1', 'test2']\n",
    "test_num = ['1', '2']\n",
    "subfolder_name = foldername + test_folder[0]\n",
    "force_file_cz_1 = subfolder_name + r'/fcss_processed_cz_test' + test_num[0] + '_' + '12_2_2020' + '.txt'\n",
    "force_cz_1 = pd.read_csv(force_file_cz_1)\n",
    "force_cz_1 = force_cz_1.iloc[:,:].values\n",
    "subfolder_name = foldername + test_folder[1]\n",
    "force_file_cz_2 = subfolder_name + r'/fcss_processed_cz_test' + test_num[1] + '_' + '12_11_2020' + '.txt'\n",
    "dataset_y_2 =  pd.read_csv(force_file_cz_2)\n",
    "force_cz_2 = dataset_y_2.iloc[:,:].values\n",
    "force_cz = np.concatenate((force_cz_1, force_cz_2))\n",
    "\n",
    "\n",
    "# Test subject yc\n",
    "foldername = r'Test_Subject_yc/'\n",
    "test_folder = ['test1', 'test3']\n",
    "test_num = ['1', '3']\n",
    "subfolder_name = foldername + test_folder[0]\n",
    "force_file_yc_1 = subfolder_name + r'/fcss_processed_yc_test' + test_num[0] + '_' + '12_2_2020' + '.txt'\n",
    "force_yc_1 = pd.read_csv(force_file_yc_1)\n",
    "force_yc_1 = force_yc_1.iloc[:,:].values\n",
    "subfolder_name = foldername + test_folder[1]\n",
    "force_file_yc_2 = subfolder_name + r'/fcss_processed_yc_test' + test_num[1] + '_' + '12_11_2020' + '.txt'\n",
    "dataset_y_2 =  pd.read_csv(force_file_yc_2)\n",
    "force_yc_2 = dataset_y_2.iloc[:,:].values\n",
    "force_yc = np.concatenate((force_yc_1, force_yc_2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36942, 6) (34098, 6)\n"
     ]
    }
   ],
   "source": [
    "print(force_yc.shape, force_cz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read output angle data --> focus on theta x and theta y\n",
    "# Test subject Leo\n",
    "foldername = r'Test_Subject_Leo/'\n",
    "test_folder = ['test24', 'test30', 'test31', 'test32','test33', 'test35' ]\n",
    "test_num = ['24', '30', '31', '32', '33', '35']\n",
    "subfolder_name = foldername + test_folder[0]\n",
    "qtm_file = subfolder_name + r'/qtm_processed_leo_test' + test_num[0] + '_' + '11_15_2020' + '.txt'\n",
    "theta_leo = pd.read_csv(qtm_file)\n",
    "theta_x_leo = theta_leo.iloc[:,1].values\n",
    "theta_y_leo = theta_leo.iloc[:,2].values\n",
    "for i in range(1,6):\n",
    "    subfolder_name = foldername + test_folder[i]\n",
    "    if test_folder[i] == 'test30' or test_folder[i] == 'test31':\n",
    "        qtm_file = subfolder_name + r'/qtm_processed_leo_test' + test_num[i] + '_' + '11_24_2020' + '.txt'\n",
    "    else: \n",
    "        qtm_file = subfolder_name + r'/qtm_processed_leo_test' + test_num[i] + '_' + '11_25_2020' + '.txt'\n",
    "    dataset_y =  pd.read_csv(qtm_file)\n",
    "    theta_x_temp = dataset_y.iloc[:,1].values\n",
    "    theta_y_temp = dataset_y.iloc[:,2].values\n",
    "    theta_x_leo = np.concatenate((theta_x_leo, theta_x_temp))\n",
    "    theta_y_leo = np.concatenate((theta_y_leo, theta_y_temp))\n",
    "    \n",
    "# Test subject cz\n",
    "\n",
    "foldername = r'Test_Subject_cz/'\n",
    "test_folder = ['test1', 'test2']\n",
    "test_num = ['1', '2']\n",
    "subfolder_name = foldername + test_folder[0]\n",
    "qtm_file_cz = subfolder_name + r'/qtm_processed_cz_test' + test_num[0] + '_' + '12_2_2020' + '.txt'\n",
    "theta_cz = pd.read_csv(qtm_file_cz)\n",
    "theta_x_cz = theta_cz.iloc[:,1].values\n",
    "theta_y_cz = theta_cz.iloc[:,2].values\n",
    "subfolder_name = foldername + test_folder[1]\n",
    "qtm_file_cz = subfolder_name + r'/qtm_processed_cz_test' + test_num[1] + '_' + '12_11_2020' + '.txt'\n",
    "dataset_y =  pd.read_csv(qtm_file_cz)\n",
    "theta_x_temp = dataset_y.iloc[:,1].values\n",
    "theta_y_temp = dataset_y.iloc[:,2].values\n",
    "theta_x_cz = np.concatenate((theta_x_cz, theta_x_temp))\n",
    "theta_y_cz = np.concatenate((theta_y_cz, theta_y_temp))\n",
    "\n",
    "# Test subject yc\n",
    "foldername = r'Test_Subject_yc/'\n",
    "test_folder = ['test1', 'test3']\n",
    "test_num = ['1', '3']\n",
    "subfolder_name = foldername + test_folder[0]\n",
    "qtm_file_yc = subfolder_name + r'/qtm_processed_yc_test' + test_num[0] + '_' + '12_2_2020' + '.txt'\n",
    "theta_yc = pd.read_csv(qtm_file_yc)\n",
    "theta_x_yc = theta_yc.iloc[:,1].values\n",
    "theta_y_yc = theta_yc.iloc[:,2].values\n",
    "subfolder_name = foldername + test_folder[1]\n",
    "qtm_file_yc = subfolder_name + r'/qtm_processed_yc_test' + test_num[1] + '_' + '12_11_2020' + '.txt'\n",
    "dataset_y =  pd.read_csv(qtm_file_yc)\n",
    "theta_x_temp = dataset_y.iloc[:,1].values\n",
    "theta_y_temp = dataset_y.iloc[:,2].values\n",
    "theta_x_yc = np.concatenate((theta_x_yc, theta_x_temp))\n",
    "theta_y_yc = np.concatenate((theta_y_yc, theta_y_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36942,) (36942,)\n"
     ]
    }
   ],
   "source": [
    "print(theta_y_yc.shape, theta_x_yc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User biometric data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force normalization using weight, height, w x h and BMI\n",
    "\n",
    "def BMI(weight, height):\n",
    "    \n",
    "    BMI = weight / ((height*0.01)**2)\n",
    "    return BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub_leo_height = 174\n",
    "test_sub_leo_weight = 67\n",
    "test_sub_cz_height = 180\n",
    "test_sub_cz_weight = 61\n",
    "test_sub_yc_height = 170\n",
    "test_sub_yc_weight = 70\n",
    "\n",
    "force_leo_w = force_leo/test_sub_leo_weight\n",
    "force_cz_w = force_cz/test_sub_cz_weight\n",
    "force_yc_w = force_yc/test_sub_yc_weight\n",
    "\n",
    "force_leo_h = force_leo/test_sub_leo_height\n",
    "force_cz_h = force_cz/test_sub_cz_height\n",
    "force_yc_h = force_yc/test_sub_yc_height\n",
    "\n",
    "force_leo_wh = force_leo/(test_sub_leo_height*test_sub_leo_weight/100)\n",
    "force_cz_wh = force_cz/(test_sub_cz_height*test_sub_cz_weight/100)\n",
    "force_yc_wh = force_yc/(test_sub_yc_height*test_sub_yc_weight/100)\n",
    "\n",
    "force_leo_bmi = force_leo/BMI(test_sub_leo_weight,test_sub_leo_height)\n",
    "force_cz_bmi = force_cz/BMI(test_sub_cz_weight,test_sub_cz_height)\n",
    "force_yc_bmi = force_yc/BMI(test_sub_yc_weight,test_sub_yc_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "515/515 [==============================] - 1s 977us/step - loss: 3.4025 - mae: 3.4025 - val_loss: 2.9963 - val_mae: 2.9963\n",
      "Epoch 2/300\n",
      "515/515 [==============================] - 0s 935us/step - loss: 3.1003 - mae: 3.1003 - val_loss: 2.9681 - val_mae: 2.9681\n",
      "Epoch 3/300\n",
      "515/515 [==============================] - 0s 863us/step - loss: 3.0642 - mae: 3.0642 - val_loss: 2.9471 - val_mae: 2.9471\n",
      "Epoch 4/300\n",
      "515/515 [==============================] - 0s 827us/step - loss: 3.0212 - mae: 3.0212 - val_loss: 2.8847 - val_mae: 2.8847\n",
      "Epoch 5/300\n",
      "515/515 [==============================] - 0s 812us/step - loss: 2.9785 - mae: 2.9785 - val_loss: 2.9062 - val_mae: 2.9062\n",
      "Epoch 6/300\n",
      "515/515 [==============================] - 0s 863us/step - loss: 2.9341 - mae: 2.9341 - val_loss: 2.8292 - val_mae: 2.8292\n",
      "Epoch 7/300\n",
      "515/515 [==============================] - 0s 850us/step - loss: 2.8954 - mae: 2.8954 - val_loss: 2.7475 - val_mae: 2.7475\n",
      "Epoch 8/300\n",
      "515/515 [==============================] - 0s 783us/step - loss: 2.8583 - mae: 2.8583 - val_loss: 2.7391 - val_mae: 2.7391\n",
      "Epoch 9/300\n",
      "515/515 [==============================] - 0s 800us/step - loss: 2.8281 - mae: 2.8281 - val_loss: 2.6883 - val_mae: 2.6883\n",
      "Epoch 10/300\n",
      "515/515 [==============================] - 0s 832us/step - loss: 2.7983 - mae: 2.7983 - val_loss: 2.6395 - val_mae: 2.6395\n",
      "Epoch 11/300\n",
      "515/515 [==============================] - 0s 793us/step - loss: 2.7934 - mae: 2.7934 - val_loss: 2.6583 - val_mae: 2.6583\n",
      "Epoch 12/300\n",
      "515/515 [==============================] - 0s 800us/step - loss: 2.7637 - mae: 2.7637 - val_loss: 2.6396 - val_mae: 2.6396\n",
      "Epoch 13/300\n",
      "515/515 [==============================] - 0s 803us/step - loss: 2.7470 - mae: 2.7470 - val_loss: 2.6499 - val_mae: 2.6499\n",
      "Epoch 14/300\n",
      "515/515 [==============================] - 0s 801us/step - loss: 2.7406 - mae: 2.7406 - val_loss: 2.6100 - val_mae: 2.6100\n",
      "Epoch 15/300\n",
      "515/515 [==============================] - 0s 785us/step - loss: 2.7318 - mae: 2.7318 - val_loss: 2.5919 - val_mae: 2.5919\n",
      "Epoch 16/300\n",
      "515/515 [==============================] - 0s 786us/step - loss: 2.7289 - mae: 2.7289 - val_loss: 2.6297 - val_mae: 2.6297\n",
      "Epoch 17/300\n",
      "515/515 [==============================] - 0s 784us/step - loss: 2.7147 - mae: 2.7147 - val_loss: 2.6384 - val_mae: 2.6384\n",
      "Epoch 18/300\n",
      "515/515 [==============================] - 0s 818us/step - loss: 2.7127 - mae: 2.7127 - val_loss: 2.6016 - val_mae: 2.6016\n",
      "Epoch 19/300\n",
      "515/515 [==============================] - 0s 892us/step - loss: 2.7119 - mae: 2.7119 - val_loss: 2.6737 - val_mae: 2.6737\n",
      "Epoch 20/300\n",
      "515/515 [==============================] - 0s 844us/step - loss: 2.7025 - mae: 2.7025 - val_loss: 2.5766 - val_mae: 2.5766\n",
      "Epoch 21/300\n",
      "515/515 [==============================] - 0s 814us/step - loss: 2.6998 - mae: 2.6998 - val_loss: 2.6061 - val_mae: 2.6061\n",
      "Epoch 22/300\n",
      "515/515 [==============================] - 0s 818us/step - loss: 2.6932 - mae: 2.6932 - val_loss: 2.5938 - val_mae: 2.5938\n",
      "Epoch 23/300\n",
      "515/515 [==============================] - 0s 836us/step - loss: 2.6940 - mae: 2.6940 - val_loss: 2.5875 - val_mae: 2.5875\n",
      "Epoch 24/300\n",
      "515/515 [==============================] - 0s 856us/step - loss: 2.6922 - mae: 2.6922 - val_loss: 2.6304 - val_mae: 2.6304\n",
      "Epoch 25/300\n",
      "515/515 [==============================] - 0s 832us/step - loss: 2.6943 - mae: 2.6943 - val_loss: 2.5939 - val_mae: 2.5939\n",
      "Epoch 26/300\n",
      "515/515 [==============================] - 0s 789us/step - loss: 2.6844 - mae: 2.6844 - val_loss: 2.6420 - val_mae: 2.6420\n",
      "Epoch 27/300\n",
      "515/515 [==============================] - 0s 779us/step - loss: 2.6836 - mae: 2.6836 - val_loss: 2.5917 - val_mae: 2.5917\n",
      "Epoch 28/300\n",
      "515/515 [==============================] - 0s 803us/step - loss: 2.6794 - mae: 2.6794 - val_loss: 2.5644 - val_mae: 2.5644\n",
      "Epoch 29/300\n",
      "515/515 [==============================] - 0s 814us/step - loss: 2.6818 - mae: 2.6818 - val_loss: 2.6197 - val_mae: 2.6197\n",
      "Epoch 30/300\n",
      "515/515 [==============================] - 0s 819us/step - loss: 2.6800 - mae: 2.6800 - val_loss: 2.5672 - val_mae: 2.5672\n",
      "Epoch 31/300\n",
      "515/515 [==============================] - 0s 818us/step - loss: 2.6740 - mae: 2.6740 - val_loss: 2.5710 - val_mae: 2.5710\n",
      "Epoch 32/300\n",
      "515/515 [==============================] - 0s 815us/step - loss: 2.6728 - mae: 2.6728 - val_loss: 2.5953 - val_mae: 2.5953\n",
      "Epoch 33/300\n",
      "515/515 [==============================] - 0s 821us/step - loss: 2.6725 - mae: 2.6725 - val_loss: 2.5600 - val_mae: 2.5600\n",
      "Epoch 34/300\n",
      "515/515 [==============================] - 0s 780us/step - loss: 2.6705 - mae: 2.6705 - val_loss: 2.5634 - val_mae: 2.5634\n",
      "Epoch 35/300\n",
      "515/515 [==============================] - 0s 784us/step - loss: 2.6736 - mae: 2.6736 - val_loss: 2.5602 - val_mae: 2.5602\n",
      "Epoch 36/300\n",
      "515/515 [==============================] - 0s 784us/step - loss: 2.6700 - mae: 2.6700 - val_loss: 2.5603 - val_mae: 2.5603\n",
      "Epoch 37/300\n",
      "515/515 [==============================] - 0s 783us/step - loss: 2.6604 - mae: 2.6604 - val_loss: 2.5636 - val_mae: 2.5636\n",
      "Epoch 38/300\n",
      "515/515 [==============================] - 0s 788us/step - loss: 2.6633 - mae: 2.6633 - val_loss: 2.5834 - val_mae: 2.5834\n",
      "Epoch 39/300\n",
      "515/515 [==============================] - 0s 770us/step - loss: 2.6645 - mae: 2.6645 - val_loss: 2.5646 - val_mae: 2.5646\n",
      "Epoch 40/300\n",
      "515/515 [==============================] - 0s 782us/step - loss: 2.6543 - mae: 2.6543 - val_loss: 2.5532 - val_mae: 2.5532\n",
      "Epoch 41/300\n",
      "515/515 [==============================] - 0s 777us/step - loss: 2.6576 - mae: 2.6576 - val_loss: 2.6439 - val_mae: 2.6439\n",
      "Epoch 42/300\n",
      "515/515 [==============================] - 0s 781us/step - loss: 2.6562 - mae: 2.6562 - val_loss: 2.5424 - val_mae: 2.5424\n",
      "Epoch 43/300\n",
      "515/515 [==============================] - 0s 775us/step - loss: 2.6560 - mae: 2.6560 - val_loss: 2.5401 - val_mae: 2.5401\n",
      "Epoch 44/300\n",
      "515/515 [==============================] - 0s 913us/step - loss: 2.6601 - mae: 2.6601 - val_loss: 2.5846 - val_mae: 2.5846\n",
      "Epoch 45/300\n",
      "515/515 [==============================] - 0s 916us/step - loss: 2.6491 - mae: 2.6491 - val_loss: 2.5668 - val_mae: 2.5668\n",
      "Epoch 46/300\n",
      "515/515 [==============================] - 0s 814us/step - loss: 2.6569 - mae: 2.6569 - val_loss: 2.5489 - val_mae: 2.5489\n",
      "Epoch 47/300\n",
      "515/515 [==============================] - 0s 832us/step - loss: 2.6548 - mae: 2.6548 - val_loss: 2.5988 - val_mae: 2.5988\n",
      "Epoch 48/300\n",
      "515/515 [==============================] - 0s 836us/step - loss: 2.6511 - mae: 2.6511 - val_loss: 2.5407 - val_mae: 2.5407\n",
      "Epoch 49/300\n",
      "515/515 [==============================] - 0s 820us/step - loss: 2.6519 - mae: 2.6519 - val_loss: 2.5809 - val_mae: 2.5809\n",
      "Epoch 50/300\n",
      "515/515 [==============================] - 0s 827us/step - loss: 2.6510 - mae: 2.6510 - val_loss: 2.5412 - val_mae: 2.5412\n",
      "Epoch 51/300\n",
      "515/515 [==============================] - 0s 779us/step - loss: 2.6456 - mae: 2.6456 - val_loss: 2.5472 - val_mae: 2.5472\n",
      "Epoch 52/300\n",
      "515/515 [==============================] - 0s 777us/step - loss: 2.6471 - mae: 2.6471 - val_loss: 2.5272 - val_mae: 2.5272\n",
      "Epoch 53/300\n",
      "515/515 [==============================] - 0s 776us/step - loss: 2.6412 - mae: 2.6412 - val_loss: 2.5539 - val_mae: 2.5539\n",
      "Epoch 54/300\n",
      "515/515 [==============================] - 0s 776us/step - loss: 2.6536 - mae: 2.6536 - val_loss: 2.5577 - val_mae: 2.5577\n",
      "Epoch 55/300\n",
      "515/515 [==============================] - 0s 780us/step - loss: 2.6419 - mae: 2.6419 - val_loss: 2.5306 - val_mae: 2.5306\n",
      "Epoch 56/300\n",
      "515/515 [==============================] - 0s 776us/step - loss: 2.6427 - mae: 2.6427 - val_loss: 2.5282 - val_mae: 2.5282\n",
      "Epoch 57/300\n",
      "515/515 [==============================] - 0s 781us/step - loss: 2.6394 - mae: 2.6394 - val_loss: 2.5478 - val_mae: 2.5478\n",
      "Epoch 58/300\n",
      "515/515 [==============================] - 0s 792us/step - loss: 2.6422 - mae: 2.6422 - val_loss: 2.5358 - val_mae: 2.5358\n",
      "Epoch 59/300\n",
      "515/515 [==============================] - 0s 802us/step - loss: 2.6450 - mae: 2.6450 - val_loss: 2.5716 - val_mae: 2.5716\n",
      "Epoch 60/300\n",
      "515/515 [==============================] - 0s 868us/step - loss: 2.6467 - mae: 2.6467 - val_loss: 2.5305 - val_mae: 2.5305\n",
      "Epoch 61/300\n",
      "515/515 [==============================] - 0s 844us/step - loss: 2.6432 - mae: 2.6432 - val_loss: 2.6208 - val_mae: 2.6208\n",
      "Epoch 62/300\n",
      "515/515 [==============================] - 0s 795us/step - loss: 2.6398 - mae: 2.6398 - val_loss: 2.5280 - val_mae: 2.5280\n",
      "Epoch 63/300\n",
      "515/515 [==============================] - 0s 808us/step - loss: 2.6382 - mae: 2.6382 - val_loss: 2.5330 - val_mae: 2.5330\n",
      "Epoch 64/300\n",
      "515/515 [==============================] - 0s 807us/step - loss: 2.6376 - mae: 2.6376 - val_loss: 2.5379 - val_mae: 2.5379\n",
      "Epoch 65/300\n",
      "515/515 [==============================] - 0s 799us/step - loss: 2.6301 - mae: 2.6301 - val_loss: 2.5361 - val_mae: 2.5361\n",
      "Epoch 66/300\n",
      "515/515 [==============================] - 0s 809us/step - loss: 2.6331 - mae: 2.6331 - val_loss: 2.5357 - val_mae: 2.5357\n",
      "Epoch 67/300\n",
      "515/515 [==============================] - 0s 824us/step - loss: 2.6366 - mae: 2.6366 - val_loss: 2.5343 - val_mae: 2.5343\n",
      "Epoch 68/300\n",
      "515/515 [==============================] - 0s 811us/step - loss: 2.6330 - mae: 2.6330 - val_loss: 2.6710 - val_mae: 2.6710\n",
      "Epoch 69/300\n",
      "515/515 [==============================] - 0s 936us/step - loss: 2.6386 - mae: 2.6386 - val_loss: 2.5343 - val_mae: 2.5343\n",
      "Epoch 70/300\n",
      "515/515 [==============================] - 0s 819us/step - loss: 2.6322 - mae: 2.6322 - val_loss: 2.5533 - val_mae: 2.5533\n",
      "Epoch 71/300\n",
      "515/515 [==============================] - 0s 846us/step - loss: 2.6334 - mae: 2.6334 - val_loss: 2.5765 - val_mae: 2.5765\n",
      "Epoch 72/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.6364 - mae: 2.6364 - val_loss: 2.5248 - val_mae: 2.5248\n",
      "Epoch 73/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.6338 - mae: 2.6338 - val_loss: 2.5725 - val_mae: 2.5725\n",
      "Epoch 74/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.6306 - mae: 2.6306 - val_loss: 2.5256 - val_mae: 2.5256\n",
      "Epoch 75/300\n",
      "515/515 [==============================] - 0s 845us/step - loss: 2.6261 - mae: 2.6261 - val_loss: 2.5565 - val_mae: 2.5565\n",
      "Epoch 76/300\n",
      "515/515 [==============================] - 0s 877us/step - loss: 2.6281 - mae: 2.6281 - val_loss: 2.5270 - val_mae: 2.5270\n",
      "Epoch 77/300\n",
      "515/515 [==============================] - 0s 820us/step - loss: 2.6300 - mae: 2.6300 - val_loss: 2.5379 - val_mae: 2.5379\n",
      "Epoch 78/300\n",
      "515/515 [==============================] - 0s 792us/step - loss: 2.6257 - mae: 2.6257 - val_loss: 2.5244 - val_mae: 2.5244\n",
      "Epoch 79/300\n",
      "515/515 [==============================] - 0s 826us/step - loss: 2.6244 - mae: 2.6244 - val_loss: 2.5348 - val_mae: 2.5348\n",
      "Epoch 80/300\n",
      "515/515 [==============================] - 0s 793us/step - loss: 2.6215 - mae: 2.6215 - val_loss: 2.5124 - val_mae: 2.5124\n",
      "Epoch 81/300\n",
      "515/515 [==============================] - 0s 808us/step - loss: 2.6249 - mae: 2.6249 - val_loss: 2.5247 - val_mae: 2.5247\n",
      "Epoch 82/300\n",
      "515/515 [==============================] - 0s 856us/step - loss: 2.6263 - mae: 2.6263 - val_loss: 2.5266 - val_mae: 2.5266\n",
      "Epoch 83/300\n",
      "515/515 [==============================] - 0s 776us/step - loss: 2.6243 - mae: 2.6243 - val_loss: 2.5405 - val_mae: 2.5405\n",
      "Epoch 84/300\n",
      "515/515 [==============================] - 0s 821us/step - loss: 2.6269 - mae: 2.6269 - val_loss: 2.5555 - val_mae: 2.5555\n",
      "Epoch 85/300\n",
      "515/515 [==============================] - 0s 802us/step - loss: 2.6131 - mae: 2.6131 - val_loss: 2.5144 - val_mae: 2.5144\n",
      "Epoch 86/300\n",
      "515/515 [==============================] - 0s 784us/step - loss: 2.6206 - mae: 2.6206 - val_loss: 2.5067 - val_mae: 2.5067\n",
      "Epoch 87/300\n",
      "515/515 [==============================] - 0s 774us/step - loss: 2.6275 - mae: 2.6275 - val_loss: 2.5101 - val_mae: 2.5101\n",
      "Epoch 88/300\n",
      "515/515 [==============================] - 0s 804us/step - loss: 2.6214 - mae: 2.6214 - val_loss: 2.5355 - val_mae: 2.5355\n",
      "Epoch 89/300\n",
      "515/515 [==============================] - 0s 804us/step - loss: 2.6228 - mae: 2.6228 - val_loss: 2.4999 - val_mae: 2.4999\n",
      "Epoch 90/300\n",
      "515/515 [==============================] - 0s 788us/step - loss: 2.6266 - mae: 2.6266 - val_loss: 2.5466 - val_mae: 2.5466\n",
      "Epoch 91/300\n",
      "515/515 [==============================] - 0s 808us/step - loss: 2.6176 - mae: 2.6176 - val_loss: 2.5171 - val_mae: 2.5171\n",
      "Epoch 92/300\n",
      "515/515 [==============================] - 0s 912us/step - loss: 2.6158 - mae: 2.6158 - val_loss: 2.5072 - val_mae: 2.5072\n",
      "Epoch 93/300\n",
      "515/515 [==============================] - 0s 837us/step - loss: 2.6185 - mae: 2.6185 - val_loss: 2.5248 - val_mae: 2.5248\n",
      "Epoch 94/300\n",
      "515/515 [==============================] - 0s 853us/step - loss: 2.6191 - mae: 2.6191 - val_loss: 2.5417 - val_mae: 2.5417\n",
      "Epoch 95/300\n",
      "515/515 [==============================] - 0s 834us/step - loss: 2.6188 - mae: 2.6188 - val_loss: 2.4971 - val_mae: 2.4971\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "force_train, force_test, theta_x_train, theta_x_test, theta_y_train, theta_y_test = train_test_split(force_leo_bmi, theta_x_leo, theta_y_leo, test_size = 0.2, random_state = 0)\n",
    "import tensorflow as tf\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 10, restore_best_weights = True)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(6,)),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss= 'mae',\n",
    "              metrics=['mae'])\n",
    "\n",
    "history = model.fit(force_train, [theta_x_train, theta_y_train], epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (force_test, [theta_x_test, theta_y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "231/231 [==============================] - 0s 989us/step - loss: 3.6981 - mae: 3.6981 - val_loss: 3.3305 - val_mae: 3.3305\n",
      "Epoch 2/300\n",
      "231/231 [==============================] - 0s 913us/step - loss: 3.4892 - mae: 3.4892 - val_loss: 3.3364 - val_mae: 3.3364\n",
      "Epoch 3/300\n",
      "231/231 [==============================] - 0s 889us/step - loss: 3.4664 - mae: 3.4664 - val_loss: 3.3449 - val_mae: 3.3449\n",
      "Epoch 4/300\n",
      "231/231 [==============================] - 0s 886us/step - loss: 3.4251 - mae: 3.4251 - val_loss: 3.3115 - val_mae: 3.3115\n",
      "Epoch 5/300\n",
      "231/231 [==============================] - 0s 975us/step - loss: 3.3976 - mae: 3.3976 - val_loss: 3.2524 - val_mae: 3.2524\n",
      "Epoch 6/300\n",
      "231/231 [==============================] - 0s 919us/step - loss: 3.4050 - mae: 3.4050 - val_loss: 3.2636 - val_mae: 3.2636\n",
      "Epoch 7/300\n",
      "231/231 [==============================] - 0s 836us/step - loss: 3.3856 - mae: 3.3856 - val_loss: 3.2436 - val_mae: 3.2436\n",
      "Epoch 8/300\n",
      "231/231 [==============================] - 0s 811us/step - loss: 3.3868 - mae: 3.3868 - val_loss: 3.2516 - val_mae: 3.2516\n",
      "Epoch 9/300\n",
      "231/231 [==============================] - 0s 827us/step - loss: 3.3819 - mae: 3.3819 - val_loss: 3.2689 - val_mae: 3.2689\n",
      "Epoch 10/300\n",
      "231/231 [==============================] - 0s 854us/step - loss: 3.3508 - mae: 3.3508 - val_loss: 3.2389 - val_mae: 3.2389\n",
      "Epoch 11/300\n",
      "231/231 [==============================] - 0s 829us/step - loss: 3.3562 - mae: 3.3562 - val_loss: 3.2163 - val_mae: 3.2163\n",
      "Epoch 12/300\n",
      "231/231 [==============================] - 0s 862us/step - loss: 3.3371 - mae: 3.3371 - val_loss: 3.2553 - val_mae: 3.2553\n",
      "Epoch 13/300\n",
      "231/231 [==============================] - 0s 859us/step - loss: 3.3488 - mae: 3.3488 - val_loss: 3.2383 - val_mae: 3.2383\n",
      "Epoch 14/300\n",
      "231/231 [==============================] - 0s 842us/step - loss: 3.3469 - mae: 3.3469 - val_loss: 3.2032 - val_mae: 3.2032\n",
      "Epoch 15/300\n",
      "231/231 [==============================] - 0s 836us/step - loss: 3.3355 - mae: 3.3355 - val_loss: 3.2166 - val_mae: 3.2166\n",
      "Epoch 16/300\n",
      "231/231 [==============================] - 0s 850us/step - loss: 3.3261 - mae: 3.3261 - val_loss: 3.1953 - val_mae: 3.1953\n",
      "Epoch 17/300\n",
      "231/231 [==============================] - 0s 870us/step - loss: 3.3320 - mae: 3.3320 - val_loss: 3.2624 - val_mae: 3.2624\n",
      "Epoch 18/300\n",
      "231/231 [==============================] - 0s 847us/step - loss: 3.3237 - mae: 3.3237 - val_loss: 3.1903 - val_mae: 3.1903\n",
      "Epoch 19/300\n",
      "231/231 [==============================] - 0s 859us/step - loss: 3.3135 - mae: 3.3135 - val_loss: 3.2209 - val_mae: 3.2209\n",
      "Epoch 20/300\n",
      "231/231 [==============================] - 0s 885us/step - loss: 3.3234 - mae: 3.3234 - val_loss: 3.2423 - val_mae: 3.2423\n",
      "Epoch 21/300\n",
      "231/231 [==============================] - 0s 844us/step - loss: 3.3067 - mae: 3.3067 - val_loss: 3.2444 - val_mae: 3.2444\n",
      "Epoch 22/300\n",
      "231/231 [==============================] - 0s 853us/step - loss: 3.3001 - mae: 3.3001 - val_loss: 3.1813 - val_mae: 3.1813\n",
      "Epoch 23/300\n",
      "231/231 [==============================] - 0s 870us/step - loss: 3.2910 - mae: 3.2910 - val_loss: 3.1772 - val_mae: 3.1772\n",
      "Epoch 24/300\n",
      "231/231 [==============================] - 0s 835us/step - loss: 3.2969 - mae: 3.2969 - val_loss: 3.2107 - val_mae: 3.2107\n",
      "Epoch 25/300\n",
      "231/231 [==============================] - 0s 853us/step - loss: 3.3025 - mae: 3.3025 - val_loss: 3.2113 - val_mae: 3.2113\n",
      "Epoch 26/300\n",
      "231/231 [==============================] - 0s 879us/step - loss: 3.3016 - mae: 3.3016 - val_loss: 3.1761 - val_mae: 3.1761\n",
      "Epoch 27/300\n",
      "231/231 [==============================] - 0s 949us/step - loss: 3.2914 - mae: 3.2914 - val_loss: 3.2031 - val_mae: 3.2031\n",
      "Epoch 28/300\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 3.2806 - mae: 3.2806 - val_loss: 3.1837 - val_mae: 3.1837\n",
      "Epoch 29/300\n",
      "231/231 [==============================] - 0s 881us/step - loss: 3.2850 - mae: 3.2850 - val_loss: 3.1863 - val_mae: 3.1863\n",
      "Epoch 30/300\n",
      "231/231 [==============================] - 0s 841us/step - loss: 3.2794 - mae: 3.2794 - val_loss: 3.2050 - val_mae: 3.2050\n",
      "Epoch 31/300\n",
      "231/231 [==============================] - 0s 871us/step - loss: 3.2712 - mae: 3.2712 - val_loss: 3.1522 - val_mae: 3.1522\n",
      "Epoch 32/300\n",
      "231/231 [==============================] - 0s 870us/step - loss: 3.2724 - mae: 3.2724 - val_loss: 3.1484 - val_mae: 3.1484\n",
      "Epoch 33/300\n",
      "231/231 [==============================] - 0s 837us/step - loss: 3.2697 - mae: 3.2697 - val_loss: 3.1840 - val_mae: 3.1840\n",
      "Epoch 34/300\n",
      "231/231 [==============================] - 0s 819us/step - loss: 3.2784 - mae: 3.2784 - val_loss: 3.2244 - val_mae: 3.2244\n",
      "Epoch 35/300\n",
      "231/231 [==============================] - 0s 826us/step - loss: 3.2633 - mae: 3.2633 - val_loss: 3.1313 - val_mae: 3.1313\n",
      "Epoch 36/300\n",
      "231/231 [==============================] - 0s 819us/step - loss: 3.2829 - mae: 3.2829 - val_loss: 3.1505 - val_mae: 3.1505\n",
      "Epoch 37/300\n",
      "231/231 [==============================] - 0s 824us/step - loss: 3.2588 - mae: 3.2588 - val_loss: 3.1714 - val_mae: 3.1714\n",
      "Epoch 38/300\n",
      "231/231 [==============================] - 0s 898us/step - loss: 3.2652 - mae: 3.2652 - val_loss: 3.1497 - val_mae: 3.1497\n",
      "Epoch 39/300\n",
      "231/231 [==============================] - 0s 857us/step - loss: 3.2585 - mae: 3.2585 - val_loss: 3.1312 - val_mae: 3.1312\n",
      "Epoch 40/300\n",
      "231/231 [==============================] - 0s 822us/step - loss: 3.2664 - mae: 3.2664 - val_loss: 3.1613 - val_mae: 3.1613\n",
      "Epoch 41/300\n",
      "231/231 [==============================] - 0s 826us/step - loss: 3.2555 - mae: 3.2555 - val_loss: 3.1436 - val_mae: 3.1436\n",
      "Epoch 42/300\n",
      "231/231 [==============================] - 0s 837us/step - loss: 3.2562 - mae: 3.2562 - val_loss: 3.1684 - val_mae: 3.1684\n",
      "Epoch 43/300\n",
      "231/231 [==============================] - 0s 940us/step - loss: 3.2451 - mae: 3.2451 - val_loss: 3.1331 - val_mae: 3.1331\n",
      "Epoch 44/300\n",
      "231/231 [==============================] - 0s 951us/step - loss: 3.2363 - mae: 3.2363 - val_loss: 3.2036 - val_mae: 3.2036\n",
      "Epoch 45/300\n",
      "231/231 [==============================] - 0s 955us/step - loss: 3.2458 - mae: 3.2458 - val_loss: 3.1520 - val_mae: 3.1520\n",
      "Epoch 46/300\n",
      "231/231 [==============================] - 0s 937us/step - loss: 3.2506 - mae: 3.2506 - val_loss: 3.1914 - val_mae: 3.1914\n",
      "Epoch 47/300\n",
      "231/231 [==============================] - 0s 940us/step - loss: 3.2385 - mae: 3.2385 - val_loss: 3.1162 - val_mae: 3.1162\n",
      "Epoch 48/300\n",
      "231/231 [==============================] - 0s 997us/step - loss: 3.2321 - mae: 3.2321 - val_loss: 3.1456 - val_mae: 3.1456\n",
      "Epoch 49/300\n",
      "231/231 [==============================] - 0s 988us/step - loss: 3.2357 - mae: 3.2357 - val_loss: 3.1318 - val_mae: 3.1318\n",
      "Epoch 50/300\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 3.2295 - mae: 3.2295 - val_loss: 3.1439 - val_mae: 3.1439\n",
      "Epoch 51/300\n",
      "231/231 [==============================] - 0s 971us/step - loss: 3.2440 - mae: 3.2440 - val_loss: 3.1430 - val_mae: 3.1430\n",
      "Epoch 52/300\n",
      "231/231 [==============================] - 0s 944us/step - loss: 3.2267 - mae: 3.2267 - val_loss: 3.1305 - val_mae: 3.1305\n",
      "Epoch 53/300\n",
      "231/231 [==============================] - 0s 920us/step - loss: 3.2237 - mae: 3.2237 - val_loss: 3.1437 - val_mae: 3.1437\n",
      "Epoch 54/300\n",
      "231/231 [==============================] - 0s 900us/step - loss: 3.2335 - mae: 3.2335 - val_loss: 3.1165 - val_mae: 3.1165\n",
      "Epoch 55/300\n",
      "231/231 [==============================] - 0s 893us/step - loss: 3.2102 - mae: 3.2102 - val_loss: 3.1583 - val_mae: 3.1583\n",
      "Epoch 56/300\n",
      "231/231 [==============================] - 0s 948us/step - loss: 3.2220 - mae: 3.2220 - val_loss: 3.1213 - val_mae: 3.1213\n",
      "Epoch 57/300\n",
      "231/231 [==============================] - 0s 931us/step - loss: 3.2201 - mae: 3.2201 - val_loss: 3.0861 - val_mae: 3.0861\n",
      "Epoch 58/300\n",
      "231/231 [==============================] - 0s 883us/step - loss: 3.2263 - mae: 3.2263 - val_loss: 3.1122 - val_mae: 3.1122\n",
      "Epoch 59/300\n",
      "231/231 [==============================] - 0s 832us/step - loss: 3.2160 - mae: 3.2160 - val_loss: 3.1744 - val_mae: 3.1744\n",
      "Epoch 60/300\n",
      "231/231 [==============================] - 0s 870us/step - loss: 3.2210 - mae: 3.2210 - val_loss: 3.1003 - val_mae: 3.1003\n",
      "Epoch 61/300\n",
      "231/231 [==============================] - 0s 850us/step - loss: 3.2153 - mae: 3.2153 - val_loss: 3.1373 - val_mae: 3.1373\n",
      "Epoch 62/300\n",
      "231/231 [==============================] - 0s 837us/step - loss: 3.2197 - mae: 3.2197 - val_loss: 3.1000 - val_mae: 3.1000\n",
      "Epoch 63/300\n",
      "231/231 [==============================] - 0s 976us/step - loss: 3.2045 - mae: 3.2045 - val_loss: 3.1093 - val_mae: 3.1093\n",
      "Epoch 64/300\n",
      "231/231 [==============================] - 0s 873us/step - loss: 3.2135 - mae: 3.2135 - val_loss: 3.0923 - val_mae: 3.0923\n",
      "Epoch 65/300\n",
      "231/231 [==============================] - 0s 873us/step - loss: 3.2087 - mae: 3.2087 - val_loss: 3.1391 - val_mae: 3.1391\n",
      "Epoch 66/300\n",
      "231/231 [==============================] - 0s 869us/step - loss: 3.2058 - mae: 3.2058 - val_loss: 3.1133 - val_mae: 3.1133\n",
      "Epoch 67/300\n",
      "231/231 [==============================] - 0s 868us/step - loss: 3.2069 - mae: 3.2069 - val_loss: 3.1530 - val_mae: 3.1530\n",
      "Epoch 68/300\n",
      "231/231 [==============================] - 0s 879us/step - loss: 3.2044 - mae: 3.2044 - val_loss: 3.1345 - val_mae: 3.1345\n",
      "Epoch 69/300\n",
      "231/231 [==============================] - 0s 833us/step - loss: 3.2066 - mae: 3.2066 - val_loss: 3.1056 - val_mae: 3.1056\n",
      "Epoch 70/300\n",
      "231/231 [==============================] - 0s 871us/step - loss: 3.2026 - mae: 3.2026 - val_loss: 3.0792 - val_mae: 3.0792\n",
      "Epoch 71/300\n",
      "231/231 [==============================] - 0s 882us/step - loss: 3.1939 - mae: 3.1939 - val_loss: 3.1058 - val_mae: 3.1058\n",
      "Epoch 72/300\n",
      "231/231 [==============================] - 0s 866us/step - loss: 3.1952 - mae: 3.1952 - val_loss: 3.1371 - val_mae: 3.1371\n",
      "Epoch 73/300\n",
      "231/231 [==============================] - 0s 903us/step - loss: 3.1954 - mae: 3.1954 - val_loss: 3.1265 - val_mae: 3.1265\n",
      "Epoch 74/300\n",
      "231/231 [==============================] - 0s 878us/step - loss: 3.1942 - mae: 3.1942 - val_loss: 3.0868 - val_mae: 3.0868\n",
      "Epoch 75/300\n",
      "231/231 [==============================] - 0s 882us/step - loss: 3.1905 - mae: 3.1905 - val_loss: 3.1078 - val_mae: 3.1078\n",
      "Epoch 76/300\n",
      "231/231 [==============================] - 0s 918us/step - loss: 3.1943 - mae: 3.1943 - val_loss: 3.0874 - val_mae: 3.0874\n",
      "Epoch 77/300\n",
      "231/231 [==============================] - 0s 903us/step - loss: 3.1857 - mae: 3.1857 - val_loss: 3.0922 - val_mae: 3.0922\n",
      "Epoch 78/300\n",
      "231/231 [==============================] - 0s 886us/step - loss: 3.1887 - mae: 3.1887 - val_loss: 3.1469 - val_mae: 3.1469\n",
      "Epoch 79/300\n",
      "231/231 [==============================] - 0s 849us/step - loss: 3.1864 - mae: 3.1864 - val_loss: 3.0732 - val_mae: 3.0732\n",
      "Epoch 80/300\n",
      "231/231 [==============================] - 0s 842us/step - loss: 3.1811 - mae: 3.1811 - val_loss: 3.1640 - val_mae: 3.1640\n",
      "Epoch 81/300\n",
      "231/231 [==============================] - 0s 841us/step - loss: 3.1900 - mae: 3.1900 - val_loss: 3.1271 - val_mae: 3.1271\n",
      "Epoch 82/300\n",
      "231/231 [==============================] - 0s 881us/step - loss: 3.1838 - mae: 3.1838 - val_loss: 3.0915 - val_mae: 3.0915\n",
      "Epoch 83/300\n",
      "231/231 [==============================] - 0s 881us/step - loss: 3.1852 - mae: 3.1852 - val_loss: 3.0953 - val_mae: 3.0953\n",
      "Epoch 84/300\n",
      "231/231 [==============================] - 0s 939us/step - loss: 3.1725 - mae: 3.1725 - val_loss: 3.0817 - val_mae: 3.0817\n",
      "Epoch 85/300\n",
      "231/231 [==============================] - 0s 930us/step - loss: 3.1868 - mae: 3.1868 - val_loss: 3.1092 - val_mae: 3.1092\n",
      "Epoch 86/300\n",
      "231/231 [==============================] - 0s 868us/step - loss: 3.1706 - mae: 3.1706 - val_loss: 3.0791 - val_mae: 3.0791\n",
      "Epoch 87/300\n",
      "231/231 [==============================] - 0s 841us/step - loss: 3.1668 - mae: 3.1668 - val_loss: 3.0871 - val_mae: 3.0871\n",
      "Epoch 88/300\n",
      "231/231 [==============================] - 0s 846us/step - loss: 3.1524 - mae: 3.1524 - val_loss: 3.0829 - val_mae: 3.0829\n",
      "Epoch 89/300\n",
      "231/231 [==============================] - 0s 874us/step - loss: 3.1707 - mae: 3.1707 - val_loss: 3.1135 - val_mae: 3.1135\n",
      "Epoch 90/300\n",
      "231/231 [==============================] - 0s 866us/step - loss: 3.1737 - mae: 3.1737 - val_loss: 3.0962 - val_mae: 3.0962\n",
      "Epoch 91/300\n",
      "231/231 [==============================] - 0s 898us/step - loss: 3.1698 - mae: 3.1698 - val_loss: 3.0598 - val_mae: 3.0598\n",
      "Epoch 92/300\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 3.1658 - mae: 3.1658 - val_loss: 3.0940 - val_mae: 3.0940\n",
      "Epoch 93/300\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 3.1601 - mae: 3.1601 - val_loss: 3.1070 - val_mae: 3.1070\n",
      "Epoch 94/300\n",
      "231/231 [==============================] - 0s 944us/step - loss: 3.1683 - mae: 3.1683 - val_loss: 3.1319 - val_mae: 3.1319\n",
      "Epoch 95/300\n",
      "231/231 [==============================] - 0s 931us/step - loss: 3.1653 - mae: 3.1653 - val_loss: 3.1118 - val_mae: 3.1118\n",
      "Epoch 96/300\n",
      "231/231 [==============================] - 0s 915us/step - loss: 3.1555 - mae: 3.1555 - val_loss: 3.1012 - val_mae: 3.1012\n",
      "Epoch 97/300\n",
      "231/231 [==============================] - 0s 933us/step - loss: 3.1518 - mae: 3.1518 - val_loss: 3.1191 - val_mae: 3.1191\n",
      "Epoch 98/300\n",
      "231/231 [==============================] - 0s 947us/step - loss: 3.1668 - mae: 3.1668 - val_loss: 3.0577 - val_mae: 3.0577\n",
      "Epoch 99/300\n",
      "231/231 [==============================] - 0s 910us/step - loss: 3.1636 - mae: 3.1636 - val_loss: 3.1165 - val_mae: 3.1165\n",
      "Epoch 100/300\n",
      "231/231 [==============================] - 0s 987us/step - loss: 3.1665 - mae: 3.1665 - val_loss: 3.0719 - val_mae: 3.0719\n",
      "Epoch 101/300\n",
      "231/231 [==============================] - 0s 957us/step - loss: 3.1605 - mae: 3.1605 - val_loss: 3.0469 - val_mae: 3.0469\n",
      "Epoch 102/300\n",
      "231/231 [==============================] - 0s 944us/step - loss: 3.1541 - mae: 3.1541 - val_loss: 3.0590 - val_mae: 3.0590\n",
      "Epoch 103/300\n",
      "231/231 [==============================] - 0s 891us/step - loss: 3.1621 - mae: 3.1621 - val_loss: 3.0685 - val_mae: 3.0685\n",
      "Epoch 104/300\n",
      "231/231 [==============================] - 0s 904us/step - loss: 3.1385 - mae: 3.1385 - val_loss: 3.0778 - val_mae: 3.0778\n",
      "Epoch 105/300\n",
      "231/231 [==============================] - 0s 1000us/step - loss: 3.1545 - mae: 3.1545 - val_loss: 3.0945 - val_mae: 3.0945\n",
      "Epoch 106/300\n",
      "231/231 [==============================] - 0s 949us/step - loss: 3.1521 - mae: 3.1521 - val_loss: 3.0655 - val_mae: 3.0655\n",
      "Epoch 107/300\n",
      "231/231 [==============================] - 0s 880us/step - loss: 3.1359 - mae: 3.1359 - val_loss: 3.0884 - val_mae: 3.0884\n",
      "Epoch 108/300\n",
      "231/231 [==============================] - 0s 854us/step - loss: 3.1427 - mae: 3.1427 - val_loss: 3.0727 - val_mae: 3.0727\n",
      "Epoch 109/300\n",
      "231/231 [==============================] - 0s 909us/step - loss: 3.1426 - mae: 3.1426 - val_loss: 3.1229 - val_mae: 3.1229\n",
      "Epoch 110/300\n",
      "231/231 [==============================] - 0s 900us/step - loss: 3.1583 - mae: 3.1583 - val_loss: 3.0804 - val_mae: 3.0804\n",
      "Epoch 111/300\n",
      "231/231 [==============================] - 0s 881us/step - loss: 3.1355 - mae: 3.1355 - val_loss: 3.1513 - val_mae: 3.1513\n",
      "Epoch 112/300\n",
      "231/231 [==============================] - 0s 883us/step - loss: 3.1575 - mae: 3.1575 - val_loss: 3.0569 - val_mae: 3.0569\n",
      "Epoch 113/300\n",
      "231/231 [==============================] - 0s 851us/step - loss: 3.1515 - mae: 3.1515 - val_loss: 3.0906 - val_mae: 3.0906\n",
      "Epoch 114/300\n",
      "231/231 [==============================] - 0s 902us/step - loss: 3.1475 - mae: 3.1475 - val_loss: 3.0845 - val_mae: 3.0845\n",
      "Epoch 115/300\n",
      "231/231 [==============================] - 0s 916us/step - loss: 3.1339 - mae: 3.1339 - val_loss: 3.0628 - val_mae: 3.0628\n",
      "Epoch 116/300\n",
      "231/231 [==============================] - 0s 844us/step - loss: 3.1381 - mae: 3.1381 - val_loss: 3.1472 - val_mae: 3.1472\n",
      "Epoch 117/300\n",
      "231/231 [==============================] - 0s 859us/step - loss: 3.1290 - mae: 3.1290 - val_loss: 3.0820 - val_mae: 3.0820\n",
      "Epoch 118/300\n",
      "231/231 [==============================] - 0s 879us/step - loss: 3.1350 - mae: 3.1350 - val_loss: 3.1183 - val_mae: 3.1183\n",
      "Epoch 119/300\n",
      "231/231 [==============================] - 0s 841us/step - loss: 3.1320 - mae: 3.1320 - val_loss: 3.0752 - val_mae: 3.0752\n",
      "Epoch 120/300\n",
      "231/231 [==============================] - 0s 867us/step - loss: 3.1389 - mae: 3.1389 - val_loss: 3.0462 - val_mae: 3.0462\n",
      "Epoch 121/300\n",
      "231/231 [==============================] - 0s 909us/step - loss: 3.1258 - mae: 3.1258 - val_loss: 3.0693 - val_mae: 3.0693\n",
      "Epoch 122/300\n",
      "231/231 [==============================] - 0s 866us/step - loss: 3.1301 - mae: 3.1301 - val_loss: 3.0171 - val_mae: 3.0171\n",
      "Epoch 123/300\n",
      "231/231 [==============================] - 0s 877us/step - loss: 3.1478 - mae: 3.1478 - val_loss: 3.0436 - val_mae: 3.0436\n",
      "Epoch 124/300\n",
      "231/231 [==============================] - 0s 888us/step - loss: 3.1435 - mae: 3.1435 - val_loss: 3.1481 - val_mae: 3.1481\n",
      "Epoch 125/300\n",
      "231/231 [==============================] - 0s 904us/step - loss: 3.1372 - mae: 3.1372 - val_loss: 3.0830 - val_mae: 3.0830\n",
      "Epoch 126/300\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 3.1237 - mae: 3.1237 - val_loss: 3.0344 - val_mae: 3.0344\n",
      "Epoch 127/300\n",
      "231/231 [==============================] - 0s 869us/step - loss: 3.1214 - mae: 3.1214 - val_loss: 3.0860 - val_mae: 3.0860\n",
      "Epoch 128/300\n",
      "231/231 [==============================] - 0s 874us/step - loss: 3.1421 - mae: 3.1421 - val_loss: 3.0383 - val_mae: 3.0383\n",
      "Epoch 129/300\n",
      "231/231 [==============================] - 0s 884us/step - loss: 3.1228 - mae: 3.1228 - val_loss: 3.1391 - val_mae: 3.1391\n",
      "Epoch 130/300\n",
      "231/231 [==============================] - 0s 870us/step - loss: 3.1109 - mae: 3.1109 - val_loss: 3.0969 - val_mae: 3.0969\n",
      "Epoch 131/300\n",
      "231/231 [==============================] - 0s 911us/step - loss: 3.1105 - mae: 3.1105 - val_loss: 3.0433 - val_mae: 3.0433\n",
      "Epoch 132/300\n",
      "231/231 [==============================] - 0s 866us/step - loss: 3.1084 - mae: 3.1084 - val_loss: 3.0377 - val_mae: 3.0377\n",
      "Epoch 133/300\n",
      "231/231 [==============================] - 0s 903us/step - loss: 3.1201 - mae: 3.1201 - val_loss: 3.0493 - val_mae: 3.0493\n",
      "Epoch 134/300\n",
      "231/231 [==============================] - 0s 818us/step - loss: 3.1315 - mae: 3.1315 - val_loss: 3.1311 - val_mae: 3.1311\n",
      "Epoch 135/300\n",
      "231/231 [==============================] - 0s 846us/step - loss: 3.1211 - mae: 3.1211 - val_loss: 3.0533 - val_mae: 3.0533\n",
      "Epoch 136/300\n",
      "231/231 [==============================] - 0s 834us/step - loss: 3.1387 - mae: 3.1387 - val_loss: 3.0214 - val_mae: 3.0214\n",
      "Epoch 137/300\n",
      "231/231 [==============================] - 0s 836us/step - loss: 3.1032 - mae: 3.1032 - val_loss: 3.0769 - val_mae: 3.0769\n",
      "Epoch 138/300\n",
      "231/231 [==============================] - 0s 831us/step - loss: 3.1147 - mae: 3.1147 - val_loss: 3.0798 - val_mae: 3.0798\n",
      "Epoch 139/300\n",
      "231/231 [==============================] - 0s 830us/step - loss: 3.1337 - mae: 3.1337 - val_loss: 3.2242 - val_mae: 3.2242\n",
      "Epoch 140/300\n",
      "231/231 [==============================] - 0s 834us/step - loss: 3.1091 - mae: 3.1091 - val_loss: 3.0430 - val_mae: 3.0430\n",
      "Epoch 141/300\n",
      "231/231 [==============================] - 0s 821us/step - loss: 3.1236 - mae: 3.1236 - val_loss: 3.0457 - val_mae: 3.0457\n",
      "Epoch 142/300\n",
      "231/231 [==============================] - 0s 959us/step - loss: 3.1189 - mae: 3.1189 - val_loss: 3.0420 - val_mae: 3.0420\n",
      "Epoch 143/300\n",
      "231/231 [==============================] - 0s 979us/step - loss: 3.1275 - mae: 3.1275 - val_loss: 3.0640 - val_mae: 3.0640\n",
      "Epoch 144/300\n",
      "231/231 [==============================] - 0s 887us/step - loss: 3.1068 - mae: 3.1068 - val_loss: 3.0690 - val_mae: 3.0690\n",
      "Epoch 145/300\n",
      "231/231 [==============================] - 0s 904us/step - loss: 3.1127 - mae: 3.1127 - val_loss: 3.0908 - val_mae: 3.0908\n",
      "Epoch 146/300\n",
      "231/231 [==============================] - 0s 900us/step - loss: 3.1015 - mae: 3.1015 - val_loss: 3.0201 - val_mae: 3.0201\n",
      "Epoch 147/300\n",
      "231/231 [==============================] - 0s 886us/step - loss: 3.1212 - mae: 3.1212 - val_loss: 3.0739 - val_mae: 3.0739\n",
      "Epoch 148/300\n",
      "231/231 [==============================] - 0s 867us/step - loss: 3.1033 - mae: 3.1033 - val_loss: 3.0673 - val_mae: 3.0673\n",
      "Epoch 149/300\n",
      "231/231 [==============================] - 0s 939us/step - loss: 3.0889 - mae: 3.0889 - val_loss: 3.0210 - val_mae: 3.0210\n",
      "Epoch 150/300\n",
      "231/231 [==============================] - 0s 974us/step - loss: 3.1114 - mae: 3.1114 - val_loss: 3.1607 - val_mae: 3.1607\n",
      "Epoch 151/300\n",
      "231/231 [==============================] - 0s 944us/step - loss: 3.1100 - mae: 3.1100 - val_loss: 3.0503 - val_mae: 3.0503\n",
      "Epoch 152/300\n",
      "231/231 [==============================] - 0s 978us/step - loss: 3.0970 - mae: 3.0970 - val_loss: 3.0375 - val_mae: 3.0375\n",
      "Epoch 153/300\n",
      "231/231 [==============================] - 0s 921us/step - loss: 3.1056 - mae: 3.1056 - val_loss: 3.0523 - val_mae: 3.0523\n",
      "Epoch 154/300\n",
      "231/231 [==============================] - 0s 890us/step - loss: 3.0983 - mae: 3.0983 - val_loss: 3.0363 - val_mae: 3.0363\n",
      "Epoch 155/300\n",
      "231/231 [==============================] - 0s 891us/step - loss: 3.1037 - mae: 3.1037 - val_loss: 3.0531 - val_mae: 3.0531\n",
      "Epoch 156/300\n",
      "231/231 [==============================] - 0s 861us/step - loss: 3.1039 - mae: 3.1039 - val_loss: 3.0110 - val_mae: 3.0110\n",
      "Epoch 157/300\n",
      "231/231 [==============================] - 0s 833us/step - loss: 3.1130 - mae: 3.1130 - val_loss: 3.0252 - val_mae: 3.0252\n",
      "Epoch 158/300\n",
      "231/231 [==============================] - 0s 833us/step - loss: 3.0910 - mae: 3.0910 - val_loss: 3.0186 - val_mae: 3.0186\n",
      "Epoch 159/300\n",
      "231/231 [==============================] - 0s 852us/step - loss: 3.0947 - mae: 3.0947 - val_loss: 3.1001 - val_mae: 3.1001\n"
     ]
    }
   ],
   "source": [
    "force_train, force_test, theta_x_train, theta_x_test, theta_y_train, theta_y_test = train_test_split(force_yc_bmi, theta_x_yc, theta_y_yc, test_size = 0.2, random_state = 0)\n",
    "history = model.fit(force_train, [theta_x_train, theta_y_train], epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (force_test, [theta_x_test, theta_y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "214/214 [==============================] - 0s 908us/step - loss: 4.0336 - mae: 4.0336 - val_loss: 3.8417 - val_mae: 3.8417\n",
      "Epoch 2/300\n",
      "214/214 [==============================] - 0s 832us/step - loss: 3.8170 - mae: 3.8170 - val_loss: 3.7683 - val_mae: 3.7683\n",
      "Epoch 3/300\n",
      "214/214 [==============================] - 0s 831us/step - loss: 3.7758 - mae: 3.7758 - val_loss: 3.6990 - val_mae: 3.6990\n",
      "Epoch 4/300\n",
      "214/214 [==============================] - 0s 844us/step - loss: 3.7374 - mae: 3.7374 - val_loss: 3.7031 - val_mae: 3.7031\n",
      "Epoch 5/300\n",
      "214/214 [==============================] - 0s 845us/step - loss: 3.7132 - mae: 3.7132 - val_loss: 3.6882 - val_mae: 3.6882\n",
      "Epoch 6/300\n",
      "214/214 [==============================] - 0s 837us/step - loss: 3.6998 - mae: 3.6998 - val_loss: 3.6661 - val_mae: 3.6661\n",
      "Epoch 7/300\n",
      "214/214 [==============================] - 0s 830us/step - loss: 3.6887 - mae: 3.6887 - val_loss: 3.6689 - val_mae: 3.6689\n",
      "Epoch 8/300\n",
      "214/214 [==============================] - 0s 863us/step - loss: 3.6748 - mae: 3.6748 - val_loss: 3.6270 - val_mae: 3.6270\n",
      "Epoch 9/300\n",
      "214/214 [==============================] - 0s 837us/step - loss: 3.6787 - mae: 3.6787 - val_loss: 3.5991 - val_mae: 3.5991\n",
      "Epoch 10/300\n",
      "214/214 [==============================] - 0s 846us/step - loss: 3.6519 - mae: 3.6519 - val_loss: 3.6068 - val_mae: 3.6068\n",
      "Epoch 11/300\n",
      "214/214 [==============================] - 0s 852us/step - loss: 3.6478 - mae: 3.6478 - val_loss: 3.5878 - val_mae: 3.5878\n",
      "Epoch 12/300\n",
      "214/214 [==============================] - 0s 841us/step - loss: 3.6355 - mae: 3.6355 - val_loss: 3.5565 - val_mae: 3.5565\n",
      "Epoch 13/300\n",
      "214/214 [==============================] - 0s 871us/step - loss: 3.6122 - mae: 3.6122 - val_loss: 3.5893 - val_mae: 3.5893\n",
      "Epoch 14/300\n",
      "214/214 [==============================] - 0s 831us/step - loss: 3.6120 - mae: 3.6120 - val_loss: 3.6087 - val_mae: 3.6087\n",
      "Epoch 15/300\n",
      "214/214 [==============================] - 0s 835us/step - loss: 3.6095 - mae: 3.6095 - val_loss: 3.5300 - val_mae: 3.5300\n",
      "Epoch 16/300\n",
      "214/214 [==============================] - 0s 846us/step - loss: 3.5932 - mae: 3.5932 - val_loss: 3.5501 - val_mae: 3.5501\n",
      "Epoch 17/300\n",
      "214/214 [==============================] - 0s 846us/step - loss: 3.5858 - mae: 3.5858 - val_loss: 3.5272 - val_mae: 3.5272\n",
      "Epoch 18/300\n",
      "214/214 [==============================] - 0s 843us/step - loss: 3.5813 - mae: 3.5813 - val_loss: 3.5608 - val_mae: 3.5608\n",
      "Epoch 19/300\n",
      "214/214 [==============================] - 0s 827us/step - loss: 3.5749 - mae: 3.5749 - val_loss: 3.5421 - val_mae: 3.5421\n",
      "Epoch 20/300\n",
      "214/214 [==============================] - 0s 831us/step - loss: 3.5627 - mae: 3.5627 - val_loss: 3.4952 - val_mae: 3.4952\n",
      "Epoch 21/300\n",
      "214/214 [==============================] - 0s 852us/step - loss: 3.5650 - mae: 3.5650 - val_loss: 3.4713 - val_mae: 3.4713\n",
      "Epoch 22/300\n",
      "214/214 [==============================] - 0s 856us/step - loss: 3.5655 - mae: 3.5655 - val_loss: 3.5082 - val_mae: 3.5082\n",
      "Epoch 23/300\n",
      "214/214 [==============================] - 0s 860us/step - loss: 3.5418 - mae: 3.5418 - val_loss: 3.4723 - val_mae: 3.4723\n",
      "Epoch 24/300\n",
      "214/214 [==============================] - 0s 859us/step - loss: 3.5513 - mae: 3.5513 - val_loss: 3.5140 - val_mae: 3.5140\n",
      "Epoch 25/300\n",
      "214/214 [==============================] - 0s 849us/step - loss: 3.5386 - mae: 3.5386 - val_loss: 3.4827 - val_mae: 3.4827\n",
      "Epoch 26/300\n",
      "214/214 [==============================] - 0s 865us/step - loss: 3.5519 - mae: 3.5519 - val_loss: 3.4915 - val_mae: 3.4915\n",
      "Epoch 27/300\n",
      "214/214 [==============================] - 0s 843us/step - loss: 3.5294 - mae: 3.5294 - val_loss: 3.4726 - val_mae: 3.4726\n",
      "Epoch 28/300\n",
      "214/214 [==============================] - 0s 839us/step - loss: 3.5251 - mae: 3.5251 - val_loss: 3.4776 - val_mae: 3.4776\n",
      "Epoch 29/300\n",
      "214/214 [==============================] - 0s 871us/step - loss: 3.5282 - mae: 3.5282 - val_loss: 3.5010 - val_mae: 3.5010\n",
      "Epoch 30/300\n",
      "214/214 [==============================] - 0s 891us/step - loss: 3.5174 - mae: 3.5174 - val_loss: 3.4757 - val_mae: 3.4757\n",
      "Epoch 31/300\n",
      "214/214 [==============================] - 0s 833us/step - loss: 3.5144 - mae: 3.5144 - val_loss: 3.4910 - val_mae: 3.4910\n",
      "Epoch 32/300\n",
      "214/214 [==============================] - 0s 831us/step - loss: 3.5091 - mae: 3.5091 - val_loss: 3.4515 - val_mae: 3.4515\n",
      "Epoch 33/300\n",
      "214/214 [==============================] - 0s 865us/step - loss: 3.5153 - mae: 3.5153 - val_loss: 3.4683 - val_mae: 3.4683\n",
      "Epoch 34/300\n",
      "214/214 [==============================] - 0s 896us/step - loss: 3.4832 - mae: 3.4832 - val_loss: 3.4174 - val_mae: 3.4174\n",
      "Epoch 35/300\n",
      "214/214 [==============================] - 0s 866us/step - loss: 3.5105 - mae: 3.5105 - val_loss: 3.4453 - val_mae: 3.4453\n",
      "Epoch 36/300\n",
      "214/214 [==============================] - 0s 1ms/step - loss: 3.4863 - mae: 3.4863 - val_loss: 3.4490 - val_mae: 3.4490\n",
      "Epoch 37/300\n",
      "214/214 [==============================] - 0s 1ms/step - loss: 3.4725 - mae: 3.4725 - val_loss: 3.4464 - val_mae: 3.4464\n",
      "Epoch 38/300\n",
      "214/214 [==============================] - 0s 940us/step - loss: 3.5027 - mae: 3.5027 - val_loss: 3.5174 - val_mae: 3.5174\n",
      "Epoch 39/300\n",
      "214/214 [==============================] - 0s 955us/step - loss: 3.4907 - mae: 3.4907 - val_loss: 3.4905 - val_mae: 3.4905\n",
      "Epoch 40/300\n",
      "214/214 [==============================] - 0s 961us/step - loss: 3.4794 - mae: 3.4794 - val_loss: 3.4687 - val_mae: 3.4687\n",
      "Epoch 41/300\n",
      "214/214 [==============================] - 0s 988us/step - loss: 3.4816 - mae: 3.4816 - val_loss: 3.4762 - val_mae: 3.4762\n",
      "Epoch 42/300\n",
      "214/214 [==============================] - 0s 970us/step - loss: 3.4714 - mae: 3.4714 - val_loss: 3.4278 - val_mae: 3.4278\n",
      "Epoch 43/300\n",
      "214/214 [==============================] - 0s 987us/step - loss: 3.4678 - mae: 3.4678 - val_loss: 3.3875 - val_mae: 3.3875\n",
      "Epoch 44/300\n",
      "214/214 [==============================] - 0s 966us/step - loss: 3.4688 - mae: 3.4688 - val_loss: 3.5366 - val_mae: 3.5366\n",
      "Epoch 45/300\n",
      "214/214 [==============================] - 0s 986us/step - loss: 3.4579 - mae: 3.4579 - val_loss: 3.4077 - val_mae: 3.4077\n",
      "Epoch 46/300\n",
      "214/214 [==============================] - 0s 926us/step - loss: 3.4761 - mae: 3.4761 - val_loss: 3.4839 - val_mae: 3.4839\n",
      "Epoch 47/300\n",
      "214/214 [==============================] - 0s 1ms/step - loss: 3.4639 - mae: 3.4639 - val_loss: 3.4810 - val_mae: 3.4810\n",
      "Epoch 48/300\n",
      "214/214 [==============================] - 0s 1ms/step - loss: 3.4455 - mae: 3.4455 - val_loss: 3.3982 - val_mae: 3.3982\n",
      "Epoch 49/300\n",
      "214/214 [==============================] - 0s 1ms/step - loss: 3.4395 - mae: 3.4395 - val_loss: 3.3725 - val_mae: 3.3725\n",
      "Epoch 50/300\n",
      "214/214 [==============================] - 0s 1ms/step - loss: 3.4553 - mae: 3.4553 - val_loss: 3.3653 - val_mae: 3.3653\n",
      "Epoch 51/300\n",
      "214/214 [==============================] - 0s 924us/step - loss: 3.4457 - mae: 3.4457 - val_loss: 3.4057 - val_mae: 3.4057\n",
      "Epoch 52/300\n",
      "214/214 [==============================] - 0s 905us/step - loss: 3.4552 - mae: 3.4552 - val_loss: 3.3808 - val_mae: 3.3808\n",
      "Epoch 53/300\n",
      "214/214 [==============================] - 0s 872us/step - loss: 3.4463 - mae: 3.4463 - val_loss: 3.3882 - val_mae: 3.3882\n",
      "Epoch 54/300\n",
      "214/214 [==============================] - 0s 884us/step - loss: 3.4341 - mae: 3.4341 - val_loss: 3.3694 - val_mae: 3.3694\n",
      "Epoch 55/300\n",
      "214/214 [==============================] - 0s 878us/step - loss: 3.4395 - mae: 3.4395 - val_loss: 3.4376 - val_mae: 3.4376\n",
      "Epoch 56/300\n",
      "214/214 [==============================] - 0s 868us/step - loss: 3.4481 - mae: 3.4481 - val_loss: 3.3742 - val_mae: 3.3742\n",
      "Epoch 57/300\n",
      "214/214 [==============================] - 0s 890us/step - loss: 3.4208 - mae: 3.4208 - val_loss: 3.3895 - val_mae: 3.3895\n",
      "Epoch 58/300\n",
      "214/214 [==============================] - 0s 847us/step - loss: 3.4243 - mae: 3.4243 - val_loss: 3.4190 - val_mae: 3.4190\n",
      "Epoch 59/300\n",
      "214/214 [==============================] - 0s 928us/step - loss: 3.4302 - mae: 3.4302 - val_loss: 3.3892 - val_mae: 3.3892\n",
      "Epoch 60/300\n",
      "214/214 [==============================] - 0s 906us/step - loss: 3.4303 - mae: 3.4303 - val_loss: 3.4256 - val_mae: 3.4256\n",
      "Epoch 61/300\n",
      "214/214 [==============================] - 0s 863us/step - loss: 3.4571 - mae: 3.4571 - val_loss: 3.3741 - val_mae: 3.3741\n",
      "Epoch 62/300\n",
      "214/214 [==============================] - 0s 872us/step - loss: 3.4213 - mae: 3.4213 - val_loss: 3.3749 - val_mae: 3.3749\n",
      "Epoch 63/300\n",
      "214/214 [==============================] - 0s 881us/step - loss: 3.4362 - mae: 3.4362 - val_loss: 3.4164 - val_mae: 3.4164\n",
      "Epoch 64/300\n",
      "214/214 [==============================] - 0s 848us/step - loss: 3.4123 - mae: 3.4123 - val_loss: 3.3589 - val_mae: 3.3589\n",
      "Epoch 65/300\n",
      "214/214 [==============================] - 0s 904us/step - loss: 3.4468 - mae: 3.4468 - val_loss: 3.3574 - val_mae: 3.3574\n",
      "Epoch 66/300\n",
      "214/214 [==============================] - 0s 975us/step - loss: 3.4048 - mae: 3.4048 - val_loss: 3.3825 - val_mae: 3.3825\n",
      "Epoch 67/300\n",
      "214/214 [==============================] - 0s 887us/step - loss: 3.4204 - mae: 3.4204 - val_loss: 3.3805 - val_mae: 3.3805\n",
      "Epoch 68/300\n",
      "214/214 [==============================] - 0s 930us/step - loss: 3.4067 - mae: 3.4067 - val_loss: 3.3901 - val_mae: 3.3901\n",
      "Epoch 69/300\n",
      "214/214 [==============================] - 0s 901us/step - loss: 3.3970 - mae: 3.3970 - val_loss: 3.3337 - val_mae: 3.3337\n",
      "Epoch 70/300\n",
      "214/214 [==============================] - 0s 833us/step - loss: 3.3906 - mae: 3.3906 - val_loss: 3.3460 - val_mae: 3.3460\n",
      "Epoch 71/300\n",
      "214/214 [==============================] - 0s 824us/step - loss: 3.4007 - mae: 3.4007 - val_loss: 3.3641 - val_mae: 3.3641\n",
      "Epoch 72/300\n",
      "214/214 [==============================] - 0s 838us/step - loss: 3.4085 - mae: 3.4085 - val_loss: 3.3695 - val_mae: 3.3695\n",
      "Epoch 73/300\n",
      "214/214 [==============================] - 0s 862us/step - loss: 3.4152 - mae: 3.4152 - val_loss: 3.4126 - val_mae: 3.4126\n",
      "Epoch 74/300\n",
      "214/214 [==============================] - 0s 864us/step - loss: 3.3898 - mae: 3.3898 - val_loss: 3.4146 - val_mae: 3.4146\n",
      "Epoch 75/300\n",
      "214/214 [==============================] - 0s 871us/step - loss: 3.3931 - mae: 3.3931 - val_loss: 3.3256 - val_mae: 3.3256\n",
      "Epoch 76/300\n",
      "214/214 [==============================] - 0s 899us/step - loss: 3.3913 - mae: 3.3913 - val_loss: 3.3502 - val_mae: 3.3502\n",
      "Epoch 77/300\n",
      "214/214 [==============================] - 0s 845us/step - loss: 3.3865 - mae: 3.3865 - val_loss: 3.3406 - val_mae: 3.3406\n",
      "Epoch 78/300\n",
      "214/214 [==============================] - 0s 851us/step - loss: 3.3992 - mae: 3.3992 - val_loss: 3.3507 - val_mae: 3.3507\n",
      "Epoch 79/300\n",
      "214/214 [==============================] - 0s 869us/step - loss: 3.3912 - mae: 3.3912 - val_loss: 3.4209 - val_mae: 3.4209\n",
      "Epoch 80/300\n",
      "214/214 [==============================] - 0s 842us/step - loss: 3.3786 - mae: 3.3786 - val_loss: 3.3168 - val_mae: 3.3168\n",
      "Epoch 81/300\n",
      "214/214 [==============================] - 0s 942us/step - loss: 3.3878 - mae: 3.3878 - val_loss: 3.3382 - val_mae: 3.3382\n",
      "Epoch 82/300\n",
      "214/214 [==============================] - 0s 949us/step - loss: 3.3944 - mae: 3.3944 - val_loss: 3.3412 - val_mae: 3.3412\n",
      "Epoch 83/300\n",
      "214/214 [==============================] - 0s 893us/step - loss: 3.3855 - mae: 3.3855 - val_loss: 3.2924 - val_mae: 3.2924\n",
      "Epoch 84/300\n",
      "214/214 [==============================] - 0s 862us/step - loss: 3.3696 - mae: 3.3696 - val_loss: 3.3224 - val_mae: 3.3224\n",
      "Epoch 85/300\n",
      "214/214 [==============================] - 0s 848us/step - loss: 3.3624 - mae: 3.3624 - val_loss: 3.3756 - val_mae: 3.3756\n",
      "Epoch 86/300\n",
      "214/214 [==============================] - 0s 839us/step - loss: 3.3849 - mae: 3.3849 - val_loss: 3.3074 - val_mae: 3.3074\n",
      "Epoch 87/300\n",
      "214/214 [==============================] - 0s 845us/step - loss: 3.3715 - mae: 3.3715 - val_loss: 3.3118 - val_mae: 3.3118\n",
      "Epoch 88/300\n",
      "214/214 [==============================] - 0s 985us/step - loss: 3.3757 - mae: 3.3757 - val_loss: 3.3556 - val_mae: 3.3556\n",
      "Epoch 89/300\n",
      "214/214 [==============================] - 0s 1ms/step - loss: 3.3368 - mae: 3.3368 - val_loss: 3.3689 - val_mae: 3.3689\n",
      "Epoch 90/300\n",
      "214/214 [==============================] - 0s 1ms/step - loss: 3.3811 - mae: 3.3811 - val_loss: 3.3321 - val_mae: 3.3321\n",
      "Epoch 91/300\n",
      "214/214 [==============================] - 0s 907us/step - loss: 3.3659 - mae: 3.3659 - val_loss: 3.2750 - val_mae: 3.2750\n",
      "Epoch 92/300\n",
      "214/214 [==============================] - 0s 881us/step - loss: 3.3631 - mae: 3.3631 - val_loss: 3.3042 - val_mae: 3.3042\n",
      "Epoch 93/300\n",
      "214/214 [==============================] - 0s 908us/step - loss: 3.3506 - mae: 3.3506 - val_loss: 3.3235 - val_mae: 3.3235\n",
      "Epoch 94/300\n",
      "214/214 [==============================] - 0s 902us/step - loss: 3.3584 - mae: 3.3584 - val_loss: 3.3297 - val_mae: 3.3297\n",
      "Epoch 95/300\n",
      "214/214 [==============================] - 0s 897us/step - loss: 3.3577 - mae: 3.3577 - val_loss: 3.2918 - val_mae: 3.2918\n",
      "Epoch 96/300\n",
      "214/214 [==============================] - 0s 900us/step - loss: 3.3469 - mae: 3.3469 - val_loss: 3.3487 - val_mae: 3.3487\n",
      "Epoch 97/300\n",
      "214/214 [==============================] - 0s 897us/step - loss: 3.3598 - mae: 3.3598 - val_loss: 3.2712 - val_mae: 3.2712\n",
      "Epoch 98/300\n",
      "214/214 [==============================] - 0s 878us/step - loss: 3.3463 - mae: 3.3463 - val_loss: 3.3152 - val_mae: 3.3152\n",
      "Epoch 99/300\n",
      "214/214 [==============================] - 0s 902us/step - loss: 3.3421 - mae: 3.3421 - val_loss: 3.3074 - val_mae: 3.3074\n"
     ]
    }
   ],
   "source": [
    "force_train, force_test, theta_x_train, theta_x_test, theta_y_train, theta_y_test = train_test_split(force_cz_bmi, theta_x_cz, theta_y_cz, test_size = 0.2, random_state = 0)\n",
    "history = model.fit(force_train, [theta_x_train, theta_y_train], epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (force_test, [theta_x_test, theta_y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "515/515 [==============================] - 0s 898us/step - loss: 3.4120 - mae: 3.4120 - val_loss: 2.9816 - val_mae: 2.9816\n",
      "Epoch 2/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 3.0773 - mae: 3.0773 - val_loss: 2.9500 - val_mae: 2.9500\n",
      "Epoch 3/300\n",
      "515/515 [==============================] - 0s 872us/step - loss: 3.0307 - mae: 3.0307 - val_loss: 2.8984 - val_mae: 2.8984\n",
      "Epoch 4/300\n",
      "515/515 [==============================] - 0s 814us/step - loss: 2.9771 - mae: 2.9771 - val_loss: 2.8406 - val_mae: 2.8406\n",
      "Epoch 5/300\n",
      "515/515 [==============================] - 0s 803us/step - loss: 2.9467 - mae: 2.9467 - val_loss: 2.8195 - val_mae: 2.8195\n",
      "Epoch 6/300\n",
      "515/515 [==============================] - 0s 803us/step - loss: 2.9025 - mae: 2.9025 - val_loss: 2.7635 - val_mae: 2.7635\n",
      "Epoch 7/300\n",
      "515/515 [==============================] - 0s 805us/step - loss: 2.8683 - mae: 2.8683 - val_loss: 2.7522 - val_mae: 2.7522\n",
      "Epoch 8/300\n",
      "515/515 [==============================] - 0s 812us/step - loss: 2.8328 - mae: 2.8328 - val_loss: 2.7093 - val_mae: 2.7093\n",
      "Epoch 9/300\n",
      "515/515 [==============================] - 0s 813us/step - loss: 2.8027 - mae: 2.8027 - val_loss: 2.7135 - val_mae: 2.7135\n",
      "Epoch 10/300\n",
      "515/515 [==============================] - 0s 763us/step - loss: 2.7894 - mae: 2.7894 - val_loss: 2.6965 - val_mae: 2.6965\n",
      "Epoch 11/300\n",
      "515/515 [==============================] - 0s 758us/step - loss: 2.7806 - mae: 2.7806 - val_loss: 2.6955 - val_mae: 2.6955\n",
      "Epoch 12/300\n",
      "515/515 [==============================] - 0s 753us/step - loss: 2.7712 - mae: 2.7712 - val_loss: 2.6267 - val_mae: 2.6267\n",
      "Epoch 13/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 2.7565 - mae: 2.7565 - val_loss: 2.6488 - val_mae: 2.6488\n",
      "Epoch 14/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 2.7598 - mae: 2.7598 - val_loss: 2.6461 - val_mae: 2.6461\n",
      "Epoch 15/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.7529 - mae: 2.7529 - val_loss: 2.6268 - val_mae: 2.6268\n",
      "Epoch 16/300\n",
      "515/515 [==============================] - 0s 763us/step - loss: 2.7346 - mae: 2.7346 - val_loss: 2.6264 - val_mae: 2.6264\n",
      "Epoch 17/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.7344 - mae: 2.7344 - val_loss: 2.6243 - val_mae: 2.6243\n",
      "Epoch 18/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.7308 - mae: 2.7308 - val_loss: 2.6089 - val_mae: 2.6089\n",
      "Epoch 19/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.7192 - mae: 2.7192 - val_loss: 2.6241 - val_mae: 2.6241\n",
      "Epoch 20/300\n",
      "515/515 [==============================] - 0s 774us/step - loss: 2.7115 - mae: 2.7115 - val_loss: 2.6121 - val_mae: 2.6121\n",
      "Epoch 21/300\n",
      "515/515 [==============================] - 0s 764us/step - loss: 2.7082 - mae: 2.7082 - val_loss: 2.6152 - val_mae: 2.6152\n",
      "Epoch 22/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 2.7148 - mae: 2.7148 - val_loss: 2.6231 - val_mae: 2.6231\n",
      "Epoch 23/300\n",
      "515/515 [==============================] - 0s 763us/step - loss: 2.7106 - mae: 2.7106 - val_loss: 2.6109 - val_mae: 2.6109\n",
      "Epoch 24/300\n",
      "515/515 [==============================] - 0s 766us/step - loss: 2.6943 - mae: 2.6943 - val_loss: 2.5788 - val_mae: 2.5788\n",
      "Epoch 25/300\n",
      "515/515 [==============================] - 0s 758us/step - loss: 2.6905 - mae: 2.6905 - val_loss: 2.6011 - val_mae: 2.6011\n",
      "Epoch 26/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.6942 - mae: 2.6942 - val_loss: 2.5869 - val_mae: 2.5869\n",
      "Epoch 27/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 2.6976 - mae: 2.6976 - val_loss: 2.5806 - val_mae: 2.5806\n",
      "Epoch 28/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.6950 - mae: 2.6950 - val_loss: 2.5958 - val_mae: 2.5958\n",
      "Epoch 29/300\n",
      "515/515 [==============================] - 0s 883us/step - loss: 2.6893 - mae: 2.6893 - val_loss: 2.6118 - val_mae: 2.6118\n",
      "Epoch 30/300\n",
      "515/515 [==============================] - 0s 864us/step - loss: 2.6770 - mae: 2.6770 - val_loss: 2.5612 - val_mae: 2.5612\n",
      "Epoch 31/300\n",
      "515/515 [==============================] - 0s 798us/step - loss: 2.6851 - mae: 2.6851 - val_loss: 2.5845 - val_mae: 2.5845\n",
      "Epoch 32/300\n",
      "515/515 [==============================] - 0s 804us/step - loss: 2.6788 - mae: 2.6788 - val_loss: 2.5911 - val_mae: 2.5911\n",
      "Epoch 33/300\n",
      "515/515 [==============================] - 0s 797us/step - loss: 2.6705 - mae: 2.6705 - val_loss: 2.5660 - val_mae: 2.5660\n",
      "Epoch 34/300\n",
      "515/515 [==============================] - 0s 801us/step - loss: 2.6752 - mae: 2.6752 - val_loss: 2.5812 - val_mae: 2.5812\n",
      "Epoch 35/300\n",
      "515/515 [==============================] - 0s 822us/step - loss: 2.6756 - mae: 2.6756 - val_loss: 2.5752 - val_mae: 2.5752\n",
      "Epoch 36/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.6741 - mae: 2.6741 - val_loss: 2.5743 - val_mae: 2.5743\n",
      "Epoch 37/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.6692 - mae: 2.6692 - val_loss: 2.5573 - val_mae: 2.5573\n",
      "Epoch 38/300\n",
      "515/515 [==============================] - 0s 771us/step - loss: 2.6715 - mae: 2.6715 - val_loss: 2.5599 - val_mae: 2.5599\n",
      "Epoch 39/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6695 - mae: 2.6695 - val_loss: 2.5742 - val_mae: 2.5742\n",
      "Epoch 40/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6730 - mae: 2.6730 - val_loss: 2.5750 - val_mae: 2.5750\n",
      "Epoch 41/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 2.6685 - mae: 2.6685 - val_loss: 2.6895 - val_mae: 2.6895\n",
      "Epoch 42/300\n",
      "515/515 [==============================] - 0s 763us/step - loss: 2.6724 - mae: 2.6724 - val_loss: 2.5641 - val_mae: 2.5641\n",
      "Epoch 43/300\n",
      "515/515 [==============================] - 0s 764us/step - loss: 2.6599 - mae: 2.6599 - val_loss: 2.5929 - val_mae: 2.5929\n",
      "Epoch 44/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.6545 - mae: 2.6545 - val_loss: 2.5499 - val_mae: 2.5499\n",
      "Epoch 45/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.6601 - mae: 2.6601 - val_loss: 2.5506 - val_mae: 2.5506\n",
      "Epoch 46/300\n",
      "515/515 [==============================] - 0s 764us/step - loss: 2.6674 - mae: 2.6674 - val_loss: 2.5771 - val_mae: 2.5771\n",
      "Epoch 47/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 2.6594 - mae: 2.6594 - val_loss: 2.5450 - val_mae: 2.5450\n",
      "Epoch 48/300\n",
      "515/515 [==============================] - 0s 763us/step - loss: 2.6637 - mae: 2.6637 - val_loss: 2.5971 - val_mae: 2.5971\n",
      "Epoch 49/300\n",
      "515/515 [==============================] - 0s 766us/step - loss: 2.6528 - mae: 2.6528 - val_loss: 2.5652 - val_mae: 2.5652\n",
      "Epoch 50/300\n",
      "515/515 [==============================] - 0s 764us/step - loss: 2.6517 - mae: 2.6517 - val_loss: 2.5758 - val_mae: 2.5758\n",
      "Epoch 51/300\n",
      "515/515 [==============================] - 0s 765us/step - loss: 2.6468 - mae: 2.6468 - val_loss: 2.5448 - val_mae: 2.5448\n",
      "Epoch 52/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6579 - mae: 2.6579 - val_loss: 2.5428 - val_mae: 2.5428\n",
      "Epoch 53/300\n",
      "515/515 [==============================] - 0s 757us/step - loss: 2.6570 - mae: 2.6570 - val_loss: 2.5500 - val_mae: 2.5500\n",
      "Epoch 54/300\n",
      "515/515 [==============================] - 0s 834us/step - loss: 2.6506 - mae: 2.6506 - val_loss: 2.5784 - val_mae: 2.5784\n",
      "Epoch 55/300\n",
      "515/515 [==============================] - 0s 854us/step - loss: 2.6467 - mae: 2.6467 - val_loss: 2.5585 - val_mae: 2.5585\n",
      "Epoch 56/300\n",
      "515/515 [==============================] - 0s 800us/step - loss: 2.6453 - mae: 2.6453 - val_loss: 2.5902 - val_mae: 2.5902\n",
      "Epoch 57/300\n",
      "515/515 [==============================] - 0s 827us/step - loss: 2.6463 - mae: 2.6463 - val_loss: 2.5416 - val_mae: 2.5416\n",
      "Epoch 58/300\n",
      "515/515 [==============================] - 0s 807us/step - loss: 2.6460 - mae: 2.6460 - val_loss: 2.6065 - val_mae: 2.6065\n",
      "Epoch 59/300\n",
      "515/515 [==============================] - 0s 825us/step - loss: 2.6509 - mae: 2.6509 - val_loss: 2.5347 - val_mae: 2.5347\n",
      "Epoch 60/300\n",
      "515/515 [==============================] - 0s 816us/step - loss: 2.6414 - mae: 2.6414 - val_loss: 2.5786 - val_mae: 2.5786\n",
      "Epoch 61/300\n",
      "515/515 [==============================] - 0s 778us/step - loss: 2.6482 - mae: 2.6482 - val_loss: 2.5405 - val_mae: 2.5405\n",
      "Epoch 62/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 2.6489 - mae: 2.6489 - val_loss: 2.5525 - val_mae: 2.5525\n",
      "Epoch 63/300\n",
      "515/515 [==============================] - 0s 750us/step - loss: 2.6515 - mae: 2.6515 - val_loss: 2.5540 - val_mae: 2.5540\n",
      "Epoch 64/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.6383 - mae: 2.6383 - val_loss: 2.5476 - val_mae: 2.5476\n",
      "Epoch 65/300\n",
      "515/515 [==============================] - 0s 775us/step - loss: 2.6389 - mae: 2.6389 - val_loss: 2.5628 - val_mae: 2.5628\n",
      "Epoch 66/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.6347 - mae: 2.6347 - val_loss: 2.5465 - val_mae: 2.5465\n",
      "Epoch 67/300\n",
      "515/515 [==============================] - 0s 752us/step - loss: 2.6388 - mae: 2.6388 - val_loss: 2.5575 - val_mae: 2.5575\n",
      "Epoch 68/300\n",
      "515/515 [==============================] - 0s 757us/step - loss: 2.6397 - mae: 2.6397 - val_loss: 2.5498 - val_mae: 2.5498\n",
      "Epoch 69/300\n",
      "515/515 [==============================] - 0s 757us/step - loss: 2.6355 - mae: 2.6355 - val_loss: 2.5358 - val_mae: 2.5358\n",
      "Epoch 70/300\n",
      "515/515 [==============================] - 0s 812us/step - loss: 2.6351 - mae: 2.6351 - val_loss: 2.5329 - val_mae: 2.5329\n",
      "Epoch 71/300\n",
      "515/515 [==============================] - 0s 755us/step - loss: 2.6362 - mae: 2.6362 - val_loss: 2.5292 - val_mae: 2.5292\n",
      "Epoch 72/300\n",
      "515/515 [==============================] - 0s 765us/step - loss: 2.6327 - mae: 2.6327 - val_loss: 2.5183 - val_mae: 2.5183\n",
      "Epoch 73/300\n",
      "515/515 [==============================] - 0s 757us/step - loss: 2.6323 - mae: 2.6323 - val_loss: 2.5427 - val_mae: 2.5427\n",
      "Epoch 74/300\n",
      "515/515 [==============================] - 0s 758us/step - loss: 2.6291 - mae: 2.6291 - val_loss: 2.5287 - val_mae: 2.5287\n",
      "Epoch 75/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6238 - mae: 2.6238 - val_loss: 2.5414 - val_mae: 2.5414\n",
      "Epoch 76/300\n",
      "515/515 [==============================] - 0s 751us/step - loss: 2.6248 - mae: 2.6248 - val_loss: 2.5316 - val_mae: 2.5316\n",
      "Epoch 77/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6242 - mae: 2.6242 - val_loss: 2.5118 - val_mae: 2.5118\n",
      "Epoch 78/300\n",
      "515/515 [==============================] - 0s 754us/step - loss: 2.6243 - mae: 2.6243 - val_loss: 2.5573 - val_mae: 2.5573\n",
      "Epoch 79/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 2.6276 - mae: 2.6276 - val_loss: 2.5170 - val_mae: 2.5170\n",
      "Epoch 80/300\n",
      "515/515 [==============================] - 0s 880us/step - loss: 2.6270 - mae: 2.6270 - val_loss: 2.5528 - val_mae: 2.5528\n",
      "Epoch 81/300\n",
      "515/515 [==============================] - 0s 784us/step - loss: 2.6233 - mae: 2.6233 - val_loss: 2.5418 - val_mae: 2.5418\n",
      "Epoch 82/300\n",
      "515/515 [==============================] - 0s 810us/step - loss: 2.6215 - mae: 2.6215 - val_loss: 2.6288 - val_mae: 2.6288\n",
      "Epoch 83/300\n",
      "515/515 [==============================] - 0s 823us/step - loss: 2.6249 - mae: 2.6249 - val_loss: 2.5285 - val_mae: 2.5285\n",
      "Epoch 84/300\n",
      "515/515 [==============================] - 0s 798us/step - loss: 2.6294 - mae: 2.6294 - val_loss: 2.5308 - val_mae: 2.5308\n",
      "Epoch 85/300\n",
      "515/515 [==============================] - 0s 806us/step - loss: 2.6258 - mae: 2.6258 - val_loss: 2.5275 - val_mae: 2.5275\n",
      "Epoch 86/300\n",
      "515/515 [==============================] - 0s 846us/step - loss: 2.6233 - mae: 2.6233 - val_loss: 2.5099 - val_mae: 2.5099\n",
      "Epoch 87/300\n",
      "515/515 [==============================] - 0s 783us/step - loss: 2.6221 - mae: 2.6221 - val_loss: 2.5309 - val_mae: 2.5309\n",
      "Epoch 88/300\n",
      "515/515 [==============================] - 0s 793us/step - loss: 2.6195 - mae: 2.6195 - val_loss: 2.5343 - val_mae: 2.5343\n",
      "Epoch 89/300\n",
      "515/515 [==============================] - 0s 778us/step - loss: 2.6236 - mae: 2.6236 - val_loss: 2.5234 - val_mae: 2.5234\n",
      "Epoch 90/300\n",
      "515/515 [==============================] - 0s 810us/step - loss: 2.6139 - mae: 2.6139 - val_loss: 2.5308 - val_mae: 2.5308\n",
      "Epoch 91/300\n",
      "515/515 [==============================] - 0s 777us/step - loss: 2.6254 - mae: 2.6254 - val_loss: 2.5325 - val_mae: 2.5325\n",
      "Epoch 92/300\n",
      "515/515 [==============================] - 0s 913us/step - loss: 2.6164 - mae: 2.6164 - val_loss: 2.5492 - val_mae: 2.5492\n",
      "Epoch 93/300\n",
      "515/515 [==============================] - 0s 789us/step - loss: 2.6121 - mae: 2.6121 - val_loss: 2.5143 - val_mae: 2.5143\n",
      "Epoch 94/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 2.6153 - mae: 2.6153 - val_loss: 2.5233 - val_mae: 2.5233\n",
      "Epoch 95/300\n",
      "515/515 [==============================] - 0s 779us/step - loss: 2.6144 - mae: 2.6144 - val_loss: 2.5531 - val_mae: 2.5531\n",
      "Epoch 96/300\n",
      "515/515 [==============================] - 0s 770us/step - loss: 2.6160 - mae: 2.6160 - val_loss: 2.5267 - val_mae: 2.5267\n",
      "Epoch 97/300\n",
      "515/515 [==============================] - 0s 778us/step - loss: 2.6125 - mae: 2.6125 - val_loss: 2.5532 - val_mae: 2.5532\n",
      "Epoch 98/300\n",
      "515/515 [==============================] - 0s 769us/step - loss: 2.6180 - mae: 2.6180 - val_loss: 2.5594 - val_mae: 2.5594\n",
      "Epoch 99/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 2.6146 - mae: 2.6146 - val_loss: 2.5199 - val_mae: 2.5199\n",
      "Epoch 100/300\n",
      "515/515 [==============================] - 0s 751us/step - loss: 2.6143 - mae: 2.6143 - val_loss: 2.5596 - val_mae: 2.5596\n",
      "Epoch 101/300\n",
      "515/515 [==============================] - 0s 754us/step - loss: 2.6129 - mae: 2.6129 - val_loss: 2.5062 - val_mae: 2.5062\n",
      "Epoch 102/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 2.6078 - mae: 2.6078 - val_loss: 2.5539 - val_mae: 2.5539\n",
      "Epoch 103/300\n",
      "515/515 [==============================] - 0s 763us/step - loss: 2.6143 - mae: 2.6143 - val_loss: 2.5033 - val_mae: 2.5033\n",
      "Epoch 104/300\n",
      "515/515 [==============================] - 0s 808us/step - loss: 2.6119 - mae: 2.6119 - val_loss: 2.5110 - val_mae: 2.5110\n",
      "Epoch 105/300\n",
      "515/515 [==============================] - 0s 913us/step - loss: 2.6083 - mae: 2.6083 - val_loss: 2.5177 - val_mae: 2.5177\n",
      "Epoch 106/300\n",
      "515/515 [==============================] - 0s 860us/step - loss: 2.6003 - mae: 2.6003 - val_loss: 2.5229 - val_mae: 2.5229\n",
      "Epoch 107/300\n",
      "515/515 [==============================] - 0s 881us/step - loss: 2.6052 - mae: 2.6052 - val_loss: 2.5047 - val_mae: 2.5047\n",
      "Epoch 108/300\n",
      "515/515 [==============================] - 1s 972us/step - loss: 2.6119 - mae: 2.6119 - val_loss: 2.5280 - val_mae: 2.5280\n",
      "Epoch 109/300\n",
      "515/515 [==============================] - 0s 923us/step - loss: 2.6006 - mae: 2.6006 - val_loss: 2.5105 - val_mae: 2.5105\n",
      "Epoch 110/300\n",
      "515/515 [==============================] - 0s 809us/step - loss: 2.6069 - mae: 2.6069 - val_loss: 2.5861 - val_mae: 2.5861\n",
      "Epoch 111/300\n",
      "515/515 [==============================] - 0s 835us/step - loss: 2.6002 - mae: 2.6002 - val_loss: 2.4999 - val_mae: 2.4999\n",
      "Epoch 112/300\n",
      "515/515 [==============================] - 0s 775us/step - loss: 2.6034 - mae: 2.6034 - val_loss: 2.5529 - val_mae: 2.5529\n",
      "Epoch 113/300\n",
      "515/515 [==============================] - 0s 782us/step - loss: 2.6028 - mae: 2.6028 - val_loss: 2.5422 - val_mae: 2.5422\n",
      "Epoch 114/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.6089 - mae: 2.6089 - val_loss: 2.5161 - val_mae: 2.5161\n",
      "Epoch 115/300\n",
      "515/515 [==============================] - 0s 784us/step - loss: 2.6045 - mae: 2.6045 - val_loss: 2.5386 - val_mae: 2.5386\n",
      "Epoch 116/300\n",
      "515/515 [==============================] - 0s 845us/step - loss: 2.6008 - mae: 2.6008 - val_loss: 2.4923 - val_mae: 2.4923\n",
      "Epoch 117/300\n",
      "515/515 [==============================] - 0s 820us/step - loss: 2.6071 - mae: 2.6071 - val_loss: 2.5124 - val_mae: 2.5124\n",
      "Epoch 118/300\n",
      "515/515 [==============================] - 0s 909us/step - loss: 2.6045 - mae: 2.6045 - val_loss: 2.5450 - val_mae: 2.5450\n",
      "Epoch 119/300\n",
      "515/515 [==============================] - 0s 800us/step - loss: 2.6035 - mae: 2.6035 - val_loss: 2.5001 - val_mae: 2.5001\n",
      "Epoch 120/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.6010 - mae: 2.6010 - val_loss: 2.5156 - val_mae: 2.5156\n",
      "Epoch 121/300\n",
      "515/515 [==============================] - 0s 853us/step - loss: 2.6023 - mae: 2.6023 - val_loss: 2.4908 - val_mae: 2.4908\n",
      "Epoch 122/300\n",
      "515/515 [==============================] - 0s 858us/step - loss: 2.6032 - mae: 2.6032 - val_loss: 2.5086 - val_mae: 2.5086\n",
      "Epoch 123/300\n",
      "515/515 [==============================] - 0s 920us/step - loss: 2.6014 - mae: 2.6014 - val_loss: 2.4924 - val_mae: 2.4924\n",
      "Epoch 124/300\n",
      "515/515 [==============================] - 0s 883us/step - loss: 2.5996 - mae: 2.5996 - val_loss: 2.5230 - val_mae: 2.5230\n",
      "Epoch 125/300\n",
      "515/515 [==============================] - 0s 784us/step - loss: 2.6023 - mae: 2.6023 - val_loss: 2.5072 - val_mae: 2.5072\n",
      "Epoch 126/300\n",
      "515/515 [==============================] - 0s 846us/step - loss: 2.5956 - mae: 2.5956 - val_loss: 2.5011 - val_mae: 2.5011\n",
      "Epoch 127/300\n",
      "515/515 [==============================] - 0s 855us/step - loss: 2.5988 - mae: 2.5988 - val_loss: 2.5105 - val_mae: 2.5105\n",
      "Epoch 128/300\n",
      "515/515 [==============================] - 0s 934us/step - loss: 2.5957 - mae: 2.5957 - val_loss: 2.5148 - val_mae: 2.5148\n",
      "Epoch 129/300\n",
      "515/515 [==============================] - 0s 931us/step - loss: 2.5957 - mae: 2.5957 - val_loss: 2.5189 - val_mae: 2.5189\n",
      "Epoch 130/300\n",
      "515/515 [==============================] - 0s 912us/step - loss: 2.5975 - mae: 2.5975 - val_loss: 2.5143 - val_mae: 2.5143\n",
      "Epoch 131/300\n",
      "515/515 [==============================] - 0s 910us/step - loss: 2.6011 - mae: 2.6011 - val_loss: 2.5258 - val_mae: 2.5258\n",
      "Epoch 132/300\n",
      "515/515 [==============================] - 0s 893us/step - loss: 2.6012 - mae: 2.6012 - val_loss: 2.5244 - val_mae: 2.5244\n",
      "Epoch 133/300\n",
      "515/515 [==============================] - 0s 891us/step - loss: 2.5881 - mae: 2.5881 - val_loss: 2.4859 - val_mae: 2.4859\n",
      "Epoch 134/300\n",
      "515/515 [==============================] - 0s 926us/step - loss: 2.5928 - mae: 2.5928 - val_loss: 2.5036 - val_mae: 2.5036\n",
      "Epoch 135/300\n",
      "515/515 [==============================] - 0s 840us/step - loss: 2.5920 - mae: 2.5920 - val_loss: 2.5099 - val_mae: 2.5099\n",
      "Epoch 136/300\n",
      "515/515 [==============================] - 0s 854us/step - loss: 2.5946 - mae: 2.5946 - val_loss: 2.5144 - val_mae: 2.5144\n",
      "Epoch 137/300\n",
      "515/515 [==============================] - 0s 838us/step - loss: 2.5930 - mae: 2.5930 - val_loss: 2.5006 - val_mae: 2.5006\n",
      "Epoch 138/300\n",
      "515/515 [==============================] - 0s 876us/step - loss: 2.5938 - mae: 2.5938 - val_loss: 2.5172 - val_mae: 2.5172\n",
      "Epoch 139/300\n",
      "515/515 [==============================] - 0s 856us/step - loss: 2.5978 - mae: 2.5978 - val_loss: 2.5173 - val_mae: 2.5173\n",
      "Epoch 140/300\n",
      "515/515 [==============================] - 0s 891us/step - loss: 2.6006 - mae: 2.6006 - val_loss: 2.5135 - val_mae: 2.5135\n",
      "Epoch 141/300\n",
      "515/515 [==============================] - 0s 841us/step - loss: 2.5879 - mae: 2.5879 - val_loss: 2.5139 - val_mae: 2.5139\n",
      "Epoch 142/300\n",
      "515/515 [==============================] - 0s 862us/step - loss: 2.5927 - mae: 2.5927 - val_loss: 2.4847 - val_mae: 2.4847\n",
      "Epoch 143/300\n",
      "515/515 [==============================] - 0s 817us/step - loss: 2.5884 - mae: 2.5884 - val_loss: 2.4968 - val_mae: 2.4968\n",
      "Epoch 144/300\n",
      "515/515 [==============================] - 0s 877us/step - loss: 2.5841 - mae: 2.5841 - val_loss: 2.4942 - val_mae: 2.4942\n",
      "Epoch 145/300\n",
      "515/515 [==============================] - 0s 871us/step - loss: 2.5911 - mae: 2.5911 - val_loss: 2.4975 - val_mae: 2.4975\n",
      "Epoch 146/300\n",
      "515/515 [==============================] - 0s 926us/step - loss: 2.5897 - mae: 2.5897 - val_loss: 2.5015 - val_mae: 2.5015\n",
      "Epoch 147/300\n",
      "515/515 [==============================] - 0s 891us/step - loss: 2.5879 - mae: 2.5879 - val_loss: 2.5035 - val_mae: 2.5035\n",
      "Epoch 148/300\n",
      "515/515 [==============================] - 0s 942us/step - loss: 2.5892 - mae: 2.5892 - val_loss: 2.4960 - val_mae: 2.4960\n",
      "Epoch 149/300\n",
      "515/515 [==============================] - 1s 989us/step - loss: 2.5882 - mae: 2.5882 - val_loss: 2.5119 - val_mae: 2.5119\n",
      "Epoch 150/300\n",
      "515/515 [==============================] - 1s 997us/step - loss: 2.5877 - mae: 2.5877 - val_loss: 2.4968 - val_mae: 2.4968\n",
      "Epoch 151/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.5892 - mae: 2.5892 - val_loss: 2.5233 - val_mae: 2.5233\n",
      "Epoch 152/300\n",
      "515/515 [==============================] - 0s 926us/step - loss: 2.5932 - mae: 2.5932 - val_loss: 2.5038 - val_mae: 2.5038\n",
      "Epoch 153/300\n",
      "515/515 [==============================] - 0s 896us/step - loss: 2.5842 - mae: 2.5842 - val_loss: 2.5421 - val_mae: 2.5421\n",
      "Epoch 154/300\n",
      "515/515 [==============================] - 0s 906us/step - loss: 2.5845 - mae: 2.5845 - val_loss: 2.4842 - val_mae: 2.4842\n",
      "Epoch 155/300\n",
      "515/515 [==============================] - 0s 927us/step - loss: 2.5847 - mae: 2.5847 - val_loss: 2.4715 - val_mae: 2.4715\n",
      "Epoch 156/300\n",
      "515/515 [==============================] - 0s 919us/step - loss: 2.5791 - mae: 2.5791 - val_loss: 2.4934 - val_mae: 2.4934\n",
      "Epoch 157/300\n",
      "515/515 [==============================] - 0s 853us/step - loss: 2.5872 - mae: 2.5872 - val_loss: 2.4820 - val_mae: 2.4820\n",
      "Epoch 158/300\n",
      "515/515 [==============================] - 0s 833us/step - loss: 2.5789 - mae: 2.5789 - val_loss: 2.5059 - val_mae: 2.5059\n",
      "Epoch 159/300\n",
      "515/515 [==============================] - 0s 821us/step - loss: 2.5836 - mae: 2.5836 - val_loss: 2.4980 - val_mae: 2.4980\n",
      "Epoch 160/300\n",
      "515/515 [==============================] - 0s 804us/step - loss: 2.5801 - mae: 2.5801 - val_loss: 2.4750 - val_mae: 2.4750\n",
      "Epoch 161/300\n",
      "515/515 [==============================] - 0s 797us/step - loss: 2.5856 - mae: 2.5856 - val_loss: 2.5016 - val_mae: 2.5016\n",
      "Epoch 162/300\n",
      "515/515 [==============================] - 0s 802us/step - loss: 2.5825 - mae: 2.5825 - val_loss: 2.4745 - val_mae: 2.4745\n",
      "Epoch 163/300\n",
      "515/515 [==============================] - 0s 840us/step - loss: 2.5843 - mae: 2.5843 - val_loss: 2.4702 - val_mae: 2.4702\n",
      "Epoch 164/300\n",
      "515/515 [==============================] - 0s 883us/step - loss: 2.5833 - mae: 2.5833 - val_loss: 2.4999 - val_mae: 2.4999\n",
      "Epoch 165/300\n",
      "515/515 [==============================] - 1s 994us/step - loss: 2.5802 - mae: 2.5802 - val_loss: 2.4793 - val_mae: 2.4793\n",
      "Epoch 166/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.5816 - mae: 2.5816 - val_loss: 2.4893 - val_mae: 2.4893\n",
      "Epoch 167/300\n",
      "515/515 [==============================] - 0s 922us/step - loss: 2.5817 - mae: 2.5817 - val_loss: 2.4819 - val_mae: 2.4819\n",
      "Epoch 168/300\n",
      "515/515 [==============================] - 0s 882us/step - loss: 2.5837 - mae: 2.5837 - val_loss: 2.5063 - val_mae: 2.5063\n",
      "Epoch 169/300\n",
      "515/515 [==============================] - 0s 830us/step - loss: 2.5867 - mae: 2.5867 - val_loss: 2.5093 - val_mae: 2.5093\n",
      "Epoch 170/300\n",
      "515/515 [==============================] - 0s 883us/step - loss: 2.5774 - mae: 2.5774 - val_loss: 2.4906 - val_mae: 2.4906\n",
      "Epoch 171/300\n",
      "515/515 [==============================] - 0s 856us/step - loss: 2.5752 - mae: 2.5752 - val_loss: 2.5369 - val_mae: 2.5369\n",
      "Epoch 172/300\n",
      "515/515 [==============================] - 0s 832us/step - loss: 2.5762 - mae: 2.5762 - val_loss: 2.4897 - val_mae: 2.4897\n",
      "Epoch 173/300\n",
      "515/515 [==============================] - 0s 902us/step - loss: 2.5766 - mae: 2.5766 - val_loss: 2.4762 - val_mae: 2.4762\n",
      "Epoch 174/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.5801 - mae: 2.5801 - val_loss: 2.4704 - val_mae: 2.4704\n",
      "Epoch 175/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.5758 - mae: 2.5758 - val_loss: 2.5009 - val_mae: 2.5009\n",
      "Epoch 176/300\n",
      "515/515 [==============================] - 0s 958us/step - loss: 2.5731 - mae: 2.5731 - val_loss: 2.5179 - val_mae: 2.5179\n",
      "Epoch 177/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.5741 - mae: 2.5741 - val_loss: 2.4835 - val_mae: 2.4835\n",
      "Epoch 178/300\n",
      "515/515 [==============================] - 1s 977us/step - loss: 2.5764 - mae: 2.5764 - val_loss: 2.5101 - val_mae: 2.5101\n",
      "Epoch 179/300\n",
      "515/515 [==============================] - 0s 925us/step - loss: 2.5852 - mae: 2.5852 - val_loss: 2.4952 - val_mae: 2.4952\n",
      "Epoch 180/300\n",
      "515/515 [==============================] - 0s 943us/step - loss: 2.5768 - mae: 2.5768 - val_loss: 2.4702 - val_mae: 2.4702\n",
      "Epoch 181/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.5798 - mae: 2.5798 - val_loss: 2.5165 - val_mae: 2.5165\n",
      "Epoch 182/300\n",
      "515/515 [==============================] - 1s 993us/step - loss: 2.5791 - mae: 2.5791 - val_loss: 2.4704 - val_mae: 2.4704\n",
      "Epoch 183/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.5761 - mae: 2.5761 - val_loss: 2.4923 - val_mae: 2.4923\n",
      "Epoch 184/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.5803 - mae: 2.5803 - val_loss: 2.5238 - val_mae: 2.5238\n",
      "Epoch 185/300\n",
      "515/515 [==============================] - 0s 831us/step - loss: 2.5771 - mae: 2.5771 - val_loss: 2.4930 - val_mae: 2.4930\n",
      "Epoch 186/300\n",
      "515/515 [==============================] - 0s 837us/step - loss: 2.5750 - mae: 2.5750 - val_loss: 2.4721 - val_mae: 2.4721\n",
      "Epoch 187/300\n",
      "515/515 [==============================] - 0s 874us/step - loss: 2.5713 - mae: 2.5713 - val_loss: 2.4732 - val_mae: 2.4732\n",
      "Epoch 188/300\n",
      "515/515 [==============================] - 0s 848us/step - loss: 2.5713 - mae: 2.5713 - val_loss: 2.4751 - val_mae: 2.4751\n",
      "Epoch 189/300\n",
      "515/515 [==============================] - 0s 919us/step - loss: 2.5687 - mae: 2.5687 - val_loss: 2.4793 - val_mae: 2.4793\n",
      "Epoch 190/300\n",
      "515/515 [==============================] - 0s 805us/step - loss: 2.5645 - mae: 2.5645 - val_loss: 2.4744 - val_mae: 2.4744\n",
      "Epoch 191/300\n",
      "515/515 [==============================] - 0s 831us/step - loss: 2.5695 - mae: 2.5695 - val_loss: 2.4629 - val_mae: 2.4629\n",
      "Epoch 192/300\n",
      "515/515 [==============================] - 0s 850us/step - loss: 2.5698 - mae: 2.5698 - val_loss: 2.4968 - val_mae: 2.4968\n",
      "Epoch 193/300\n",
      "515/515 [==============================] - 0s 841us/step - loss: 2.5731 - mae: 2.5731 - val_loss: 2.4958 - val_mae: 2.4958\n",
      "Epoch 194/300\n",
      "515/515 [==============================] - 0s 947us/step - loss: 2.5756 - mae: 2.5756 - val_loss: 2.5223 - val_mae: 2.5223\n",
      "Epoch 195/300\n",
      "515/515 [==============================] - 0s 923us/step - loss: 2.5696 - mae: 2.5696 - val_loss: 2.4598 - val_mae: 2.4598\n",
      "Epoch 196/300\n",
      "515/515 [==============================] - 0s 924us/step - loss: 2.5749 - mae: 2.5749 - val_loss: 2.4885 - val_mae: 2.4885\n",
      "Epoch 197/300\n",
      "515/515 [==============================] - 0s 898us/step - loss: 2.5684 - mae: 2.5684 - val_loss: 2.4955 - val_mae: 2.4955\n",
      "Epoch 198/300\n",
      "515/515 [==============================] - 0s 898us/step - loss: 2.5720 - mae: 2.5720 - val_loss: 2.4909 - val_mae: 2.4909\n",
      "Epoch 199/300\n",
      "515/515 [==============================] - 0s 929us/step - loss: 2.5711 - mae: 2.5711 - val_loss: 2.4980 - val_mae: 2.4980\n",
      "Epoch 200/300\n",
      "515/515 [==============================] - 1s 973us/step - loss: 2.5641 - mae: 2.5641 - val_loss: 2.5022 - val_mae: 2.5022\n",
      "Epoch 201/300\n",
      "515/515 [==============================] - 0s 891us/step - loss: 2.5684 - mae: 2.5684 - val_loss: 2.5192 - val_mae: 2.5192\n",
      "Epoch 202/300\n",
      "515/515 [==============================] - 0s 857us/step - loss: 2.5684 - mae: 2.5684 - val_loss: 2.5113 - val_mae: 2.5113\n",
      "Epoch 203/300\n",
      "515/515 [==============================] - 0s 824us/step - loss: 2.5673 - mae: 2.5673 - val_loss: 2.4652 - val_mae: 2.4652\n",
      "Epoch 204/300\n",
      "515/515 [==============================] - 0s 839us/step - loss: 2.5627 - mae: 2.5627 - val_loss: 2.4792 - val_mae: 2.4792\n",
      "Epoch 205/300\n",
      "515/515 [==============================] - 0s 823us/step - loss: 2.5638 - mae: 2.5638 - val_loss: 2.4670 - val_mae: 2.4670\n",
      "Epoch 206/300\n",
      "515/515 [==============================] - 0s 784us/step - loss: 2.5654 - mae: 2.5654 - val_loss: 2.5108 - val_mae: 2.5108\n",
      "Epoch 207/300\n",
      "515/515 [==============================] - 0s 848us/step - loss: 2.5673 - mae: 2.5673 - val_loss: 2.4901 - val_mae: 2.4901\n",
      "Epoch 208/300\n",
      "515/515 [==============================] - 0s 891us/step - loss: 2.5612 - mae: 2.5612 - val_loss: 2.4861 - val_mae: 2.4861\n",
      "Epoch 209/300\n",
      "515/515 [==============================] - 0s 825us/step - loss: 2.5601 - mae: 2.5601 - val_loss: 2.4832 - val_mae: 2.4832\n",
      "Epoch 210/300\n",
      "515/515 [==============================] - 0s 836us/step - loss: 2.5594 - mae: 2.5594 - val_loss: 2.4600 - val_mae: 2.4600\n",
      "Epoch 211/300\n",
      "515/515 [==============================] - 0s 820us/step - loss: 2.5666 - mae: 2.5666 - val_loss: 2.5002 - val_mae: 2.5002\n",
      "Epoch 212/300\n",
      "515/515 [==============================] - 0s 839us/step - loss: 2.5642 - mae: 2.5642 - val_loss: 2.4801 - val_mae: 2.4801\n",
      "Epoch 213/300\n",
      "515/515 [==============================] - 0s 797us/step - loss: 2.5718 - mae: 2.5718 - val_loss: 2.4840 - val_mae: 2.4840\n",
      "Epoch 214/300\n",
      "515/515 [==============================] - 0s 809us/step - loss: 2.5731 - mae: 2.5731 - val_loss: 2.5071 - val_mae: 2.5071\n",
      "Epoch 215/300\n",
      "515/515 [==============================] - 0s 861us/step - loss: 2.5603 - mae: 2.5603 - val_loss: 2.4831 - val_mae: 2.4831\n",
      "Epoch 216/300\n",
      "515/515 [==============================] - 0s 827us/step - loss: 2.5636 - mae: 2.5636 - val_loss: 2.4885 - val_mae: 2.4885\n",
      "Epoch 217/300\n",
      "515/515 [==============================] - 0s 925us/step - loss: 2.5641 - mae: 2.5641 - val_loss: 2.4871 - val_mae: 2.4871\n",
      "Epoch 218/300\n",
      "515/515 [==============================] - 0s 941us/step - loss: 2.5665 - mae: 2.5665 - val_loss: 2.5072 - val_mae: 2.5072\n",
      "Epoch 219/300\n",
      "515/515 [==============================] - 0s 898us/step - loss: 2.5608 - mae: 2.5608 - val_loss: 2.4896 - val_mae: 2.4896\n",
      "Epoch 220/300\n",
      "515/515 [==============================] - 0s 912us/step - loss: 2.5581 - mae: 2.5581 - val_loss: 2.5074 - val_mae: 2.5074\n",
      "Epoch 221/300\n",
      "515/515 [==============================] - 0s 900us/step - loss: 2.5611 - mae: 2.5611 - val_loss: 2.4910 - val_mae: 2.4910\n",
      "Epoch 222/300\n",
      "515/515 [==============================] - 0s 896us/step - loss: 2.5656 - mae: 2.5656 - val_loss: 2.5080 - val_mae: 2.5080\n",
      "Epoch 223/300\n",
      "515/515 [==============================] - 0s 900us/step - loss: 2.5587 - mae: 2.5587 - val_loss: 2.4971 - val_mae: 2.4971\n",
      "Epoch 224/300\n",
      "515/515 [==============================] - 0s 834us/step - loss: 2.5626 - mae: 2.5626 - val_loss: 2.5055 - val_mae: 2.5055\n",
      "Epoch 225/300\n",
      "515/515 [==============================] - 0s 809us/step - loss: 2.5593 - mae: 2.5593 - val_loss: 2.4973 - val_mae: 2.4973\n",
      "Epoch 226/300\n",
      "515/515 [==============================] - 0s 831us/step - loss: 2.5596 - mae: 2.5596 - val_loss: 2.4900 - val_mae: 2.4900\n",
      "Epoch 227/300\n",
      "515/515 [==============================] - 0s 821us/step - loss: 2.5625 - mae: 2.5625 - val_loss: 2.4894 - val_mae: 2.4894\n",
      "Epoch 228/300\n",
      "515/515 [==============================] - 0s 853us/step - loss: 2.5572 - mae: 2.5572 - val_loss: 2.5006 - val_mae: 2.5006\n",
      "Epoch 229/300\n",
      "515/515 [==============================] - 0s 830us/step - loss: 2.5622 - mae: 2.5622 - val_loss: 2.4880 - val_mae: 2.4880\n",
      "Epoch 230/300\n",
      "515/515 [==============================] - 0s 920us/step - loss: 2.5544 - mae: 2.5544 - val_loss: 2.4927 - val_mae: 2.4927\n",
      "Epoch 231/300\n",
      "515/515 [==============================] - 0s 830us/step - loss: 2.5628 - mae: 2.5628 - val_loss: 2.4972 - val_mae: 2.4972\n",
      "Epoch 232/300\n",
      "515/515 [==============================] - 0s 805us/step - loss: 2.5617 - mae: 2.5617 - val_loss: 2.5118 - val_mae: 2.5118\n",
      "Epoch 233/300\n",
      "515/515 [==============================] - 0s 788us/step - loss: 2.5603 - mae: 2.5603 - val_loss: 2.4835 - val_mae: 2.4835\n",
      "Epoch 234/300\n",
      "515/515 [==============================] - 0s 804us/step - loss: 2.5515 - mae: 2.5515 - val_loss: 2.5137 - val_mae: 2.5137\n",
      "Epoch 235/300\n",
      "515/515 [==============================] - 0s 825us/step - loss: 2.5614 - mae: 2.5614 - val_loss: 2.4792 - val_mae: 2.4792\n",
      "Epoch 236/300\n",
      "515/515 [==============================] - 0s 825us/step - loss: 2.5600 - mae: 2.5600 - val_loss: 2.4882 - val_mae: 2.4882\n",
      "Epoch 237/300\n",
      "515/515 [==============================] - 0s 829us/step - loss: 2.5559 - mae: 2.5559 - val_loss: 2.4812 - val_mae: 2.4812\n",
      "Epoch 238/300\n",
      "515/515 [==============================] - 0s 853us/step - loss: 2.5659 - mae: 2.5659 - val_loss: 2.4761 - val_mae: 2.4761\n",
      "Epoch 239/300\n",
      "515/515 [==============================] - 0s 839us/step - loss: 2.5596 - mae: 2.5596 - val_loss: 2.4724 - val_mae: 2.4724\n",
      "Epoch 240/300\n",
      "515/515 [==============================] - 0s 853us/step - loss: 2.5566 - mae: 2.5566 - val_loss: 2.5692 - val_mae: 2.5692\n",
      "Epoch 241/300\n",
      "515/515 [==============================] - 0s 965us/step - loss: 2.5616 - mae: 2.5616 - val_loss: 2.5276 - val_mae: 2.5276\n",
      "Epoch 242/300\n",
      "515/515 [==============================] - 0s 924us/step - loss: 2.5615 - mae: 2.5615 - val_loss: 2.4753 - val_mae: 2.4753\n",
      "Epoch 243/300\n",
      "515/515 [==============================] - 0s 896us/step - loss: 2.5549 - mae: 2.5549 - val_loss: 2.4968 - val_mae: 2.4968\n",
      "Epoch 244/300\n",
      "515/515 [==============================] - 0s 917us/step - loss: 2.5586 - mae: 2.5586 - val_loss: 2.5186 - val_mae: 2.5186\n",
      "Epoch 245/300\n",
      "515/515 [==============================] - 0s 894us/step - loss: 2.5532 - mae: 2.5532 - val_loss: 2.4796 - val_mae: 2.4796\n",
      "Epoch 246/300\n",
      "515/515 [==============================] - 0s 907us/step - loss: 2.5603 - mae: 2.5603 - val_loss: 2.4724 - val_mae: 2.4724\n",
      "Epoch 247/300\n",
      "515/515 [==============================] - 0s 854us/step - loss: 2.5600 - mae: 2.5600 - val_loss: 2.4688 - val_mae: 2.4688\n",
      "Epoch 248/300\n",
      "515/515 [==============================] - 0s 867us/step - loss: 2.5574 - mae: 2.5574 - val_loss: 2.4716 - val_mae: 2.4716\n",
      "Epoch 249/300\n",
      "515/515 [==============================] - 0s 792us/step - loss: 2.5540 - mae: 2.5540 - val_loss: 2.5085 - val_mae: 2.5085\n",
      "Epoch 250/300\n",
      "515/515 [==============================] - 0s 800us/step - loss: 2.5543 - mae: 2.5543 - val_loss: 2.4975 - val_mae: 2.4975\n",
      "Epoch 251/300\n",
      "515/515 [==============================] - 0s 871us/step - loss: 2.5533 - mae: 2.5533 - val_loss: 2.4931 - val_mae: 2.4931\n",
      "Epoch 252/300\n",
      "515/515 [==============================] - 0s 854us/step - loss: 2.5608 - mae: 2.5608 - val_loss: 2.4999 - val_mae: 2.4999\n",
      "Epoch 253/300\n",
      "515/515 [==============================] - 0s 787us/step - loss: 2.5563 - mae: 2.5563 - val_loss: 2.4818 - val_mae: 2.4818\n",
      "Epoch 254/300\n",
      "515/515 [==============================] - 0s 790us/step - loss: 2.5609 - mae: 2.5609 - val_loss: 2.4805 - val_mae: 2.4805\n"
     ]
    }
   ],
   "source": [
    "# Leo - theta_x, bmi\n",
    "force_train, force_test, theta_x_train, theta_x_test= train_test_split(force_leo_bmi, theta_x_leo, test_size = 0.2, random_state = 0)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 20, restore_best_weights = True)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(6,)),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss= 'mae',\n",
    "              metrics=['mae'])\n",
    "history = model.fit(force_train, theta_x_train, epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (force_test, theta_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "515/515 [==============================] - 0s 936us/step - loss: 2.5532 - mae: 2.5532 - val_loss: 2.4884 - val_mae: 2.4884\n",
      "Epoch 2/300\n",
      "515/515 [==============================] - 0s 798us/step - loss: 2.5591 - mae: 2.5591 - val_loss: 2.4875 - val_mae: 2.4875\n",
      "Epoch 3/300\n",
      "515/515 [==============================] - 0s 793us/step - loss: 2.5562 - mae: 2.5562 - val_loss: 2.4658 - val_mae: 2.4658\n",
      "Epoch 4/300\n",
      "515/515 [==============================] - 0s 784us/step - loss: 2.5555 - mae: 2.5555 - val_loss: 2.5012 - val_mae: 2.5012\n",
      "Epoch 5/300\n",
      "515/515 [==============================] - 0s 819us/step - loss: 2.5531 - mae: 2.5531 - val_loss: 2.4813 - val_mae: 2.4813\n",
      "Epoch 6/300\n",
      "515/515 [==============================] - 0s 826us/step - loss: 2.5541 - mae: 2.5541 - val_loss: 2.4860 - val_mae: 2.4860\n",
      "Epoch 7/300\n",
      "515/515 [==============================] - 0s 813us/step - loss: 2.5626 - mae: 2.5626 - val_loss: 2.4806 - val_mae: 2.4806\n",
      "Epoch 8/300\n",
      "515/515 [==============================] - 0s 822us/step - loss: 2.5522 - mae: 2.5522 - val_loss: 2.4598 - val_mae: 2.4598\n",
      "Epoch 9/300\n",
      "515/515 [==============================] - 0s 844us/step - loss: 2.5552 - mae: 2.5552 - val_loss: 2.4824 - val_mae: 2.4824\n",
      "Epoch 10/300\n",
      "515/515 [==============================] - 0s 828us/step - loss: 2.5530 - mae: 2.5530 - val_loss: 2.4788 - val_mae: 2.4788\n",
      "Epoch 11/300\n",
      "515/515 [==============================] - 0s 805us/step - loss: 2.5568 - mae: 2.5568 - val_loss: 2.4981 - val_mae: 2.4981\n",
      "Epoch 12/300\n",
      "515/515 [==============================] - 0s 815us/step - loss: 2.5495 - mae: 2.5495 - val_loss: 2.4690 - val_mae: 2.4690\n",
      "Epoch 13/300\n",
      "515/515 [==============================] - 0s 824us/step - loss: 2.5492 - mae: 2.5492 - val_loss: 2.4696 - val_mae: 2.4696\n",
      "Epoch 14/300\n",
      "515/515 [==============================] - 0s 829us/step - loss: 2.5477 - mae: 2.5477 - val_loss: 2.4919 - val_mae: 2.4919\n",
      "Epoch 15/300\n",
      "515/515 [==============================] - 0s 829us/step - loss: 2.5625 - mae: 2.5625 - val_loss: 2.4840 - val_mae: 2.4840\n",
      "Epoch 16/300\n",
      "515/515 [==============================] - 0s 832us/step - loss: 2.5498 - mae: 2.5498 - val_loss: 2.4649 - val_mae: 2.4649\n",
      "Epoch 17/300\n",
      "515/515 [==============================] - 0s 816us/step - loss: 2.5529 - mae: 2.5529 - val_loss: 2.4843 - val_mae: 2.4843\n",
      "Epoch 18/300\n",
      "515/515 [==============================] - 0s 783us/step - loss: 2.5535 - mae: 2.5535 - val_loss: 2.5074 - val_mae: 2.5074\n",
      "Epoch 19/300\n",
      "515/515 [==============================] - 0s 780us/step - loss: 2.5508 - mae: 2.5508 - val_loss: 2.4984 - val_mae: 2.4984\n",
      "Epoch 20/300\n",
      "515/515 [==============================] - 0s 929us/step - loss: 2.5503 - mae: 2.5503 - val_loss: 2.4677 - val_mae: 2.4677\n",
      "Epoch 21/300\n",
      "515/515 [==============================] - 0s 922us/step - loss: 2.5492 - mae: 2.5492 - val_loss: 2.4816 - val_mae: 2.4816\n",
      "Epoch 22/300\n",
      "515/515 [==============================] - 0s 877us/step - loss: 2.5480 - mae: 2.5480 - val_loss: 2.4995 - val_mae: 2.4995\n",
      "Epoch 23/300\n",
      "515/515 [==============================] - 0s 885us/step - loss: 2.5626 - mae: 2.5626 - val_loss: 2.4928 - val_mae: 2.4928\n",
      "Epoch 24/300\n",
      "515/515 [==============================] - 0s 896us/step - loss: 2.5534 - mae: 2.5534 - val_loss: 2.4687 - val_mae: 2.4687\n",
      "Epoch 25/300\n",
      "515/515 [==============================] - 0s 881us/step - loss: 2.5522 - mae: 2.5522 - val_loss: 2.4984 - val_mae: 2.4984\n",
      "Epoch 26/300\n",
      "515/515 [==============================] - 0s 908us/step - loss: 2.5489 - mae: 2.5489 - val_loss: 2.4593 - val_mae: 2.4593\n",
      "Epoch 27/300\n",
      "515/515 [==============================] - 0s 834us/step - loss: 2.5533 - mae: 2.5533 - val_loss: 2.4932 - val_mae: 2.4932\n",
      "Epoch 28/300\n",
      "515/515 [==============================] - 0s 817us/step - loss: 2.5489 - mae: 2.5489 - val_loss: 2.4922 - val_mae: 2.4922\n",
      "Epoch 29/300\n",
      "515/515 [==============================] - 0s 834us/step - loss: 2.5510 - mae: 2.5510 - val_loss: 2.4728 - val_mae: 2.4728\n",
      "Epoch 30/300\n",
      "515/515 [==============================] - 0s 809us/step - loss: 2.5517 - mae: 2.5517 - val_loss: 2.4616 - val_mae: 2.4616\n",
      "Epoch 31/300\n",
      "515/515 [==============================] - 0s 875us/step - loss: 2.5488 - mae: 2.5488 - val_loss: 2.5128 - val_mae: 2.5128\n",
      "Epoch 32/300\n",
      "515/515 [==============================] - 0s 820us/step - loss: 2.5423 - mae: 2.5423 - val_loss: 2.4590 - val_mae: 2.4590\n",
      "Epoch 33/300\n",
      "515/515 [==============================] - 0s 831us/step - loss: 2.5469 - mae: 2.5469 - val_loss: 2.4668 - val_mae: 2.4668\n",
      "Epoch 34/300\n",
      "515/515 [==============================] - 0s 842us/step - loss: 2.5578 - mae: 2.5578 - val_loss: 2.4507 - val_mae: 2.4507\n",
      "Epoch 35/300\n",
      "515/515 [==============================] - 0s 839us/step - loss: 2.5528 - mae: 2.5528 - val_loss: 2.4667 - val_mae: 2.4667\n",
      "Epoch 36/300\n",
      "515/515 [==============================] - 0s 838us/step - loss: 2.5486 - mae: 2.5486 - val_loss: 2.4615 - val_mae: 2.4615\n",
      "Epoch 37/300\n",
      "515/515 [==============================] - 0s 842us/step - loss: 2.5484 - mae: 2.5484 - val_loss: 2.4684 - val_mae: 2.4684\n",
      "Epoch 38/300\n",
      "515/515 [==============================] - 0s 824us/step - loss: 2.5481 - mae: 2.5481 - val_loss: 2.4833 - val_mae: 2.4833\n",
      "Epoch 39/300\n",
      "515/515 [==============================] - 0s 830us/step - loss: 2.5483 - mae: 2.5483 - val_loss: 2.5070 - val_mae: 2.5070\n",
      "Epoch 40/300\n",
      "515/515 [==============================] - 0s 767us/step - loss: 2.5482 - mae: 2.5482 - val_loss: 2.4823 - val_mae: 2.4823\n",
      "Epoch 41/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.5537 - mae: 2.5537 - val_loss: 2.4599 - val_mae: 2.4599\n",
      "Epoch 42/300\n",
      "515/515 [==============================] - 0s 767us/step - loss: 2.5493 - mae: 2.5493 - val_loss: 2.4825 - val_mae: 2.4825\n",
      "Epoch 43/300\n",
      "515/515 [==============================] - 0s 771us/step - loss: 2.5435 - mae: 2.5435 - val_loss: 2.4634 - val_mae: 2.4634\n",
      "Epoch 44/300\n",
      "515/515 [==============================] - 0s 945us/step - loss: 2.5507 - mae: 2.5507 - val_loss: 2.4661 - val_mae: 2.4661\n",
      "Epoch 45/300\n",
      "515/515 [==============================] - 0s 834us/step - loss: 2.5595 - mae: 2.5595 - val_loss: 2.4480 - val_mae: 2.4480\n",
      "Epoch 46/300\n",
      "515/515 [==============================] - 0s 811us/step - loss: 2.5454 - mae: 2.5454 - val_loss: 2.4411 - val_mae: 2.4411\n",
      "Epoch 47/300\n",
      "515/515 [==============================] - 0s 808us/step - loss: 2.5475 - mae: 2.5475 - val_loss: 2.4650 - val_mae: 2.4650\n",
      "Epoch 48/300\n",
      "515/515 [==============================] - 0s 814us/step - loss: 2.5443 - mae: 2.5443 - val_loss: 2.4771 - val_mae: 2.4771\n",
      "Epoch 49/300\n",
      "515/515 [==============================] - 0s 810us/step - loss: 2.5498 - mae: 2.5498 - val_loss: 2.4598 - val_mae: 2.4598\n",
      "Epoch 50/300\n",
      "515/515 [==============================] - 0s 830us/step - loss: 2.5548 - mae: 2.5548 - val_loss: 2.4908 - val_mae: 2.4908\n",
      "Epoch 51/300\n",
      "515/515 [==============================] - 0s 771us/step - loss: 2.5453 - mae: 2.5453 - val_loss: 2.4846 - val_mae: 2.4846\n",
      "Epoch 52/300\n",
      "515/515 [==============================] - 0s 778us/step - loss: 2.5461 - mae: 2.5461 - val_loss: 2.4902 - val_mae: 2.4902\n"
     ]
    }
   ],
   "source": [
    "force_train, force_test, theta_x_train, theta_x_test= train_test_split(force_leo_w, theta_x_leo, test_size = 0.2, random_state = 0)\n",
    "history = model.fit(force_train, theta_x_train, epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (force_test, theta_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "515/515 [==============================] - 0s 806us/step - loss: 2.8159 - mae: 2.8159 - val_loss: 2.5941 - val_mae: 2.5941\n",
      "Epoch 2/300\n",
      "515/515 [==============================] - 0s 778us/step - loss: 2.6941 - mae: 2.6941 - val_loss: 2.6421 - val_mae: 2.6421\n",
      "Epoch 3/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.6677 - mae: 2.6677 - val_loss: 2.5630 - val_mae: 2.5630\n",
      "Epoch 4/300\n",
      "515/515 [==============================] - 0s 765us/step - loss: 2.6543 - mae: 2.6543 - val_loss: 2.5381 - val_mae: 2.5381\n",
      "Epoch 5/300\n",
      "515/515 [==============================] - 0s 769us/step - loss: 2.6437 - mae: 2.6437 - val_loss: 2.5740 - val_mae: 2.5740\n",
      "Epoch 6/300\n",
      "515/515 [==============================] - 0s 777us/step - loss: 2.6475 - mae: 2.6475 - val_loss: 2.5276 - val_mae: 2.5276\n",
      "Epoch 7/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 2.6422 - mae: 2.6422 - val_loss: 2.5602 - val_mae: 2.5602\n",
      "Epoch 8/300\n",
      "515/515 [==============================] - 0s 765us/step - loss: 2.6347 - mae: 2.6347 - val_loss: 2.5306 - val_mae: 2.5306\n",
      "Epoch 9/300\n",
      "515/515 [==============================] - 0s 786us/step - loss: 2.6328 - mae: 2.6328 - val_loss: 2.5455 - val_mae: 2.5455\n",
      "Epoch 10/300\n",
      "515/515 [==============================] - 0s 758us/step - loss: 2.6313 - mae: 2.6313 - val_loss: 2.5451 - val_mae: 2.5451\n",
      "Epoch 11/300\n",
      "515/515 [==============================] - 0s 754us/step - loss: 2.6273 - mae: 2.6273 - val_loss: 2.5576 - val_mae: 2.5576\n",
      "Epoch 12/300\n",
      "515/515 [==============================] - 0s 887us/step - loss: 2.6299 - mae: 2.6299 - val_loss: 2.5447 - val_mae: 2.5447\n",
      "Epoch 13/300\n",
      "515/515 [==============================] - 0s 857us/step - loss: 2.6243 - mae: 2.6243 - val_loss: 2.5125 - val_mae: 2.5125\n",
      "Epoch 14/300\n",
      "515/515 [==============================] - 0s 876us/step - loss: 2.6215 - mae: 2.6215 - val_loss: 2.5308 - val_mae: 2.5308\n",
      "Epoch 15/300\n",
      "515/515 [==============================] - 0s 852us/step - loss: 2.6252 - mae: 2.6252 - val_loss: 2.5076 - val_mae: 2.5076\n",
      "Epoch 16/300\n",
      "515/515 [==============================] - 0s 848us/step - loss: 2.6152 - mae: 2.6152 - val_loss: 2.5025 - val_mae: 2.5025\n",
      "Epoch 17/300\n",
      "515/515 [==============================] - 0s 862us/step - loss: 2.6254 - mae: 2.6254 - val_loss: 2.5747 - val_mae: 2.5747\n",
      "Epoch 18/300\n",
      "515/515 [==============================] - 0s 839us/step - loss: 2.6174 - mae: 2.6174 - val_loss: 2.6037 - val_mae: 2.6037\n",
      "Epoch 19/300\n",
      "515/515 [==============================] - 0s 782us/step - loss: 2.6209 - mae: 2.6209 - val_loss: 2.5210 - val_mae: 2.5210\n",
      "Epoch 20/300\n",
      "515/515 [==============================] - 0s 818us/step - loss: 2.6310 - mae: 2.6310 - val_loss: 2.5355 - val_mae: 2.5355\n",
      "Epoch 21/300\n",
      "515/515 [==============================] - 0s 781us/step - loss: 2.6174 - mae: 2.6174 - val_loss: 2.4926 - val_mae: 2.4926\n",
      "Epoch 22/300\n",
      "515/515 [==============================] - 0s 770us/step - loss: 2.6165 - mae: 2.6165 - val_loss: 2.4987 - val_mae: 2.4987\n",
      "Epoch 23/300\n",
      "515/515 [==============================] - 0s 802us/step - loss: 2.6202 - mae: 2.6202 - val_loss: 2.5641 - val_mae: 2.5641\n",
      "Epoch 24/300\n",
      "515/515 [==============================] - 0s 794us/step - loss: 2.6176 - mae: 2.6176 - val_loss: 2.5270 - val_mae: 2.5270\n",
      "Epoch 25/300\n",
      "515/515 [==============================] - 0s 795us/step - loss: 2.6111 - mae: 2.6111 - val_loss: 2.5076 - val_mae: 2.5076\n",
      "Epoch 26/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 2.6132 - mae: 2.6132 - val_loss: 2.5098 - val_mae: 2.5098\n",
      "Epoch 27/300\n",
      "515/515 [==============================] - 0s 803us/step - loss: 2.6163 - mae: 2.6163 - val_loss: 2.5095 - val_mae: 2.5095\n",
      "Epoch 28/300\n",
      "515/515 [==============================] - 0s 787us/step - loss: 2.6097 - mae: 2.6097 - val_loss: 2.4764 - val_mae: 2.4764\n",
      "Epoch 29/300\n",
      "515/515 [==============================] - 0s 769us/step - loss: 2.6180 - mae: 2.6180 - val_loss: 2.5892 - val_mae: 2.5892\n",
      "Epoch 30/300\n",
      "515/515 [==============================] - 0s 770us/step - loss: 2.6180 - mae: 2.6180 - val_loss: 2.5175 - val_mae: 2.5175\n",
      "Epoch 31/300\n",
      "515/515 [==============================] - 0s 779us/step - loss: 2.6091 - mae: 2.6091 - val_loss: 2.5179 - val_mae: 2.5179\n",
      "Epoch 32/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.6060 - mae: 2.6060 - val_loss: 2.5227 - val_mae: 2.5227\n",
      "Epoch 33/300\n",
      "515/515 [==============================] - 0s 781us/step - loss: 2.6124 - mae: 2.6124 - val_loss: 2.5218 - val_mae: 2.5218\n",
      "Epoch 34/300\n",
      "515/515 [==============================] - 0s 780us/step - loss: 2.6161 - mae: 2.6161 - val_loss: 2.4844 - val_mae: 2.4844\n",
      "Epoch 35/300\n",
      "515/515 [==============================] - 0s 799us/step - loss: 2.6110 - mae: 2.6110 - val_loss: 2.5535 - val_mae: 2.5535\n",
      "Epoch 36/300\n",
      "515/515 [==============================] - 0s 795us/step - loss: 2.6077 - mae: 2.6077 - val_loss: 2.5036 - val_mae: 2.5036\n",
      "Epoch 37/300\n",
      "515/515 [==============================] - 0s 891us/step - loss: 2.6136 - mae: 2.6136 - val_loss: 2.5032 - val_mae: 2.5032\n",
      "Epoch 38/300\n",
      "515/515 [==============================] - 0s 842us/step - loss: 2.6071 - mae: 2.6071 - val_loss: 2.5368 - val_mae: 2.5368\n",
      "Epoch 39/300\n",
      "515/515 [==============================] - 0s 830us/step - loss: 2.6148 - mae: 2.6148 - val_loss: 2.5097 - val_mae: 2.5097\n",
      "Epoch 40/300\n",
      "515/515 [==============================] - 0s 906us/step - loss: 2.6112 - mae: 2.6112 - val_loss: 2.5143 - val_mae: 2.5143\n",
      "Epoch 41/300\n",
      "515/515 [==============================] - 0s 848us/step - loss: 2.6094 - mae: 2.6094 - val_loss: 2.5244 - val_mae: 2.5244\n",
      "Epoch 42/300\n",
      "515/515 [==============================] - 0s 880us/step - loss: 2.6068 - mae: 2.6068 - val_loss: 2.5245 - val_mae: 2.5245\n",
      "Epoch 43/300\n",
      "515/515 [==============================] - 0s 905us/step - loss: 2.6036 - mae: 2.6036 - val_loss: 2.5585 - val_mae: 2.5585\n",
      "Epoch 44/300\n",
      "515/515 [==============================] - 0s 807us/step - loss: 2.6056 - mae: 2.6056 - val_loss: 2.5174 - val_mae: 2.5174\n",
      "Epoch 45/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 2.6042 - mae: 2.6042 - val_loss: 2.6211 - val_mae: 2.6211\n",
      "Epoch 46/300\n",
      "515/515 [==============================] - 0s 798us/step - loss: 2.5997 - mae: 2.5997 - val_loss: 2.5402 - val_mae: 2.5402\n",
      "Epoch 47/300\n",
      "515/515 [==============================] - 0s 819us/step - loss: 2.6065 - mae: 2.6065 - val_loss: 2.5365 - val_mae: 2.5365\n",
      "Epoch 48/300\n",
      "515/515 [==============================] - 0s 797us/step - loss: 2.6076 - mae: 2.6076 - val_loss: 2.4933 - val_mae: 2.4933\n",
      "Epoch 49/300\n",
      "515/515 [==============================] - 0s 788us/step - loss: 2.5977 - mae: 2.5977 - val_loss: 2.5562 - val_mae: 2.5562\n",
      "Epoch 50/300\n",
      "515/515 [==============================] - 0s 775us/step - loss: 2.5991 - mae: 2.5991 - val_loss: 2.5265 - val_mae: 2.5265\n",
      "Epoch 51/300\n",
      "515/515 [==============================] - 0s 784us/step - loss: 2.6026 - mae: 2.6026 - val_loss: 2.5091 - val_mae: 2.5091\n",
      "Epoch 52/300\n",
      "515/515 [==============================] - 0s 866us/step - loss: 2.6021 - mae: 2.6021 - val_loss: 2.5542 - val_mae: 2.5542\n",
      "Epoch 53/300\n",
      "515/515 [==============================] - 0s 796us/step - loss: 2.6044 - mae: 2.6044 - val_loss: 2.5502 - val_mae: 2.5502\n",
      "Epoch 54/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.6054 - mae: 2.6054 - val_loss: 2.5400 - val_mae: 2.5400\n",
      "Epoch 55/300\n",
      "515/515 [==============================] - 0s 778us/step - loss: 2.6012 - mae: 2.6012 - val_loss: 2.5196 - val_mae: 2.5196\n",
      "Epoch 56/300\n",
      "515/515 [==============================] - 0s 777us/step - loss: 2.6100 - mae: 2.6100 - val_loss: 2.5538 - val_mae: 2.5538\n",
      "Epoch 57/300\n",
      "515/515 [==============================] - 0s 783us/step - loss: 2.6040 - mae: 2.6040 - val_loss: 2.5082 - val_mae: 2.5082\n",
      "Epoch 58/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 2.6072 - mae: 2.6072 - val_loss: 2.5056 - val_mae: 2.5056\n",
      "Epoch 59/300\n",
      "515/515 [==============================] - 0s 843us/step - loss: 2.5997 - mae: 2.5997 - val_loss: 2.5108 - val_mae: 2.5108\n",
      "Epoch 60/300\n",
      "515/515 [==============================] - 0s 830us/step - loss: 2.5944 - mae: 2.5944 - val_loss: 2.4958 - val_mae: 2.4958\n",
      "Epoch 61/300\n",
      "515/515 [==============================] - 0s 865us/step - loss: 2.5949 - mae: 2.5949 - val_loss: 2.5166 - val_mae: 2.5166\n",
      "Epoch 62/300\n",
      "515/515 [==============================] - 0s 873us/step - loss: 2.6037 - mae: 2.6037 - val_loss: 2.5352 - val_mae: 2.5352\n",
      "Epoch 63/300\n",
      "515/515 [==============================] - 0s 806us/step - loss: 2.5949 - mae: 2.5949 - val_loss: 2.5138 - val_mae: 2.5138\n",
      "Epoch 64/300\n",
      "515/515 [==============================] - 0s 799us/step - loss: 2.6001 - mae: 2.6001 - val_loss: 2.5210 - val_mae: 2.5210\n",
      "Epoch 65/300\n",
      "515/515 [==============================] - 0s 806us/step - loss: 2.5945 - mae: 2.5945 - val_loss: 2.5273 - val_mae: 2.5273\n",
      "Epoch 66/300\n",
      "515/515 [==============================] - 0s 795us/step - loss: 2.5957 - mae: 2.5957 - val_loss: 2.5111 - val_mae: 2.5111\n",
      "Epoch 67/300\n",
      "515/515 [==============================] - 0s 788us/step - loss: 2.5988 - mae: 2.5988 - val_loss: 2.4989 - val_mae: 2.4989\n",
      "Epoch 68/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 2.5918 - mae: 2.5918 - val_loss: 2.4935 - val_mae: 2.4935\n",
      "Epoch 69/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 2.6068 - mae: 2.6068 - val_loss: 2.5857 - val_mae: 2.5857\n",
      "Epoch 70/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6040 - mae: 2.6040 - val_loss: 2.5462 - val_mae: 2.5462\n",
      "Epoch 71/300\n",
      "515/515 [==============================] - 0s 764us/step - loss: 2.6014 - mae: 2.6014 - val_loss: 2.5152 - val_mae: 2.5152\n",
      "Epoch 72/300\n",
      "515/515 [==============================] - 0s 754us/step - loss: 2.6008 - mae: 2.6008 - val_loss: 2.4760 - val_mae: 2.4760\n",
      "Epoch 73/300\n",
      "515/515 [==============================] - 0s 758us/step - loss: 2.6006 - mae: 2.6006 - val_loss: 2.5129 - val_mae: 2.5129\n",
      "Epoch 74/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.6038 - mae: 2.6038 - val_loss: 2.5060 - val_mae: 2.5060\n",
      "Epoch 75/300\n",
      "515/515 [==============================] - 0s 771us/step - loss: 2.6028 - mae: 2.6028 - val_loss: 2.5015 - val_mae: 2.5015\n",
      "Epoch 76/300\n",
      "515/515 [==============================] - 0s 774us/step - loss: 2.5989 - mae: 2.5989 - val_loss: 2.5085 - val_mae: 2.5085\n",
      "Epoch 77/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.6015 - mae: 2.6015 - val_loss: 2.5298 - val_mae: 2.5298\n",
      "Epoch 78/300\n",
      "515/515 [==============================] - 0s 774us/step - loss: 2.6073 - mae: 2.6073 - val_loss: 2.5407 - val_mae: 2.5407\n",
      "Epoch 79/300\n",
      "515/515 [==============================] - 0s 766us/step - loss: 2.5970 - mae: 2.5970 - val_loss: 2.5101 - val_mae: 2.5101\n",
      "Epoch 80/300\n",
      "515/515 [==============================] - 0s 758us/step - loss: 2.5987 - mae: 2.5987 - val_loss: 2.4793 - val_mae: 2.4793\n",
      "Epoch 81/300\n",
      "515/515 [==============================] - 0s 794us/step - loss: 2.5883 - mae: 2.5883 - val_loss: 2.5425 - val_mae: 2.5425\n",
      "Epoch 82/300\n",
      "515/515 [==============================] - 0s 769us/step - loss: 2.5984 - mae: 2.5984 - val_loss: 2.5196 - val_mae: 2.5196\n",
      "Epoch 83/300\n",
      "515/515 [==============================] - 0s 757us/step - loss: 2.5965 - mae: 2.5965 - val_loss: 2.5177 - val_mae: 2.5177\n",
      "Epoch 84/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 2.5978 - mae: 2.5978 - val_loss: 2.5209 - val_mae: 2.5209\n",
      "Epoch 85/300\n",
      "515/515 [==============================] - 0s 753us/step - loss: 2.6003 - mae: 2.6003 - val_loss: 2.4855 - val_mae: 2.4855\n",
      "Epoch 86/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.5905 - mae: 2.5905 - val_loss: 2.5041 - val_mae: 2.5041\n",
      "Epoch 87/300\n",
      "515/515 [==============================] - 0s 837us/step - loss: 2.5991 - mae: 2.5991 - val_loss: 2.5177 - val_mae: 2.5177\n",
      "Epoch 88/300\n",
      "515/515 [==============================] - 0s 820us/step - loss: 2.5974 - mae: 2.5974 - val_loss: 2.5193 - val_mae: 2.5193\n",
      "Epoch 89/300\n",
      "515/515 [==============================] - 0s 789us/step - loss: 2.5923 - mae: 2.5923 - val_loss: 2.5316 - val_mae: 2.5316\n",
      "Epoch 90/300\n",
      "515/515 [==============================] - 0s 804us/step - loss: 2.5959 - mae: 2.5959 - val_loss: 2.5223 - val_mae: 2.5223\n",
      "Epoch 91/300\n",
      "515/515 [==============================] - 0s 802us/step - loss: 2.5889 - mae: 2.5889 - val_loss: 2.4973 - val_mae: 2.4973\n",
      "Epoch 92/300\n",
      "515/515 [==============================] - 0s 797us/step - loss: 2.5894 - mae: 2.5894 - val_loss: 2.4987 - val_mae: 2.4987\n",
      "Epoch 93/300\n",
      "515/515 [==============================] - 0s 812us/step - loss: 2.5934 - mae: 2.5934 - val_loss: 2.5099 - val_mae: 2.5099\n",
      "Epoch 94/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.5930 - mae: 2.5930 - val_loss: 2.5101 - val_mae: 2.5101\n",
      "Epoch 95/300\n",
      "515/515 [==============================] - 0s 779us/step - loss: 2.6044 - mae: 2.6044 - val_loss: 2.5006 - val_mae: 2.5006\n",
      "Epoch 96/300\n",
      "515/515 [==============================] - 0s 775us/step - loss: 2.5919 - mae: 2.5919 - val_loss: 2.5421 - val_mae: 2.5421\n",
      "Epoch 97/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.6004 - mae: 2.6004 - val_loss: 2.5238 - val_mae: 2.5238\n",
      "Epoch 98/300\n",
      "515/515 [==============================] - 0s 839us/step - loss: 2.5960 - mae: 2.5960 - val_loss: 2.5111 - val_mae: 2.5111\n",
      "Epoch 99/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 2.5939 - mae: 2.5939 - val_loss: 2.5307 - val_mae: 2.5307\n",
      "Epoch 100/300\n",
      "515/515 [==============================] - 0s 789us/step - loss: 2.5897 - mae: 2.5897 - val_loss: 2.5057 - val_mae: 2.5057\n",
      "Epoch 101/300\n",
      "515/515 [==============================] - 0s 793us/step - loss: 2.5884 - mae: 2.5884 - val_loss: 2.4944 - val_mae: 2.4944\n"
     ]
    }
   ],
   "source": [
    "force_train, force_test, theta_x_train, theta_x_test= train_test_split(force_leo_h, theta_x_leo, test_size = 0.2, random_state = 0)\n",
    "history = model.fit(force_train, theta_x_train, epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (force_test, theta_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "515/515 [==============================] - 0s 800us/step - loss: 10.4533 - mae: 10.4533 - val_loss: 4.5828 - val_mae: 4.5828\n",
      "Epoch 2/300\n",
      "515/515 [==============================] - 0s 781us/step - loss: 4.6180 - mae: 4.6180 - val_loss: 4.5173 - val_mae: 4.5173\n",
      "Epoch 3/300\n",
      "515/515 [==============================] - 0s 784us/step - loss: 4.4612 - mae: 4.4612 - val_loss: 4.4786 - val_mae: 4.4786\n",
      "Epoch 4/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 4.4377 - mae: 4.4377 - val_loss: 4.4532 - val_mae: 4.4532\n",
      "Epoch 5/300\n",
      "515/515 [==============================] - 0s 819us/step - loss: 4.3847 - mae: 4.3847 - val_loss: 4.4416 - val_mae: 4.4416\n",
      "Epoch 6/300\n",
      "515/515 [==============================] - 0s 796us/step - loss: 4.3636 - mae: 4.3636 - val_loss: 4.4317 - val_mae: 4.4317\n",
      "Epoch 7/300\n",
      "515/515 [==============================] - 0s 785us/step - loss: 4.3546 - mae: 4.3546 - val_loss: 4.4291 - val_mae: 4.4291\n",
      "Epoch 8/300\n",
      "515/515 [==============================] - 0s 774us/step - loss: 4.3500 - mae: 4.3500 - val_loss: 4.4269 - val_mae: 4.4269\n",
      "Epoch 9/300\n",
      "515/515 [==============================] - 0s 865us/step - loss: 4.3333 - mae: 4.3333 - val_loss: 4.4271 - val_mae: 4.4271\n",
      "Epoch 10/300\n",
      "515/515 [==============================] - 0s 946us/step - loss: 4.3346 - mae: 4.3346 - val_loss: 4.4252 - val_mae: 4.4252\n",
      "Epoch 11/300\n",
      "515/515 [==============================] - 0s 841us/step - loss: 4.3292 - mae: 4.3292 - val_loss: 4.4261 - val_mae: 4.4261\n",
      "Epoch 12/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 4.3264 - mae: 4.3264 - val_loss: 4.4272 - val_mae: 4.4272\n",
      "Epoch 13/300\n",
      "515/515 [==============================] - 0s 785us/step - loss: 3.6562 - mae: 3.6562 - val_loss: 3.0670 - val_mae: 3.0670\n",
      "Epoch 14/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 3.2393 - mae: 3.2393 - val_loss: 3.0037 - val_mae: 3.0037\n",
      "Epoch 15/300\n",
      "515/515 [==============================] - 0s 777us/step - loss: 3.1454 - mae: 3.1454 - val_loss: 2.9612 - val_mae: 2.9612\n",
      "Epoch 16/300\n",
      "515/515 [==============================] - 0s 852us/step - loss: 3.0769 - mae: 3.0769 - val_loss: 2.9046 - val_mae: 2.9046\n",
      "Epoch 17/300\n",
      "515/515 [==============================] - 0s 865us/step - loss: 3.0440 - mae: 3.0440 - val_loss: 2.8414 - val_mae: 2.8414\n",
      "Epoch 18/300\n",
      "515/515 [==============================] - 0s 791us/step - loss: 2.9972 - mae: 2.9972 - val_loss: 2.8253 - val_mae: 2.8253\n",
      "Epoch 19/300\n",
      "515/515 [==============================] - 0s 836us/step - loss: 2.9544 - mae: 2.9544 - val_loss: 2.7866 - val_mae: 2.7866\n",
      "Epoch 20/300\n",
      "515/515 [==============================] - 0s 848us/step - loss: 2.9245 - mae: 2.9245 - val_loss: 2.8013 - val_mae: 2.8013\n",
      "Epoch 21/300\n",
      "515/515 [==============================] - 0s 882us/step - loss: 2.9059 - mae: 2.9059 - val_loss: 2.7965 - val_mae: 2.7965\n",
      "Epoch 22/300\n",
      "515/515 [==============================] - 0s 869us/step - loss: 2.9011 - mae: 2.9011 - val_loss: 2.7594 - val_mae: 2.7594\n",
      "Epoch 23/300\n",
      "515/515 [==============================] - 0s 785us/step - loss: 2.8792 - mae: 2.8792 - val_loss: 2.7676 - val_mae: 2.7676\n",
      "Epoch 24/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 2.8683 - mae: 2.8683 - val_loss: 2.7234 - val_mae: 2.7234\n",
      "Epoch 25/300\n",
      "515/515 [==============================] - 0s 767us/step - loss: 2.8595 - mae: 2.8595 - val_loss: 2.7268 - val_mae: 2.7268\n",
      "Epoch 26/300\n",
      "515/515 [==============================] - 0s 756us/step - loss: 2.8424 - mae: 2.8424 - val_loss: 2.7459 - val_mae: 2.7459\n",
      "Epoch 27/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 2.8331 - mae: 2.8331 - val_loss: 2.7094 - val_mae: 2.7094\n",
      "Epoch 28/300\n",
      "515/515 [==============================] - 0s 812us/step - loss: 2.8353 - mae: 2.8353 - val_loss: 2.7495 - val_mae: 2.7495\n",
      "Epoch 29/300\n",
      "515/515 [==============================] - 0s 787us/step - loss: 2.8220 - mae: 2.8220 - val_loss: 2.7293 - val_mae: 2.7293\n",
      "Epoch 30/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 2.8172 - mae: 2.8172 - val_loss: 2.7358 - val_mae: 2.7358\n",
      "Epoch 31/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 2.8110 - mae: 2.8110 - val_loss: 2.7195 - val_mae: 2.7195\n",
      "Epoch 32/300\n",
      "515/515 [==============================] - 0s 771us/step - loss: 2.8101 - mae: 2.8101 - val_loss: 2.7497 - val_mae: 2.7497\n",
      "Epoch 33/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 2.7994 - mae: 2.7994 - val_loss: 2.7042 - val_mae: 2.7042\n",
      "Epoch 34/300\n",
      "515/515 [==============================] - 0s 786us/step - loss: 2.8034 - mae: 2.8034 - val_loss: 2.7704 - val_mae: 2.7704\n",
      "Epoch 35/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.7901 - mae: 2.7901 - val_loss: 2.6846 - val_mae: 2.6846\n",
      "Epoch 36/300\n",
      "515/515 [==============================] - 0s 779us/step - loss: 2.7908 - mae: 2.7908 - val_loss: 2.6906 - val_mae: 2.6906\n",
      "Epoch 37/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.7948 - mae: 2.7948 - val_loss: 2.7477 - val_mae: 2.7477\n",
      "Epoch 38/300\n",
      "515/515 [==============================] - 0s 786us/step - loss: 2.7887 - mae: 2.7887 - val_loss: 2.7214 - val_mae: 2.7214\n",
      "Epoch 39/300\n",
      "515/515 [==============================] - 0s 781us/step - loss: 2.7827 - mae: 2.7827 - val_loss: 2.7167 - val_mae: 2.7167\n",
      "Epoch 40/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 2.7836 - mae: 2.7836 - val_loss: 2.7493 - val_mae: 2.7493\n",
      "Epoch 41/300\n",
      "515/515 [==============================] - 0s 894us/step - loss: 2.7744 - mae: 2.7744 - val_loss: 2.7270 - val_mae: 2.7270\n",
      "Epoch 42/300\n",
      "515/515 [==============================] - 0s 934us/step - loss: 2.7717 - mae: 2.7717 - val_loss: 2.7297 - val_mae: 2.7297\n",
      "Epoch 43/300\n",
      "515/515 [==============================] - 0s 902us/step - loss: 2.7685 - mae: 2.7685 - val_loss: 2.7053 - val_mae: 2.7053\n",
      "Epoch 44/300\n",
      "515/515 [==============================] - 0s 845us/step - loss: 2.7628 - mae: 2.7628 - val_loss: 2.7586 - val_mae: 2.7586\n",
      "Epoch 45/300\n",
      "515/515 [==============================] - 0s 921us/step - loss: 2.7615 - mae: 2.7615 - val_loss: 2.7198 - val_mae: 2.7198\n",
      "Epoch 46/300\n",
      "515/515 [==============================] - 0s 949us/step - loss: 2.7716 - mae: 2.7716 - val_loss: 2.7019 - val_mae: 2.7019\n",
      "Epoch 47/300\n",
      "515/515 [==============================] - 0s 933us/step - loss: 2.7618 - mae: 2.7618 - val_loss: 2.7198 - val_mae: 2.7198\n",
      "Epoch 48/300\n",
      "515/515 [==============================] - 0s 905us/step - loss: 2.7605 - mae: 2.7605 - val_loss: 2.6696 - val_mae: 2.6696\n",
      "Epoch 49/300\n",
      "515/515 [==============================] - 0s 861us/step - loss: 2.7568 - mae: 2.7568 - val_loss: 2.7359 - val_mae: 2.7359\n",
      "Epoch 50/300\n",
      "515/515 [==============================] - 0s 786us/step - loss: 2.7539 - mae: 2.7539 - val_loss: 2.6786 - val_mae: 2.6786\n",
      "Epoch 51/300\n",
      "515/515 [==============================] - 0s 769us/step - loss: 2.7524 - mae: 2.7524 - val_loss: 2.7173 - val_mae: 2.7173\n",
      "Epoch 52/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 2.7428 - mae: 2.7428 - val_loss: 2.7226 - val_mae: 2.7226\n",
      "Epoch 53/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.7471 - mae: 2.7471 - val_loss: 2.7046 - val_mae: 2.7046\n",
      "Epoch 54/300\n",
      "515/515 [==============================] - 0s 778us/step - loss: 2.7433 - mae: 2.7433 - val_loss: 2.7120 - val_mae: 2.7120\n",
      "Epoch 55/300\n",
      "515/515 [==============================] - 0s 784us/step - loss: 2.7492 - mae: 2.7492 - val_loss: 2.6867 - val_mae: 2.6867\n",
      "Epoch 56/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.7407 - mae: 2.7407 - val_loss: 2.7206 - val_mae: 2.7206\n",
      "Epoch 57/300\n",
      "515/515 [==============================] - 0s 767us/step - loss: 2.7377 - mae: 2.7377 - val_loss: 2.6812 - val_mae: 2.6812\n",
      "Epoch 58/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.7371 - mae: 2.7371 - val_loss: 2.7000 - val_mae: 2.7000\n",
      "Epoch 59/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 2.7396 - mae: 2.7396 - val_loss: 2.7040 - val_mae: 2.7040\n",
      "Epoch 60/300\n",
      "515/515 [==============================] - 0s 774us/step - loss: 2.7320 - mae: 2.7320 - val_loss: 2.6781 - val_mae: 2.6781\n",
      "Epoch 61/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 2.7343 - mae: 2.7343 - val_loss: 2.6842 - val_mae: 2.6842\n",
      "Epoch 62/300\n",
      "515/515 [==============================] - 0s 765us/step - loss: 2.7282 - mae: 2.7282 - val_loss: 2.6956 - val_mae: 2.6956\n",
      "Epoch 63/300\n",
      "515/515 [==============================] - 0s 756us/step - loss: 2.7290 - mae: 2.7290 - val_loss: 2.6560 - val_mae: 2.6560\n",
      "Epoch 64/300\n",
      "515/515 [==============================] - 0s 853us/step - loss: 2.7290 - mae: 2.7290 - val_loss: 2.7157 - val_mae: 2.7157\n",
      "Epoch 65/300\n",
      "515/515 [==============================] - 0s 815us/step - loss: 2.7242 - mae: 2.7242 - val_loss: 2.7138 - val_mae: 2.7138\n",
      "Epoch 66/300\n",
      "515/515 [==============================] - 0s 899us/step - loss: 2.7200 - mae: 2.7200 - val_loss: 2.6829 - val_mae: 2.6829\n",
      "Epoch 67/300\n",
      "515/515 [==============================] - 0s 809us/step - loss: 2.7255 - mae: 2.7255 - val_loss: 2.7326 - val_mae: 2.7326\n",
      "Epoch 68/300\n",
      "515/515 [==============================] - 0s 806us/step - loss: 2.7262 - mae: 2.7262 - val_loss: 2.6845 - val_mae: 2.6845\n",
      "Epoch 69/300\n",
      "515/515 [==============================] - 0s 824us/step - loss: 2.7220 - mae: 2.7220 - val_loss: 2.6788 - val_mae: 2.6788\n",
      "Epoch 70/300\n",
      "515/515 [==============================] - 0s 839us/step - loss: 2.7151 - mae: 2.7151 - val_loss: 2.7030 - val_mae: 2.7030\n",
      "Epoch 71/300\n",
      "515/515 [==============================] - 0s 850us/step - loss: 2.7154 - mae: 2.7154 - val_loss: 2.6969 - val_mae: 2.6969\n",
      "Epoch 72/300\n",
      "515/515 [==============================] - 0s 824us/step - loss: 2.7139 - mae: 2.7139 - val_loss: 2.6749 - val_mae: 2.6749\n",
      "Epoch 73/300\n",
      "515/515 [==============================] - 0s 777us/step - loss: 2.7124 - mae: 2.7124 - val_loss: 2.6976 - val_mae: 2.6976\n",
      "Epoch 74/300\n",
      "515/515 [==============================] - 0s 748us/step - loss: 2.7154 - mae: 2.7154 - val_loss: 2.6921 - val_mae: 2.6921\n",
      "Epoch 75/300\n",
      "515/515 [==============================] - 0s 776us/step - loss: 2.7128 - mae: 2.7128 - val_loss: 2.7051 - val_mae: 2.7051\n",
      "Epoch 76/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 2.7114 - mae: 2.7114 - val_loss: 2.6760 - val_mae: 2.6760\n",
      "Epoch 77/300\n",
      "515/515 [==============================] - 0s 769us/step - loss: 2.7077 - mae: 2.7077 - val_loss: 2.6678 - val_mae: 2.6678\n",
      "Epoch 78/300\n",
      "515/515 [==============================] - 0s 781us/step - loss: 2.7051 - mae: 2.7051 - val_loss: 2.7002 - val_mae: 2.7002\n",
      "Epoch 79/300\n",
      "515/515 [==============================] - 0s 793us/step - loss: 2.7017 - mae: 2.7017 - val_loss: 2.6922 - val_mae: 2.6922\n",
      "Epoch 80/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 2.7101 - mae: 2.7101 - val_loss: 2.6569 - val_mae: 2.6569\n",
      "Epoch 81/300\n",
      "515/515 [==============================] - 0s 827us/step - loss: 2.7052 - mae: 2.7052 - val_loss: 2.6881 - val_mae: 2.6881\n",
      "Epoch 82/300\n",
      "515/515 [==============================] - 0s 778us/step - loss: 2.7045 - mae: 2.7045 - val_loss: 2.6962 - val_mae: 2.6962\n",
      "Epoch 83/300\n",
      "515/515 [==============================] - 0s 786us/step - loss: 2.7044 - mae: 2.7044 - val_loss: 2.6710 - val_mae: 2.6710\n",
      "Epoch 84/300\n",
      "515/515 [==============================] - 0s 765us/step - loss: 2.7021 - mae: 2.7021 - val_loss: 2.6732 - val_mae: 2.6732\n",
      "Epoch 85/300\n",
      "515/515 [==============================] - 0s 782us/step - loss: 2.7005 - mae: 2.7005 - val_loss: 2.6411 - val_mae: 2.6411\n",
      "Epoch 86/300\n",
      "515/515 [==============================] - 0s 778us/step - loss: 2.7029 - mae: 2.7029 - val_loss: 2.7148 - val_mae: 2.7148\n",
      "Epoch 87/300\n",
      "515/515 [==============================] - 0s 758us/step - loss: 2.6966 - mae: 2.6966 - val_loss: 2.6572 - val_mae: 2.6572\n",
      "Epoch 88/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.6983 - mae: 2.6983 - val_loss: 2.6569 - val_mae: 2.6569\n",
      "Epoch 89/300\n",
      "515/515 [==============================] - 0s 753us/step - loss: 2.6936 - mae: 2.6936 - val_loss: 2.6919 - val_mae: 2.6919\n",
      "Epoch 90/300\n",
      "515/515 [==============================] - 0s 758us/step - loss: 2.6971 - mae: 2.6971 - val_loss: 2.6625 - val_mae: 2.6625\n",
      "Epoch 91/300\n",
      "515/515 [==============================] - 0s 888us/step - loss: 2.6921 - mae: 2.6921 - val_loss: 2.6752 - val_mae: 2.6752\n",
      "Epoch 92/300\n",
      "515/515 [==============================] - 0s 800us/step - loss: 2.6913 - mae: 2.6913 - val_loss: 2.6587 - val_mae: 2.6587\n",
      "Epoch 93/300\n",
      "515/515 [==============================] - 0s 809us/step - loss: 2.6945 - mae: 2.6945 - val_loss: 2.6843 - val_mae: 2.6843\n",
      "Epoch 94/300\n",
      "515/515 [==============================] - 0s 824us/step - loss: 2.6924 - mae: 2.6924 - val_loss: 2.7144 - val_mae: 2.7144\n",
      "Epoch 95/300\n",
      "515/515 [==============================] - 0s 797us/step - loss: 2.6923 - mae: 2.6923 - val_loss: 2.6902 - val_mae: 2.6902\n",
      "Epoch 96/300\n",
      "515/515 [==============================] - 0s 919us/step - loss: 2.6825 - mae: 2.6825 - val_loss: 2.6806 - val_mae: 2.6806\n",
      "Epoch 97/300\n",
      "515/515 [==============================] - 0s 931us/step - loss: 2.6918 - mae: 2.6918 - val_loss: 2.6338 - val_mae: 2.6338\n",
      "Epoch 98/300\n",
      "515/515 [==============================] - 0s 775us/step - loss: 2.6865 - mae: 2.6865 - val_loss: 2.7064 - val_mae: 2.7064\n",
      "Epoch 99/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6871 - mae: 2.6871 - val_loss: 2.6600 - val_mae: 2.6600\n",
      "Epoch 100/300\n",
      "515/515 [==============================] - 0s 792us/step - loss: 2.6881 - mae: 2.6881 - val_loss: 2.6911 - val_mae: 2.6911\n",
      "Epoch 101/300\n",
      "515/515 [==============================] - 0s 806us/step - loss: 2.6859 - mae: 2.6859 - val_loss: 2.6844 - val_mae: 2.6844\n",
      "Epoch 102/300\n",
      "515/515 [==============================] - 0s 774us/step - loss: 2.6869 - mae: 2.6869 - val_loss: 2.6100 - val_mae: 2.6100\n",
      "Epoch 103/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 2.6836 - mae: 2.6836 - val_loss: 2.6337 - val_mae: 2.6337\n",
      "Epoch 104/300\n",
      "515/515 [==============================] - 0s 758us/step - loss: 2.6772 - mae: 2.6772 - val_loss: 2.6771 - val_mae: 2.6771\n",
      "Epoch 105/300\n",
      "515/515 [==============================] - 0s 755us/step - loss: 2.6849 - mae: 2.6849 - val_loss: 2.7219 - val_mae: 2.7219\n",
      "Epoch 106/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 2.6836 - mae: 2.6836 - val_loss: 2.6680 - val_mae: 2.6680\n",
      "Epoch 107/300\n",
      "515/515 [==============================] - 0s 755us/step - loss: 2.6811 - mae: 2.6811 - val_loss: 2.6238 - val_mae: 2.6238\n",
      "Epoch 108/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6836 - mae: 2.6836 - val_loss: 2.6664 - val_mae: 2.6664\n",
      "Epoch 109/300\n",
      "515/515 [==============================] - 0s 756us/step - loss: 2.6805 - mae: 2.6805 - val_loss: 2.7147 - val_mae: 2.7147\n",
      "Epoch 110/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 2.6783 - mae: 2.6783 - val_loss: 2.6672 - val_mae: 2.6672\n",
      "Epoch 111/300\n",
      "515/515 [==============================] - 0s 751us/step - loss: 2.6757 - mae: 2.6757 - val_loss: 2.6790 - val_mae: 2.6790\n",
      "Epoch 112/300\n",
      "515/515 [==============================] - 0s 756us/step - loss: 2.6765 - mae: 2.6765 - val_loss: 2.6935 - val_mae: 2.6935\n",
      "Epoch 113/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6787 - mae: 2.6787 - val_loss: 2.6714 - val_mae: 2.6714\n",
      "Epoch 114/300\n",
      "515/515 [==============================] - 0s 770us/step - loss: 2.6763 - mae: 2.6763 - val_loss: 2.6799 - val_mae: 2.6799\n",
      "Epoch 115/300\n",
      "515/515 [==============================] - 0s 770us/step - loss: 2.6783 - mae: 2.6783 - val_loss: 2.6854 - val_mae: 2.6854\n",
      "Epoch 116/300\n",
      "515/515 [==============================] - 0s 880us/step - loss: 2.6726 - mae: 2.6726 - val_loss: 2.6487 - val_mae: 2.6487\n",
      "Epoch 117/300\n",
      "515/515 [==============================] - 0s 849us/step - loss: 2.6735 - mae: 2.6735 - val_loss: 2.6863 - val_mae: 2.6863\n",
      "Epoch 118/300\n",
      "515/515 [==============================] - 0s 849us/step - loss: 2.6799 - mae: 2.6799 - val_loss: 2.6498 - val_mae: 2.6498\n",
      "Epoch 119/300\n",
      "515/515 [==============================] - 0s 847us/step - loss: 2.6649 - mae: 2.6649 - val_loss: 2.7204 - val_mae: 2.7204\n",
      "Epoch 120/300\n",
      "515/515 [==============================] - 0s 904us/step - loss: 2.6736 - mae: 2.6736 - val_loss: 2.7194 - val_mae: 2.7194\n",
      "Epoch 121/300\n",
      "515/515 [==============================] - 0s 836us/step - loss: 2.6695 - mae: 2.6695 - val_loss: 2.6856 - val_mae: 2.6856\n",
      "Epoch 122/300\n",
      "515/515 [==============================] - 0s 834us/step - loss: 2.6698 - mae: 2.6698 - val_loss: 2.6596 - val_mae: 2.6596\n",
      "Epoch 123/300\n",
      "515/515 [==============================] - 0s 823us/step - loss: 2.6724 - mae: 2.6724 - val_loss: 2.6572 - val_mae: 2.6572\n",
      "Epoch 124/300\n",
      "515/515 [==============================] - 0s 802us/step - loss: 2.6686 - mae: 2.6686 - val_loss: 2.6134 - val_mae: 2.6134\n",
      "Epoch 125/300\n",
      "515/515 [==============================] - 0s 805us/step - loss: 2.6655 - mae: 2.6655 - val_loss: 2.6799 - val_mae: 2.6799\n",
      "Epoch 126/300\n",
      "515/515 [==============================] - 0s 838us/step - loss: 2.6681 - mae: 2.6681 - val_loss: 2.6679 - val_mae: 2.6679\n",
      "Epoch 127/300\n",
      "515/515 [==============================] - 0s 834us/step - loss: 2.6653 - mae: 2.6653 - val_loss: 2.7109 - val_mae: 2.7109\n",
      "Epoch 128/300\n",
      "515/515 [==============================] - 0s 846us/step - loss: 2.6701 - mae: 2.6701 - val_loss: 2.6753 - val_mae: 2.6753\n",
      "Epoch 129/300\n",
      "515/515 [==============================] - 0s 813us/step - loss: 2.6753 - mae: 2.6753 - val_loss: 2.6815 - val_mae: 2.6815\n",
      "Epoch 130/300\n",
      "515/515 [==============================] - 0s 787us/step - loss: 2.6710 - mae: 2.6710 - val_loss: 2.6350 - val_mae: 2.6350\n",
      "Epoch 131/300\n",
      "515/515 [==============================] - 0s 881us/step - loss: 2.6706 - mae: 2.6706 - val_loss: 2.6894 - val_mae: 2.6894\n",
      "Epoch 132/300\n",
      "515/515 [==============================] - 0s 833us/step - loss: 2.6681 - mae: 2.6681 - val_loss: 2.6567 - val_mae: 2.6567\n",
      "Epoch 133/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 2.6631 - mae: 2.6631 - val_loss: 2.6647 - val_mae: 2.6647\n",
      "Epoch 134/300\n",
      "515/515 [==============================] - 0s 763us/step - loss: 2.6689 - mae: 2.6689 - val_loss: 2.6424 - val_mae: 2.6424\n",
      "Epoch 135/300\n",
      "515/515 [==============================] - 0s 764us/step - loss: 2.6580 - mae: 2.6580 - val_loss: 2.6636 - val_mae: 2.6636\n",
      "Epoch 136/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 2.6675 - mae: 2.6675 - val_loss: 2.6619 - val_mae: 2.6619\n",
      "Epoch 137/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6694 - mae: 2.6694 - val_loss: 2.6531 - val_mae: 2.6531\n",
      "Epoch 138/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 2.6664 - mae: 2.6664 - val_loss: 2.6678 - val_mae: 2.6678\n",
      "Epoch 139/300\n",
      "515/515 [==============================] - 0s 783us/step - loss: 2.6620 - mae: 2.6620 - val_loss: 2.6503 - val_mae: 2.6503\n",
      "Epoch 140/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 2.6673 - mae: 2.6673 - val_loss: 2.6858 - val_mae: 2.6858\n",
      "Epoch 141/300\n",
      "515/515 [==============================] - 0s 890us/step - loss: 2.6645 - mae: 2.6645 - val_loss: 2.6365 - val_mae: 2.6365\n",
      "Epoch 142/300\n",
      "515/515 [==============================] - 0s 801us/step - loss: 2.6568 - mae: 2.6568 - val_loss: 2.6704 - val_mae: 2.6704\n",
      "Epoch 143/300\n",
      "515/515 [==============================] - 0s 806us/step - loss: 2.6596 - mae: 2.6596 - val_loss: 2.6566 - val_mae: 2.6566\n",
      "Epoch 144/300\n",
      "515/515 [==============================] - 0s 824us/step - loss: 2.6572 - mae: 2.6572 - val_loss: 2.6771 - val_mae: 2.6771\n",
      "Epoch 145/300\n",
      "515/515 [==============================] - 0s 808us/step - loss: 2.6601 - mae: 2.6601 - val_loss: 2.6384 - val_mae: 2.6384\n",
      "Epoch 146/300\n",
      "515/515 [==============================] - 0s 801us/step - loss: 2.6665 - mae: 2.6665 - val_loss: 2.6692 - val_mae: 2.6692\n",
      "Epoch 147/300\n",
      "515/515 [==============================] - 0s 795us/step - loss: 2.6628 - mae: 2.6628 - val_loss: 2.6965 - val_mae: 2.6965\n",
      "Epoch 148/300\n",
      "515/515 [==============================] - 0s 763us/step - loss: 2.6614 - mae: 2.6614 - val_loss: 2.6554 - val_mae: 2.6554\n",
      "Epoch 149/300\n",
      "515/515 [==============================] - 0s 769us/step - loss: 2.6619 - mae: 2.6619 - val_loss: 2.6893 - val_mae: 2.6893\n",
      "Epoch 150/300\n",
      "515/515 [==============================] - 0s 781us/step - loss: 2.6572 - mae: 2.6572 - val_loss: 2.6514 - val_mae: 2.6514\n",
      "Epoch 151/300\n",
      "515/515 [==============================] - 0s 789us/step - loss: 2.6608 - mae: 2.6608 - val_loss: 2.6819 - val_mae: 2.6819\n",
      "Epoch 152/300\n",
      "515/515 [==============================] - 0s 758us/step - loss: 2.6623 - mae: 2.6623 - val_loss: 2.6594 - val_mae: 2.6594\n",
      "Epoch 153/300\n",
      "515/515 [==============================] - 0s 764us/step - loss: 2.6594 - mae: 2.6594 - val_loss: 2.6782 - val_mae: 2.6782\n",
      "Epoch 154/300\n",
      "515/515 [==============================] - 0s 807us/step - loss: 2.6552 - mae: 2.6552 - val_loss: 2.6711 - val_mae: 2.6711\n",
      "Epoch 155/300\n",
      "515/515 [==============================] - 0s 766us/step - loss: 2.6611 - mae: 2.6611 - val_loss: 2.6333 - val_mae: 2.6333\n",
      "Epoch 156/300\n",
      "515/515 [==============================] - 0s 763us/step - loss: 2.6603 - mae: 2.6603 - val_loss: 2.6177 - val_mae: 2.6177\n",
      "Epoch 157/300\n",
      "515/515 [==============================] - 0s 771us/step - loss: 2.6595 - mae: 2.6595 - val_loss: 2.6515 - val_mae: 2.6515\n",
      "Epoch 158/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6588 - mae: 2.6588 - val_loss: 2.6381 - val_mae: 2.6381\n",
      "Epoch 159/300\n",
      "515/515 [==============================] - 0s 819us/step - loss: 2.6562 - mae: 2.6562 - val_loss: 2.6619 - val_mae: 2.6619\n",
      "Epoch 160/300\n",
      "515/515 [==============================] - 0s 767us/step - loss: 2.6570 - mae: 2.6570 - val_loss: 2.6817 - val_mae: 2.6817\n",
      "Epoch 161/300\n",
      "515/515 [==============================] - 0s 766us/step - loss: 2.6535 - mae: 2.6535 - val_loss: 2.6762 - val_mae: 2.6762\n",
      "Epoch 162/300\n",
      "515/515 [==============================] - 0s 757us/step - loss: 2.6597 - mae: 2.6597 - val_loss: 2.6845 - val_mae: 2.6845\n",
      "Epoch 163/300\n",
      "515/515 [==============================] - 0s 764us/step - loss: 2.6506 - mae: 2.6506 - val_loss: 2.6494 - val_mae: 2.6494\n",
      "Epoch 164/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.6536 - mae: 2.6536 - val_loss: 2.6107 - val_mae: 2.6107\n",
      "Epoch 165/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.6520 - mae: 2.6520 - val_loss: 2.6778 - val_mae: 2.6778\n",
      "Epoch 166/300\n",
      "515/515 [==============================] - 0s 853us/step - loss: 2.6520 - mae: 2.6520 - val_loss: 2.6627 - val_mae: 2.6627\n",
      "Epoch 167/300\n",
      "515/515 [==============================] - 0s 823us/step - loss: 2.6549 - mae: 2.6549 - val_loss: 2.6450 - val_mae: 2.6450\n",
      "Epoch 168/300\n",
      "515/515 [==============================] - 0s 810us/step - loss: 2.6533 - mae: 2.6533 - val_loss: 2.6907 - val_mae: 2.6907\n",
      "Epoch 169/300\n",
      "515/515 [==============================] - 0s 825us/step - loss: 2.6554 - mae: 2.6554 - val_loss: 2.6664 - val_mae: 2.6664\n",
      "Epoch 170/300\n",
      "515/515 [==============================] - 0s 806us/step - loss: 2.6537 - mae: 2.6537 - val_loss: 2.6608 - val_mae: 2.6608\n",
      "Epoch 171/300\n",
      "515/515 [==============================] - 0s 846us/step - loss: 2.6530 - mae: 2.6530 - val_loss: 2.6634 - val_mae: 2.6634\n",
      "Epoch 172/300\n",
      "515/515 [==============================] - 0s 801us/step - loss: 2.6515 - mae: 2.6515 - val_loss: 2.6735 - val_mae: 2.6735\n",
      "Epoch 173/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 2.6511 - mae: 2.6511 - val_loss: 2.6602 - val_mae: 2.6602\n",
      "Epoch 174/300\n",
      "515/515 [==============================] - 0s 807us/step - loss: 2.6532 - mae: 2.6532 - val_loss: 2.6785 - val_mae: 2.6785\n",
      "Epoch 175/300\n",
      "515/515 [==============================] - 0s 816us/step - loss: 2.6535 - mae: 2.6535 - val_loss: 2.6748 - val_mae: 2.6748\n",
      "Epoch 176/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.6525 - mae: 2.6525 - val_loss: 2.6786 - val_mae: 2.6786\n",
      "Epoch 177/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 2.6459 - mae: 2.6459 - val_loss: 2.6143 - val_mae: 2.6143\n",
      "Epoch 178/300\n",
      "515/515 [==============================] - 0s 766us/step - loss: 2.6557 - mae: 2.6557 - val_loss: 2.6678 - val_mae: 2.6678\n",
      "Epoch 179/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 2.6558 - mae: 2.6558 - val_loss: 2.6693 - val_mae: 2.6693\n",
      "Epoch 180/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 2.6488 - mae: 2.6488 - val_loss: 2.6535 - val_mae: 2.6535\n",
      "Epoch 181/300\n",
      "515/515 [==============================] - 0s 754us/step - loss: 2.6456 - mae: 2.6456 - val_loss: 2.6549 - val_mae: 2.6549\n",
      "Epoch 182/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.6513 - mae: 2.6513 - val_loss: 2.6561 - val_mae: 2.6561\n",
      "Epoch 183/300\n",
      "515/515 [==============================] - 0s 757us/step - loss: 2.6480 - mae: 2.6480 - val_loss: 2.6566 - val_mae: 2.6566\n",
      "Epoch 184/300\n",
      "515/515 [==============================] - 0s 752us/step - loss: 2.6495 - mae: 2.6495 - val_loss: 2.6407 - val_mae: 2.6407\n",
      "Epoch 185/300\n",
      "515/515 [==============================] - 0s 750us/step - loss: 2.6490 - mae: 2.6490 - val_loss: 2.6760 - val_mae: 2.6760\n",
      "Epoch 186/300\n",
      "515/515 [==============================] - 0s 756us/step - loss: 2.6452 - mae: 2.6452 - val_loss: 2.6269 - val_mae: 2.6269\n",
      "Epoch 187/300\n",
      "515/515 [==============================] - 0s 757us/step - loss: 2.6427 - mae: 2.6427 - val_loss: 2.6596 - val_mae: 2.6596\n",
      "Epoch 188/300\n",
      "515/515 [==============================] - 0s 754us/step - loss: 2.6462 - mae: 2.6462 - val_loss: 2.6661 - val_mae: 2.6661\n",
      "Epoch 189/300\n",
      "515/515 [==============================] - 0s 754us/step - loss: 2.6466 - mae: 2.6466 - val_loss: 2.6299 - val_mae: 2.6299\n",
      "Epoch 190/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6420 - mae: 2.6420 - val_loss: 2.6950 - val_mae: 2.6950\n",
      "Epoch 191/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.6483 - mae: 2.6483 - val_loss: 2.6419 - val_mae: 2.6419\n",
      "Epoch 192/300\n",
      "515/515 [==============================] - 0s 872us/step - loss: 2.6456 - mae: 2.6456 - val_loss: 2.6931 - val_mae: 2.6931\n",
      "Epoch 193/300\n",
      "515/515 [==============================] - 0s 794us/step - loss: 2.6417 - mae: 2.6417 - val_loss: 2.6358 - val_mae: 2.6358\n",
      "Epoch 194/300\n",
      "515/515 [==============================] - 0s 802us/step - loss: 2.6445 - mae: 2.6445 - val_loss: 2.6553 - val_mae: 2.6553\n",
      "Epoch 195/300\n",
      "515/515 [==============================] - 0s 806us/step - loss: 2.6438 - mae: 2.6438 - val_loss: 2.6461 - val_mae: 2.6461\n",
      "Epoch 196/300\n",
      "515/515 [==============================] - 0s 799us/step - loss: 2.6412 - mae: 2.6412 - val_loss: 2.6697 - val_mae: 2.6697\n",
      "Epoch 197/300\n",
      "515/515 [==============================] - 0s 813us/step - loss: 2.6445 - mae: 2.6445 - val_loss: 2.6649 - val_mae: 2.6649\n",
      "Epoch 198/300\n",
      "515/515 [==============================] - 0s 856us/step - loss: 2.6411 - mae: 2.6411 - val_loss: 2.6613 - val_mae: 2.6613\n",
      "Epoch 199/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 2.6453 - mae: 2.6453 - val_loss: 2.6474 - val_mae: 2.6474\n",
      "Epoch 200/300\n",
      "515/515 [==============================] - 0s 758us/step - loss: 2.6403 - mae: 2.6403 - val_loss: 2.6432 - val_mae: 2.6432\n",
      "Epoch 201/300\n",
      "515/515 [==============================] - 0s 753us/step - loss: 2.6437 - mae: 2.6437 - val_loss: 2.6363 - val_mae: 2.6363\n",
      "Epoch 202/300\n",
      "515/515 [==============================] - 0s 758us/step - loss: 2.6436 - mae: 2.6436 - val_loss: 2.6528 - val_mae: 2.6528\n",
      "Epoch 203/300\n",
      "515/515 [==============================] - 0s 756us/step - loss: 2.6466 - mae: 2.6466 - val_loss: 2.6380 - val_mae: 2.6380\n",
      "Epoch 204/300\n",
      "515/515 [==============================] - 0s 758us/step - loss: 2.6440 - mae: 2.6440 - val_loss: 2.6995 - val_mae: 2.6995\n",
      "Epoch 205/300\n",
      "515/515 [==============================] - 0s 755us/step - loss: 2.6373 - mae: 2.6373 - val_loss: 2.6488 - val_mae: 2.6488\n",
      "Epoch 206/300\n",
      "515/515 [==============================] - 0s 849us/step - loss: 2.6433 - mae: 2.6433 - val_loss: 2.6684 - val_mae: 2.6684\n",
      "Epoch 207/300\n",
      "515/515 [==============================] - 0s 883us/step - loss: 2.6449 - mae: 2.6449 - val_loss: 2.6393 - val_mae: 2.6393\n",
      "Epoch 208/300\n",
      "515/515 [==============================] - 0s 924us/step - loss: 2.6424 - mae: 2.6424 - val_loss: 2.6429 - val_mae: 2.6429\n",
      "Epoch 209/300\n",
      "515/515 [==============================] - 0s 881us/step - loss: 2.6431 - mae: 2.6431 - val_loss: 2.6697 - val_mae: 2.6697\n",
      "Epoch 210/300\n",
      "515/515 [==============================] - 0s 886us/step - loss: 2.6427 - mae: 2.6427 - val_loss: 2.7100 - val_mae: 2.7100\n",
      "Epoch 211/300\n",
      "515/515 [==============================] - 0s 879us/step - loss: 2.6412 - mae: 2.6412 - val_loss: 2.6606 - val_mae: 2.6606\n",
      "Epoch 212/300\n",
      "515/515 [==============================] - 0s 901us/step - loss: 2.6375 - mae: 2.6375 - val_loss: 2.6653 - val_mae: 2.6653\n",
      "Epoch 213/300\n",
      "515/515 [==============================] - 0s 900us/step - loss: 2.6423 - mae: 2.6423 - val_loss: 2.6457 - val_mae: 2.6457\n",
      "Epoch 214/300\n",
      "515/515 [==============================] - 0s 917us/step - loss: 2.6360 - mae: 2.6360 - val_loss: 2.6522 - val_mae: 2.6522\n",
      "Epoch 215/300\n",
      "515/515 [==============================] - 0s 908us/step - loss: 2.6441 - mae: 2.6441 - val_loss: 2.6472 - val_mae: 2.6472\n",
      "Epoch 216/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.6387 - mae: 2.6387 - val_loss: 2.6394 - val_mae: 2.6394\n",
      "Epoch 217/300\n",
      "515/515 [==============================] - 1s 983us/step - loss: 2.6409 - mae: 2.6409 - val_loss: 2.6447 - val_mae: 2.6447\n",
      "Epoch 218/300\n",
      "515/515 [==============================] - 1s 988us/step - loss: 2.6402 - mae: 2.6402 - val_loss: 2.6420 - val_mae: 2.6420\n",
      "Epoch 219/300\n",
      "515/515 [==============================] - 1s 983us/step - loss: 2.6421 - mae: 2.6421 - val_loss: 2.6948 - val_mae: 2.6948\n",
      "Epoch 220/300\n",
      "515/515 [==============================] - 1s 999us/step - loss: 2.6425 - mae: 2.6425 - val_loss: 2.6201 - val_mae: 2.6201\n",
      "Epoch 221/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.6388 - mae: 2.6388 - val_loss: 2.6664 - val_mae: 2.6664\n",
      "Epoch 222/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.6448 - mae: 2.6448 - val_loss: 2.6256 - val_mae: 2.6256\n",
      "Epoch 223/300\n",
      "515/515 [==============================] - 0s 932us/step - loss: 2.6398 - mae: 2.6398 - val_loss: 2.6352 - val_mae: 2.6352\n",
      "Epoch 224/300\n",
      "515/515 [==============================] - 0s 782us/step - loss: 2.6393 - mae: 2.6393 - val_loss: 2.6376 - val_mae: 2.6376\n",
      "Epoch 225/300\n",
      "515/515 [==============================] - 0s 784us/step - loss: 2.6440 - mae: 2.6440 - val_loss: 2.7123 - val_mae: 2.7123\n",
      "Epoch 226/300\n",
      "515/515 [==============================] - 0s 808us/step - loss: 2.6366 - mae: 2.6366 - val_loss: 2.6473 - val_mae: 2.6473\n",
      "Epoch 227/300\n",
      "515/515 [==============================] - 0s 813us/step - loss: 2.6351 - mae: 2.6351 - val_loss: 2.6077 - val_mae: 2.6077\n",
      "Epoch 228/300\n",
      "515/515 [==============================] - 0s 811us/step - loss: 2.6414 - mae: 2.6414 - val_loss: 2.6541 - val_mae: 2.6541\n",
      "Epoch 229/300\n",
      "515/515 [==============================] - 0s 842us/step - loss: 2.6337 - mae: 2.6337 - val_loss: 2.6395 - val_mae: 2.6395\n",
      "Epoch 230/300\n",
      "515/515 [==============================] - 0s 811us/step - loss: 2.6426 - mae: 2.6426 - val_loss: 2.6457 - val_mae: 2.6457\n",
      "Epoch 231/300\n",
      "515/515 [==============================] - 0s 799us/step - loss: 2.6375 - mae: 2.6375 - val_loss: 2.6645 - val_mae: 2.6645\n",
      "Epoch 232/300\n",
      "515/515 [==============================] - 0s 786us/step - loss: 2.6401 - mae: 2.6401 - val_loss: 2.6952 - val_mae: 2.6952\n",
      "Epoch 233/300\n",
      "515/515 [==============================] - 0s 797us/step - loss: 2.6393 - mae: 2.6393 - val_loss: 2.6181 - val_mae: 2.6181\n",
      "Epoch 234/300\n",
      "515/515 [==============================] - 0s 884us/step - loss: 2.6405 - mae: 2.6405 - val_loss: 2.6467 - val_mae: 2.6467\n",
      "Epoch 235/300\n",
      "515/515 [==============================] - 0s 845us/step - loss: 2.6364 - mae: 2.6364 - val_loss: 2.6691 - val_mae: 2.6691\n",
      "Epoch 236/300\n",
      "515/515 [==============================] - 0s 820us/step - loss: 2.6394 - mae: 2.6394 - val_loss: 2.6397 - val_mae: 2.6397\n",
      "Epoch 237/300\n",
      "515/515 [==============================] - 0s 786us/step - loss: 2.6292 - mae: 2.6292 - val_loss: 2.6431 - val_mae: 2.6431\n",
      "Epoch 238/300\n",
      "515/515 [==============================] - 0s 944us/step - loss: 2.6395 - mae: 2.6395 - val_loss: 2.6754 - val_mae: 2.6754\n",
      "Epoch 239/300\n",
      "515/515 [==============================] - 0s 899us/step - loss: 2.6358 - mae: 2.6358 - val_loss: 2.5974 - val_mae: 2.5974\n",
      "Epoch 240/300\n",
      "515/515 [==============================] - 0s 850us/step - loss: 2.6275 - mae: 2.6275 - val_loss: 2.6416 - val_mae: 2.6416\n",
      "Epoch 241/300\n",
      "515/515 [==============================] - 0s 816us/step - loss: 2.6424 - mae: 2.6424 - val_loss: 2.6996 - val_mae: 2.6996\n",
      "Epoch 242/300\n",
      "515/515 [==============================] - 0s 808us/step - loss: 2.6380 - mae: 2.6380 - val_loss: 2.6284 - val_mae: 2.6284\n",
      "Epoch 243/300\n",
      "515/515 [==============================] - 0s 809us/step - loss: 2.6333 - mae: 2.6333 - val_loss: 2.6671 - val_mae: 2.6671\n",
      "Epoch 244/300\n",
      "515/515 [==============================] - 0s 817us/step - loss: 2.6398 - mae: 2.6398 - val_loss: 2.6696 - val_mae: 2.6696\n",
      "Epoch 245/300\n",
      "515/515 [==============================] - 0s 774us/step - loss: 2.6369 - mae: 2.6369 - val_loss: 2.6682 - val_mae: 2.6682\n",
      "Epoch 246/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6353 - mae: 2.6353 - val_loss: 2.6356 - val_mae: 2.6356\n",
      "Epoch 247/300\n",
      "515/515 [==============================] - 0s 757us/step - loss: 2.6435 - mae: 2.6435 - val_loss: 2.6786 - val_mae: 2.6786\n",
      "Epoch 248/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.6300 - mae: 2.6300 - val_loss: 2.6229 - val_mae: 2.6229\n",
      "Epoch 249/300\n",
      "515/515 [==============================] - 0s 771us/step - loss: 2.6334 - mae: 2.6334 - val_loss: 2.6625 - val_mae: 2.6625\n",
      "Epoch 250/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6358 - mae: 2.6358 - val_loss: 2.6293 - val_mae: 2.6293\n",
      "Epoch 251/300\n",
      "515/515 [==============================] - 0s 755us/step - loss: 2.6315 - mae: 2.6315 - val_loss: 2.6674 - val_mae: 2.6674\n",
      "Epoch 252/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.6345 - mae: 2.6345 - val_loss: 2.6790 - val_mae: 2.6790\n",
      "Epoch 253/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 2.6377 - mae: 2.6377 - val_loss: 2.6280 - val_mae: 2.6280\n",
      "Epoch 254/300\n",
      "515/515 [==============================] - 0s 756us/step - loss: 2.6357 - mae: 2.6357 - val_loss: 2.6495 - val_mae: 2.6495\n",
      "Epoch 255/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6335 - mae: 2.6335 - val_loss: 2.6544 - val_mae: 2.6544\n",
      "Epoch 256/300\n",
      "515/515 [==============================] - 0s 754us/step - loss: 2.6300 - mae: 2.6300 - val_loss: 2.6680 - val_mae: 2.6680\n",
      "Epoch 257/300\n",
      "515/515 [==============================] - 0s 760us/step - loss: 2.6293 - mae: 2.6293 - val_loss: 2.6975 - val_mae: 2.6975\n",
      "Epoch 258/300\n",
      "515/515 [==============================] - 0s 765us/step - loss: 2.6285 - mae: 2.6285 - val_loss: 2.6751 - val_mae: 2.6751\n",
      "Epoch 259/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6331 - mae: 2.6331 - val_loss: 2.6675 - val_mae: 2.6675\n",
      "Epoch 260/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 2.6349 - mae: 2.6349 - val_loss: 2.6234 - val_mae: 2.6234\n"
     ]
    }
   ],
   "source": [
    "force_train, force_test, theta_x_train, theta_x_test= train_test_split(force_leo, theta_x_leo, test_size = 0.2, random_state = 0)\n",
    "history = model.fit(force_train, theta_x_train, epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (force_test, theta_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "231/231 [==============================] - 0s 891us/step - loss: 5.5029 - mae: 5.5029 - val_loss: 3.7787 - val_mae: 3.7787\n",
      "Epoch 2/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 4.0603 - mae: 4.0603 - val_loss: 3.6915 - val_mae: 3.6915\n",
      "Epoch 3/300\n",
      "231/231 [==============================] - 0s 808us/step - loss: 3.9099 - mae: 3.9099 - val_loss: 3.6680 - val_mae: 3.6680\n",
      "Epoch 4/300\n",
      "231/231 [==============================] - 0s 804us/step - loss: 3.8256 - mae: 3.8256 - val_loss: 3.6310 - val_mae: 3.6310\n",
      "Epoch 5/300\n",
      "231/231 [==============================] - 0s 806us/step - loss: 3.8080 - mae: 3.8080 - val_loss: 3.6689 - val_mae: 3.6689\n",
      "Epoch 6/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.7608 - mae: 3.7608 - val_loss: 3.6988 - val_mae: 3.6988\n",
      "Epoch 7/300\n",
      "231/231 [==============================] - 0s 805us/step - loss: 3.7389 - mae: 3.7389 - val_loss: 3.6918 - val_mae: 3.6918\n",
      "Epoch 8/300\n",
      "231/231 [==============================] - 0s 918us/step - loss: 3.7012 - mae: 3.7012 - val_loss: 3.6582 - val_mae: 3.6582\n",
      "Epoch 9/300\n",
      "231/231 [==============================] - 0s 814us/step - loss: 3.6697 - mae: 3.6697 - val_loss: 3.6801 - val_mae: 3.6801\n",
      "Epoch 10/300\n",
      "231/231 [==============================] - 0s 806us/step - loss: 3.6466 - mae: 3.6466 - val_loss: 3.6770 - val_mae: 3.6770\n",
      "Epoch 11/300\n",
      "231/231 [==============================] - 0s 804us/step - loss: 3.6212 - mae: 3.6212 - val_loss: 3.6640 - val_mae: 3.6640\n",
      "Epoch 12/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.6183 - mae: 3.6183 - val_loss: 3.6722 - val_mae: 3.6722\n",
      "Epoch 13/300\n",
      "231/231 [==============================] - 0s 941us/step - loss: 3.6030 - mae: 3.6030 - val_loss: 3.6047 - val_mae: 3.6047\n",
      "Epoch 14/300\n",
      "231/231 [==============================] - 0s 973us/step - loss: 3.5786 - mae: 3.5786 - val_loss: 3.6453 - val_mae: 3.6453\n",
      "Epoch 15/300\n",
      "231/231 [==============================] - 0s 873us/step - loss: 3.5677 - mae: 3.5677 - val_loss: 3.6574 - val_mae: 3.6574\n",
      "Epoch 16/300\n",
      "231/231 [==============================] - 0s 868us/step - loss: 3.5409 - mae: 3.5409 - val_loss: 3.6309 - val_mae: 3.6309\n",
      "Epoch 17/300\n",
      "231/231 [==============================] - 0s 852us/step - loss: 3.5255 - mae: 3.5255 - val_loss: 3.5719 - val_mae: 3.5719\n",
      "Epoch 18/300\n",
      "231/231 [==============================] - 0s 854us/step - loss: 3.5157 - mae: 3.5157 - val_loss: 3.6429 - val_mae: 3.6429\n",
      "Epoch 19/300\n",
      "231/231 [==============================] - 0s 850us/step - loss: 3.5004 - mae: 3.5004 - val_loss: 3.5640 - val_mae: 3.5640\n",
      "Epoch 20/300\n",
      "231/231 [==============================] - 0s 861us/step - loss: 3.5023 - mae: 3.5023 - val_loss: 3.6541 - val_mae: 3.6541\n",
      "Epoch 21/300\n",
      "231/231 [==============================] - 0s 857us/step - loss: 3.5080 - mae: 3.5080 - val_loss: 3.6716 - val_mae: 3.6716\n",
      "Epoch 22/300\n",
      "231/231 [==============================] - 0s 903us/step - loss: 3.4885 - mae: 3.4885 - val_loss: 3.6184 - val_mae: 3.6184\n",
      "Epoch 23/300\n",
      "231/231 [==============================] - 0s 946us/step - loss: 3.4847 - mae: 3.4847 - val_loss: 3.6221 - val_mae: 3.6221\n",
      "Epoch 24/300\n",
      "231/231 [==============================] - 0s 947us/step - loss: 3.4802 - mae: 3.4802 - val_loss: 3.6150 - val_mae: 3.6150\n",
      "Epoch 25/300\n",
      "231/231 [==============================] - 0s 945us/step - loss: 3.4761 - mae: 3.4761 - val_loss: 3.5305 - val_mae: 3.5305\n",
      "Epoch 26/300\n",
      "231/231 [==============================] - 0s 879us/step - loss: 3.4652 - mae: 3.4652 - val_loss: 3.5995 - val_mae: 3.5995\n",
      "Epoch 27/300\n",
      "231/231 [==============================] - 0s 847us/step - loss: 3.4575 - mae: 3.4575 - val_loss: 3.6025 - val_mae: 3.6025\n",
      "Epoch 28/300\n",
      "231/231 [==============================] - 0s 845us/step - loss: 3.4494 - mae: 3.4494 - val_loss: 3.6494 - val_mae: 3.6494\n",
      "Epoch 29/300\n",
      "231/231 [==============================] - 0s 824us/step - loss: 3.4565 - mae: 3.4565 - val_loss: 3.5931 - val_mae: 3.5931\n",
      "Epoch 30/300\n",
      "231/231 [==============================] - 0s 823us/step - loss: 3.4426 - mae: 3.4426 - val_loss: 3.5984 - val_mae: 3.5984\n",
      "Epoch 31/300\n",
      "231/231 [==============================] - 0s 827us/step - loss: 3.4412 - mae: 3.4412 - val_loss: 3.6131 - val_mae: 3.6131\n",
      "Epoch 32/300\n",
      "231/231 [==============================] - 0s 824us/step - loss: 3.4312 - mae: 3.4312 - val_loss: 3.6525 - val_mae: 3.6525\n",
      "Epoch 33/300\n",
      "231/231 [==============================] - 0s 844us/step - loss: 3.4321 - mae: 3.4321 - val_loss: 3.5673 - val_mae: 3.5673\n",
      "Epoch 34/300\n",
      "231/231 [==============================] - 0s 820us/step - loss: 3.4287 - mae: 3.4287 - val_loss: 3.6315 - val_mae: 3.6315\n",
      "Epoch 35/300\n",
      "231/231 [==============================] - 0s 817us/step - loss: 3.4338 - mae: 3.4338 - val_loss: 3.6103 - val_mae: 3.6103\n",
      "Epoch 36/300\n",
      "231/231 [==============================] - 0s 849us/step - loss: 3.4210 - mae: 3.4210 - val_loss: 3.6955 - val_mae: 3.6955\n",
      "Epoch 37/300\n",
      "231/231 [==============================] - 0s 854us/step - loss: 3.4138 - mae: 3.4138 - val_loss: 3.6655 - val_mae: 3.6655\n",
      "Epoch 38/300\n",
      "231/231 [==============================] - 0s 821us/step - loss: 3.4207 - mae: 3.4207 - val_loss: 3.6206 - val_mae: 3.6206\n",
      "Epoch 39/300\n",
      "231/231 [==============================] - 0s 814us/step - loss: 3.4006 - mae: 3.4006 - val_loss: 3.6144 - val_mae: 3.6144\n",
      "Epoch 40/300\n",
      "231/231 [==============================] - 0s 836us/step - loss: 3.3843 - mae: 3.3843 - val_loss: 3.6054 - val_mae: 3.6054\n",
      "Epoch 41/300\n",
      "231/231 [==============================] - 0s 808us/step - loss: 3.3899 - mae: 3.3899 - val_loss: 3.6481 - val_mae: 3.6481\n",
      "Epoch 42/300\n",
      "231/231 [==============================] - 0s 810us/step - loss: 3.3899 - mae: 3.3899 - val_loss: 3.5998 - val_mae: 3.5998\n",
      "Epoch 43/300\n",
      "231/231 [==============================] - 0s 822us/step - loss: 3.3817 - mae: 3.3817 - val_loss: 3.5862 - val_mae: 3.5862\n",
      "Epoch 44/300\n",
      "231/231 [==============================] - 0s 805us/step - loss: 3.3679 - mae: 3.3679 - val_loss: 3.5808 - val_mae: 3.5808\n",
      "Epoch 45/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.3751 - mae: 3.3751 - val_loss: 3.6082 - val_mae: 3.6082\n",
      "Epoch 46/300\n",
      "231/231 [==============================] - 0s 802us/step - loss: 3.3716 - mae: 3.3716 - val_loss: 3.6123 - val_mae: 3.6123\n",
      "Epoch 47/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.3712 - mae: 3.3712 - val_loss: 3.6861 - val_mae: 3.6861\n",
      "Epoch 48/300\n",
      "231/231 [==============================] - 0s 808us/step - loss: 3.3755 - mae: 3.3755 - val_loss: 3.5127 - val_mae: 3.5127\n",
      "Epoch 49/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.3754 - mae: 3.3754 - val_loss: 3.5726 - val_mae: 3.5726\n",
      "Epoch 50/300\n",
      "231/231 [==============================] - 0s 806us/step - loss: 3.3675 - mae: 3.3675 - val_loss: 3.5677 - val_mae: 3.5677\n",
      "Epoch 51/300\n",
      "231/231 [==============================] - 0s 830us/step - loss: 3.3663 - mae: 3.3663 - val_loss: 3.5368 - val_mae: 3.5368\n",
      "Epoch 52/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.3709 - mae: 3.3709 - val_loss: 3.6204 - val_mae: 3.6204\n",
      "Epoch 53/300\n",
      "231/231 [==============================] - 0s 818us/step - loss: 3.3537 - mae: 3.3537 - val_loss: 3.5618 - val_mae: 3.5618\n",
      "Epoch 54/300\n",
      "231/231 [==============================] - 0s 813us/step - loss: 3.3414 - mae: 3.3414 - val_loss: 3.6185 - val_mae: 3.6185\n",
      "Epoch 55/300\n",
      "231/231 [==============================] - 0s 804us/step - loss: 3.3400 - mae: 3.3400 - val_loss: 3.5570 - val_mae: 3.5570\n",
      "Epoch 56/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.3393 - mae: 3.3393 - val_loss: 3.5298 - val_mae: 3.5298\n",
      "Epoch 57/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.3485 - mae: 3.3485 - val_loss: 3.5834 - val_mae: 3.5834\n",
      "Epoch 58/300\n",
      "231/231 [==============================] - 0s 856us/step - loss: 3.3334 - mae: 3.3334 - val_loss: 3.5490 - val_mae: 3.5490\n",
      "Epoch 59/300\n",
      "231/231 [==============================] - 0s 854us/step - loss: 3.3338 - mae: 3.3338 - val_loss: 3.6020 - val_mae: 3.6020\n",
      "Epoch 60/300\n",
      "231/231 [==============================] - 0s 855us/step - loss: 3.3302 - mae: 3.3302 - val_loss: 3.5757 - val_mae: 3.5757\n",
      "Epoch 61/300\n",
      "231/231 [==============================] - 0s 856us/step - loss: 3.3257 - mae: 3.3257 - val_loss: 3.4873 - val_mae: 3.4873\n",
      "Epoch 62/300\n",
      "231/231 [==============================] - 0s 848us/step - loss: 3.3429 - mae: 3.3429 - val_loss: 3.5919 - val_mae: 3.5919\n",
      "Epoch 63/300\n",
      "231/231 [==============================] - 0s 848us/step - loss: 3.3278 - mae: 3.3278 - val_loss: 3.5237 - val_mae: 3.5237\n",
      "Epoch 64/300\n",
      "231/231 [==============================] - 0s 838us/step - loss: 3.3269 - mae: 3.3269 - val_loss: 3.5105 - val_mae: 3.5105\n",
      "Epoch 65/300\n",
      "231/231 [==============================] - 0s 936us/step - loss: 3.3136 - mae: 3.3136 - val_loss: 3.5219 - val_mae: 3.5219\n",
      "Epoch 66/300\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 3.3155 - mae: 3.3155 - val_loss: 3.5671 - val_mae: 3.5671\n",
      "Epoch 67/300\n",
      "231/231 [==============================] - 0s 867us/step - loss: 3.3239 - mae: 3.3239 - val_loss: 3.4756 - val_mae: 3.4756\n",
      "Epoch 68/300\n",
      "231/231 [==============================] - 0s 841us/step - loss: 3.3284 - mae: 3.3284 - val_loss: 3.5192 - val_mae: 3.5192\n",
      "Epoch 69/300\n",
      "231/231 [==============================] - 0s 867us/step - loss: 3.3058 - mae: 3.3058 - val_loss: 3.4632 - val_mae: 3.4632\n",
      "Epoch 70/300\n",
      "231/231 [==============================] - 0s 916us/step - loss: 3.3093 - mae: 3.3093 - val_loss: 3.4920 - val_mae: 3.4920\n",
      "Epoch 71/300\n",
      "231/231 [==============================] - 0s 845us/step - loss: 3.3277 - mae: 3.3277 - val_loss: 3.4517 - val_mae: 3.4517\n",
      "Epoch 72/300\n",
      "231/231 [==============================] - 0s 833us/step - loss: 3.3093 - mae: 3.3093 - val_loss: 3.5199 - val_mae: 3.5199\n",
      "Epoch 73/300\n",
      "231/231 [==============================] - 0s 853us/step - loss: 3.2992 - mae: 3.2992 - val_loss: 3.5303 - val_mae: 3.5303\n",
      "Epoch 74/300\n",
      "231/231 [==============================] - 0s 861us/step - loss: 3.3064 - mae: 3.3064 - val_loss: 3.5108 - val_mae: 3.5108\n",
      "Epoch 75/300\n",
      "231/231 [==============================] - 0s 830us/step - loss: 3.3138 - mae: 3.3138 - val_loss: 3.5390 - val_mae: 3.5390\n",
      "Epoch 76/300\n",
      "231/231 [==============================] - 0s 853us/step - loss: 3.3067 - mae: 3.3067 - val_loss: 3.5496 - val_mae: 3.5496\n",
      "Epoch 77/300\n",
      "231/231 [==============================] - 0s 843us/step - loss: 3.2868 - mae: 3.2868 - val_loss: 3.5788 - val_mae: 3.5788\n",
      "Epoch 78/300\n",
      "231/231 [==============================] - 0s 854us/step - loss: 3.3152 - mae: 3.3152 - val_loss: 3.5062 - val_mae: 3.5062\n",
      "Epoch 79/300\n",
      "231/231 [==============================] - 0s 842us/step - loss: 3.2911 - mae: 3.2911 - val_loss: 3.5495 - val_mae: 3.5495\n",
      "Epoch 80/300\n",
      "231/231 [==============================] - 0s 791us/step - loss: 3.3004 - mae: 3.3004 - val_loss: 3.4867 - val_mae: 3.4867\n",
      "Epoch 81/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.2910 - mae: 3.2910 - val_loss: 3.5302 - val_mae: 3.5302\n",
      "Epoch 82/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.2906 - mae: 3.2906 - val_loss: 3.5258 - val_mae: 3.5258\n",
      "Epoch 83/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2971 - mae: 3.2971 - val_loss: 3.5314 - val_mae: 3.5314\n",
      "Epoch 84/300\n",
      "231/231 [==============================] - 0s 783us/step - loss: 3.2895 - mae: 3.2895 - val_loss: 3.4555 - val_mae: 3.4555\n",
      "Epoch 85/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.2795 - mae: 3.2795 - val_loss: 3.4586 - val_mae: 3.4586\n",
      "Epoch 86/300\n",
      "231/231 [==============================] - 0s 781us/step - loss: 3.2984 - mae: 3.2984 - val_loss: 3.5528 - val_mae: 3.5528\n",
      "Epoch 87/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.2910 - mae: 3.2910 - val_loss: 3.5125 - val_mae: 3.5125\n",
      "Epoch 88/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.2927 - mae: 3.2927 - val_loss: 3.4992 - val_mae: 3.4992\n",
      "Epoch 89/300\n",
      "231/231 [==============================] - 0s 898us/step - loss: 3.2950 - mae: 3.2950 - val_loss: 3.4786 - val_mae: 3.4786\n",
      "Epoch 90/300\n",
      "231/231 [==============================] - 0s 805us/step - loss: 3.2888 - mae: 3.2888 - val_loss: 3.4672 - val_mae: 3.4672\n",
      "Epoch 91/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.2779 - mae: 3.2779 - val_loss: 3.4697 - val_mae: 3.4697\n",
      "Epoch 92/300\n",
      "231/231 [==============================] - 0s 788us/step - loss: 3.2729 - mae: 3.2729 - val_loss: 3.4315 - val_mae: 3.4315\n",
      "Epoch 93/300\n",
      "231/231 [==============================] - 0s 808us/step - loss: 3.2798 - mae: 3.2798 - val_loss: 3.5089 - val_mae: 3.5089\n",
      "Epoch 94/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2831 - mae: 3.2831 - val_loss: 3.4695 - val_mae: 3.4695\n",
      "Epoch 95/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.2770 - mae: 3.2770 - val_loss: 3.4233 - val_mae: 3.4233\n",
      "Epoch 96/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.2551 - mae: 3.2551 - val_loss: 3.4900 - val_mae: 3.4900\n",
      "Epoch 97/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2795 - mae: 3.2795 - val_loss: 3.4762 - val_mae: 3.4762\n",
      "Epoch 98/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.2816 - mae: 3.2816 - val_loss: 3.4957 - val_mae: 3.4957\n",
      "Epoch 99/300\n",
      "231/231 [==============================] - 0s 795us/step - loss: 3.2798 - mae: 3.2798 - val_loss: 3.5363 - val_mae: 3.5363\n",
      "Epoch 100/300\n",
      "231/231 [==============================] - 0s 811us/step - loss: 3.2697 - mae: 3.2697 - val_loss: 3.5611 - val_mae: 3.5611\n",
      "Epoch 101/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.2633 - mae: 3.2633 - val_loss: 3.5027 - val_mae: 3.5027\n",
      "Epoch 102/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.2646 - mae: 3.2646 - val_loss: 3.4519 - val_mae: 3.4519\n",
      "Epoch 103/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.2591 - mae: 3.2591 - val_loss: 3.5116 - val_mae: 3.5116\n",
      "Epoch 104/300\n",
      "231/231 [==============================] - 0s 795us/step - loss: 3.2609 - mae: 3.2609 - val_loss: 3.5125 - val_mae: 3.5125\n",
      "Epoch 105/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.2766 - mae: 3.2766 - val_loss: 3.3789 - val_mae: 3.3789\n",
      "Epoch 106/300\n",
      "231/231 [==============================] - 0s 802us/step - loss: 3.2558 - mae: 3.2558 - val_loss: 3.5133 - val_mae: 3.5133\n",
      "Epoch 107/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.2652 - mae: 3.2652 - val_loss: 3.4611 - val_mae: 3.4611\n",
      "Epoch 108/300\n",
      "231/231 [==============================] - 0s 795us/step - loss: 3.2558 - mae: 3.2558 - val_loss: 3.4981 - val_mae: 3.4981\n",
      "Epoch 109/300\n",
      "231/231 [==============================] - 0s 812us/step - loss: 3.2724 - mae: 3.2724 - val_loss: 3.4814 - val_mae: 3.4814\n",
      "Epoch 110/300\n",
      "231/231 [==============================] - 0s 835us/step - loss: 3.2427 - mae: 3.2427 - val_loss: 3.4626 - val_mae: 3.4626\n",
      "Epoch 111/300\n",
      "231/231 [==============================] - 0s 808us/step - loss: 3.2556 - mae: 3.2556 - val_loss: 3.5533 - val_mae: 3.5533\n",
      "Epoch 112/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.2577 - mae: 3.2577 - val_loss: 3.4714 - val_mae: 3.4714\n",
      "Epoch 113/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2532 - mae: 3.2532 - val_loss: 3.4673 - val_mae: 3.4673\n",
      "Epoch 114/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.2611 - mae: 3.2611 - val_loss: 3.4303 - val_mae: 3.4303\n",
      "Epoch 115/300\n",
      "231/231 [==============================] - 0s 805us/step - loss: 3.2584 - mae: 3.2584 - val_loss: 3.5530 - val_mae: 3.5530\n",
      "Epoch 116/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.2615 - mae: 3.2615 - val_loss: 3.4900 - val_mae: 3.4900\n",
      "Epoch 117/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.2472 - mae: 3.2472 - val_loss: 3.4107 - val_mae: 3.4107\n",
      "Epoch 118/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.2485 - mae: 3.2485 - val_loss: 3.5517 - val_mae: 3.5517\n",
      "Epoch 119/300\n",
      "231/231 [==============================] - 0s 881us/step - loss: 3.2378 - mae: 3.2378 - val_loss: 3.5318 - val_mae: 3.5318\n",
      "Epoch 120/300\n",
      "231/231 [==============================] - 0s 920us/step - loss: 3.2387 - mae: 3.2387 - val_loss: 3.4571 - val_mae: 3.4571\n",
      "Epoch 121/300\n",
      "231/231 [==============================] - 0s 894us/step - loss: 3.2594 - mae: 3.2594 - val_loss: 3.5192 - val_mae: 3.5192\n",
      "Epoch 122/300\n",
      "231/231 [==============================] - 0s 830us/step - loss: 3.2446 - mae: 3.2446 - val_loss: 3.5286 - val_mae: 3.5286\n",
      "Epoch 123/300\n",
      "231/231 [==============================] - 0s 841us/step - loss: 3.2400 - mae: 3.2400 - val_loss: 3.4859 - val_mae: 3.4859\n",
      "Epoch 124/300\n",
      "231/231 [==============================] - 0s 839us/step - loss: 3.2345 - mae: 3.2345 - val_loss: 3.4886 - val_mae: 3.4886\n",
      "Epoch 125/300\n",
      "231/231 [==============================] - 0s 837us/step - loss: 3.2497 - mae: 3.2497 - val_loss: 3.4490 - val_mae: 3.4490\n",
      "Epoch 126/300\n",
      "231/231 [==============================] - 0s 843us/step - loss: 3.2507 - mae: 3.2507 - val_loss: 3.4893 - val_mae: 3.4893\n",
      "Epoch 127/300\n",
      "231/231 [==============================] - 0s 847us/step - loss: 3.2373 - mae: 3.2373 - val_loss: 3.5060 - val_mae: 3.5060\n",
      "Epoch 128/300\n",
      "231/231 [==============================] - 0s 856us/step - loss: 3.2352 - mae: 3.2352 - val_loss: 3.4957 - val_mae: 3.4957\n",
      "Epoch 129/300\n",
      "231/231 [==============================] - 0s 822us/step - loss: 3.2446 - mae: 3.2446 - val_loss: 3.4995 - val_mae: 3.4995\n",
      "Epoch 130/300\n",
      "231/231 [==============================] - 0s 851us/step - loss: 3.2297 - mae: 3.2297 - val_loss: 3.5114 - val_mae: 3.5114\n",
      "Epoch 131/300\n",
      "231/231 [==============================] - 0s 839us/step - loss: 3.2353 - mae: 3.2353 - val_loss: 3.5082 - val_mae: 3.5082\n",
      "Epoch 132/300\n",
      "231/231 [==============================] - 0s 852us/step - loss: 3.2436 - mae: 3.2436 - val_loss: 3.4766 - val_mae: 3.4766\n",
      "Epoch 133/300\n",
      "231/231 [==============================] - 0s 849us/step - loss: 3.2312 - mae: 3.2312 - val_loss: 3.4997 - val_mae: 3.4997\n",
      "Epoch 134/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.2375 - mae: 3.2375 - val_loss: 3.5026 - val_mae: 3.5026\n",
      "Epoch 135/300\n",
      "231/231 [==============================] - 0s 802us/step - loss: 3.2355 - mae: 3.2355 - val_loss: 3.4270 - val_mae: 3.4270\n",
      "Epoch 136/300\n",
      "231/231 [==============================] - 0s 801us/step - loss: 3.2285 - mae: 3.2285 - val_loss: 3.4800 - val_mae: 3.4800\n",
      "Epoch 137/300\n",
      "231/231 [==============================] - 0s 811us/step - loss: 3.2292 - mae: 3.2292 - val_loss: 3.5316 - val_mae: 3.5316\n",
      "Epoch 138/300\n",
      "231/231 [==============================] - 0s 806us/step - loss: 3.2153 - mae: 3.2153 - val_loss: 3.5307 - val_mae: 3.5307\n",
      "Epoch 139/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.2297 - mae: 3.2297 - val_loss: 3.6290 - val_mae: 3.6290\n",
      "Epoch 140/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.2319 - mae: 3.2319 - val_loss: 3.4809 - val_mae: 3.4809\n",
      "Epoch 141/300\n",
      "231/231 [==============================] - 0s 807us/step - loss: 3.2299 - mae: 3.2299 - val_loss: 3.4941 - val_mae: 3.4941\n",
      "Epoch 142/300\n",
      "231/231 [==============================] - 0s 808us/step - loss: 3.2223 - mae: 3.2223 - val_loss: 3.6559 - val_mae: 3.6559\n",
      "Epoch 143/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.2339 - mae: 3.2339 - val_loss: 3.3672 - val_mae: 3.3672\n",
      "Epoch 144/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.2297 - mae: 3.2297 - val_loss: 3.4985 - val_mae: 3.4985\n",
      "Epoch 145/300\n",
      "231/231 [==============================] - 0s 792us/step - loss: 3.2308 - mae: 3.2308 - val_loss: 3.4298 - val_mae: 3.4298\n",
      "Epoch 146/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2293 - mae: 3.2293 - val_loss: 3.4758 - val_mae: 3.4758\n",
      "Epoch 147/300\n",
      "231/231 [==============================] - 0s 812us/step - loss: 3.2295 - mae: 3.2295 - val_loss: 3.6131 - val_mae: 3.6131\n",
      "Epoch 148/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.2258 - mae: 3.2258 - val_loss: 3.5026 - val_mae: 3.5026\n",
      "Epoch 149/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.2235 - mae: 3.2235 - val_loss: 3.4494 - val_mae: 3.4494\n",
      "Epoch 150/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.2280 - mae: 3.2280 - val_loss: 3.5184 - val_mae: 3.5184\n",
      "Epoch 151/300\n",
      "231/231 [==============================] - 0s 783us/step - loss: 3.2237 - mae: 3.2237 - val_loss: 3.4422 - val_mae: 3.4422\n",
      "Epoch 152/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.2233 - mae: 3.2233 - val_loss: 3.5351 - val_mae: 3.5351\n",
      "Epoch 153/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2264 - mae: 3.2264 - val_loss: 3.4576 - val_mae: 3.4576\n",
      "Epoch 154/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.2119 - mae: 3.2119 - val_loss: 3.5325 - val_mae: 3.5325\n",
      "Epoch 155/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.2205 - mae: 3.2205 - val_loss: 3.4729 - val_mae: 3.4729\n",
      "Epoch 156/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2190 - mae: 3.2190 - val_loss: 3.5296 - val_mae: 3.5296\n",
      "Epoch 157/300\n",
      "231/231 [==============================] - 0s 802us/step - loss: 3.2155 - mae: 3.2155 - val_loss: 3.4499 - val_mae: 3.4499\n",
      "Epoch 158/300\n",
      "231/231 [==============================] - 0s 787us/step - loss: 3.2109 - mae: 3.2109 - val_loss: 3.4522 - val_mae: 3.4522\n",
      "Epoch 159/300\n",
      "231/231 [==============================] - 0s 804us/step - loss: 3.2116 - mae: 3.2116 - val_loss: 3.5131 - val_mae: 3.5131\n",
      "Epoch 160/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2183 - mae: 3.2183 - val_loss: 3.4939 - val_mae: 3.4939\n",
      "Epoch 161/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.2300 - mae: 3.2300 - val_loss: 3.4850 - val_mae: 3.4850\n",
      "Epoch 162/300\n",
      "231/231 [==============================] - 0s 792us/step - loss: 3.2149 - mae: 3.2149 - val_loss: 3.4571 - val_mae: 3.4571\n",
      "Epoch 163/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.2034 - mae: 3.2034 - val_loss: 3.4446 - val_mae: 3.4446\n",
      "Epoch 164/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2176 - mae: 3.2176 - val_loss: 3.4311 - val_mae: 3.4311\n",
      "Epoch 165/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.2252 - mae: 3.2252 - val_loss: 3.4532 - val_mae: 3.4532\n",
      "Epoch 166/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.2087 - mae: 3.2087 - val_loss: 3.4165 - val_mae: 3.4165\n",
      "Epoch 167/300\n",
      "231/231 [==============================] - 0s 811us/step - loss: 3.1967 - mae: 3.1967 - val_loss: 3.4424 - val_mae: 3.4424\n",
      "Epoch 168/300\n",
      "231/231 [==============================] - 0s 809us/step - loss: 3.2072 - mae: 3.2072 - val_loss: 3.4504 - val_mae: 3.4504\n",
      "Epoch 169/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.2286 - mae: 3.2286 - val_loss: 3.5502 - val_mae: 3.5502\n",
      "Epoch 170/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.2195 - mae: 3.2195 - val_loss: 3.4717 - val_mae: 3.4717\n",
      "Epoch 171/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.2078 - mae: 3.2078 - val_loss: 3.5026 - val_mae: 3.5026\n",
      "Epoch 172/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2000 - mae: 3.2000 - val_loss: 3.4114 - val_mae: 3.4114\n",
      "Epoch 173/300\n",
      "231/231 [==============================] - 0s 836us/step - loss: 3.2012 - mae: 3.2012 - val_loss: 3.5464 - val_mae: 3.5464\n",
      "Epoch 174/300\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 3.2107 - mae: 3.2107 - val_loss: 3.4685 - val_mae: 3.4685\n",
      "Epoch 175/300\n",
      "231/231 [==============================] - 0s 938us/step - loss: 3.2194 - mae: 3.2194 - val_loss: 3.5089 - val_mae: 3.5089\n",
      "Epoch 176/300\n",
      "231/231 [==============================] - 0s 832us/step - loss: 3.2045 - mae: 3.2045 - val_loss: 3.4773 - val_mae: 3.4773\n",
      "Epoch 177/300\n",
      "231/231 [==============================] - 0s 861us/step - loss: 3.2014 - mae: 3.2014 - val_loss: 3.4176 - val_mae: 3.4176\n",
      "Epoch 178/300\n",
      "231/231 [==============================] - 0s 862us/step - loss: 3.2097 - mae: 3.2097 - val_loss: 3.4340 - val_mae: 3.4340\n",
      "Epoch 179/300\n",
      "231/231 [==============================] - 0s 838us/step - loss: 3.2072 - mae: 3.2072 - val_loss: 3.4106 - val_mae: 3.4106\n",
      "Epoch 180/300\n",
      "231/231 [==============================] - 0s 871us/step - loss: 3.2063 - mae: 3.2063 - val_loss: 3.4756 - val_mae: 3.4756\n",
      "Epoch 181/300\n",
      "231/231 [==============================] - 0s 842us/step - loss: 3.2063 - mae: 3.2063 - val_loss: 3.4901 - val_mae: 3.4901\n",
      "Epoch 182/300\n",
      "231/231 [==============================] - 0s 836us/step - loss: 3.1968 - mae: 3.1968 - val_loss: 3.5154 - val_mae: 3.5154\n",
      "Epoch 183/300\n",
      "231/231 [==============================] - 0s 841us/step - loss: 3.1942 - mae: 3.1942 - val_loss: 3.4845 - val_mae: 3.4845\n",
      "Epoch 184/300\n",
      "231/231 [==============================] - 0s 846us/step - loss: 3.2037 - mae: 3.2037 - val_loss: 3.4015 - val_mae: 3.4015\n",
      "Epoch 185/300\n",
      "231/231 [==============================] - 0s 837us/step - loss: 3.2147 - mae: 3.2147 - val_loss: 3.4732 - val_mae: 3.4732\n",
      "Epoch 186/300\n",
      "231/231 [==============================] - 0s 842us/step - loss: 3.1977 - mae: 3.1977 - val_loss: 3.4552 - val_mae: 3.4552\n",
      "Epoch 187/300\n",
      "231/231 [==============================] - 0s 836us/step - loss: 3.2036 - mae: 3.2036 - val_loss: 3.5461 - val_mae: 3.5461\n",
      "Epoch 188/300\n",
      "231/231 [==============================] - 0s 811us/step - loss: 3.2065 - mae: 3.2065 - val_loss: 3.4881 - val_mae: 3.4881\n",
      "Epoch 189/300\n",
      "231/231 [==============================] - 0s 787us/step - loss: 3.2004 - mae: 3.2004 - val_loss: 3.4780 - val_mae: 3.4780\n",
      "Epoch 190/300\n",
      "231/231 [==============================] - 0s 805us/step - loss: 3.1861 - mae: 3.1861 - val_loss: 3.5145 - val_mae: 3.5145\n",
      "Epoch 191/300\n",
      "231/231 [==============================] - 0s 791us/step - loss: 3.1950 - mae: 3.1950 - val_loss: 3.4263 - val_mae: 3.4263\n",
      "Epoch 192/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.1881 - mae: 3.1881 - val_loss: 3.4469 - val_mae: 3.4469\n",
      "Epoch 193/300\n",
      "231/231 [==============================] - 0s 806us/step - loss: 3.1877 - mae: 3.1877 - val_loss: 3.5482 - val_mae: 3.5482\n",
      "Epoch 194/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.1901 - mae: 3.1901 - val_loss: 3.5185 - val_mae: 3.5185\n",
      "Epoch 195/300\n",
      "231/231 [==============================] - 0s 825us/step - loss: 3.1917 - mae: 3.1917 - val_loss: 3.3880 - val_mae: 3.3880\n",
      "Epoch 196/300\n",
      "231/231 [==============================] - 0s 782us/step - loss: 3.1944 - mae: 3.1944 - val_loss: 3.4790 - val_mae: 3.4790\n",
      "Epoch 197/300\n",
      "231/231 [==============================] - 0s 782us/step - loss: 3.1801 - mae: 3.1801 - val_loss: 3.4216 - val_mae: 3.4216\n",
      "Epoch 198/300\n",
      "231/231 [==============================] - 0s 804us/step - loss: 3.1984 - mae: 3.1984 - val_loss: 3.4681 - val_mae: 3.4681\n",
      "Epoch 199/300\n",
      "231/231 [==============================] - 0s 795us/step - loss: 3.1902 - mae: 3.1902 - val_loss: 3.4972 - val_mae: 3.4972\n",
      "Epoch 200/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.2052 - mae: 3.2052 - val_loss: 3.4866 - val_mae: 3.4866\n",
      "Epoch 201/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.1890 - mae: 3.1890 - val_loss: 3.3969 - val_mae: 3.3969\n",
      "Epoch 202/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.1874 - mae: 3.1874 - val_loss: 3.5180 - val_mae: 3.5180\n",
      "Epoch 203/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.1972 - mae: 3.1972 - val_loss: 3.4793 - val_mae: 3.4793\n",
      "Epoch 204/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.1981 - mae: 3.1981 - val_loss: 3.4608 - val_mae: 3.4608\n",
      "Epoch 205/300\n",
      "231/231 [==============================] - 0s 790us/step - loss: 3.1899 - mae: 3.1899 - val_loss: 3.4598 - val_mae: 3.4598\n",
      "Epoch 206/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.1934 - mae: 3.1934 - val_loss: 3.4333 - val_mae: 3.4333\n",
      "Epoch 207/300\n",
      "231/231 [==============================] - 0s 804us/step - loss: 3.1870 - mae: 3.1870 - val_loss: 3.4806 - val_mae: 3.4806\n",
      "Epoch 208/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.1822 - mae: 3.1822 - val_loss: 3.4676 - val_mae: 3.4676\n",
      "Epoch 209/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.2030 - mae: 3.2030 - val_loss: 3.4245 - val_mae: 3.4245\n",
      "Epoch 210/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.1861 - mae: 3.1861 - val_loss: 3.4809 - val_mae: 3.4809\n",
      "Epoch 211/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.1746 - mae: 3.1746 - val_loss: 3.5369 - val_mae: 3.5369\n",
      "Epoch 212/300\n",
      "231/231 [==============================] - 0s 787us/step - loss: 3.1806 - mae: 3.1806 - val_loss: 3.4213 - val_mae: 3.4213\n",
      "Epoch 213/300\n",
      "231/231 [==============================] - 0s 795us/step - loss: 3.1923 - mae: 3.1923 - val_loss: 3.5111 - val_mae: 3.5111\n",
      "Epoch 214/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.1860 - mae: 3.1860 - val_loss: 3.4380 - val_mae: 3.4380\n",
      "Epoch 215/300\n",
      "231/231 [==============================] - 0s 805us/step - loss: 3.1814 - mae: 3.1814 - val_loss: 3.4196 - val_mae: 3.4196\n",
      "Epoch 216/300\n",
      "231/231 [==============================] - 0s 801us/step - loss: 3.1844 - mae: 3.1844 - val_loss: 3.3898 - val_mae: 3.3898\n",
      "Epoch 217/300\n",
      "231/231 [==============================] - 0s 795us/step - loss: 3.1819 - mae: 3.1819 - val_loss: 3.4874 - val_mae: 3.4874\n",
      "Epoch 218/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.1804 - mae: 3.1804 - val_loss: 3.4750 - val_mae: 3.4750\n",
      "Epoch 219/300\n",
      "231/231 [==============================] - 0s 782us/step - loss: 3.1980 - mae: 3.1980 - val_loss: 3.4210 - val_mae: 3.4210\n",
      "Epoch 220/300\n",
      "231/231 [==============================] - 0s 802us/step - loss: 3.1850 - mae: 3.1850 - val_loss: 3.4821 - val_mae: 3.4821\n",
      "Epoch 221/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.1756 - mae: 3.1756 - val_loss: 3.3951 - val_mae: 3.3951\n",
      "Epoch 222/300\n",
      "231/231 [==============================] - 0s 801us/step - loss: 3.1796 - mae: 3.1796 - val_loss: 3.4582 - val_mae: 3.4582\n",
      "Epoch 223/300\n",
      "231/231 [==============================] - 0s 819us/step - loss: 3.1897 - mae: 3.1897 - val_loss: 3.4482 - val_mae: 3.4482\n",
      "Epoch 224/300\n",
      "231/231 [==============================] - 0s 791us/step - loss: 3.1818 - mae: 3.1818 - val_loss: 3.4704 - val_mae: 3.4704\n",
      "Epoch 225/300\n",
      "231/231 [==============================] - 0s 810us/step - loss: 3.1769 - mae: 3.1769 - val_loss: 3.4203 - val_mae: 3.4203\n",
      "Epoch 226/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.1838 - mae: 3.1838 - val_loss: 3.4592 - val_mae: 3.4592\n",
      "Epoch 227/300\n",
      "231/231 [==============================] - 0s 806us/step - loss: 3.1820 - mae: 3.1820 - val_loss: 3.5028 - val_mae: 3.5028\n",
      "Epoch 228/300\n",
      "231/231 [==============================] - 0s 917us/step - loss: 3.1925 - mae: 3.1925 - val_loss: 3.4865 - val_mae: 3.4865\n",
      "Epoch 229/300\n",
      "231/231 [==============================] - 0s 937us/step - loss: 3.1803 - mae: 3.1803 - val_loss: 3.4424 - val_mae: 3.4424\n",
      "Epoch 230/300\n",
      "231/231 [==============================] - 0s 851us/step - loss: 3.1864 - mae: 3.1864 - val_loss: 3.5003 - val_mae: 3.5003\n",
      "Epoch 231/300\n",
      "231/231 [==============================] - 0s 918us/step - loss: 3.1725 - mae: 3.1725 - val_loss: 3.4795 - val_mae: 3.4795\n",
      "Epoch 232/300\n",
      "231/231 [==============================] - 0s 927us/step - loss: 3.1695 - mae: 3.1695 - val_loss: 3.4982 - val_mae: 3.4982\n",
      "Epoch 233/300\n",
      "231/231 [==============================] - 0s 909us/step - loss: 3.1817 - mae: 3.1817 - val_loss: 3.4259 - val_mae: 3.4259\n",
      "Epoch 234/300\n",
      "231/231 [==============================] - 0s 933us/step - loss: 3.1763 - mae: 3.1763 - val_loss: 3.5060 - val_mae: 3.5060\n",
      "Epoch 235/300\n",
      "231/231 [==============================] - 0s 905us/step - loss: 3.1735 - mae: 3.1735 - val_loss: 3.5447 - val_mae: 3.5447\n",
      "Epoch 236/300\n",
      "231/231 [==============================] - 0s 908us/step - loss: 3.1727 - mae: 3.1727 - val_loss: 3.4140 - val_mae: 3.4140\n",
      "Epoch 237/300\n",
      "231/231 [==============================] - 0s 855us/step - loss: 3.1659 - mae: 3.1659 - val_loss: 3.4693 - val_mae: 3.4693\n",
      "Epoch 238/300\n",
      "231/231 [==============================] - 0s 885us/step - loss: 3.1773 - mae: 3.1773 - val_loss: 3.4233 - val_mae: 3.4233\n",
      "Epoch 239/300\n",
      "231/231 [==============================] - 0s 891us/step - loss: 3.1744 - mae: 3.1744 - val_loss: 3.4266 - val_mae: 3.4266\n",
      "Epoch 240/300\n",
      "231/231 [==============================] - 0s 896us/step - loss: 3.1736 - mae: 3.1736 - val_loss: 3.4002 - val_mae: 3.4002\n",
      "Epoch 241/300\n",
      "231/231 [==============================] - 0s 841us/step - loss: 3.1712 - mae: 3.1712 - val_loss: 3.4670 - val_mae: 3.4670\n",
      "Epoch 242/300\n",
      "231/231 [==============================] - 0s 804us/step - loss: 3.1782 - mae: 3.1782 - val_loss: 3.5290 - val_mae: 3.5290\n",
      "Epoch 243/300\n",
      "231/231 [==============================] - 0s 785us/step - loss: 3.1587 - mae: 3.1587 - val_loss: 3.4730 - val_mae: 3.4730\n",
      "Epoch 244/300\n",
      "231/231 [==============================] - 0s 785us/step - loss: 3.1718 - mae: 3.1718 - val_loss: 3.4438 - val_mae: 3.4438\n",
      "Epoch 245/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.1792 - mae: 3.1792 - val_loss: 3.4869 - val_mae: 3.4869\n",
      "Epoch 246/300\n",
      "231/231 [==============================] - 0s 786us/step - loss: 3.1762 - mae: 3.1762 - val_loss: 3.4564 - val_mae: 3.4564\n",
      "Epoch 247/300\n",
      "231/231 [==============================] - 0s 785us/step - loss: 3.1762 - mae: 3.1762 - val_loss: 3.4220 - val_mae: 3.4220\n",
      "Epoch 248/300\n",
      "231/231 [==============================] - 0s 792us/step - loss: 3.1762 - mae: 3.1762 - val_loss: 3.4380 - val_mae: 3.4380\n",
      "Epoch 249/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.1673 - mae: 3.1673 - val_loss: 3.4387 - val_mae: 3.4387\n",
      "Epoch 250/300\n",
      "231/231 [==============================] - 0s 781us/step - loss: 3.1782 - mae: 3.1782 - val_loss: 3.4704 - val_mae: 3.4704\n",
      "Epoch 251/300\n",
      "231/231 [==============================] - 0s 802us/step - loss: 3.1717 - mae: 3.1717 - val_loss: 3.5145 - val_mae: 3.5145\n",
      "Epoch 252/300\n",
      "231/231 [==============================] - 0s 790us/step - loss: 3.1645 - mae: 3.1645 - val_loss: 3.4306 - val_mae: 3.4306\n",
      "Epoch 253/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.1881 - mae: 3.1881 - val_loss: 3.5119 - val_mae: 3.5119\n",
      "Epoch 254/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.1670 - mae: 3.1670 - val_loss: 3.4582 - val_mae: 3.4582\n",
      "Epoch 255/300\n",
      "231/231 [==============================] - 0s 807us/step - loss: 3.1812 - mae: 3.1812 - val_loss: 3.4825 - val_mae: 3.4825\n",
      "Epoch 256/300\n",
      "231/231 [==============================] - 0s 864us/step - loss: 3.1750 - mae: 3.1750 - val_loss: 3.4358 - val_mae: 3.4358\n",
      "Epoch 257/300\n",
      "231/231 [==============================] - 0s 834us/step - loss: 3.1628 - mae: 3.1628 - val_loss: 3.5095 - val_mae: 3.5095\n",
      "Epoch 258/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.1809 - mae: 3.1809 - val_loss: 3.4275 - val_mae: 3.4275\n",
      "Epoch 259/300\n",
      "231/231 [==============================] - 0s 795us/step - loss: 3.1687 - mae: 3.1687 - val_loss: 3.5045 - val_mae: 3.5045\n",
      "Epoch 260/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.1698 - mae: 3.1698 - val_loss: 3.4443 - val_mae: 3.4443\n",
      "Epoch 261/300\n",
      "231/231 [==============================] - 0s 806us/step - loss: 3.1797 - mae: 3.1797 - val_loss: 3.5349 - val_mae: 3.5349\n",
      "Epoch 262/300\n",
      "231/231 [==============================] - 0s 816us/step - loss: 3.1718 - mae: 3.1718 - val_loss: 3.4547 - val_mae: 3.4547\n",
      "Epoch 263/300\n",
      "231/231 [==============================] - 0s 801us/step - loss: 3.1595 - mae: 3.1595 - val_loss: 3.4415 - val_mae: 3.4415\n"
     ]
    }
   ],
   "source": [
    "force_train, force_test, theta_x_train, theta_x_test= train_test_split(force_yc_bmi, theta_x_yc, test_size = 0.2, random_state = 0)\n",
    "history = model.fit(force_train, theta_x_train, epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (force_test, theta_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "231/231 [==============================] - 0s 888us/step - loss: 4.3619 - mae: 4.3619 - val_loss: 3.8812 - val_mae: 3.8812\n",
      "Epoch 2/300\n",
      "231/231 [==============================] - 0s 818us/step - loss: 3.9167 - mae: 3.9167 - val_loss: 3.8283 - val_mae: 3.8283\n",
      "Epoch 3/300\n",
      "231/231 [==============================] - 0s 820us/step - loss: 3.7804 - mae: 3.7804 - val_loss: 3.7412 - val_mae: 3.7412\n",
      "Epoch 4/300\n",
      "231/231 [==============================] - 0s 843us/step - loss: 3.7331 - mae: 3.7331 - val_loss: 3.7723 - val_mae: 3.7723\n",
      "Epoch 5/300\n",
      "231/231 [==============================] - 0s 891us/step - loss: 3.7137 - mae: 3.7137 - val_loss: 3.7037 - val_mae: 3.7037\n",
      "Epoch 6/300\n",
      "231/231 [==============================] - 0s 819us/step - loss: 3.6653 - mae: 3.6653 - val_loss: 3.8194 - val_mae: 3.8194\n",
      "Epoch 7/300\n",
      "231/231 [==============================] - 0s 836us/step - loss: 3.6331 - mae: 3.6331 - val_loss: 3.7357 - val_mae: 3.7357\n",
      "Epoch 8/300\n",
      "231/231 [==============================] - 0s 847us/step - loss: 3.6242 - mae: 3.6242 - val_loss: 3.8040 - val_mae: 3.8040\n",
      "Epoch 9/300\n",
      "231/231 [==============================] - 0s 833us/step - loss: 3.5974 - mae: 3.5974 - val_loss: 3.7207 - val_mae: 3.7207\n",
      "Epoch 10/300\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 3.5788 - mae: 3.5788 - val_loss: 3.6896 - val_mae: 3.6896\n",
      "Epoch 11/300\n",
      "231/231 [==============================] - 0s 946us/step - loss: 3.5681 - mae: 3.5681 - val_loss: 3.7316 - val_mae: 3.7316\n",
      "Epoch 12/300\n",
      "231/231 [==============================] - 0s 872us/step - loss: 3.5260 - mae: 3.5260 - val_loss: 3.6916 - val_mae: 3.6916\n",
      "Epoch 13/300\n",
      "231/231 [==============================] - 0s 980us/step - loss: 3.5250 - mae: 3.5250 - val_loss: 3.7247 - val_mae: 3.7247\n",
      "Epoch 14/300\n",
      "231/231 [==============================] - 0s 846us/step - loss: 3.5106 - mae: 3.5106 - val_loss: 3.7193 - val_mae: 3.7193\n",
      "Epoch 15/300\n",
      "231/231 [==============================] - 0s 869us/step - loss: 3.4868 - mae: 3.4868 - val_loss: 3.6240 - val_mae: 3.6240\n",
      "Epoch 16/300\n",
      "231/231 [==============================] - 0s 859us/step - loss: 3.4724 - mae: 3.4724 - val_loss: 3.6482 - val_mae: 3.6482\n",
      "Epoch 17/300\n",
      "231/231 [==============================] - 0s 884us/step - loss: 3.4511 - mae: 3.4511 - val_loss: 3.6315 - val_mae: 3.6315\n",
      "Epoch 18/300\n",
      "231/231 [==============================] - 0s 910us/step - loss: 3.4444 - mae: 3.4444 - val_loss: 3.6501 - val_mae: 3.6501\n",
      "Epoch 19/300\n",
      "231/231 [==============================] - 0s 890us/step - loss: 3.4107 - mae: 3.4107 - val_loss: 3.5386 - val_mae: 3.5386\n",
      "Epoch 20/300\n",
      "231/231 [==============================] - 0s 862us/step - loss: 3.4010 - mae: 3.4010 - val_loss: 3.5700 - val_mae: 3.5700\n",
      "Epoch 21/300\n",
      "231/231 [==============================] - 0s 913us/step - loss: 3.3809 - mae: 3.3809 - val_loss: 3.5868 - val_mae: 3.5868\n",
      "Epoch 22/300\n",
      "231/231 [==============================] - 0s 852us/step - loss: 3.3779 - mae: 3.3779 - val_loss: 3.6027 - val_mae: 3.6027\n",
      "Epoch 23/300\n",
      "231/231 [==============================] - 0s 851us/step - loss: 3.3562 - mae: 3.3562 - val_loss: 3.5883 - val_mae: 3.5883\n",
      "Epoch 24/300\n",
      "231/231 [==============================] - 0s 836us/step - loss: 3.3599 - mae: 3.3599 - val_loss: 3.5051 - val_mae: 3.5051\n",
      "Epoch 25/300\n",
      "231/231 [==============================] - 0s 813us/step - loss: 3.3546 - mae: 3.3546 - val_loss: 3.4961 - val_mae: 3.4961\n",
      "Epoch 26/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.3493 - mae: 3.3493 - val_loss: 3.5747 - val_mae: 3.5747\n",
      "Epoch 27/300\n",
      "231/231 [==============================] - 0s 805us/step - loss: 3.3398 - mae: 3.3398 - val_loss: 3.5779 - val_mae: 3.5779\n",
      "Epoch 28/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.3549 - mae: 3.3549 - val_loss: 3.6062 - val_mae: 3.6062\n",
      "Epoch 29/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.3404 - mae: 3.3404 - val_loss: 3.5119 - val_mae: 3.5119\n",
      "Epoch 30/300\n",
      "231/231 [==============================] - 0s 808us/step - loss: 3.3281 - mae: 3.3281 - val_loss: 3.5740 - val_mae: 3.5740\n",
      "Epoch 31/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.3281 - mae: 3.3281 - val_loss: 3.4890 - val_mae: 3.4890\n",
      "Epoch 32/300\n",
      "231/231 [==============================] - 0s 810us/step - loss: 3.3137 - mae: 3.3137 - val_loss: 3.4908 - val_mae: 3.4908\n",
      "Epoch 33/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.3226 - mae: 3.3226 - val_loss: 3.5127 - val_mae: 3.5127\n",
      "Epoch 34/300\n",
      "231/231 [==============================] - 0s 801us/step - loss: 3.3002 - mae: 3.3002 - val_loss: 3.5053 - val_mae: 3.5053\n",
      "Epoch 35/300\n",
      "231/231 [==============================] - 0s 804us/step - loss: 3.2975 - mae: 3.2975 - val_loss: 3.5119 - val_mae: 3.5119\n",
      "Epoch 36/300\n",
      "231/231 [==============================] - 0s 837us/step - loss: 3.3170 - mae: 3.3170 - val_loss: 3.5404 - val_mae: 3.5404\n",
      "Epoch 37/300\n",
      "231/231 [==============================] - 0s 801us/step - loss: 3.2950 - mae: 3.2950 - val_loss: 3.5072 - val_mae: 3.5072\n",
      "Epoch 38/300\n",
      "231/231 [==============================] - 0s 806us/step - loss: 3.3007 - mae: 3.3007 - val_loss: 3.5620 - val_mae: 3.5620\n",
      "Epoch 39/300\n",
      "231/231 [==============================] - 0s 887us/step - loss: 3.3005 - mae: 3.3005 - val_loss: 3.5582 - val_mae: 3.5582\n",
      "Epoch 40/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.2921 - mae: 3.2921 - val_loss: 3.5169 - val_mae: 3.5169\n",
      "Epoch 41/300\n",
      "231/231 [==============================] - 0s 817us/step - loss: 3.2884 - mae: 3.2884 - val_loss: 3.5140 - val_mae: 3.5140\n",
      "Epoch 42/300\n",
      "231/231 [==============================] - 0s 814us/step - loss: 3.2917 - mae: 3.2917 - val_loss: 3.5869 - val_mae: 3.5869\n",
      "Epoch 43/300\n",
      "231/231 [==============================] - 0s 818us/step - loss: 3.2773 - mae: 3.2773 - val_loss: 3.4960 - val_mae: 3.4960\n",
      "Epoch 44/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.2760 - mae: 3.2760 - val_loss: 3.4705 - val_mae: 3.4705\n",
      "Epoch 45/300\n",
      "231/231 [==============================] - 0s 795us/step - loss: 3.2868 - mae: 3.2868 - val_loss: 3.5531 - val_mae: 3.5531\n",
      "Epoch 46/300\n",
      "231/231 [==============================] - 0s 804us/step - loss: 3.2709 - mae: 3.2709 - val_loss: 3.5108 - val_mae: 3.5108\n",
      "Epoch 47/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.2626 - mae: 3.2626 - val_loss: 3.4498 - val_mae: 3.4498\n",
      "Epoch 48/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.2577 - mae: 3.2577 - val_loss: 3.5247 - val_mae: 3.5247\n",
      "Epoch 49/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.2715 - mae: 3.2715 - val_loss: 3.4629 - val_mae: 3.4629\n",
      "Epoch 50/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.2580 - mae: 3.2580 - val_loss: 3.5825 - val_mae: 3.5825\n",
      "Epoch 51/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.2541 - mae: 3.2541 - val_loss: 3.4549 - val_mae: 3.4549\n",
      "Epoch 52/300\n",
      "231/231 [==============================] - 0s 809us/step - loss: 3.2456 - mae: 3.2456 - val_loss: 3.4500 - val_mae: 3.4500\n",
      "Epoch 53/300\n",
      "231/231 [==============================] - 0s 818us/step - loss: 3.2505 - mae: 3.2505 - val_loss: 3.4839 - val_mae: 3.4839\n",
      "Epoch 54/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.2377 - mae: 3.2377 - val_loss: 3.5294 - val_mae: 3.5294\n",
      "Epoch 55/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.2484 - mae: 3.2484 - val_loss: 3.4586 - val_mae: 3.4586\n",
      "Epoch 56/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.2379 - mae: 3.2379 - val_loss: 3.5259 - val_mae: 3.5259\n",
      "Epoch 57/300\n",
      "231/231 [==============================] - 0s 813us/step - loss: 3.2356 - mae: 3.2356 - val_loss: 3.4792 - val_mae: 3.4792\n",
      "Epoch 58/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.2430 - mae: 3.2430 - val_loss: 3.4680 - val_mae: 3.4680\n",
      "Epoch 59/300\n",
      "231/231 [==============================] - 0s 801us/step - loss: 3.2428 - mae: 3.2428 - val_loss: 3.4859 - val_mae: 3.4859\n",
      "Epoch 60/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.2418 - mae: 3.2418 - val_loss: 3.4250 - val_mae: 3.4250\n",
      "Epoch 61/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2324 - mae: 3.2324 - val_loss: 3.5002 - val_mae: 3.5002\n",
      "Epoch 62/300\n",
      "231/231 [==============================] - 0s 795us/step - loss: 3.2318 - mae: 3.2318 - val_loss: 3.4588 - val_mae: 3.4588\n",
      "Epoch 63/300\n",
      "231/231 [==============================] - 0s 913us/step - loss: 3.2431 - mae: 3.2431 - val_loss: 3.4779 - val_mae: 3.4779\n",
      "Epoch 64/300\n",
      "231/231 [==============================] - 0s 945us/step - loss: 3.2410 - mae: 3.2410 - val_loss: 3.5470 - val_mae: 3.5470\n",
      "Epoch 65/300\n",
      "231/231 [==============================] - 0s 838us/step - loss: 3.2280 - mae: 3.2280 - val_loss: 3.4716 - val_mae: 3.4716\n",
      "Epoch 66/300\n",
      "231/231 [==============================] - 0s 840us/step - loss: 3.2298 - mae: 3.2298 - val_loss: 3.4483 - val_mae: 3.4483\n",
      "Epoch 67/300\n",
      "231/231 [==============================] - 0s 840us/step - loss: 3.2293 - mae: 3.2293 - val_loss: 3.5076 - val_mae: 3.5076\n",
      "Epoch 68/300\n",
      "231/231 [==============================] - 0s 842us/step - loss: 3.2316 - mae: 3.2316 - val_loss: 3.4792 - val_mae: 3.4792\n",
      "Epoch 69/300\n",
      "231/231 [==============================] - 0s 858us/step - loss: 3.2196 - mae: 3.2196 - val_loss: 3.5353 - val_mae: 3.5353\n",
      "Epoch 70/300\n",
      "231/231 [==============================] - 0s 848us/step - loss: 3.2304 - mae: 3.2304 - val_loss: 3.4772 - val_mae: 3.4772\n",
      "Epoch 71/300\n",
      "231/231 [==============================] - 0s 850us/step - loss: 3.2109 - mae: 3.2109 - val_loss: 3.4315 - val_mae: 3.4315\n",
      "Epoch 72/300\n",
      "231/231 [==============================] - 0s 907us/step - loss: 3.2253 - mae: 3.2253 - val_loss: 3.4854 - val_mae: 3.4854\n",
      "Epoch 73/300\n",
      "231/231 [==============================] - 0s 890us/step - loss: 3.2266 - mae: 3.2266 - val_loss: 3.5221 - val_mae: 3.5221\n",
      "Epoch 74/300\n",
      "231/231 [==============================] - 0s 836us/step - loss: 3.2325 - mae: 3.2325 - val_loss: 3.4837 - val_mae: 3.4837\n",
      "Epoch 75/300\n",
      "231/231 [==============================] - 0s 844us/step - loss: 3.2284 - mae: 3.2284 - val_loss: 3.4943 - val_mae: 3.4943\n",
      "Epoch 76/300\n",
      "231/231 [==============================] - 0s 831us/step - loss: 3.2201 - mae: 3.2201 - val_loss: 3.4453 - val_mae: 3.4453\n",
      "Epoch 77/300\n",
      "231/231 [==============================] - 0s 831us/step - loss: 3.2267 - mae: 3.2267 - val_loss: 3.4729 - val_mae: 3.4729\n",
      "Epoch 78/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.2235 - mae: 3.2235 - val_loss: 3.4878 - val_mae: 3.4878\n",
      "Epoch 79/300\n",
      "231/231 [==============================] - 0s 779us/step - loss: 3.2193 - mae: 3.2193 - val_loss: 3.4697 - val_mae: 3.4697\n",
      "Epoch 80/300\n",
      "231/231 [==============================] - 0s 784us/step - loss: 3.2282 - mae: 3.2282 - val_loss: 3.4917 - val_mae: 3.4917\n",
      "Epoch 81/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.2136 - mae: 3.2136 - val_loss: 3.4646 - val_mae: 3.4646\n",
      "Epoch 82/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2225 - mae: 3.2225 - val_loss: 3.4290 - val_mae: 3.4290\n",
      "Epoch 83/300\n",
      "231/231 [==============================] - 0s 784us/step - loss: 3.2202 - mae: 3.2202 - val_loss: 3.4981 - val_mae: 3.4981\n",
      "Epoch 84/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2176 - mae: 3.2176 - val_loss: 3.4410 - val_mae: 3.4410\n",
      "Epoch 85/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.2218 - mae: 3.2218 - val_loss: 3.4819 - val_mae: 3.4819\n",
      "Epoch 86/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.2132 - mae: 3.2132 - val_loss: 3.3871 - val_mae: 3.3871\n",
      "Epoch 87/300\n",
      "231/231 [==============================] - 0s 808us/step - loss: 3.2143 - mae: 3.2143 - val_loss: 3.4614 - val_mae: 3.4614\n",
      "Epoch 88/300\n",
      "231/231 [==============================] - 0s 812us/step - loss: 3.2129 - mae: 3.2129 - val_loss: 3.5099 - val_mae: 3.5099\n",
      "Epoch 89/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2190 - mae: 3.2190 - val_loss: 3.4539 - val_mae: 3.4539\n",
      "Epoch 90/300\n",
      "231/231 [==============================] - 0s 790us/step - loss: 3.2045 - mae: 3.2045 - val_loss: 3.4565 - val_mae: 3.4565\n",
      "Epoch 91/300\n",
      "231/231 [==============================] - 0s 795us/step - loss: 3.2162 - mae: 3.2162 - val_loss: 3.4332 - val_mae: 3.4332\n",
      "Epoch 92/300\n",
      "231/231 [==============================] - 0s 782us/step - loss: 3.2228 - mae: 3.2228 - val_loss: 3.5040 - val_mae: 3.5040\n",
      "Epoch 93/300\n",
      "231/231 [==============================] - 0s 802us/step - loss: 3.2077 - mae: 3.2077 - val_loss: 3.4207 - val_mae: 3.4207\n",
      "Epoch 94/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.2022 - mae: 3.2022 - val_loss: 3.4674 - val_mae: 3.4674\n",
      "Epoch 95/300\n",
      "231/231 [==============================] - 0s 795us/step - loss: 3.2087 - mae: 3.2087 - val_loss: 3.5002 - val_mae: 3.5002\n",
      "Epoch 96/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.2098 - mae: 3.2098 - val_loss: 3.4654 - val_mae: 3.4654\n",
      "Epoch 97/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.2120 - mae: 3.2120 - val_loss: 3.3916 - val_mae: 3.3916\n",
      "Epoch 98/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.2035 - mae: 3.2035 - val_loss: 3.4590 - val_mae: 3.4590\n",
      "Epoch 99/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.2088 - mae: 3.2088 - val_loss: 3.4803 - val_mae: 3.4803\n",
      "Epoch 100/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.2053 - mae: 3.2053 - val_loss: 3.4608 - val_mae: 3.4608\n",
      "Epoch 101/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.2112 - mae: 3.2112 - val_loss: 3.4654 - val_mae: 3.4654\n",
      "Epoch 102/300\n",
      "231/231 [==============================] - 0s 802us/step - loss: 3.2138 - mae: 3.2138 - val_loss: 3.5022 - val_mae: 3.5022\n",
      "Epoch 103/300\n",
      "231/231 [==============================] - 0s 802us/step - loss: 3.2021 - mae: 3.2021 - val_loss: 3.4998 - val_mae: 3.4998\n",
      "Epoch 104/300\n",
      "231/231 [==============================] - 0s 806us/step - loss: 3.2071 - mae: 3.2071 - val_loss: 3.4679 - val_mae: 3.4679\n",
      "Epoch 105/300\n",
      "231/231 [==============================] - 0s 815us/step - loss: 3.1970 - mae: 3.1970 - val_loss: 3.4177 - val_mae: 3.4177\n",
      "Epoch 106/300\n",
      "231/231 [==============================] - 0s 792us/step - loss: 3.2135 - mae: 3.2135 - val_loss: 3.4610 - val_mae: 3.4610\n",
      "Epoch 107/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.1929 - mae: 3.1929 - val_loss: 3.3837 - val_mae: 3.3837\n",
      "Epoch 108/300\n",
      "231/231 [==============================] - 0s 792us/step - loss: 3.1951 - mae: 3.1951 - val_loss: 3.4474 - val_mae: 3.4474\n",
      "Epoch 109/300\n",
      "231/231 [==============================] - 0s 790us/step - loss: 3.2067 - mae: 3.2067 - val_loss: 3.4847 - val_mae: 3.4847\n",
      "Epoch 110/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2041 - mae: 3.2041 - val_loss: 3.4705 - val_mae: 3.4705\n",
      "Epoch 111/300\n",
      "231/231 [==============================] - 0s 820us/step - loss: 3.1947 - mae: 3.1947 - val_loss: 3.4468 - val_mae: 3.4468\n",
      "Epoch 112/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.2030 - mae: 3.2030 - val_loss: 3.5169 - val_mae: 3.5169\n",
      "Epoch 113/300\n",
      "231/231 [==============================] - 0s 789us/step - loss: 3.2031 - mae: 3.2031 - val_loss: 3.4232 - val_mae: 3.4232\n",
      "Epoch 114/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.1974 - mae: 3.1974 - val_loss: 3.4439 - val_mae: 3.4439\n",
      "Epoch 115/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.1960 - mae: 3.1960 - val_loss: 3.4666 - val_mae: 3.4666\n",
      "Epoch 116/300\n",
      "231/231 [==============================] - 0s 801us/step - loss: 3.2142 - mae: 3.2142 - val_loss: 3.3758 - val_mae: 3.3758\n",
      "Epoch 117/300\n",
      "231/231 [==============================] - 0s 888us/step - loss: 3.2030 - mae: 3.2030 - val_loss: 3.4478 - val_mae: 3.4478\n",
      "Epoch 118/300\n",
      "231/231 [==============================] - 0s 947us/step - loss: 3.2030 - mae: 3.2030 - val_loss: 3.4452 - val_mae: 3.4452\n",
      "Epoch 119/300\n",
      "231/231 [==============================] - 0s 850us/step - loss: 3.2016 - mae: 3.2016 - val_loss: 3.4312 - val_mae: 3.4312\n",
      "Epoch 120/300\n",
      "231/231 [==============================] - 0s 835us/step - loss: 3.2083 - mae: 3.2083 - val_loss: 3.4106 - val_mae: 3.4106\n",
      "Epoch 121/300\n",
      "231/231 [==============================] - 0s 849us/step - loss: 3.2044 - mae: 3.2044 - val_loss: 3.4533 - val_mae: 3.4533\n",
      "Epoch 122/300\n",
      "231/231 [==============================] - 0s 851us/step - loss: 3.1964 - mae: 3.1964 - val_loss: 3.5057 - val_mae: 3.5057\n",
      "Epoch 123/300\n",
      "231/231 [==============================] - 0s 836us/step - loss: 3.1850 - mae: 3.1850 - val_loss: 3.4322 - val_mae: 3.4322\n",
      "Epoch 124/300\n",
      "231/231 [==============================] - 0s 836us/step - loss: 3.2013 - mae: 3.2013 - val_loss: 3.4664 - val_mae: 3.4664\n",
      "Epoch 125/300\n",
      "231/231 [==============================] - 0s 831us/step - loss: 3.1970 - mae: 3.1970 - val_loss: 3.4668 - val_mae: 3.4668\n",
      "Epoch 126/300\n",
      "231/231 [==============================] - 0s 829us/step - loss: 3.1966 - mae: 3.1966 - val_loss: 3.4598 - val_mae: 3.4598\n",
      "Epoch 127/300\n",
      "231/231 [==============================] - 0s 840us/step - loss: 3.1949 - mae: 3.1949 - val_loss: 3.4873 - val_mae: 3.4873\n",
      "Epoch 128/300\n",
      "231/231 [==============================] - 0s 853us/step - loss: 3.1824 - mae: 3.1824 - val_loss: 3.4413 - val_mae: 3.4413\n",
      "Epoch 129/300\n",
      "231/231 [==============================] - 0s 835us/step - loss: 3.1892 - mae: 3.1892 - val_loss: 3.4423 - val_mae: 3.4423\n",
      "Epoch 130/300\n",
      "231/231 [==============================] - 0s 854us/step - loss: 3.1884 - mae: 3.1884 - val_loss: 3.5119 - val_mae: 3.5119\n",
      "Epoch 131/300\n",
      "231/231 [==============================] - 0s 831us/step - loss: 3.1831 - mae: 3.1831 - val_loss: 3.4713 - val_mae: 3.4713\n",
      "Epoch 132/300\n",
      "231/231 [==============================] - 0s 791us/step - loss: 3.1907 - mae: 3.1907 - val_loss: 3.4077 - val_mae: 3.4077\n",
      "Epoch 133/300\n",
      "231/231 [==============================] - 0s 791us/step - loss: 3.1878 - mae: 3.1878 - val_loss: 3.4279 - val_mae: 3.4279\n",
      "Epoch 134/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.1892 - mae: 3.1892 - val_loss: 3.5053 - val_mae: 3.5053\n",
      "Epoch 135/300\n",
      "231/231 [==============================] - 0s 801us/step - loss: 3.1789 - mae: 3.1789 - val_loss: 3.4374 - val_mae: 3.4374\n",
      "Epoch 136/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.2033 - mae: 3.2033 - val_loss: 3.4995 - val_mae: 3.4995\n",
      "Epoch 137/300\n",
      "231/231 [==============================] - 0s 791us/step - loss: 3.1765 - mae: 3.1765 - val_loss: 3.4493 - val_mae: 3.4493\n",
      "Epoch 138/300\n",
      "231/231 [==============================] - 0s 787us/step - loss: 3.1861 - mae: 3.1861 - val_loss: 3.4902 - val_mae: 3.4902\n",
      "Epoch 139/300\n",
      "231/231 [==============================] - 0s 791us/step - loss: 3.1795 - mae: 3.1795 - val_loss: 3.4938 - val_mae: 3.4938\n",
      "Epoch 140/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.1912 - mae: 3.1912 - val_loss: 3.4736 - val_mae: 3.4736\n",
      "Epoch 141/300\n",
      "231/231 [==============================] - 0s 782us/step - loss: 3.1935 - mae: 3.1935 - val_loss: 3.4993 - val_mae: 3.4993\n",
      "Epoch 142/300\n",
      "231/231 [==============================] - 0s 792us/step - loss: 3.1860 - mae: 3.1860 - val_loss: 3.3866 - val_mae: 3.3866\n",
      "Epoch 143/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.1816 - mae: 3.1816 - val_loss: 3.4758 - val_mae: 3.4758\n",
      "Epoch 144/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.1863 - mae: 3.1863 - val_loss: 3.4859 - val_mae: 3.4859\n",
      "Epoch 145/300\n",
      "231/231 [==============================] - 0s 792us/step - loss: 3.1894 - mae: 3.1894 - val_loss: 3.4294 - val_mae: 3.4294\n",
      "Epoch 146/300\n",
      "231/231 [==============================] - 0s 811us/step - loss: 3.1867 - mae: 3.1867 - val_loss: 3.4214 - val_mae: 3.4214\n",
      "Epoch 147/300\n",
      "231/231 [==============================] - 0s 841us/step - loss: 3.1807 - mae: 3.1807 - val_loss: 3.4299 - val_mae: 3.4299\n",
      "Epoch 148/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.1892 - mae: 3.1892 - val_loss: 3.3965 - val_mae: 3.3965\n",
      "Epoch 149/300\n",
      "231/231 [==============================] - 0s 823us/step - loss: 3.1846 - mae: 3.1846 - val_loss: 3.4297 - val_mae: 3.4297\n",
      "Epoch 150/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.1771 - mae: 3.1771 - val_loss: 3.5305 - val_mae: 3.5305\n",
      "Epoch 151/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.1766 - mae: 3.1766 - val_loss: 3.4239 - val_mae: 3.4239\n",
      "Epoch 152/300\n",
      "231/231 [==============================] - 0s 794us/step - loss: 3.1895 - mae: 3.1895 - val_loss: 3.4883 - val_mae: 3.4883\n",
      "Epoch 153/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.1926 - mae: 3.1926 - val_loss: 3.4745 - val_mae: 3.4745\n",
      "Epoch 154/300\n",
      "231/231 [==============================] - 0s 787us/step - loss: 3.1741 - mae: 3.1741 - val_loss: 3.4136 - val_mae: 3.4136\n",
      "Epoch 155/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.1809 - mae: 3.1809 - val_loss: 3.4805 - val_mae: 3.4805\n",
      "Epoch 156/300\n",
      "231/231 [==============================] - 0s 811us/step - loss: 3.1746 - mae: 3.1746 - val_loss: 3.4182 - val_mae: 3.4182\n",
      "Epoch 157/300\n",
      "231/231 [==============================] - 0s 917us/step - loss: 3.1885 - mae: 3.1885 - val_loss: 3.5113 - val_mae: 3.5113\n",
      "Epoch 158/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.1749 - mae: 3.1749 - val_loss: 3.3719 - val_mae: 3.3719\n",
      "Epoch 159/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.1802 - mae: 3.1802 - val_loss: 3.5017 - val_mae: 3.5017\n",
      "Epoch 160/300\n",
      "231/231 [==============================] - 0s 795us/step - loss: 3.1778 - mae: 3.1778 - val_loss: 3.4304 - val_mae: 3.4304\n",
      "Epoch 161/300\n",
      "231/231 [==============================] - 0s 787us/step - loss: 3.1736 - mae: 3.1736 - val_loss: 3.4224 - val_mae: 3.4224\n",
      "Epoch 162/300\n",
      "231/231 [==============================] - 0s 819us/step - loss: 3.1873 - mae: 3.1873 - val_loss: 3.4260 - val_mae: 3.4260\n",
      "Epoch 163/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.1814 - mae: 3.1814 - val_loss: 3.4146 - val_mae: 3.4146\n",
      "Epoch 164/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.1763 - mae: 3.1763 - val_loss: 3.4789 - val_mae: 3.4789\n",
      "Epoch 165/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.1840 - mae: 3.1840 - val_loss: 3.4210 - val_mae: 3.4210\n",
      "Epoch 166/300\n",
      "231/231 [==============================] - 0s 802us/step - loss: 3.1785 - mae: 3.1785 - val_loss: 3.4542 - val_mae: 3.4542\n",
      "Epoch 167/300\n",
      "231/231 [==============================] - 0s 814us/step - loss: 3.1619 - mae: 3.1619 - val_loss: 3.3850 - val_mae: 3.3850\n",
      "Epoch 168/300\n",
      "231/231 [==============================] - 0s 801us/step - loss: 3.1750 - mae: 3.1750 - val_loss: 3.4802 - val_mae: 3.4802\n",
      "Epoch 169/300\n",
      "231/231 [==============================] - 0s 807us/step - loss: 3.1720 - mae: 3.1720 - val_loss: 3.4589 - val_mae: 3.4589\n",
      "Epoch 170/300\n",
      "231/231 [==============================] - 0s 805us/step - loss: 3.1882 - mae: 3.1882 - val_loss: 3.4407 - val_mae: 3.4407\n",
      "Epoch 171/300\n",
      "231/231 [==============================] - 0s 866us/step - loss: 3.1708 - mae: 3.1708 - val_loss: 3.4441 - val_mae: 3.4441\n",
      "Epoch 172/300\n",
      "231/231 [==============================] - 0s 925us/step - loss: 3.1805 - mae: 3.1805 - val_loss: 3.4156 - val_mae: 3.4156\n",
      "Epoch 173/300\n",
      "231/231 [==============================] - 0s 882us/step - loss: 3.1829 - mae: 3.1829 - val_loss: 3.4065 - val_mae: 3.4065\n",
      "Epoch 174/300\n",
      "231/231 [==============================] - 0s 832us/step - loss: 3.1854 - mae: 3.1854 - val_loss: 3.4728 - val_mae: 3.4728\n",
      "Epoch 175/300\n",
      "231/231 [==============================] - 0s 862us/step - loss: 3.1826 - mae: 3.1826 - val_loss: 3.4168 - val_mae: 3.4168\n",
      "Epoch 176/300\n",
      "231/231 [==============================] - 0s 850us/step - loss: 3.1850 - mae: 3.1850 - val_loss: 3.3927 - val_mae: 3.3927\n",
      "Epoch 177/300\n",
      "231/231 [==============================] - 0s 881us/step - loss: 3.1702 - mae: 3.1702 - val_loss: 3.4556 - val_mae: 3.4556\n",
      "Epoch 178/300\n",
      "231/231 [==============================] - 0s 871us/step - loss: 3.1796 - mae: 3.1796 - val_loss: 3.3857 - val_mae: 3.3857\n",
      "Epoch 179/300\n",
      "231/231 [==============================] - 0s 835us/step - loss: 3.1796 - mae: 3.1796 - val_loss: 3.4557 - val_mae: 3.4557\n",
      "Epoch 180/300\n",
      "231/231 [==============================] - 0s 846us/step - loss: 3.1782 - mae: 3.1782 - val_loss: 3.4328 - val_mae: 3.4328\n",
      "Epoch 181/300\n",
      "231/231 [==============================] - 0s 815us/step - loss: 3.1812 - mae: 3.1812 - val_loss: 3.4373 - val_mae: 3.4373\n",
      "Epoch 182/300\n",
      "231/231 [==============================] - 0s 854us/step - loss: 3.1765 - mae: 3.1765 - val_loss: 3.4092 - val_mae: 3.4092\n",
      "Epoch 183/300\n",
      "231/231 [==============================] - 0s 836us/step - loss: 3.1766 - mae: 3.1766 - val_loss: 3.3795 - val_mae: 3.3795\n",
      "Epoch 184/300\n",
      "231/231 [==============================] - 0s 836us/step - loss: 3.1659 - mae: 3.1659 - val_loss: 3.4147 - val_mae: 3.4147\n",
      "Epoch 185/300\n",
      "231/231 [==============================] - 0s 858us/step - loss: 3.1839 - mae: 3.1839 - val_loss: 3.3959 - val_mae: 3.3959\n",
      "Epoch 186/300\n",
      "231/231 [==============================] - 0s 792us/step - loss: 3.1717 - mae: 3.1717 - val_loss: 3.4367 - val_mae: 3.4367\n",
      "Epoch 187/300\n",
      "231/231 [==============================] - 0s 789us/step - loss: 3.1753 - mae: 3.1753 - val_loss: 3.5043 - val_mae: 3.5043\n"
     ]
    }
   ],
   "source": [
    "force_train, force_test, theta_x_train, theta_x_test= train_test_split(force_yc_w, theta_x_yc, test_size = 0.2, random_state = 0)\n",
    "history = model.fit(force_train, theta_x_train, epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (force_test, theta_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "231/231 [==============================] - 0s 892us/step - loss: 3.9808 - mae: 3.9808 - val_loss: 3.8499 - val_mae: 3.8499\n",
      "Epoch 2/300\n",
      "231/231 [==============================] - 0s 809us/step - loss: 3.6593 - mae: 3.6593 - val_loss: 3.7646 - val_mae: 3.7646\n",
      "Epoch 3/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.5803 - mae: 3.5803 - val_loss: 3.7295 - val_mae: 3.7295\n",
      "Epoch 4/300\n",
      "231/231 [==============================] - 0s 829us/step - loss: 3.5332 - mae: 3.5332 - val_loss: 3.7069 - val_mae: 3.7069\n",
      "Epoch 5/300\n",
      "231/231 [==============================] - 0s 824us/step - loss: 3.4876 - mae: 3.4876 - val_loss: 3.7708 - val_mae: 3.7708\n",
      "Epoch 6/300\n",
      "231/231 [==============================] - 0s 821us/step - loss: 3.4392 - mae: 3.4392 - val_loss: 3.6524 - val_mae: 3.6524\n",
      "Epoch 7/300\n",
      "231/231 [==============================] - 0s 862us/step - loss: 3.4068 - mae: 3.4068 - val_loss: 3.5820 - val_mae: 3.5820\n",
      "Epoch 8/300\n",
      "231/231 [==============================] - 0s 810us/step - loss: 3.3623 - mae: 3.3623 - val_loss: 3.5927 - val_mae: 3.5927\n",
      "Epoch 9/300\n",
      "231/231 [==============================] - 0s 806us/step - loss: 3.3443 - mae: 3.3443 - val_loss: 3.5350 - val_mae: 3.5350\n",
      "Epoch 10/300\n",
      "231/231 [==============================] - 0s 813us/step - loss: 3.3211 - mae: 3.3211 - val_loss: 3.5789 - val_mae: 3.5789\n",
      "Epoch 11/300\n",
      "231/231 [==============================] - 0s 808us/step - loss: 3.2999 - mae: 3.2999 - val_loss: 3.5795 - val_mae: 3.5795\n",
      "Epoch 12/300\n",
      "231/231 [==============================] - 0s 813us/step - loss: 3.2811 - mae: 3.2811 - val_loss: 3.4750 - val_mae: 3.4750\n",
      "Epoch 13/300\n",
      "231/231 [==============================] - 0s 816us/step - loss: 3.2737 - mae: 3.2737 - val_loss: 3.4714 - val_mae: 3.4714\n",
      "Epoch 14/300\n",
      "231/231 [==============================] - 0s 806us/step - loss: 3.2829 - mae: 3.2829 - val_loss: 3.4699 - val_mae: 3.4699\n",
      "Epoch 15/300\n",
      "231/231 [==============================] - 0s 806us/step - loss: 3.2668 - mae: 3.2668 - val_loss: 3.4289 - val_mae: 3.4289\n",
      "Epoch 16/300\n",
      "231/231 [==============================] - 0s 806us/step - loss: 3.2698 - mae: 3.2698 - val_loss: 3.5547 - val_mae: 3.5547\n",
      "Epoch 17/300\n",
      "231/231 [==============================] - 0s 812us/step - loss: 3.2774 - mae: 3.2774 - val_loss: 3.4604 - val_mae: 3.4604\n",
      "Epoch 18/300\n",
      "231/231 [==============================] - 0s 810us/step - loss: 3.2677 - mae: 3.2677 - val_loss: 3.4278 - val_mae: 3.4278\n",
      "Epoch 19/300\n",
      "231/231 [==============================] - 0s 823us/step - loss: 3.2506 - mae: 3.2506 - val_loss: 3.4999 - val_mae: 3.4999\n",
      "Epoch 20/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.2630 - mae: 3.2630 - val_loss: 3.5170 - val_mae: 3.5170\n",
      "Epoch 21/300\n",
      "231/231 [==============================] - 0s 805us/step - loss: 3.2579 - mae: 3.2579 - val_loss: 3.4679 - val_mae: 3.4679\n",
      "Epoch 22/300\n",
      "231/231 [==============================] - 0s 823us/step - loss: 3.2556 - mae: 3.2556 - val_loss: 3.5348 - val_mae: 3.5348\n",
      "Epoch 23/300\n",
      "231/231 [==============================] - 0s 813us/step - loss: 3.2444 - mae: 3.2444 - val_loss: 3.4177 - val_mae: 3.4177\n",
      "Epoch 24/300\n",
      "231/231 [==============================] - 0s 804us/step - loss: 3.2513 - mae: 3.2513 - val_loss: 3.4361 - val_mae: 3.4361\n",
      "Epoch 25/300\n",
      "231/231 [==============================] - 0s 804us/step - loss: 3.2419 - mae: 3.2419 - val_loss: 3.5019 - val_mae: 3.5019\n",
      "Epoch 26/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.2528 - mae: 3.2528 - val_loss: 3.4630 - val_mae: 3.4630\n",
      "Epoch 27/300\n",
      "231/231 [==============================] - 0s 808us/step - loss: 3.2438 - mae: 3.2438 - val_loss: 3.4890 - val_mae: 3.4890\n",
      "Epoch 28/300\n",
      "231/231 [==============================] - 0s 810us/step - loss: 3.2375 - mae: 3.2375 - val_loss: 3.4894 - val_mae: 3.4894\n",
      "Epoch 29/300\n",
      "231/231 [==============================] - 0s 809us/step - loss: 3.2458 - mae: 3.2458 - val_loss: 3.4644 - val_mae: 3.4644\n",
      "Epoch 30/300\n",
      "231/231 [==============================] - 0s 811us/step - loss: 3.2472 - mae: 3.2472 - val_loss: 3.5521 - val_mae: 3.5521\n",
      "Epoch 31/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.2277 - mae: 3.2277 - val_loss: 3.4996 - val_mae: 3.4996\n",
      "Epoch 32/300\n",
      "231/231 [==============================] - 0s 854us/step - loss: 3.2305 - mae: 3.2305 - val_loss: 3.4869 - val_mae: 3.4869\n",
      "Epoch 33/300\n",
      "231/231 [==============================] - 0s 943us/step - loss: 3.2438 - mae: 3.2438 - val_loss: 3.5214 - val_mae: 3.5214\n",
      "Epoch 34/300\n",
      "231/231 [==============================] - 0s 908us/step - loss: 3.2230 - mae: 3.2230 - val_loss: 3.4697 - val_mae: 3.4697\n",
      "Epoch 35/300\n",
      "231/231 [==============================] - 0s 842us/step - loss: 3.2251 - mae: 3.2251 - val_loss: 3.4937 - val_mae: 3.4937\n",
      "Epoch 36/300\n",
      "231/231 [==============================] - 0s 853us/step - loss: 3.2056 - mae: 3.2056 - val_loss: 3.4471 - val_mae: 3.4471\n",
      "Epoch 37/300\n",
      "231/231 [==============================] - 0s 861us/step - loss: 3.2160 - mae: 3.2160 - val_loss: 3.4427 - val_mae: 3.4427\n",
      "Epoch 38/300\n",
      "231/231 [==============================] - 0s 974us/step - loss: 3.2095 - mae: 3.2095 - val_loss: 3.4222 - val_mae: 3.4222\n",
      "Epoch 39/300\n",
      "231/231 [==============================] - 0s 869us/step - loss: 3.2079 - mae: 3.2079 - val_loss: 3.4563 - val_mae: 3.4563\n",
      "Epoch 40/300\n",
      "231/231 [==============================] - 0s 844us/step - loss: 3.2085 - mae: 3.2085 - val_loss: 3.4739 - val_mae: 3.4739\n",
      "Epoch 41/300\n",
      "231/231 [==============================] - 0s 855us/step - loss: 3.1964 - mae: 3.1964 - val_loss: 3.4142 - val_mae: 3.4142\n",
      "Epoch 42/300\n",
      "231/231 [==============================] - 0s 869us/step - loss: 3.2073 - mae: 3.2073 - val_loss: 3.4537 - val_mae: 3.4537\n",
      "Epoch 43/300\n",
      "231/231 [==============================] - 0s 895us/step - loss: 3.2097 - mae: 3.2097 - val_loss: 3.4536 - val_mae: 3.4536\n",
      "Epoch 44/300\n",
      "231/231 [==============================] - 0s 870us/step - loss: 3.1881 - mae: 3.1881 - val_loss: 3.4934 - val_mae: 3.4934\n",
      "Epoch 45/300\n",
      "231/231 [==============================] - 0s 874us/step - loss: 3.2034 - mae: 3.2034 - val_loss: 3.5145 - val_mae: 3.5145\n",
      "Epoch 46/300\n",
      "231/231 [==============================] - 0s 874us/step - loss: 3.2125 - mae: 3.2125 - val_loss: 3.4618 - val_mae: 3.4618\n",
      "Epoch 47/300\n",
      "231/231 [==============================] - 0s 807us/step - loss: 3.2133 - mae: 3.2133 - val_loss: 3.4597 - val_mae: 3.4597\n",
      "Epoch 48/300\n",
      "231/231 [==============================] - 0s 810us/step - loss: 3.2107 - mae: 3.2107 - val_loss: 3.5282 - val_mae: 3.5282\n",
      "Epoch 49/300\n",
      "231/231 [==============================] - 0s 805us/step - loss: 3.2009 - mae: 3.2009 - val_loss: 3.4995 - val_mae: 3.4995\n",
      "Epoch 50/300\n",
      "231/231 [==============================] - 0s 809us/step - loss: 3.2005 - mae: 3.2005 - val_loss: 3.4526 - val_mae: 3.4526\n",
      "Epoch 51/300\n",
      "231/231 [==============================] - 0s 804us/step - loss: 3.1964 - mae: 3.1964 - val_loss: 3.5062 - val_mae: 3.5062\n",
      "Epoch 52/300\n",
      "231/231 [==============================] - 0s 802us/step - loss: 3.1967 - mae: 3.1967 - val_loss: 3.5146 - val_mae: 3.5146\n",
      "Epoch 53/300\n",
      "231/231 [==============================] - 0s 808us/step - loss: 3.2002 - mae: 3.2002 - val_loss: 3.4382 - val_mae: 3.4382\n",
      "Epoch 54/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.1990 - mae: 3.1990 - val_loss: 3.4997 - val_mae: 3.4997\n",
      "Epoch 55/300\n",
      "231/231 [==============================] - 0s 798us/step - loss: 3.2195 - mae: 3.2195 - val_loss: 3.4943 - val_mae: 3.4943\n",
      "Epoch 56/300\n",
      "231/231 [==============================] - 0s 820us/step - loss: 3.1935 - mae: 3.1935 - val_loss: 3.4886 - val_mae: 3.4886\n",
      "Epoch 57/300\n",
      "231/231 [==============================] - 0s 819us/step - loss: 3.2008 - mae: 3.2008 - val_loss: 3.4336 - val_mae: 3.4336\n",
      "Epoch 58/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.2054 - mae: 3.2054 - val_loss: 3.4706 - val_mae: 3.4706\n",
      "Epoch 59/300\n",
      "231/231 [==============================] - 0s 845us/step - loss: 3.1975 - mae: 3.1975 - val_loss: 3.4819 - val_mae: 3.4819\n",
      "Epoch 60/300\n",
      "231/231 [==============================] - 0s 839us/step - loss: 3.2004 - mae: 3.2004 - val_loss: 3.4988 - val_mae: 3.4988\n",
      "Epoch 61/300\n",
      "231/231 [==============================] - 0s 821us/step - loss: 3.1940 - mae: 3.1940 - val_loss: 3.5164 - val_mae: 3.5164\n",
      "Epoch 62/300\n",
      "231/231 [==============================] - 0s 809us/step - loss: 3.2019 - mae: 3.2019 - val_loss: 3.5064 - val_mae: 3.5064\n",
      "Epoch 63/300\n",
      "231/231 [==============================] - 0s 834us/step - loss: 3.1869 - mae: 3.1869 - val_loss: 3.4458 - val_mae: 3.4458\n",
      "Epoch 64/300\n",
      "231/231 [==============================] - 0s 911us/step - loss: 3.1955 - mae: 3.1955 - val_loss: 3.4961 - val_mae: 3.4961\n",
      "Epoch 65/300\n",
      "231/231 [==============================] - 0s 866us/step - loss: 3.1788 - mae: 3.1788 - val_loss: 3.4899 - val_mae: 3.4899\n",
      "Epoch 66/300\n",
      "231/231 [==============================] - 0s 875us/step - loss: 3.2012 - mae: 3.2012 - val_loss: 3.4841 - val_mae: 3.4841\n",
      "Epoch 67/300\n",
      "231/231 [==============================] - 0s 897us/step - loss: 3.1825 - mae: 3.1825 - val_loss: 3.5002 - val_mae: 3.5002\n",
      "Epoch 68/300\n",
      "231/231 [==============================] - 0s 826us/step - loss: 3.1909 - mae: 3.1909 - val_loss: 3.4632 - val_mae: 3.4632\n",
      "Epoch 69/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.1961 - mae: 3.1961 - val_loss: 3.5162 - val_mae: 3.5162\n",
      "Epoch 70/300\n",
      "231/231 [==============================] - 0s 818us/step - loss: 3.1775 - mae: 3.1775 - val_loss: 3.4837 - val_mae: 3.4837\n",
      "Epoch 71/300\n",
      "231/231 [==============================] - 0s 805us/step - loss: 3.1868 - mae: 3.1868 - val_loss: 3.4731 - val_mae: 3.4731\n",
      "Epoch 72/300\n",
      "231/231 [==============================] - 0s 801us/step - loss: 3.1814 - mae: 3.1814 - val_loss: 3.5188 - val_mae: 3.5188\n",
      "Epoch 73/300\n",
      "231/231 [==============================] - 0s 800us/step - loss: 3.1833 - mae: 3.1833 - val_loss: 3.3902 - val_mae: 3.3902\n",
      "Epoch 74/300\n",
      "231/231 [==============================] - 0s 792us/step - loss: 3.1815 - mae: 3.1815 - val_loss: 3.5748 - val_mae: 3.5748\n",
      "Epoch 75/300\n",
      "231/231 [==============================] - 0s 805us/step - loss: 3.2009 - mae: 3.2009 - val_loss: 3.5522 - val_mae: 3.5522\n",
      "Epoch 76/300\n",
      "231/231 [==============================] - 0s 820us/step - loss: 3.1945 - mae: 3.1945 - val_loss: 3.4663 - val_mae: 3.4663\n",
      "Epoch 77/300\n",
      "231/231 [==============================] - 0s 857us/step - loss: 3.1880 - mae: 3.1880 - val_loss: 3.4023 - val_mae: 3.4023\n",
      "Epoch 78/300\n",
      "231/231 [==============================] - 0s 849us/step - loss: 3.1750 - mae: 3.1750 - val_loss: 3.4704 - val_mae: 3.4704\n",
      "Epoch 79/300\n",
      "231/231 [==============================] - 0s 837us/step - loss: 3.1870 - mae: 3.1870 - val_loss: 3.3749 - val_mae: 3.3749\n",
      "Epoch 80/300\n",
      "231/231 [==============================] - 0s 848us/step - loss: 3.1991 - mae: 3.1991 - val_loss: 3.4141 - val_mae: 3.4141\n",
      "Epoch 81/300\n",
      "231/231 [==============================] - 0s 833us/step - loss: 3.1990 - mae: 3.1990 - val_loss: 3.4167 - val_mae: 3.4167\n",
      "Epoch 82/300\n",
      "231/231 [==============================] - 0s 838us/step - loss: 3.1924 - mae: 3.1924 - val_loss: 3.4657 - val_mae: 3.4657\n",
      "Epoch 83/300\n",
      "231/231 [==============================] - 0s 850us/step - loss: 3.1894 - mae: 3.1894 - val_loss: 3.5553 - val_mae: 3.5553\n",
      "Epoch 84/300\n",
      "231/231 [==============================] - 0s 844us/step - loss: 3.1816 - mae: 3.1816 - val_loss: 3.4931 - val_mae: 3.4931\n",
      "Epoch 85/300\n",
      "231/231 [==============================] - 0s 961us/step - loss: 3.1795 - mae: 3.1795 - val_loss: 3.4523 - val_mae: 3.4523\n",
      "Epoch 86/300\n",
      "231/231 [==============================] - 0s 966us/step - loss: 3.1826 - mae: 3.1826 - val_loss: 3.4928 - val_mae: 3.4928\n",
      "Epoch 87/300\n",
      "231/231 [==============================] - 0s 858us/step - loss: 3.1707 - mae: 3.1707 - val_loss: 3.4890 - val_mae: 3.4890\n",
      "Epoch 88/300\n",
      "231/231 [==============================] - 0s 851us/step - loss: 3.1843 - mae: 3.1843 - val_loss: 3.4137 - val_mae: 3.4137\n",
      "Epoch 89/300\n",
      "231/231 [==============================] - 0s 844us/step - loss: 3.1768 - mae: 3.1768 - val_loss: 3.4624 - val_mae: 3.4624\n",
      "Epoch 90/300\n",
      "231/231 [==============================] - 0s 843us/step - loss: 3.1771 - mae: 3.1771 - val_loss: 3.4852 - val_mae: 3.4852\n",
      "Epoch 91/300\n",
      "231/231 [==============================] - 0s 829us/step - loss: 3.1902 - mae: 3.1902 - val_loss: 3.4658 - val_mae: 3.4658\n",
      "Epoch 92/300\n",
      "231/231 [==============================] - 0s 845us/step - loss: 3.1783 - mae: 3.1783 - val_loss: 3.4768 - val_mae: 3.4768\n",
      "Epoch 93/300\n",
      "231/231 [==============================] - 0s 859us/step - loss: 3.1754 - mae: 3.1754 - val_loss: 3.4441 - val_mae: 3.4441\n",
      "Epoch 94/300\n",
      "231/231 [==============================] - 0s 847us/step - loss: 3.1821 - mae: 3.1821 - val_loss: 3.4810 - val_mae: 3.4810\n",
      "Epoch 95/300\n",
      "231/231 [==============================] - 0s 874us/step - loss: 3.1739 - mae: 3.1739 - val_loss: 3.4747 - val_mae: 3.4747\n",
      "Epoch 96/300\n",
      "231/231 [==============================] - 0s 853us/step - loss: 3.1783 - mae: 3.1783 - val_loss: 3.4510 - val_mae: 3.4510\n",
      "Epoch 97/300\n",
      "231/231 [==============================] - 0s 851us/step - loss: 3.1736 - mae: 3.1736 - val_loss: 3.5214 - val_mae: 3.5214\n",
      "Epoch 98/300\n",
      "231/231 [==============================] - 0s 865us/step - loss: 3.1672 - mae: 3.1672 - val_loss: 3.5015 - val_mae: 3.5015\n",
      "Epoch 99/300\n",
      "231/231 [==============================] - 0s 838us/step - loss: 3.1741 - mae: 3.1741 - val_loss: 3.5457 - val_mae: 3.5457\n",
      "Epoch 100/300\n",
      "231/231 [==============================] - 0s 785us/step - loss: 3.1868 - mae: 3.1868 - val_loss: 3.4595 - val_mae: 3.4595\n",
      "Epoch 101/300\n",
      "231/231 [==============================] - 0s 782us/step - loss: 3.1671 - mae: 3.1671 - val_loss: 3.4848 - val_mae: 3.4848\n",
      "Epoch 102/300\n",
      "231/231 [==============================] - 0s 788us/step - loss: 3.1671 - mae: 3.1671 - val_loss: 3.5111 - val_mae: 3.5111\n",
      "Epoch 103/300\n",
      "231/231 [==============================] - 0s 786us/step - loss: 3.1753 - mae: 3.1753 - val_loss: 3.4665 - val_mae: 3.4665\n",
      "Epoch 104/300\n",
      "231/231 [==============================] - 0s 796us/step - loss: 3.1626 - mae: 3.1626 - val_loss: 3.4498 - val_mae: 3.4498\n",
      "Epoch 105/300\n",
      "231/231 [==============================] - 0s 813us/step - loss: 3.1689 - mae: 3.1689 - val_loss: 3.4808 - val_mae: 3.4808\n",
      "Epoch 106/300\n",
      "231/231 [==============================] - 0s 799us/step - loss: 3.1835 - mae: 3.1835 - val_loss: 3.4691 - val_mae: 3.4691\n",
      "Epoch 107/300\n",
      "231/231 [==============================] - 0s 820us/step - loss: 3.1750 - mae: 3.1750 - val_loss: 3.4734 - val_mae: 3.4734\n",
      "Epoch 108/300\n",
      "231/231 [==============================] - 0s 802us/step - loss: 3.1796 - mae: 3.1796 - val_loss: 3.4552 - val_mae: 3.4552\n",
      "Epoch 109/300\n",
      "231/231 [==============================] - 0s 824us/step - loss: 3.1740 - mae: 3.1740 - val_loss: 3.4736 - val_mae: 3.4736\n",
      "Epoch 110/300\n",
      "231/231 [==============================] - 0s 808us/step - loss: 3.1757 - mae: 3.1757 - val_loss: 3.4687 - val_mae: 3.4687\n",
      "Epoch 111/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.1665 - mae: 3.1665 - val_loss: 3.4675 - val_mae: 3.4675\n",
      "Epoch 112/300\n",
      "231/231 [==============================] - 0s 793us/step - loss: 3.1636 - mae: 3.1636 - val_loss: 3.5324 - val_mae: 3.5324\n",
      "Epoch 113/300\n",
      "231/231 [==============================] - 0s 777us/step - loss: 3.1686 - mae: 3.1686 - val_loss: 3.4993 - val_mae: 3.4993\n",
      "Epoch 114/300\n",
      "231/231 [==============================] - 0s 803us/step - loss: 3.1790 - mae: 3.1790 - val_loss: 3.4333 - val_mae: 3.4333\n",
      "Epoch 115/300\n",
      "231/231 [==============================] - 0s 788us/step - loss: 3.1702 - mae: 3.1702 - val_loss: 3.4642 - val_mae: 3.4642\n",
      "Epoch 116/300\n",
      "231/231 [==============================] - 0s 805us/step - loss: 3.1669 - mae: 3.1669 - val_loss: 3.4697 - val_mae: 3.4697\n",
      "Epoch 117/300\n",
      "231/231 [==============================] - 0s 797us/step - loss: 3.1694 - mae: 3.1694 - val_loss: 3.4358 - val_mae: 3.4358\n",
      "Epoch 118/300\n",
      "231/231 [==============================] - 0s 784us/step - loss: 3.1778 - mae: 3.1778 - val_loss: 3.4869 - val_mae: 3.4869\n",
      "Epoch 119/300\n",
      "231/231 [==============================] - 0s 802us/step - loss: 3.1671 - mae: 3.1671 - val_loss: 3.4496 - val_mae: 3.4496\n",
      "Epoch 120/300\n",
      "231/231 [==============================] - 0s 923us/step - loss: 3.1667 - mae: 3.1667 - val_loss: 3.3743 - val_mae: 3.3743\n",
      "Epoch 121/300\n",
      "231/231 [==============================] - 0s 801us/step - loss: 3.1728 - mae: 3.1728 - val_loss: 3.4974 - val_mae: 3.4974\n",
      "Epoch 122/300\n",
      "231/231 [==============================] - 0s 782us/step - loss: 3.1769 - mae: 3.1769 - val_loss: 3.4855 - val_mae: 3.4855\n",
      "Epoch 123/300\n",
      "231/231 [==============================] - 0s 785us/step - loss: 3.1739 - mae: 3.1739 - val_loss: 3.4970 - val_mae: 3.4970\n",
      "Epoch 124/300\n",
      "231/231 [==============================] - 0s 801us/step - loss: 3.1653 - mae: 3.1653 - val_loss: 3.5109 - val_mae: 3.5109\n"
     ]
    }
   ],
   "source": [
    "force_train, force_test, theta_x_train, theta_x_test= train_test_split(force_yc_wh, theta_x_yc, test_size = 0.2, random_state = 0)\n",
    "history = model.fit(force_train, theta_x_train, epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (force_test, theta_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_x_predict_poly = lin_reg_2.predict(poly_reg.fit_transform(force_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(y_original,'-')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (20,5)\n",
    "plt.plot(theta_x_predict_poly,'--')\n",
    "plt.plot(theta_x_test,'--')\n",
    "plt.title('Polynomial Regression')\n",
    "plt.ylabel('Angle')\n",
    "plt.xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.475024619335076"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "force_train, force_test, theta_x_train, theta_x_test= train_test_split(force_leo_bmi, theta_x_leo, test_size = 0.2, random_state = 0)\n",
    "reg = LinearRegression().fit(force_train, theta_x_train)\n",
    "y_predict = reg.predict(force_test)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(theta_x_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(theta_x_test,'-')\n",
    "plt.plot(y_predict,'--')\n",
    "\n",
    "plt.title('Linear Regression')\n",
    "plt.ylabel('Angle (deg)')\n",
    "plt.xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-316008c24351>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# X_scaled = scaler.fit_transform(force_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_poly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpoly_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_poly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta_x_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlin_reg_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlin_reg_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_x_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1516\u001b[0m                                           self.include_bias)\n\u001b[1;32m   1517\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_input_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_output_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1516\u001b[0m                                           self.include_bias)\n\u001b[1;32m   1517\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_input_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_output_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "force_train, force_test, theta_x_train, theta_x_test= train_test_split(force_yc_bmi, theta_x_yc, test_size = 0.2, random_state = 0)\n",
    "poly_reg = PolynomialFeatures(degree = 5)\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(force_train)\n",
    "X_poly = poly_reg.fit_transform(force_train)\n",
    "poly_reg.fit(X_poly,theta_x_train)\n",
    "lin_reg_2 = LinearRegression()\n",
    "lin_reg_2.fit(X_poly, theta_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_poly = lin_reg_2.predict(poly_reg.fit_transform(force_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(theta_x_test,'-')\n",
    "plt.plot(y_predict,'--')\n",
    "\n",
    "plt.title('Polynomial Regression')\n",
    "plt.ylabel('Angle (deg)')\n",
    "plt.xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature scaling\n",
    "# fc = StandardScaler()\n",
    "# sc_y = StandardScaler()\n",
    "\n",
    "# force_train = fc.fit_transform(force_train)\n",
    "# force_test = fc.transform(force_test)\n",
    "\n",
    "# theta_z_train = theta_z_train.reshape(-1,1)\n",
    "# theta_z_train = sc_y.fit_transform(theta_z_train)\n",
    "# theta_z_train = theta_z_train.ravel()\n",
    "force_train, force_test, theta_x_train, theta_x_test= train_test_split(force_yc_bmi, theta_x_yc, test_size = 0.2, random_state = 0)\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 2)\n",
    "regressor.fit(force_train, theta_x_train)\n",
    "\n",
    "#y_pred = sc_y.inverse_transform(regressor.predict(force_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8371877943672879"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred = regressor.predict(force_test)\n",
    "mean_absolute_error(theta_x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9341074859141355"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(force_test,theta_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "plt.plot(theta_x_test,'-')\n",
    "plt.plot(y_pred,'--')\n",
    "\n",
    "plt.title('Random Forest Regression')\n",
    "plt.ylabel('Angle (deg)')\n",
    "plt.xlabel('Time')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
