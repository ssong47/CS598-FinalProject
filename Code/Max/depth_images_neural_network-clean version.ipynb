{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib tk\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read output angle data (test folder 24, 30, 31, 32, 33, 35 from Preliminary result v5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the dimension of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read video frame\n",
    "def dep_cam_reduced(dep_v_name):\n",
    "    dep_v = cv2.VideoCapture(dep_v_name)\n",
    "    ret, frame = dep_v.read()\n",
    "    counter=0\n",
    "\n",
    "    frame_count = int(dep_v.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "#     frame_height = int(frame.shape[0]/5)\n",
    "#     frame_width = int(frame.shape[1]/5)\n",
    "#     frame_height = frame.shape[0]\n",
    "#     frame_width = frame.shape[1]\n",
    "    frame_height = 30\n",
    "    frame_width = 40\n",
    "    depth_frames = np.empty((frame_count, frame_height, frame_width))\n",
    "\n",
    "    while(dep_v.isOpened()):\n",
    "        ret, frame = dep_v.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        if ret == True:\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray_frame = cv2.resize(gray_frame, (frame_width, frame_height), interpolation = cv2.INTER_AREA)\n",
    "            depth_frames[counter] = gray_frame\n",
    "            counter+=1\n",
    "\n",
    "    dep_v.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return depth_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read output depth images data\n",
    "foldername = r'Test_Subject_Leo/'\n",
    "test_folder = ['test24', 'test30', 'test31', 'test32','test33', 'test35' ]\n",
    "test_num = ['24', '30', '31', '32', '33', '35']\n",
    "sub_name = foldername + test_folder[0]\n",
    "dep_name = sub_name + r'/depth_processed_leo_test' + test_num[0] + '.avi';\n",
    "depth =  dep_cam_reduced(dep_name)\n",
    "for i in range(1, 6):\n",
    "    subfolder_name = foldername + test_folder[i]\n",
    "    dep_video_name = subfolder_name + r'/depth_processed_leo_test' + test_num[i] + '.avi'\n",
    "    #print(dep_video_name)\n",
    "    dep_v_temp =  dep_cam_reduced(dep_video_name)/255.0\n",
    "    depth = np.concatenate((depth, dep_v_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(depth.shape)\n",
    "print(theta_z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read force data\n",
    "subfolder_name = foldername + test_folder[0]\n",
    "force_file = subfolder_name + r'/fcss_processed_leo_test' + test_num[0] + '_' + '11_15_2020' + '.txt'\n",
    "force = pd.read_csv(force_file)\n",
    "force = force.iloc[:,:].values\n",
    "for i in range(1,6):\n",
    "    subfolder_name = foldername + test_folder[i]\n",
    "    if test_folder[i] == 'test30' or test_folder[i] == 'test31':\n",
    "        force_file = subfolder_name + r'/fcss_processed_leo_test' + test_num[i] + '_' + '11_24_2020' + '.txt'\n",
    "    else: \n",
    "        force_file = subfolder_name + r'/fcss_processed_leo_test' + test_num[i] + '_' + '11_25_2020' + '.txt'\n",
    "    dataset_y =  pd.read_csv(force_file)\n",
    "    force_temp = dataset_y.iloc[:,:].values\n",
    "    force = np.concatenate((force, force_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Observation: Comparing to the NN that uses tanh and sigmoid activation function, the rectified linear unit fucntion seemed to have better performance (lower mae) when the layers number are the same. Also, the choice of metrics of model evaluation seemed to be important (mse is quite large compared to mae). But I wonder what happened to my plots ;(     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Also, right now I am using a dimension of 120 * 160, performing a dimensionality reduction could be helpful for extracting necessary features. A longer epoch time may also improve performance. Tried sklearn neural network MLPRegressor but does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_train, depth_test, force_train, force_test, theta_z_train, theta_z_test = train_test_split(depth, force, theta_z, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 9.6339 - mae: 9.6339 - val_loss: 9.3093 - val_mae: 9.3093\n",
      "Epoch 2/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 9.2564 - mae: 9.2564 - val_loss: 9.1086 - val_mae: 9.1086\n",
      "Epoch 3/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 9.0410 - mae: 9.0410 - val_loss: 8.8175 - val_mae: 8.8175\n",
      "Epoch 4/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 8.9281 - mae: 8.9281 - val_loss: 8.8209 - val_mae: 8.8209\n",
      "Epoch 5/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 8.7499 - mae: 8.7499 - val_loss: 8.5831 - val_mae: 8.5831\n",
      "Epoch 6/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 8.5872 - mae: 8.5872 - val_loss: 8.3356 - val_mae: 8.3356\n",
      "Epoch 7/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 8.4767 - mae: 8.4767 - val_loss: 8.2559 - val_mae: 8.2559\n",
      "Epoch 8/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 8.3467 - mae: 8.3467 - val_loss: 8.1737 - val_mae: 8.1737\n",
      "Epoch 9/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 8.2701 - mae: 8.2701 - val_loss: 8.1403 - val_mae: 8.1403\n",
      "Epoch 10/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 8.1971 - mae: 8.1971 - val_loss: 7.9726 - val_mae: 7.9726\n",
      "Epoch 11/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 8.1750 - mae: 8.1750 - val_loss: 7.9199 - val_mae: 7.9199\n",
      "Epoch 12/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 8.0724 - mae: 8.0724 - val_loss: 7.8772 - val_mae: 7.8772\n",
      "Epoch 13/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.9480 - mae: 7.9480 - val_loss: 7.6463 - val_mae: 7.6463\n",
      "Epoch 14/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.8646 - mae: 7.8646 - val_loss: 7.5894 - val_mae: 7.5894\n",
      "Epoch 15/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.8105 - mae: 7.8105 - val_loss: 7.5386 - val_mae: 7.5386\n",
      "Epoch 16/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.7684 - mae: 7.7684 - val_loss: 7.6310 - val_mae: 7.6310\n",
      "Epoch 17/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.6922 - mae: 7.6922 - val_loss: 7.5086 - val_mae: 7.5086\n",
      "Epoch 18/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.6731 - mae: 7.6731 - val_loss: 7.3533 - val_mae: 7.3533\n",
      "Epoch 19/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.5810 - mae: 7.5810 - val_loss: 7.3768 - val_mae: 7.3768\n",
      "Epoch 20/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.5173 - mae: 7.5173 - val_loss: 7.2984 - val_mae: 7.2984\n",
      "Epoch 21/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.4325 - mae: 7.4325 - val_loss: 7.2838 - val_mae: 7.2838\n",
      "Epoch 22/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.4755 - mae: 7.4755 - val_loss: 7.4218 - val_mae: 7.4218\n",
      "Epoch 23/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.5422 - mae: 7.5422 - val_loss: 7.2247 - val_mae: 7.2247\n",
      "Epoch 24/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.4351 - mae: 7.4351 - val_loss: 7.3598 - val_mae: 7.3598\n",
      "Epoch 25/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.4089 - mae: 7.4089 - val_loss: 7.1217 - val_mae: 7.1217\n",
      "Epoch 26/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.3568 - mae: 7.3568 - val_loss: 7.1442 - val_mae: 7.1442\n",
      "Epoch 27/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.3535 - mae: 7.3535 - val_loss: 7.1421 - val_mae: 7.1421\n",
      "Epoch 28/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.2697 - mae: 7.2697 - val_loss: 7.0933 - val_mae: 7.0933\n",
      "Epoch 29/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.2547 - mae: 7.2547 - val_loss: 7.0281 - val_mae: 7.0281\n",
      "Epoch 30/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.2063 - mae: 7.2063 - val_loss: 7.0201 - val_mae: 7.0201\n",
      "Epoch 31/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.2049 - mae: 7.2049 - val_loss: 7.0168 - val_mae: 7.0168\n",
      "Epoch 32/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.1535 - mae: 7.1535 - val_loss: 6.8985 - val_mae: 6.8985\n",
      "Epoch 33/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.1854 - mae: 7.1854 - val_loss: 7.0647 - val_mae: 7.0647\n",
      "Epoch 34/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.1656 - mae: 7.1656 - val_loss: 6.9104 - val_mae: 6.9104\n",
      "Epoch 35/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.1442 - mae: 7.1442 - val_loss: 6.9794 - val_mae: 6.9794\n",
      "Epoch 36/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.0953 - mae: 7.0953 - val_loss: 6.9608 - val_mae: 6.9608\n",
      "Epoch 37/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.0394 - mae: 7.0394 - val_loss: 6.8277 - val_mae: 6.8277\n",
      "Epoch 38/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.0043 - mae: 7.0043 - val_loss: 6.7504 - val_mae: 6.7504\n",
      "Epoch 39/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.9517 - mae: 6.9517 - val_loss: 6.8106 - val_mae: 6.8106\n",
      "Epoch 40/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.9579 - mae: 6.9579 - val_loss: 6.7294 - val_mae: 6.7294\n",
      "Epoch 41/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.9771 - mae: 6.9771 - val_loss: 6.7326 - val_mae: 6.7326\n",
      "Epoch 42/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.9533 - mae: 6.9533 - val_loss: 6.7242 - val_mae: 6.7242\n",
      "Epoch 43/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.9066 - mae: 6.9066 - val_loss: 6.6731 - val_mae: 6.6731\n",
      "Epoch 44/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.8772 - mae: 6.8772 - val_loss: 6.7804 - val_mae: 6.7804\n",
      "Epoch 45/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.9407 - mae: 6.9407 - val_loss: 6.7969 - val_mae: 6.7969\n",
      "Epoch 46/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.8639 - mae: 6.8639 - val_loss: 6.7415 - val_mae: 6.7415\n",
      "Epoch 47/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.8775 - mae: 6.8775 - val_loss: 6.7840 - val_mae: 6.7840\n",
      "Epoch 48/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.9627 - mae: 6.9627 - val_loss: 7.1462 - val_mae: 7.1462\n",
      "Epoch 49/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.2700 - mae: 7.2700 - val_loss: 7.0687 - val_mae: 7.0687\n",
      "Epoch 50/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.1691 - mae: 7.1691 - val_loss: 7.0151 - val_mae: 7.0151\n",
      "Epoch 51/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.0787 - mae: 7.0787 - val_loss: 7.0457 - val_mae: 7.0457\n",
      "Epoch 52/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.0446 - mae: 7.0446 - val_loss: 6.9432 - val_mae: 6.9432\n",
      "Epoch 53/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.0355 - mae: 7.0355 - val_loss: 7.0238 - val_mae: 7.0238\n",
      "Epoch 54/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.0065 - mae: 7.0065 - val_loss: 6.8400 - val_mae: 6.8400\n",
      "Epoch 55/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.9366 - mae: 6.9366 - val_loss: 6.8016 - val_mae: 6.8016\n",
      "Epoch 56/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.9273 - mae: 6.9273 - val_loss: 6.8337 - val_mae: 6.8337\n"
     ]
    }
   ],
   "source": [
    "# dropout at both visible layer and hidden layer\n",
    "\n",
    "import tensorflow as tf\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 10, restore_best_weights = True)\n",
    "model_dp = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(30, 40)),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "\n",
    "model_dp.compile(optimizer='adam', \n",
    "              loss= 'mae',\n",
    "              metrics=['mae'])\n",
    "\n",
    "history = model_dp.fit(depth_train, theta_z_train, epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (depth_test, theta_z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "mpl.rcParams['figure.figsize'] = (20,5)\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(len(training_loss))\n",
    "\n",
    "# Visualize loss history\n",
    "mpl.rcParams['figure.figsize'] = (20,5)\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Angle (degree)')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prediction = model_dp.predict(depth_test)\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (20,5)\n",
    "plt.plot(theta_z_test)\n",
    "plt.plot(y_prediction,'--')\n",
    "plt.legend(['Ground Truth', 'Prediction'])\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Angle (degree)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.741460756272304"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(theta_z_test, y_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mulitple inputs in neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "depth_train, depth_test, force_train, force_test, theta_z_train, theta_z_test = train_test_split(depth, force, theta_z, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "input_depth = layers.Input(shape = (30, 40))\n",
    "input_force = layers.Input(shape = (6, ))\n",
    "\n",
    "# first branch\n",
    "x = layers.Flatten(input_shape=(30, 40))(input_depth)\n",
    "x = layers.Dense(units=128, activation='relu')(x)\n",
    "x = layers.Dense(units=64, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "x = tf.keras.Model(inputs= input_depth, outputs = x)\n",
    "\n",
    "# second branch\n",
    "y = layers.Dense(units=128, activation='relu')(input_force)\n",
    "y = layers.Dense(units=64, activation='relu')(y)\n",
    "y = layers.Dense(32, activation='relu')(y)\n",
    "y = layers.Dropout(0.2)(y)\n",
    "y = tf.keras.Model(inputs= input_force, outputs = y)\n",
    "\n",
    "# combine two branches\n",
    "combined = layers.concatenate([x.output, y.output])\n",
    "\n",
    "# regression to one output\n",
    "z = layers.Dense(units=32, activation='relu')(combined)\n",
    "z = layers.Dropout(0.2)(z)\n",
    "z = layers.Dense(units=16, activation='relu')(combined)\n",
    "z = layers.Dense(1, activation='linear')(z)\n",
    "model_fd = tf.keras.Model(inputs = [x.input, y.input], outputs = z)\n",
    "\n",
    "#tf.keras.utils.plot_model(model, to_file = 'model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.9915 - mae: 7.9915 - val_loss: 7.4197 - val_mae: 7.4197\n",
      "Epoch 2/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.0734 - mae: 7.0734 - val_loss: 6.7159 - val_mae: 6.7159\n",
      "Epoch 3/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.6195 - mae: 6.6195 - val_loss: 6.2822 - val_mae: 6.2822\n",
      "Epoch 4/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.2594 - mae: 6.2594 - val_loss: 5.9572 - val_mae: 5.9572\n",
      "Epoch 5/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.9354 - mae: 5.9354 - val_loss: 5.8057 - val_mae: 5.8057\n",
      "Epoch 6/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.7589 - mae: 5.7589 - val_loss: 5.5760 - val_mae: 5.5760\n",
      "Epoch 7/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.8777 - mae: 5.8777 - val_loss: 5.5381 - val_mae: 5.5381\n",
      "Epoch 8/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.5238 - mae: 5.5238 - val_loss: 5.3890 - val_mae: 5.3890\n",
      "Epoch 9/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.3870 - mae: 5.3870 - val_loss: 5.2848 - val_mae: 5.2848\n",
      "Epoch 10/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.2636 - mae: 5.2636 - val_loss: 5.1974 - val_mae: 5.1974\n",
      "Epoch 11/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.1647 - mae: 5.1647 - val_loss: 5.0916 - val_mae: 5.0916\n",
      "Epoch 12/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.0794 - mae: 5.0794 - val_loss: 4.9801 - val_mae: 4.9801\n",
      "Epoch 13/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.0109 - mae: 5.0109 - val_loss: 5.0125 - val_mae: 5.0125\n",
      "Epoch 14/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.9599 - mae: 4.9599 - val_loss: 4.8658 - val_mae: 4.8658\n",
      "Epoch 15/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.8670 - mae: 4.8670 - val_loss: 4.8688 - val_mae: 4.8688\n",
      "Epoch 16/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.7943 - mae: 4.7943 - val_loss: 4.7448 - val_mae: 4.7448\n",
      "Epoch 17/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.7413 - mae: 4.7413 - val_loss: 4.7310 - val_mae: 4.7310\n",
      "Epoch 18/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.6667 - mae: 4.6667 - val_loss: 4.7139 - val_mae: 4.7139\n",
      "Epoch 19/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.6399 - mae: 4.6399 - val_loss: 4.5426 - val_mae: 4.5426\n",
      "Epoch 20/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.5098 - mae: 4.5098 - val_loss: 4.4321 - val_mae: 4.4321\n",
      "Epoch 21/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.5462 - mae: 4.5462 - val_loss: 4.4545 - val_mae: 4.4545\n",
      "Epoch 22/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.4319 - mae: 4.4319 - val_loss: 4.3947 - val_mae: 4.3947\n",
      "Epoch 23/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.3519 - mae: 4.3519 - val_loss: 4.4633 - val_mae: 4.4633\n",
      "Epoch 24/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.3377 - mae: 4.3377 - val_loss: 4.3417 - val_mae: 4.3417\n",
      "Epoch 25/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.2778 - mae: 4.2778 - val_loss: 4.5207 - val_mae: 4.5207\n",
      "Epoch 26/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.2702 - mae: 4.2702 - val_loss: 4.4011 - val_mae: 4.4011\n",
      "Epoch 27/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.2291 - mae: 4.2291 - val_loss: 4.2030 - val_mae: 4.2030\n",
      "Epoch 28/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.2095 - mae: 4.2095 - val_loss: 4.2715 - val_mae: 4.2715\n",
      "Epoch 29/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.1457 - mae: 4.1457 - val_loss: 4.2940 - val_mae: 4.2940\n",
      "Epoch 30/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.1317 - mae: 4.1317 - val_loss: 4.1562 - val_mae: 4.1562\n",
      "Epoch 31/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.0888 - mae: 4.0888 - val_loss: 4.2134 - val_mae: 4.2134\n",
      "Epoch 32/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.1669 - mae: 4.1669 - val_loss: 4.1567 - val_mae: 4.1567\n",
      "Epoch 33/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.0277 - mae: 4.0277 - val_loss: 4.1335 - val_mae: 4.1335\n",
      "Epoch 34/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.0021 - mae: 4.0021 - val_loss: 4.2700 - val_mae: 4.2700\n",
      "Epoch 35/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.9861 - mae: 3.9861 - val_loss: 4.0391 - val_mae: 4.0391\n",
      "Epoch 36/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.9409 - mae: 3.9409 - val_loss: 4.0397 - val_mae: 4.0397\n",
      "Epoch 37/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.9160 - mae: 3.9160 - val_loss: 4.0043 - val_mae: 4.0043\n",
      "Epoch 38/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.8908 - mae: 3.8908 - val_loss: 4.0874 - val_mae: 4.0874\n",
      "Epoch 39/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.9076 - mae: 3.9076 - val_loss: 3.9568 - val_mae: 3.9568\n",
      "Epoch 40/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.8833 - mae: 3.8833 - val_loss: 3.9026 - val_mae: 3.9026\n",
      "Epoch 41/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.8372 - mae: 3.8372 - val_loss: 3.9771 - val_mae: 3.9771\n",
      "Epoch 42/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.8122 - mae: 3.8122 - val_loss: 3.9271 - val_mae: 3.9271\n",
      "Epoch 43/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7826 - mae: 3.7826 - val_loss: 3.9347 - val_mae: 3.9347\n",
      "Epoch 44/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7848 - mae: 3.7848 - val_loss: 3.8279 - val_mae: 3.8279\n",
      "Epoch 45/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.8497 - mae: 3.8497 - val_loss: 3.9976 - val_mae: 3.9976\n",
      "Epoch 46/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7729 - mae: 3.7729 - val_loss: 3.8711 - val_mae: 3.8711\n",
      "Epoch 47/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7300 - mae: 3.7300 - val_loss: 3.9491 - val_mae: 3.9491\n",
      "Epoch 48/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7067 - mae: 3.7067 - val_loss: 3.9039 - val_mae: 3.9039\n",
      "Epoch 49/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6985 - mae: 3.6985 - val_loss: 3.8383 - val_mae: 3.8383\n",
      "Epoch 50/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6906 - mae: 3.6906 - val_loss: 3.8821 - val_mae: 3.8821\n",
      "Epoch 51/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6609 - mae: 3.6609 - val_loss: 3.7568 - val_mae: 3.7568\n",
      "Epoch 52/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6638 - mae: 3.6638 - val_loss: 3.7495 - val_mae: 3.7495\n",
      "Epoch 53/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6264 - mae: 3.6264 - val_loss: 3.7496 - val_mae: 3.7496\n",
      "Epoch 54/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6030 - mae: 3.6030 - val_loss: 3.7968 - val_mae: 3.7968\n",
      "Epoch 55/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5947 - mae: 3.5947 - val_loss: 3.7537 - val_mae: 3.7537\n",
      "Epoch 56/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5724 - mae: 3.5724 - val_loss: 3.7126 - val_mae: 3.7126\n",
      "Epoch 57/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5767 - mae: 3.5767 - val_loss: 3.6274 - val_mae: 3.6274\n",
      "Epoch 58/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5431 - mae: 3.5431 - val_loss: 3.6690 - val_mae: 3.6690\n",
      "Epoch 59/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5541 - mae: 3.5541 - val_loss: 3.7380 - val_mae: 3.7380\n",
      "Epoch 60/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5190 - mae: 3.5190 - val_loss: 3.6116 - val_mae: 3.6116\n",
      "Epoch 61/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5252 - mae: 3.5252 - val_loss: 3.6501 - val_mae: 3.6501\n",
      "Epoch 62/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5076 - mae: 3.5076 - val_loss: 3.7794 - val_mae: 3.7794\n",
      "Epoch 63/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5455 - mae: 3.5455 - val_loss: 3.7348 - val_mae: 3.7348\n",
      "Epoch 64/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4914 - mae: 3.4914 - val_loss: 3.5966 - val_mae: 3.5966\n",
      "Epoch 65/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4571 - mae: 3.4571 - val_loss: 3.6084 - val_mae: 3.6084\n",
      "Epoch 66/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4849 - mae: 3.4849 - val_loss: 3.5507 - val_mae: 3.5507\n",
      "Epoch 67/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4342 - mae: 3.4342 - val_loss: 3.6348 - val_mae: 3.6348\n",
      "Epoch 68/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4576 - mae: 3.4576 - val_loss: 3.5551 - val_mae: 3.5551\n",
      "Epoch 69/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3991 - mae: 3.3991 - val_loss: 3.5850 - val_mae: 3.5850\n",
      "Epoch 70/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3939 - mae: 3.3939 - val_loss: 3.8240 - val_mae: 3.8240\n",
      "Epoch 71/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3903 - mae: 3.3903 - val_loss: 3.5877 - val_mae: 3.5877\n",
      "Epoch 72/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3822 - mae: 3.3822 - val_loss: 3.6606 - val_mae: 3.6606\n",
      "Epoch 73/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3629 - mae: 3.3629 - val_loss: 3.5865 - val_mae: 3.5865\n",
      "Epoch 74/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3619 - mae: 3.3619 - val_loss: 3.5703 - val_mae: 3.5703\n",
      "Epoch 75/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3839 - mae: 3.3839 - val_loss: 3.5872 - val_mae: 3.5872\n",
      "Epoch 76/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3510 - mae: 3.3510 - val_loss: 3.6720 - val_mae: 3.6720\n",
      "Epoch 77/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3507 - mae: 3.3507 - val_loss: 3.5011 - val_mae: 3.5011\n",
      "Epoch 78/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3489 - mae: 3.3489 - val_loss: 3.4901 - val_mae: 3.4901\n",
      "Epoch 79/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3810 - mae: 3.3810 - val_loss: 3.5595 - val_mae: 3.5595\n",
      "Epoch 80/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3177 - mae: 3.3177 - val_loss: 3.6414 - val_mae: 3.6414\n",
      "Epoch 81/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3125 - mae: 3.3125 - val_loss: 3.6009 - val_mae: 3.6009\n",
      "Epoch 82/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2910 - mae: 3.2910 - val_loss: 3.6569 - val_mae: 3.6569\n",
      "Epoch 83/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2960 - mae: 3.2960 - val_loss: 3.4500 - val_mae: 3.4500\n",
      "Epoch 84/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2623 - mae: 3.2623 - val_loss: 3.5225 - val_mae: 3.5225\n",
      "Epoch 85/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2844 - mae: 3.2844 - val_loss: 3.5636 - val_mae: 3.5636\n",
      "Epoch 86/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2688 - mae: 3.2688 - val_loss: 3.4651 - val_mae: 3.4651\n",
      "Epoch 87/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2406 - mae: 3.2406 - val_loss: 3.5124 - val_mae: 3.5124\n",
      "Epoch 88/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2504 - mae: 3.2504 - val_loss: 3.5858 - val_mae: 3.5858\n",
      "Epoch 89/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2244 - mae: 3.2244 - val_loss: 3.5362 - val_mae: 3.5362\n",
      "Epoch 90/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2463 - mae: 3.2463 - val_loss: 3.4689 - val_mae: 3.4689\n",
      "Epoch 91/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2390 - mae: 3.2390 - val_loss: 3.5307 - val_mae: 3.5307\n",
      "Epoch 92/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2002 - mae: 3.2002 - val_loss: 3.5026 - val_mae: 3.5026\n",
      "Epoch 93/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2604 - mae: 3.2604 - val_loss: 3.5078 - val_mae: 3.5078\n",
      "Epoch 94/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2097 - mae: 3.2097 - val_loss: 3.4219 - val_mae: 3.4219\n",
      "Epoch 95/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2047 - mae: 3.2047 - val_loss: 3.3475 - val_mae: 3.3475\n",
      "Epoch 96/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1845 - mae: 3.1845 - val_loss: 3.3844 - val_mae: 3.3844\n",
      "Epoch 97/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1872 - mae: 3.1872 - val_loss: 3.4548 - val_mae: 3.4548\n",
      "Epoch 98/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1559 - mae: 3.1559 - val_loss: 3.4245 - val_mae: 3.4245\n",
      "Epoch 99/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1333 - mae: 3.1333 - val_loss: 3.5338 - val_mae: 3.5338\n",
      "Epoch 100/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1551 - mae: 3.1551 - val_loss: 3.6055 - val_mae: 3.6055\n",
      "Epoch 101/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1588 - mae: 3.1588 - val_loss: 3.3486 - val_mae: 3.3486\n",
      "Epoch 102/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1492 - mae: 3.1492 - val_loss: 3.3480 - val_mae: 3.3480\n",
      "Epoch 103/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1377 - mae: 3.1377 - val_loss: 3.4386 - val_mae: 3.4386\n",
      "Epoch 104/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1127 - mae: 3.1127 - val_loss: 3.3836 - val_mae: 3.3836\n",
      "Epoch 105/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1512 - mae: 3.1512 - val_loss: 3.4543 - val_mae: 3.4543\n",
      "Epoch 106/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0981 - mae: 3.0981 - val_loss: 3.4584 - val_mae: 3.4584\n",
      "Epoch 107/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1312 - mae: 3.1312 - val_loss: 3.3808 - val_mae: 3.3808\n",
      "Epoch 108/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0905 - mae: 3.0905 - val_loss: 3.4109 - val_mae: 3.4109\n",
      "Epoch 109/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0874 - mae: 3.0874 - val_loss: 3.3772 - val_mae: 3.3772\n",
      "Epoch 110/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1085 - mae: 3.1085 - val_loss: 3.3486 - val_mae: 3.3486\n",
      "Epoch 111/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1125 - mae: 3.1125 - val_loss: 3.2884 - val_mae: 3.2884\n",
      "Epoch 112/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0863 - mae: 3.0863 - val_loss: 3.3745 - val_mae: 3.3745\n",
      "Epoch 113/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0845 - mae: 3.0845 - val_loss: 3.4327 - val_mae: 3.4327\n",
      "Epoch 114/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0647 - mae: 3.0647 - val_loss: 3.4042 - val_mae: 3.4042\n",
      "Epoch 115/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0663 - mae: 3.0663 - val_loss: 3.4056 - val_mae: 3.4056\n",
      "Epoch 116/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2512 - mae: 3.2512 - val_loss: 3.3025 - val_mae: 3.3025\n",
      "Epoch 117/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0548 - mae: 3.0548 - val_loss: 3.4096 - val_mae: 3.4096\n",
      "Epoch 118/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0522 - mae: 3.0522 - val_loss: 3.3301 - val_mae: 3.3301\n",
      "Epoch 119/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0334 - mae: 3.0334 - val_loss: 3.2123 - val_mae: 3.2123\n",
      "Epoch 120/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0270 - mae: 3.0270 - val_loss: 3.3840 - val_mae: 3.3840\n",
      "Epoch 121/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0110 - mae: 3.0110 - val_loss: 3.3388 - val_mae: 3.3388\n",
      "Epoch 122/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0175 - mae: 3.0175 - val_loss: 3.4263 - val_mae: 3.4263\n",
      "Epoch 123/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0198 - mae: 3.0198 - val_loss: 3.3976 - val_mae: 3.3976\n",
      "Epoch 124/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0240 - mae: 3.0240 - val_loss: 3.3834 - val_mae: 3.3834\n",
      "Epoch 125/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0082 - mae: 3.0082 - val_loss: 3.3199 - val_mae: 3.3199\n",
      "Epoch 126/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9976 - mae: 2.9976 - val_loss: 3.2136 - val_mae: 3.2136\n",
      "Epoch 127/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9901 - mae: 2.9901 - val_loss: 3.2041 - val_mae: 3.2041\n",
      "Epoch 128/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0053 - mae: 3.0053 - val_loss: 3.3023 - val_mae: 3.3023\n",
      "Epoch 129/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9934 - mae: 2.9934 - val_loss: 3.4826 - val_mae: 3.4826\n",
      "Epoch 130/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9761 - mae: 2.9761 - val_loss: 3.2621 - val_mae: 3.2621\n",
      "Epoch 131/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9960 - mae: 2.9960 - val_loss: 3.2984 - val_mae: 3.2984\n",
      "Epoch 132/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9898 - mae: 2.9898 - val_loss: 3.3021 - val_mae: 3.3021\n",
      "Epoch 133/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9743 - mae: 2.9743 - val_loss: 3.2148 - val_mae: 3.2148\n",
      "Epoch 134/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9678 - mae: 2.9678 - val_loss: 3.2566 - val_mae: 3.2566\n",
      "Epoch 135/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9715 - mae: 2.9715 - val_loss: 3.5706 - val_mae: 3.5706\n",
      "Epoch 136/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0467 - mae: 3.0467 - val_loss: 3.2771 - val_mae: 3.2771\n",
      "Epoch 137/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9255 - mae: 2.9255 - val_loss: 3.2455 - val_mae: 3.2455\n",
      "Epoch 138/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9540 - mae: 2.9540 - val_loss: 3.3813 - val_mae: 3.3813\n",
      "Epoch 139/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9468 - mae: 2.9468 - val_loss: 3.3181 - val_mae: 3.3181\n",
      "Epoch 140/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9021 - mae: 2.9021 - val_loss: 3.2560 - val_mae: 3.2560\n",
      "Epoch 141/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9175 - mae: 2.9175 - val_loss: 3.2005 - val_mae: 3.2005\n",
      "Epoch 142/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9365 - mae: 2.9365 - val_loss: 3.2740 - val_mae: 3.2740\n",
      "Epoch 143/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0045 - mae: 3.0045 - val_loss: 3.3154 - val_mae: 3.3154\n",
      "Epoch 144/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9304 - mae: 2.9304 - val_loss: 3.2888 - val_mae: 3.2888\n",
      "Epoch 145/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9276 - mae: 2.9276 - val_loss: 3.2568 - val_mae: 3.2568\n",
      "Epoch 146/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9287 - mae: 2.9287 - val_loss: 3.5300 - val_mae: 3.5300\n",
      "Epoch 147/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9025 - mae: 2.9025 - val_loss: 3.2471 - val_mae: 3.2471\n",
      "Epoch 148/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9090 - mae: 2.9090 - val_loss: 3.2060 - val_mae: 3.2060\n",
      "Epoch 149/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9139 - mae: 2.9139 - val_loss: 3.1670 - val_mae: 3.1670\n",
      "Epoch 150/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9042 - mae: 2.9042 - val_loss: 3.2796 - val_mae: 3.2796\n",
      "Epoch 151/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8708 - mae: 2.8708 - val_loss: 3.3701 - val_mae: 3.3701\n",
      "Epoch 152/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8952 - mae: 2.8952 - val_loss: 3.1935 - val_mae: 3.1935\n",
      "Epoch 153/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8467 - mae: 2.8467 - val_loss: 3.2340 - val_mae: 3.2340\n",
      "Epoch 154/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8827 - mae: 2.8827 - val_loss: 3.2608 - val_mae: 3.2608\n",
      "Epoch 155/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8752 - mae: 2.8752 - val_loss: 3.2255 - val_mae: 3.2255\n",
      "Epoch 156/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8612 - mae: 2.8612 - val_loss: 3.2640 - val_mae: 3.2640\n",
      "Epoch 157/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8476 - mae: 2.8476 - val_loss: 3.2746 - val_mae: 3.2746\n",
      "Epoch 158/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9064 - mae: 2.9064 - val_loss: 3.2012 - val_mae: 3.2012\n",
      "Epoch 159/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8512 - mae: 2.8512 - val_loss: 3.2997 - val_mae: 3.2997\n",
      "Epoch 160/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8439 - mae: 2.8439 - val_loss: 3.2353 - val_mae: 3.2353\n",
      "Epoch 161/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8359 - mae: 2.8359 - val_loss: 3.1742 - val_mae: 3.1742\n",
      "Epoch 162/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8383 - mae: 2.8383 - val_loss: 3.2194 - val_mae: 3.2194\n",
      "Epoch 163/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8580 - mae: 2.8580 - val_loss: 3.2735 - val_mae: 3.2735\n",
      "Epoch 164/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8245 - mae: 2.8245 - val_loss: 3.2707 - val_mae: 3.2707\n",
      "Epoch 165/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8211 - mae: 2.8211 - val_loss: 3.2715 - val_mae: 3.2715\n",
      "Epoch 166/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8394 - mae: 2.8394 - val_loss: 3.1780 - val_mae: 3.1780\n",
      "Epoch 167/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8499 - mae: 2.8499 - val_loss: 3.2048 - val_mae: 3.2048\n",
      "Epoch 168/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8539 - mae: 2.8539 - val_loss: 3.1932 - val_mae: 3.1932\n",
      "Epoch 169/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8299 - mae: 2.8299 - val_loss: 3.1458 - val_mae: 3.1458\n",
      "Epoch 170/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8189 - mae: 2.8189 - val_loss: 3.2405 - val_mae: 3.2405\n",
      "Epoch 171/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8346 - mae: 2.8346 - val_loss: 3.5133 - val_mae: 3.5133\n",
      "Epoch 172/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8150 - mae: 2.8150 - val_loss: 3.2423 - val_mae: 3.2423\n",
      "Epoch 173/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7979 - mae: 2.7979 - val_loss: 3.2063 - val_mae: 3.2063\n",
      "Epoch 174/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7835 - mae: 2.7835 - val_loss: 3.2180 - val_mae: 3.2180\n",
      "Epoch 175/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8056 - mae: 2.8056 - val_loss: 3.4193 - val_mae: 3.4193\n",
      "Epoch 176/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8300 - mae: 2.8300 - val_loss: 3.2636 - val_mae: 3.2636\n",
      "Epoch 177/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8002 - mae: 2.8002 - val_loss: 3.2395 - val_mae: 3.2395\n",
      "Epoch 178/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7949 - mae: 2.7949 - val_loss: 3.2850 - val_mae: 3.2850\n",
      "Epoch 179/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7959 - mae: 2.7959 - val_loss: 3.1202 - val_mae: 3.1202\n",
      "Epoch 180/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8053 - mae: 2.8053 - val_loss: 3.2460 - val_mae: 3.2460\n",
      "Epoch 181/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8027 - mae: 2.8027 - val_loss: 3.2572 - val_mae: 3.2572\n",
      "Epoch 182/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7720 - mae: 2.7720 - val_loss: 3.1633 - val_mae: 3.1633\n",
      "Epoch 183/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7865 - mae: 2.7865 - val_loss: 3.1603 - val_mae: 3.1603\n",
      "Epoch 184/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7779 - mae: 2.7779 - val_loss: 3.2544 - val_mae: 3.2544\n",
      "Epoch 185/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7832 - mae: 2.7832 - val_loss: 3.1992 - val_mae: 3.1992\n",
      "Epoch 186/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7523 - mae: 2.7523 - val_loss: 3.1601 - val_mae: 3.1601\n",
      "Epoch 187/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7469 - mae: 2.7469 - val_loss: 3.1526 - val_mae: 3.1526\n",
      "Epoch 188/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8594 - mae: 2.8594 - val_loss: 3.3638 - val_mae: 3.3638\n",
      "Epoch 189/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7644 - mae: 2.7644 - val_loss: 3.0862 - val_mae: 3.0862\n",
      "Epoch 190/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7449 - mae: 2.7449 - val_loss: 3.2601 - val_mae: 3.2601\n",
      "Epoch 191/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7492 - mae: 2.7492 - val_loss: 3.1872 - val_mae: 3.1872\n",
      "Epoch 192/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7314 - mae: 2.7314 - val_loss: 3.2233 - val_mae: 3.2233\n",
      "Epoch 193/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7676 - mae: 2.7676 - val_loss: 3.1189 - val_mae: 3.1189\n",
      "Epoch 194/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8103 - mae: 2.8103 - val_loss: 3.2068 - val_mae: 3.2068\n",
      "Epoch 195/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7771 - mae: 2.7771 - val_loss: 3.2641 - val_mae: 3.2641\n",
      "Epoch 196/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7574 - mae: 2.7574 - val_loss: 3.2638 - val_mae: 3.2638\n",
      "Epoch 197/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7305 - mae: 2.7305 - val_loss: 3.2933 - val_mae: 3.2933\n",
      "Epoch 198/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7419 - mae: 2.7419 - val_loss: 3.2944 - val_mae: 3.2944\n",
      "Epoch 199/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7831 - mae: 2.7831 - val_loss: 3.1348 - val_mae: 3.1348\n",
      "Epoch 200/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7360 - mae: 2.7360 - val_loss: 3.1226 - val_mae: 3.1226\n",
      "Epoch 201/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7841 - mae: 2.7841 - val_loss: 3.1258 - val_mae: 3.1258\n",
      "Epoch 202/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7607 - mae: 2.7607 - val_loss: 3.2110 - val_mae: 3.2110\n",
      "Epoch 203/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7416 - mae: 2.7416 - val_loss: 3.1709 - val_mae: 3.1709\n",
      "Epoch 204/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6991 - mae: 2.6991 - val_loss: 3.1323 - val_mae: 3.1323\n",
      "Epoch 205/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6866 - mae: 2.6866 - val_loss: 3.1813 - val_mae: 3.1813\n",
      "Epoch 206/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6850 - mae: 2.6850 - val_loss: 3.1574 - val_mae: 3.1574\n",
      "Epoch 207/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7002 - mae: 2.7002 - val_loss: 3.2503 - val_mae: 3.2503\n",
      "Epoch 208/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7080 - mae: 2.7080 - val_loss: 3.1248 - val_mae: 3.1248\n",
      "Epoch 209/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6935 - mae: 2.6935 - val_loss: 3.1541 - val_mae: 3.1541\n",
      "Epoch 210/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7419 - mae: 2.7419 - val_loss: 3.1553 - val_mae: 3.1553\n",
      "Epoch 211/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6882 - mae: 2.6882 - val_loss: 3.1787 - val_mae: 3.1787\n",
      "Epoch 212/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7076 - mae: 2.7076 - val_loss: 3.1781 - val_mae: 3.1781\n",
      "Epoch 213/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6911 - mae: 2.6911 - val_loss: 3.1806 - val_mae: 3.1806\n",
      "Epoch 214/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7360 - mae: 2.7360 - val_loss: 3.1000 - val_mae: 3.1000\n",
      "Epoch 215/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6803 - mae: 2.6803 - val_loss: 3.2392 - val_mae: 3.2392\n",
      "Epoch 216/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6791 - mae: 2.6791 - val_loss: 3.0587 - val_mae: 3.0587\n",
      "Epoch 217/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6760 - mae: 2.6760 - val_loss: 3.1123 - val_mae: 3.1123\n",
      "Epoch 218/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6901 - mae: 2.6901 - val_loss: 3.1356 - val_mae: 3.1356\n",
      "Epoch 219/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6801 - mae: 2.6801 - val_loss: 3.1197 - val_mae: 3.1197\n",
      "Epoch 220/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6555 - mae: 2.6555 - val_loss: 3.1612 - val_mae: 3.1612\n",
      "Epoch 221/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6967 - mae: 2.6967 - val_loss: 3.3994 - val_mae: 3.3994\n",
      "Epoch 222/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6737 - mae: 2.6737 - val_loss: 3.1590 - val_mae: 3.1590\n",
      "Epoch 223/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6474 - mae: 2.6474 - val_loss: 3.0704 - val_mae: 3.0704\n",
      "Epoch 224/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6573 - mae: 2.6573 - val_loss: 3.0766 - val_mae: 3.0766\n",
      "Epoch 225/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6994 - mae: 2.6994 - val_loss: 3.2533 - val_mae: 3.2533\n",
      "Epoch 226/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6932 - mae: 2.6932 - val_loss: 3.1415 - val_mae: 3.1415\n",
      "Epoch 227/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6765 - mae: 2.6765 - val_loss: 3.0540 - val_mae: 3.0540\n",
      "Epoch 228/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6265 - mae: 2.6265 - val_loss: 3.1397 - val_mae: 3.1397\n",
      "Epoch 229/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6468 - mae: 2.6468 - val_loss: 3.1126 - val_mae: 3.1126\n",
      "Epoch 230/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6408 - mae: 2.6408 - val_loss: 3.1480 - val_mae: 3.1480\n",
      "Epoch 231/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6275 - mae: 2.6275 - val_loss: 3.1220 - val_mae: 3.1220\n",
      "Epoch 232/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6636 - mae: 2.6636 - val_loss: 3.1693 - val_mae: 3.1693\n",
      "Epoch 233/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6499 - mae: 2.6499 - val_loss: 3.1872 - val_mae: 3.1872\n",
      "Epoch 234/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6199 - mae: 2.6199 - val_loss: 3.0446 - val_mae: 3.0446\n",
      "Epoch 235/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6366 - mae: 2.6366 - val_loss: 3.1095 - val_mae: 3.1095\n",
      "Epoch 236/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6446 - mae: 2.6446 - val_loss: 3.0823 - val_mae: 3.0823\n",
      "Epoch 237/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6341 - mae: 2.6341 - val_loss: 3.0879 - val_mae: 3.0879\n",
      "Epoch 238/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6434 - mae: 2.6434 - val_loss: 3.0500 - val_mae: 3.0500\n",
      "Epoch 239/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6273 - mae: 2.6273 - val_loss: 3.1381 - val_mae: 3.1381\n",
      "Epoch 240/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6395 - mae: 2.6395 - val_loss: 3.0409 - val_mae: 3.0409\n",
      "Epoch 241/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6108 - mae: 2.6108 - val_loss: 3.1353 - val_mae: 3.1353\n",
      "Epoch 242/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6260 - mae: 2.6260 - val_loss: 3.1377 - val_mae: 3.1377\n",
      "Epoch 243/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6278 - mae: 2.6278 - val_loss: 3.0890 - val_mae: 3.0890\n",
      "Epoch 244/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5966 - mae: 2.5966 - val_loss: 3.0980 - val_mae: 3.0980\n",
      "Epoch 245/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6029 - mae: 2.6029 - val_loss: 3.2405 - val_mae: 3.2405\n",
      "Epoch 246/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5965 - mae: 2.5965 - val_loss: 3.1152 - val_mae: 3.1152\n",
      "Epoch 247/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5982 - mae: 2.5982 - val_loss: 3.1445 - val_mae: 3.1445\n",
      "Epoch 248/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6171 - mae: 2.6171 - val_loss: 3.0882 - val_mae: 3.0882\n",
      "Epoch 249/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6086 - mae: 2.6086 - val_loss: 3.0402 - val_mae: 3.0402\n",
      "Epoch 250/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6010 - mae: 2.6010 - val_loss: 3.1311 - val_mae: 3.1311\n",
      "Epoch 251/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6032 - mae: 2.6032 - val_loss: 3.0049 - val_mae: 3.0049\n",
      "Epoch 252/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5599 - mae: 2.5599 - val_loss: 3.1028 - val_mae: 3.1028\n",
      "Epoch 253/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6279 - mae: 2.6279 - val_loss: 3.1482 - val_mae: 3.1482\n",
      "Epoch 254/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5690 - mae: 2.5690 - val_loss: 3.0622 - val_mae: 3.0622\n",
      "Epoch 255/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5930 - mae: 2.5930 - val_loss: 3.1687 - val_mae: 3.1687\n",
      "Epoch 256/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6192 - mae: 2.6192 - val_loss: 3.0925 - val_mae: 3.0925\n",
      "Epoch 257/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5698 - mae: 2.5698 - val_loss: 3.1658 - val_mae: 3.1658\n",
      "Epoch 258/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5833 - mae: 2.5833 - val_loss: 3.1745 - val_mae: 3.1745\n",
      "Epoch 259/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5671 - mae: 2.5671 - val_loss: 3.0248 - val_mae: 3.0248\n",
      "Epoch 260/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6035 - mae: 2.6035 - val_loss: 3.1637 - val_mae: 3.1637\n",
      "Epoch 261/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6098 - mae: 2.6098 - val_loss: 3.0590 - val_mae: 3.0590\n",
      "Epoch 262/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5683 - mae: 2.5683 - val_loss: 2.9797 - val_mae: 2.9797\n",
      "Epoch 263/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5764 - mae: 2.5764 - val_loss: 3.0620 - val_mae: 3.0620\n",
      "Epoch 264/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5880 - mae: 2.5880 - val_loss: 3.1309 - val_mae: 3.1309\n",
      "Epoch 265/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5400 - mae: 2.5400 - val_loss: 3.0387 - val_mae: 3.0387\n",
      "Epoch 266/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5793 - mae: 2.5793 - val_loss: 3.0943 - val_mae: 3.0943\n",
      "Epoch 267/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5651 - mae: 2.5651 - val_loss: 3.0944 - val_mae: 3.0944\n",
      "Epoch 268/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5430 - mae: 2.5430 - val_loss: 3.0324 - val_mae: 3.0324\n",
      "Epoch 269/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6077 - mae: 2.6077 - val_loss: 2.9961 - val_mae: 2.9961\n",
      "Epoch 270/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5774 - mae: 2.5774 - val_loss: 3.1223 - val_mae: 3.1223\n",
      "Epoch 271/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5403 - mae: 2.5403 - val_loss: 3.0846 - val_mae: 3.0846\n",
      "Epoch 272/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5980 - mae: 2.5980 - val_loss: 3.0818 - val_mae: 3.0818\n",
      "Epoch 273/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5706 - mae: 2.5706 - val_loss: 3.2927 - val_mae: 3.2927\n",
      "Epoch 274/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6078 - mae: 2.6078 - val_loss: 3.0744 - val_mae: 3.0744\n",
      "Epoch 275/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5556 - mae: 2.5556 - val_loss: 2.9850 - val_mae: 2.9850\n",
      "Epoch 276/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5828 - mae: 2.5828 - val_loss: 3.0411 - val_mae: 3.0411\n",
      "Epoch 277/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5479 - mae: 2.5479 - val_loss: 3.1156 - val_mae: 3.1156\n",
      "Epoch 278/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5379 - mae: 2.5379 - val_loss: 3.0997 - val_mae: 3.0997\n",
      "Epoch 279/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5502 - mae: 2.5502 - val_loss: 3.0780 - val_mae: 3.0780\n",
      "Epoch 280/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5246 - mae: 2.5246 - val_loss: 3.1415 - val_mae: 3.1415\n",
      "Epoch 281/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5188 - mae: 2.5188 - val_loss: 3.0558 - val_mae: 3.0558\n",
      "Epoch 282/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5362 - mae: 2.5362 - val_loss: 3.1080 - val_mae: 3.1080\n",
      "Epoch 283/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5183 - mae: 2.5183 - val_loss: 3.1040 - val_mae: 3.1040\n",
      "Epoch 284/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5142 - mae: 2.5142 - val_loss: 3.0289 - val_mae: 3.0289\n",
      "Epoch 285/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5085 - mae: 2.5085 - val_loss: 3.0495 - val_mae: 3.0495\n",
      "Epoch 286/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5138 - mae: 2.5138 - val_loss: 3.2391 - val_mae: 3.2391\n",
      "Epoch 287/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5488 - mae: 2.5488 - val_loss: 2.9675 - val_mae: 2.9675\n",
      "Epoch 288/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5244 - mae: 2.5244 - val_loss: 3.0447 - val_mae: 3.0447\n",
      "Epoch 289/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5375 - mae: 2.5375 - val_loss: 3.1396 - val_mae: 3.1396\n",
      "Epoch 290/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5437 - mae: 2.5437 - val_loss: 3.0692 - val_mae: 3.0692\n",
      "Epoch 291/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5012 - mae: 2.5012 - val_loss: 3.1421 - val_mae: 3.1421\n",
      "Epoch 292/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5153 - mae: 2.5153 - val_loss: 3.0608 - val_mae: 3.0608\n",
      "Epoch 293/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5135 - mae: 2.5135 - val_loss: 3.0940 - val_mae: 3.0940\n",
      "Epoch 294/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5289 - mae: 2.5289 - val_loss: 3.0234 - val_mae: 3.0234\n",
      "Epoch 295/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5950 - mae: 2.5950 - val_loss: 3.0470 - val_mae: 3.0470\n",
      "Epoch 296/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5288 - mae: 2.5288 - val_loss: 3.0353 - val_mae: 3.0353\n",
      "Epoch 297/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5010 - mae: 2.5010 - val_loss: 2.9790 - val_mae: 2.9790\n",
      "Epoch 298/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5156 - mae: 2.5156 - val_loss: 3.0732 - val_mae: 3.0732\n",
      "Epoch 299/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4793 - mae: 2.4793 - val_loss: 3.1273 - val_mae: 3.1273\n",
      "Epoch 300/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6161 - mae: 2.6161 - val_loss: 3.1044 - val_mae: 3.1044\n"
     ]
    }
   ],
   "source": [
    "model_fd.compile(optimizer='adam', loss= 'mae', metrics=['mae'])\n",
    "\n",
    "history = model_fd.fit([depth_train, force_train],theta_z_train, verbose = 1, epochs = 300, batch_size = 128,\n",
    "                   validation_data = ([depth_test, force_test], theta_z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(len(training_loss))\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model_fd.predict([depth_test, force_test])\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (10,7)\n",
    "mpl.rc('xtick', labelsize=18) \n",
    "mpl.rc('ytick', labelsize=18)\n",
    "plt.plot(theta_z_test)\n",
    "plt.plot(y_prediction,'--')\n",
    "plt.xlim([4900, 5200])\n",
    "plt.ylim([-110, 110])\n",
    "plt.legend(['Ground Truth', 'Prediction'])\n",
    "plt.xlabel('Sample', fontsize=18)\n",
    "plt.ylabel('Angle (degree)', fontsize=18)\n",
    "plt.show()\n",
    "plt.savefig('ground_v_prediction_zoomed in.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (15,10)\n",
    "ax1 = plt.subplot(211)\n",
    "ax1.plot(theta_z_test)\n",
    "ax1.plot(y_prediction,'--')\n",
    "plt.legend(['Ground Truth', 'Prediction'])\n",
    "plt.ylabel('Angle (degree)')\n",
    "\n",
    "ax2 = plt.subplot(212)\n",
    "ax2.plot(theta_z_test)\n",
    "ax2.plot(y_prediction,'--')\n",
    "ax2.set_xlim([4900, 5200])\n",
    "plt.legend(['Ground Truth', 'Prediction'])\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Angle (degree)')\n",
    "plt.show()\n",
    "plt.savefig('ground_v_prediction.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.104436460064926"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(theta_z_test, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_prediction, theta_z_test)\n",
    "plt.xlabel('Prediction angle')\n",
    "plt.ylabel('Ground angle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed only force data to the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "515/515 [==============================] - 0s 885us/step - loss: 8.8208 - mae: 8.8208 - val_loss: 7.7199 - val_mae: 7.7199\n",
      "Epoch 2/300\n",
      "515/515 [==============================] - 0s 776us/step - loss: 7.7106 - mae: 7.7106 - val_loss: 7.4109 - val_mae: 7.4109\n",
      "Epoch 3/300\n",
      "515/515 [==============================] - 0s 756us/step - loss: 7.4826 - mae: 7.4826 - val_loss: 7.3380 - val_mae: 7.3380\n",
      "Epoch 4/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 7.4321 - mae: 7.4321 - val_loss: 7.3043 - val_mae: 7.3043\n",
      "Epoch 5/300\n",
      "515/515 [==============================] - 0s 777us/step - loss: 7.3942 - mae: 7.3942 - val_loss: 7.3428 - val_mae: 7.3428\n",
      "Epoch 6/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 7.3432 - mae: 7.3432 - val_loss: 7.3509 - val_mae: 7.3509\n",
      "Epoch 7/300\n",
      "515/515 [==============================] - 0s 776us/step - loss: 7.3434 - mae: 7.3434 - val_loss: 7.2937 - val_mae: 7.2937\n",
      "Epoch 8/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 7.3233 - mae: 7.3233 - val_loss: 7.2345 - val_mae: 7.2345\n",
      "Epoch 9/300\n",
      "515/515 [==============================] - 0s 779us/step - loss: 7.3155 - mae: 7.3155 - val_loss: 7.2632 - val_mae: 7.2632\n",
      "Epoch 10/300\n",
      "515/515 [==============================] - 0s 758us/step - loss: 7.2846 - mae: 7.2846 - val_loss: 7.2570 - val_mae: 7.2570\n",
      "Epoch 11/300\n",
      "515/515 [==============================] - 0s 756us/step - loss: 7.2688 - mae: 7.2688 - val_loss: 7.2366 - val_mae: 7.2366\n",
      "Epoch 12/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 7.2590 - mae: 7.2590 - val_loss: 7.2549 - val_mae: 7.2549\n",
      "Epoch 13/300\n",
      "515/515 [==============================] - 0s 765us/step - loss: 7.2477 - mae: 7.2477 - val_loss: 7.1858 - val_mae: 7.1858\n",
      "Epoch 14/300\n",
      "515/515 [==============================] - 0s 785us/step - loss: 7.2345 - mae: 7.2345 - val_loss: 7.1863 - val_mae: 7.1863\n",
      "Epoch 15/300\n",
      "515/515 [==============================] - 0s 766us/step - loss: 7.2395 - mae: 7.2395 - val_loss: 7.2067 - val_mae: 7.2067\n",
      "Epoch 16/300\n",
      "515/515 [==============================] - 0s 781us/step - loss: 7.2257 - mae: 7.2257 - val_loss: 7.1695 - val_mae: 7.1695\n",
      "Epoch 17/300\n",
      "515/515 [==============================] - 1s 976us/step - loss: 7.2063 - mae: 7.2063 - val_loss: 7.2839 - val_mae: 7.2839\n",
      "Epoch 18/300\n",
      "515/515 [==============================] - 0s 821us/step - loss: 7.2020 - mae: 7.2020 - val_loss: 7.2210 - val_mae: 7.2210\n",
      "Epoch 19/300\n",
      "515/515 [==============================] - 0s 954us/step - loss: 7.1763 - mae: 7.1763 - val_loss: 7.1749 - val_mae: 7.1749\n",
      "Epoch 20/300\n",
      "515/515 [==============================] - 0s 833us/step - loss: 7.2062 - mae: 7.2062 - val_loss: 7.1796 - val_mae: 7.1796\n",
      "Epoch 21/300\n",
      "515/515 [==============================] - 0s 901us/step - loss: 7.1872 - mae: 7.1872 - val_loss: 7.2120 - val_mae: 7.2120\n",
      "Epoch 22/300\n",
      "515/515 [==============================] - 0s 854us/step - loss: 7.1743 - mae: 7.1743 - val_loss: 7.1468 - val_mae: 7.1468\n",
      "Epoch 23/300\n",
      "515/515 [==============================] - 0s 869us/step - loss: 7.1710 - mae: 7.1710 - val_loss: 7.1385 - val_mae: 7.1385\n",
      "Epoch 24/300\n",
      "515/515 [==============================] - 0s 780us/step - loss: 7.1574 - mae: 7.1574 - val_loss: 7.1619 - val_mae: 7.1619\n",
      "Epoch 25/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 7.1572 - mae: 7.1572 - val_loss: 7.1413 - val_mae: 7.1413\n",
      "Epoch 26/300\n",
      "515/515 [==============================] - 0s 763us/step - loss: 7.1482 - mae: 7.1482 - val_loss: 7.1361 - val_mae: 7.1361\n",
      "Epoch 27/300\n",
      "515/515 [==============================] - 0s 766us/step - loss: 7.1502 - mae: 7.1502 - val_loss: 7.1175 - val_mae: 7.1175\n",
      "Epoch 28/300\n",
      "515/515 [==============================] - 0s 771us/step - loss: 7.1346 - mae: 7.1346 - val_loss: 7.1580 - val_mae: 7.1580\n",
      "Epoch 29/300\n",
      "515/515 [==============================] - 0s 777us/step - loss: 7.1487 - mae: 7.1487 - val_loss: 7.1241 - val_mae: 7.1241\n",
      "Epoch 30/300\n",
      "515/515 [==============================] - 0s 765us/step - loss: 7.1402 - mae: 7.1402 - val_loss: 7.1383 - val_mae: 7.1383\n",
      "Epoch 31/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 7.1365 - mae: 7.1365 - val_loss: 7.1228 - val_mae: 7.1228\n",
      "Epoch 32/300\n",
      "515/515 [==============================] - 0s 767us/step - loss: 7.1360 - mae: 7.1360 - val_loss: 7.1790 - val_mae: 7.1790\n",
      "Epoch 33/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 7.1178 - mae: 7.1178 - val_loss: 7.1413 - val_mae: 7.1413\n",
      "Epoch 34/300\n",
      "515/515 [==============================] - 0s 765us/step - loss: 7.1181 - mae: 7.1181 - val_loss: 7.1065 - val_mae: 7.1065\n",
      "Epoch 35/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 7.1285 - mae: 7.1285 - val_loss: 7.1562 - val_mae: 7.1562\n",
      "Epoch 36/300\n",
      "515/515 [==============================] - 0s 782us/step - loss: 7.1216 - mae: 7.1216 - val_loss: 7.0986 - val_mae: 7.0986\n",
      "Epoch 37/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 7.1204 - mae: 7.1204 - val_loss: 7.1729 - val_mae: 7.1729\n",
      "Epoch 38/300\n",
      "515/515 [==============================] - 0s 766us/step - loss: 7.1217 - mae: 7.1217 - val_loss: 7.1429 - val_mae: 7.1429\n",
      "Epoch 39/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 7.1235 - mae: 7.1235 - val_loss: 7.1207 - val_mae: 7.1207\n",
      "Epoch 40/300\n",
      "515/515 [==============================] - 0s 779us/step - loss: 7.1051 - mae: 7.1051 - val_loss: 7.1089 - val_mae: 7.1089\n",
      "Epoch 41/300\n",
      "515/515 [==============================] - 0s 783us/step - loss: 7.0988 - mae: 7.0988 - val_loss: 7.1406 - val_mae: 7.1406\n",
      "Epoch 42/300\n",
      "515/515 [==============================] - 0s 945us/step - loss: 7.0982 - mae: 7.0982 - val_loss: 7.1209 - val_mae: 7.1209\n",
      "Epoch 43/300\n",
      "515/515 [==============================] - 0s 817us/step - loss: 7.0989 - mae: 7.0989 - val_loss: 7.1123 - val_mae: 7.1123\n",
      "Epoch 44/300\n",
      "515/515 [==============================] - 0s 826us/step - loss: 7.1065 - mae: 7.1065 - val_loss: 7.0945 - val_mae: 7.0945\n",
      "Epoch 45/300\n",
      "515/515 [==============================] - 0s 833us/step - loss: 7.1007 - mae: 7.1007 - val_loss: 7.0923 - val_mae: 7.0923\n",
      "Epoch 46/300\n",
      "515/515 [==============================] - 0s 830us/step - loss: 7.0958 - mae: 7.0958 - val_loss: 7.0799 - val_mae: 7.0799\n",
      "Epoch 47/300\n",
      "515/515 [==============================] - 0s 848us/step - loss: 7.0886 - mae: 7.0886 - val_loss: 7.0823 - val_mae: 7.0823\n",
      "Epoch 48/300\n",
      "515/515 [==============================] - 0s 828us/step - loss: 7.0974 - mae: 7.0974 - val_loss: 7.1353 - val_mae: 7.1353\n",
      "Epoch 49/300\n",
      "515/515 [==============================] - 0s 775us/step - loss: 7.0977 - mae: 7.0977 - val_loss: 7.0834 - val_mae: 7.0834\n",
      "Epoch 50/300\n",
      "515/515 [==============================] - 0s 788us/step - loss: 7.0884 - mae: 7.0884 - val_loss: 7.1302 - val_mae: 7.1302\n",
      "Epoch 51/300\n",
      "515/515 [==============================] - 0s 770us/step - loss: 7.0768 - mae: 7.0768 - val_loss: 7.1463 - val_mae: 7.1463\n",
      "Epoch 52/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 7.0702 - mae: 7.0702 - val_loss: 7.0957 - val_mae: 7.0957\n",
      "Epoch 53/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 7.0820 - mae: 7.0820 - val_loss: 7.0786 - val_mae: 7.0786\n",
      "Epoch 54/300\n",
      "515/515 [==============================] - 0s 776us/step - loss: 7.0784 - mae: 7.0784 - val_loss: 7.0534 - val_mae: 7.0534\n",
      "Epoch 55/300\n",
      "515/515 [==============================] - 0s 833us/step - loss: 7.0786 - mae: 7.0786 - val_loss: 7.1280 - val_mae: 7.1280\n",
      "Epoch 56/300\n",
      "515/515 [==============================] - 0s 763us/step - loss: 7.0711 - mae: 7.0711 - val_loss: 7.1152 - val_mae: 7.1152\n",
      "Epoch 57/300\n",
      "515/515 [==============================] - 0s 764us/step - loss: 7.0678 - mae: 7.0678 - val_loss: 7.0806 - val_mae: 7.0806\n",
      "Epoch 58/300\n",
      "515/515 [==============================] - 0s 776us/step - loss: 7.0647 - mae: 7.0647 - val_loss: 7.0806 - val_mae: 7.0806\n",
      "Epoch 59/300\n",
      "515/515 [==============================] - 0s 805us/step - loss: 7.0728 - mae: 7.0728 - val_loss: 7.1288 - val_mae: 7.1288\n",
      "Epoch 60/300\n",
      "515/515 [==============================] - 0s 848us/step - loss: 7.0700 - mae: 7.0700 - val_loss: 7.1319 - val_mae: 7.1319\n",
      "Epoch 61/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 7.0576 - mae: 7.0576 - val_loss: 7.1217 - val_mae: 7.1217\n",
      "Epoch 62/300\n",
      "515/515 [==============================] - 0s 775us/step - loss: 7.0655 - mae: 7.0655 - val_loss: 7.0519 - val_mae: 7.0519\n",
      "Epoch 63/300\n",
      "515/515 [==============================] - 0s 831us/step - loss: 7.0669 - mae: 7.0669 - val_loss: 7.1556 - val_mae: 7.1556\n",
      "Epoch 64/300\n",
      "515/515 [==============================] - 0s 824us/step - loss: 7.0605 - mae: 7.0605 - val_loss: 7.0684 - val_mae: 7.0684\n",
      "Epoch 65/300\n",
      "515/515 [==============================] - 0s 851us/step - loss: 7.0611 - mae: 7.0611 - val_loss: 7.0370 - val_mae: 7.0370\n",
      "Epoch 66/300\n",
      "515/515 [==============================] - 0s 844us/step - loss: 7.0613 - mae: 7.0613 - val_loss: 7.0917 - val_mae: 7.0917\n",
      "Epoch 67/300\n",
      "515/515 [==============================] - 0s 879us/step - loss: 7.0708 - mae: 7.0708 - val_loss: 7.0297 - val_mae: 7.0297\n",
      "Epoch 68/300\n",
      "515/515 [==============================] - 0s 816us/step - loss: 7.0532 - mae: 7.0532 - val_loss: 7.0806 - val_mae: 7.0806\n",
      "Epoch 69/300\n",
      "515/515 [==============================] - 0s 848us/step - loss: 7.0577 - mae: 7.0577 - val_loss: 7.0628 - val_mae: 7.0628\n",
      "Epoch 70/300\n",
      "515/515 [==============================] - 0s 824us/step - loss: 7.0416 - mae: 7.0416 - val_loss: 7.0634 - val_mae: 7.0634\n",
      "Epoch 71/300\n",
      "515/515 [==============================] - 0s 813us/step - loss: 7.0507 - mae: 7.0507 - val_loss: 7.0557 - val_mae: 7.0557\n",
      "Epoch 72/300\n",
      "515/515 [==============================] - 0s 810us/step - loss: 7.0412 - mae: 7.0412 - val_loss: 7.0676 - val_mae: 7.0676\n",
      "Epoch 73/300\n",
      "515/515 [==============================] - 0s 819us/step - loss: 7.0447 - mae: 7.0447 - val_loss: 7.0713 - val_mae: 7.0713\n",
      "Epoch 74/300\n",
      "515/515 [==============================] - 0s 820us/step - loss: 7.0500 - mae: 7.0500 - val_loss: 7.0209 - val_mae: 7.0209\n",
      "Epoch 75/300\n",
      "515/515 [==============================] - 0s 788us/step - loss: 7.0426 - mae: 7.0426 - val_loss: 7.0453 - val_mae: 7.0453\n",
      "Epoch 76/300\n",
      "515/515 [==============================] - 0s 775us/step - loss: 7.0530 - mae: 7.0530 - val_loss: 7.0530 - val_mae: 7.0530\n",
      "Epoch 77/300\n",
      "515/515 [==============================] - 0s 764us/step - loss: 7.0314 - mae: 7.0314 - val_loss: 7.0610 - val_mae: 7.0610\n",
      "Epoch 78/300\n",
      "515/515 [==============================] - 0s 765us/step - loss: 7.0409 - mae: 7.0409 - val_loss: 7.0800 - val_mae: 7.0800\n",
      "Epoch 79/300\n",
      "515/515 [==============================] - 0s 803us/step - loss: 7.0444 - mae: 7.0444 - val_loss: 7.0594 - val_mae: 7.0594\n",
      "Epoch 80/300\n",
      "515/515 [==============================] - 0s 792us/step - loss: 7.0377 - mae: 7.0377 - val_loss: 7.0536 - val_mae: 7.0536\n",
      "Epoch 81/300\n",
      "515/515 [==============================] - 0s 779us/step - loss: 7.0443 - mae: 7.0443 - val_loss: 7.0822 - val_mae: 7.0822\n",
      "Epoch 82/300\n",
      "515/515 [==============================] - 0s 802us/step - loss: 7.0433 - mae: 7.0433 - val_loss: 7.1693 - val_mae: 7.1693\n",
      "Epoch 83/300\n",
      "515/515 [==============================] - 0s 785us/step - loss: 7.0377 - mae: 7.0377 - val_loss: 7.0633 - val_mae: 7.0633\n",
      "Epoch 84/300\n",
      "515/515 [==============================] - 0s 779us/step - loss: 7.0277 - mae: 7.0277 - val_loss: 7.0221 - val_mae: 7.0221\n",
      "Epoch 85/300\n",
      "515/515 [==============================] - 0s 803us/step - loss: 7.0246 - mae: 7.0246 - val_loss: 7.0328 - val_mae: 7.0328\n",
      "Epoch 86/300\n",
      "515/515 [==============================] - 0s 802us/step - loss: 7.0321 - mae: 7.0321 - val_loss: 7.1270 - val_mae: 7.1270\n",
      "Epoch 87/300\n",
      "515/515 [==============================] - 0s 759us/step - loss: 7.0373 - mae: 7.0373 - val_loss: 7.0285 - val_mae: 7.0285\n",
      "Epoch 88/300\n",
      "515/515 [==============================] - 0s 765us/step - loss: 7.0182 - mae: 7.0182 - val_loss: 7.0349 - val_mae: 7.0349\n",
      "Epoch 89/300\n",
      "515/515 [==============================] - 0s 802us/step - loss: 7.0217 - mae: 7.0217 - val_loss: 7.0089 - val_mae: 7.0089\n",
      "Epoch 90/300\n",
      "515/515 [==============================] - 0s 837us/step - loss: 7.0298 - mae: 7.0298 - val_loss: 7.0665 - val_mae: 7.0665\n",
      "Epoch 91/300\n",
      "515/515 [==============================] - 0s 912us/step - loss: 7.0283 - mae: 7.0283 - val_loss: 7.0599 - val_mae: 7.0599\n",
      "Epoch 92/300\n",
      "515/515 [==============================] - 0s 956us/step - loss: 7.0143 - mae: 7.0143 - val_loss: 7.0289 - val_mae: 7.0289\n",
      "Epoch 93/300\n",
      "515/515 [==============================] - 0s 913us/step - loss: 7.0195 - mae: 7.0195 - val_loss: 7.0204 - val_mae: 7.0204\n",
      "Epoch 94/300\n",
      "515/515 [==============================] - 0s 870us/step - loss: 7.0206 - mae: 7.0206 - val_loss: 7.0043 - val_mae: 7.0043\n",
      "Epoch 95/300\n",
      "515/515 [==============================] - 0s 918us/step - loss: 7.0251 - mae: 7.0251 - val_loss: 7.0069 - val_mae: 7.0069\n",
      "Epoch 96/300\n",
      "515/515 [==============================] - 0s 850us/step - loss: 7.0024 - mae: 7.0024 - val_loss: 7.0417 - val_mae: 7.0417\n",
      "Epoch 97/300\n",
      "515/515 [==============================] - 0s 811us/step - loss: 7.0183 - mae: 7.0183 - val_loss: 7.0967 - val_mae: 7.0967\n",
      "Epoch 98/300\n",
      "515/515 [==============================] - 0s 856us/step - loss: 7.0269 - mae: 7.0269 - val_loss: 7.0163 - val_mae: 7.0163\n",
      "Epoch 99/300\n",
      "515/515 [==============================] - 0s 797us/step - loss: 7.0151 - mae: 7.0151 - val_loss: 7.0679 - val_mae: 7.0679\n",
      "Epoch 100/300\n",
      "515/515 [==============================] - 0s 789us/step - loss: 7.0200 - mae: 7.0200 - val_loss: 6.9914 - val_mae: 6.9914\n",
      "Epoch 101/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 7.0156 - mae: 7.0156 - val_loss: 6.9874 - val_mae: 6.9874\n",
      "Epoch 102/300\n",
      "515/515 [==============================] - 0s 779us/step - loss: 7.0099 - mae: 7.0099 - val_loss: 7.0094 - val_mae: 7.0094\n",
      "Epoch 103/300\n",
      "515/515 [==============================] - 0s 767us/step - loss: 7.0266 - mae: 7.0266 - val_loss: 7.0162 - val_mae: 7.0162\n",
      "Epoch 104/300\n",
      "515/515 [==============================] - 0s 763us/step - loss: 7.0092 - mae: 7.0092 - val_loss: 7.0335 - val_mae: 7.0335\n",
      "Epoch 105/300\n",
      "515/515 [==============================] - 0s 795us/step - loss: 7.0098 - mae: 7.0098 - val_loss: 7.0669 - val_mae: 7.0669\n",
      "Epoch 106/300\n",
      "515/515 [==============================] - 0s 765us/step - loss: 7.0014 - mae: 7.0014 - val_loss: 7.0355 - val_mae: 7.0355\n",
      "Epoch 107/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 7.0205 - mae: 7.0205 - val_loss: 7.0262 - val_mae: 7.0262\n",
      "Epoch 108/300\n",
      "515/515 [==============================] - 0s 781us/step - loss: 7.0130 - mae: 7.0130 - val_loss: 6.9894 - val_mae: 6.9894\n",
      "Epoch 109/300\n",
      "515/515 [==============================] - 0s 797us/step - loss: 7.0046 - mae: 7.0046 - val_loss: 6.9999 - val_mae: 6.9999\n",
      "Epoch 110/300\n",
      "515/515 [==============================] - 0s 777us/step - loss: 7.0025 - mae: 7.0025 - val_loss: 7.0301 - val_mae: 7.0301\n",
      "Epoch 111/300\n",
      "515/515 [==============================] - 0s 804us/step - loss: 7.0114 - mae: 7.0114 - val_loss: 7.0441 - val_mae: 7.0441\n",
      "Epoch 112/300\n",
      "515/515 [==============================] - 0s 807us/step - loss: 7.0042 - mae: 7.0042 - val_loss: 7.0314 - val_mae: 7.0314\n",
      "Epoch 113/300\n",
      "515/515 [==============================] - 0s 846us/step - loss: 7.0016 - mae: 7.0016 - val_loss: 7.0632 - val_mae: 7.0632\n",
      "Epoch 114/300\n",
      "515/515 [==============================] - 0s 810us/step - loss: 7.0026 - mae: 7.0026 - val_loss: 7.0253 - val_mae: 7.0253\n",
      "Epoch 115/300\n",
      "515/515 [==============================] - 0s 816us/step - loss: 6.9977 - mae: 6.9977 - val_loss: 7.0355 - val_mae: 7.0355\n",
      "Epoch 116/300\n",
      "515/515 [==============================] - 0s 923us/step - loss: 7.0024 - mae: 7.0024 - val_loss: 7.0103 - val_mae: 7.0103\n",
      "Epoch 117/300\n",
      "515/515 [==============================] - 0s 846us/step - loss: 6.9882 - mae: 6.9882 - val_loss: 7.0160 - val_mae: 7.0160\n",
      "Epoch 118/300\n",
      "515/515 [==============================] - 0s 825us/step - loss: 7.0031 - mae: 7.0031 - val_loss: 7.0293 - val_mae: 7.0293\n",
      "Epoch 119/300\n",
      "515/515 [==============================] - 0s 870us/step - loss: 6.9853 - mae: 6.9853 - val_loss: 7.0145 - val_mae: 7.0145\n",
      "Epoch 120/300\n",
      "515/515 [==============================] - 0s 899us/step - loss: 6.9957 - mae: 6.9957 - val_loss: 6.9980 - val_mae: 6.9980\n",
      "Epoch 121/300\n",
      "515/515 [==============================] - 0s 818us/step - loss: 6.9923 - mae: 6.9923 - val_loss: 6.9437 - val_mae: 6.9437\n",
      "Epoch 122/300\n",
      "515/515 [==============================] - 0s 836us/step - loss: 7.0049 - mae: 7.0049 - val_loss: 7.0455 - val_mae: 7.0455\n",
      "Epoch 123/300\n",
      "515/515 [==============================] - 0s 803us/step - loss: 6.9929 - mae: 6.9929 - val_loss: 7.0064 - val_mae: 7.0064\n",
      "Epoch 124/300\n",
      "515/515 [==============================] - 0s 792us/step - loss: 6.9898 - mae: 6.9898 - val_loss: 6.9808 - val_mae: 6.9808\n",
      "Epoch 125/300\n",
      "515/515 [==============================] - 0s 778us/step - loss: 6.9909 - mae: 6.9909 - val_loss: 7.0443 - val_mae: 7.0443\n",
      "Epoch 126/300\n",
      "515/515 [==============================] - 0s 811us/step - loss: 6.9962 - mae: 6.9962 - val_loss: 7.0171 - val_mae: 7.0171\n",
      "Epoch 127/300\n",
      "515/515 [==============================] - 0s 808us/step - loss: 7.0046 - mae: 7.0046 - val_loss: 7.0236 - val_mae: 7.0236\n",
      "Epoch 128/300\n",
      "515/515 [==============================] - 0s 802us/step - loss: 6.9949 - mae: 6.9949 - val_loss: 7.0804 - val_mae: 7.0804\n",
      "Epoch 129/300\n",
      "515/515 [==============================] - 0s 801us/step - loss: 6.9833 - mae: 6.9833 - val_loss: 7.0237 - val_mae: 7.0237\n",
      "Epoch 130/300\n",
      "515/515 [==============================] - 0s 802us/step - loss: 6.9883 - mae: 6.9883 - val_loss: 6.9837 - val_mae: 6.9837\n",
      "Epoch 131/300\n",
      "515/515 [==============================] - 0s 839us/step - loss: 6.9944 - mae: 6.9944 - val_loss: 7.0164 - val_mae: 7.0164\n",
      "Epoch 132/300\n",
      "515/515 [==============================] - 0s 775us/step - loss: 6.9838 - mae: 6.9838 - val_loss: 7.0043 - val_mae: 7.0043\n",
      "Epoch 133/300\n",
      "515/515 [==============================] - 0s 769us/step - loss: 6.9896 - mae: 6.9896 - val_loss: 7.0200 - val_mae: 7.0200\n",
      "Epoch 134/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 6.9871 - mae: 6.9871 - val_loss: 6.9791 - val_mae: 6.9791\n",
      "Epoch 135/300\n",
      "515/515 [==============================] - 0s 775us/step - loss: 6.9940 - mae: 6.9940 - val_loss: 7.0191 - val_mae: 7.0191\n",
      "Epoch 136/300\n",
      "515/515 [==============================] - 0s 782us/step - loss: 6.9809 - mae: 6.9809 - val_loss: 7.0147 - val_mae: 7.0147\n",
      "Epoch 137/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 6.9831 - mae: 6.9831 - val_loss: 7.0693 - val_mae: 7.0693\n",
      "Epoch 138/300\n",
      "515/515 [==============================] - 0s 778us/step - loss: 6.9880 - mae: 6.9880 - val_loss: 7.0051 - val_mae: 7.0051\n",
      "Epoch 139/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 6.9798 - mae: 6.9798 - val_loss: 6.9932 - val_mae: 6.9932\n",
      "Epoch 140/300\n",
      "515/515 [==============================] - 0s 771us/step - loss: 6.9867 - mae: 6.9867 - val_loss: 7.0428 - val_mae: 7.0428\n",
      "Epoch 141/300\n",
      "515/515 [==============================] - 0s 948us/step - loss: 6.9888 - mae: 6.9888 - val_loss: 6.9949 - val_mae: 6.9949\n",
      "Epoch 142/300\n",
      "515/515 [==============================] - 0s 837us/step - loss: 6.9858 - mae: 6.9858 - val_loss: 6.9429 - val_mae: 6.9429\n",
      "Epoch 143/300\n",
      "515/515 [==============================] - 0s 834us/step - loss: 6.9798 - mae: 6.9798 - val_loss: 7.0123 - val_mae: 7.0123\n",
      "Epoch 144/300\n",
      "515/515 [==============================] - 0s 811us/step - loss: 6.9766 - mae: 6.9766 - val_loss: 6.9687 - val_mae: 6.9687\n",
      "Epoch 145/300\n",
      "515/515 [==============================] - 0s 812us/step - loss: 6.9790 - mae: 6.9790 - val_loss: 6.9950 - val_mae: 6.9950\n",
      "Epoch 146/300\n",
      "515/515 [==============================] - 0s 836us/step - loss: 6.9762 - mae: 6.9762 - val_loss: 7.0005 - val_mae: 7.0005\n",
      "Epoch 147/300\n",
      "515/515 [==============================] - 0s 832us/step - loss: 6.9770 - mae: 6.9770 - val_loss: 6.9867 - val_mae: 6.9867\n",
      "Epoch 148/300\n",
      "515/515 [==============================] - 0s 770us/step - loss: 6.9774 - mae: 6.9774 - val_loss: 6.9532 - val_mae: 6.9532\n",
      "Epoch 149/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 6.9721 - mae: 6.9721 - val_loss: 6.9904 - val_mae: 6.9904\n",
      "Epoch 150/300\n",
      "515/515 [==============================] - 0s 792us/step - loss: 6.9739 - mae: 6.9739 - val_loss: 7.0486 - val_mae: 7.0486\n",
      "Epoch 151/300\n",
      "515/515 [==============================] - 0s 792us/step - loss: 6.9927 - mae: 6.9927 - val_loss: 7.0288 - val_mae: 7.0288\n",
      "Epoch 152/300\n",
      "515/515 [==============================] - 0s 770us/step - loss: 6.9714 - mae: 6.9714 - val_loss: 6.9595 - val_mae: 6.9595\n",
      "Epoch 153/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 6.9646 - mae: 6.9646 - val_loss: 6.9877 - val_mae: 6.9877\n",
      "Epoch 154/300\n",
      "515/515 [==============================] - 0s 770us/step - loss: 6.9674 - mae: 6.9674 - val_loss: 6.9625 - val_mae: 6.9625\n",
      "Epoch 155/300\n",
      "515/515 [==============================] - 0s 778us/step - loss: 6.9680 - mae: 6.9680 - val_loss: 7.0298 - val_mae: 7.0298\n",
      "Epoch 156/300\n",
      "515/515 [==============================] - 0s 776us/step - loss: 6.9710 - mae: 6.9710 - val_loss: 6.9933 - val_mae: 6.9933\n",
      "Epoch 157/300\n",
      "515/515 [==============================] - 0s 769us/step - loss: 6.9651 - mae: 6.9651 - val_loss: 7.0032 - val_mae: 7.0032\n",
      "Epoch 158/300\n",
      "515/515 [==============================] - 0s 802us/step - loss: 6.9639 - mae: 6.9639 - val_loss: 7.0215 - val_mae: 7.0215\n",
      "Epoch 159/300\n",
      "515/515 [==============================] - 0s 772us/step - loss: 6.9700 - mae: 6.9700 - val_loss: 7.0472 - val_mae: 7.0472\n",
      "Epoch 160/300\n",
      "515/515 [==============================] - 0s 778us/step - loss: 6.9657 - mae: 6.9657 - val_loss: 6.9820 - val_mae: 6.9820\n",
      "Epoch 161/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 6.9563 - mae: 6.9563 - val_loss: 6.9837 - val_mae: 6.9837\n",
      "Epoch 162/300\n",
      "515/515 [==============================] - 0s 774us/step - loss: 6.9597 - mae: 6.9597 - val_loss: 6.9966 - val_mae: 6.9966\n",
      "Epoch 163/300\n",
      "515/515 [==============================] - 0s 794us/step - loss: 6.9677 - mae: 6.9677 - val_loss: 6.9531 - val_mae: 6.9531\n",
      "Epoch 164/300\n",
      "515/515 [==============================] - 0s 783us/step - loss: 6.9599 - mae: 6.9599 - val_loss: 6.9661 - val_mae: 6.9661\n",
      "Epoch 165/300\n",
      "515/515 [==============================] - 0s 764us/step - loss: 6.9581 - mae: 6.9581 - val_loss: 6.9818 - val_mae: 6.9818\n",
      "Epoch 166/300\n",
      "515/515 [==============================] - 0s 934us/step - loss: 6.9580 - mae: 6.9580 - val_loss: 6.9515 - val_mae: 6.9515\n",
      "Epoch 167/300\n",
      "515/515 [==============================] - 0s 839us/step - loss: 6.9706 - mae: 6.9706 - val_loss: 6.9975 - val_mae: 6.9975\n",
      "Epoch 168/300\n",
      "515/515 [==============================] - 0s 846us/step - loss: 6.9640 - mae: 6.9640 - val_loss: 7.0028 - val_mae: 7.0028\n",
      "Epoch 169/300\n",
      "515/515 [==============================] - 0s 848us/step - loss: 6.9657 - mae: 6.9657 - val_loss: 6.9525 - val_mae: 6.9525\n",
      "Epoch 170/300\n",
      "515/515 [==============================] - 0s 888us/step - loss: 6.9650 - mae: 6.9650 - val_loss: 6.9690 - val_mae: 6.9690\n",
      "Epoch 171/300\n",
      "515/515 [==============================] - 0s 872us/step - loss: 6.9593 - mae: 6.9593 - val_loss: 7.0243 - val_mae: 7.0243\n",
      "Epoch 172/300\n",
      "515/515 [==============================] - 0s 873us/step - loss: 6.9561 - mae: 6.9561 - val_loss: 6.9854 - val_mae: 6.9854\n",
      "Epoch 173/300\n",
      "515/515 [==============================] - 0s 793us/step - loss: 6.9552 - mae: 6.9552 - val_loss: 6.9719 - val_mae: 6.9719\n",
      "Epoch 174/300\n",
      "515/515 [==============================] - 0s 763us/step - loss: 6.9526 - mae: 6.9526 - val_loss: 6.9701 - val_mae: 6.9701\n",
      "Epoch 175/300\n",
      "515/515 [==============================] - 0s 762us/step - loss: 6.9519 - mae: 6.9519 - val_loss: 6.9639 - val_mae: 6.9639\n",
      "Epoch 176/300\n",
      "515/515 [==============================] - 0s 763us/step - loss: 6.9639 - mae: 6.9639 - val_loss: 7.0079 - val_mae: 7.0079\n",
      "Epoch 177/300\n",
      "515/515 [==============================] - 0s 766us/step - loss: 6.9649 - mae: 6.9649 - val_loss: 6.9531 - val_mae: 6.9531\n",
      "Epoch 178/300\n",
      "515/515 [==============================] - 0s 796us/step - loss: 6.9539 - mae: 6.9539 - val_loss: 6.9732 - val_mae: 6.9732\n",
      "Epoch 179/300\n",
      "515/515 [==============================] - 0s 801us/step - loss: 6.9420 - mae: 6.9420 - val_loss: 6.9602 - val_mae: 6.9602\n",
      "Epoch 180/300\n",
      "515/515 [==============================] - 0s 854us/step - loss: 6.9511 - mae: 6.9511 - val_loss: 7.0317 - val_mae: 7.0317\n",
      "Epoch 181/300\n",
      "515/515 [==============================] - 0s 880us/step - loss: 6.9448 - mae: 6.9448 - val_loss: 6.9670 - val_mae: 6.9670\n",
      "Epoch 182/300\n",
      "515/515 [==============================] - 0s 767us/step - loss: 6.9554 - mae: 6.9554 - val_loss: 6.9995 - val_mae: 6.9995\n",
      "Epoch 183/300\n",
      "515/515 [==============================] - 0s 789us/step - loss: 6.9608 - mae: 6.9608 - val_loss: 6.9765 - val_mae: 6.9765\n",
      "Epoch 184/300\n",
      "515/515 [==============================] - 0s 847us/step - loss: 6.9567 - mae: 6.9567 - val_loss: 7.0063 - val_mae: 7.0063\n",
      "Epoch 185/300\n",
      "515/515 [==============================] - 0s 852us/step - loss: 6.9484 - mae: 6.9484 - val_loss: 6.9512 - val_mae: 6.9512\n",
      "Epoch 186/300\n",
      "515/515 [==============================] - 0s 847us/step - loss: 6.9485 - mae: 6.9485 - val_loss: 6.9650 - val_mae: 6.9650\n",
      "Epoch 187/300\n",
      "515/515 [==============================] - 0s 829us/step - loss: 6.9486 - mae: 6.9486 - val_loss: 6.9686 - val_mae: 6.9686\n",
      "Epoch 188/300\n",
      "515/515 [==============================] - 0s 820us/step - loss: 6.9522 - mae: 6.9522 - val_loss: 6.9755 - val_mae: 6.9755\n",
      "Epoch 189/300\n",
      "515/515 [==============================] - 0s 828us/step - loss: 6.9448 - mae: 6.9448 - val_loss: 7.0328 - val_mae: 7.0328\n",
      "Epoch 190/300\n",
      "515/515 [==============================] - 1s 987us/step - loss: 6.9535 - mae: 6.9535 - val_loss: 6.9772 - val_mae: 6.9772\n",
      "Epoch 191/300\n",
      "515/515 [==============================] - 0s 845us/step - loss: 6.9443 - mae: 6.9443 - val_loss: 6.9809 - val_mae: 6.9809\n",
      "Epoch 192/300\n",
      "515/515 [==============================] - 0s 879us/step - loss: 6.9537 - mae: 6.9537 - val_loss: 6.9541 - val_mae: 6.9541\n",
      "Epoch 193/300\n",
      "515/515 [==============================] - 0s 925us/step - loss: 6.9461 - mae: 6.9461 - val_loss: 6.9869 - val_mae: 6.9869\n",
      "Epoch 194/300\n",
      "515/515 [==============================] - 0s 862us/step - loss: 6.9465 - mae: 6.9465 - val_loss: 6.9459 - val_mae: 6.9459\n",
      "Epoch 195/300\n",
      "515/515 [==============================] - 0s 820us/step - loss: 6.9572 - mae: 6.9572 - val_loss: 6.9664 - val_mae: 6.9664\n",
      "Epoch 196/300\n",
      "515/515 [==============================] - 0s 850us/step - loss: 6.9534 - mae: 6.9534 - val_loss: 7.0149 - val_mae: 7.0149\n",
      "Epoch 197/300\n",
      "515/515 [==============================] - 0s 793us/step - loss: 6.9494 - mae: 6.9494 - val_loss: 6.9419 - val_mae: 6.9419\n",
      "Epoch 198/300\n",
      "515/515 [==============================] - 0s 769us/step - loss: 6.9495 - mae: 6.9495 - val_loss: 6.9809 - val_mae: 6.9809\n",
      "Epoch 199/300\n",
      "515/515 [==============================] - 0s 764us/step - loss: 6.9511 - mae: 6.9511 - val_loss: 6.9996 - val_mae: 6.9996\n",
      "Epoch 200/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 6.9433 - mae: 6.9433 - val_loss: 6.9651 - val_mae: 6.9651\n",
      "Epoch 201/300\n",
      "515/515 [==============================] - 0s 765us/step - loss: 6.9509 - mae: 6.9509 - val_loss: 6.9993 - val_mae: 6.9993\n",
      "Epoch 202/300\n",
      "515/515 [==============================] - 0s 774us/step - loss: 6.9480 - mae: 6.9480 - val_loss: 6.9407 - val_mae: 6.9407\n",
      "Epoch 203/300\n",
      "515/515 [==============================] - 0s 786us/step - loss: 6.9435 - mae: 6.9435 - val_loss: 7.0047 - val_mae: 7.0047\n",
      "Epoch 204/300\n",
      "515/515 [==============================] - 0s 824us/step - loss: 6.9366 - mae: 6.9366 - val_loss: 7.0112 - val_mae: 7.0112\n",
      "Epoch 205/300\n",
      "515/515 [==============================] - 0s 775us/step - loss: 6.9502 - mae: 6.9502 - val_loss: 7.0288 - val_mae: 7.0288\n",
      "Epoch 206/300\n",
      "515/515 [==============================] - 0s 791us/step - loss: 6.9589 - mae: 6.9589 - val_loss: 6.9414 - val_mae: 6.9414\n",
      "Epoch 207/300\n",
      "515/515 [==============================] - 0s 853us/step - loss: 6.9497 - mae: 6.9497 - val_loss: 7.0048 - val_mae: 7.0048\n",
      "Epoch 208/300\n",
      "515/515 [==============================] - 0s 820us/step - loss: 6.9374 - mae: 6.9374 - val_loss: 6.9348 - val_mae: 6.9348\n",
      "Epoch 209/300\n",
      "515/515 [==============================] - 0s 795us/step - loss: 6.9487 - mae: 6.9487 - val_loss: 6.9723 - val_mae: 6.9723\n",
      "Epoch 210/300\n",
      "515/515 [==============================] - 0s 864us/step - loss: 6.9480 - mae: 6.9480 - val_loss: 7.0204 - val_mae: 7.0204\n",
      "Epoch 211/300\n",
      "515/515 [==============================] - 0s 876us/step - loss: 6.9477 - mae: 6.9477 - val_loss: 6.9625 - val_mae: 6.9625\n",
      "Epoch 212/300\n",
      "515/515 [==============================] - 0s 909us/step - loss: 6.9354 - mae: 6.9354 - val_loss: 6.9762 - val_mae: 6.9762\n",
      "Epoch 213/300\n",
      "515/515 [==============================] - 0s 870us/step - loss: 6.9442 - mae: 6.9442 - val_loss: 6.9263 - val_mae: 6.9263\n",
      "Epoch 214/300\n",
      "515/515 [==============================] - 1s 984us/step - loss: 6.9439 - mae: 6.9439 - val_loss: 6.9570 - val_mae: 6.9570\n",
      "Epoch 215/300\n",
      "515/515 [==============================] - 0s 926us/step - loss: 6.9339 - mae: 6.9339 - val_loss: 6.9824 - val_mae: 6.9824\n",
      "Epoch 216/300\n",
      "515/515 [==============================] - 0s 927us/step - loss: 6.9450 - mae: 6.9450 - val_loss: 6.9724 - val_mae: 6.9724\n",
      "Epoch 217/300\n",
      "515/515 [==============================] - 0s 896us/step - loss: 6.9322 - mae: 6.9322 - val_loss: 6.9416 - val_mae: 6.9416\n",
      "Epoch 218/300\n",
      "515/515 [==============================] - 0s 815us/step - loss: 6.9412 - mae: 6.9412 - val_loss: 6.9663 - val_mae: 6.9663\n",
      "Epoch 219/300\n",
      "515/515 [==============================] - 0s 826us/step - loss: 6.9417 - mae: 6.9417 - val_loss: 6.9482 - val_mae: 6.9482\n",
      "Epoch 220/300\n",
      "515/515 [==============================] - 0s 833us/step - loss: 6.9465 - mae: 6.9465 - val_loss: 6.9590 - val_mae: 6.9590\n",
      "Epoch 221/300\n",
      "515/515 [==============================] - 0s 798us/step - loss: 6.9385 - mae: 6.9385 - val_loss: 6.9821 - val_mae: 6.9821\n",
      "Epoch 222/300\n",
      "515/515 [==============================] - 0s 770us/step - loss: 6.9350 - mae: 6.9350 - val_loss: 6.9924 - val_mae: 6.9924\n",
      "Epoch 223/300\n",
      "515/515 [==============================] - 0s 769us/step - loss: 6.9355 - mae: 6.9355 - val_loss: 6.9298 - val_mae: 6.9298\n",
      "Epoch 224/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 6.9276 - mae: 6.9276 - val_loss: 6.9582 - val_mae: 6.9582\n",
      "Epoch 225/300\n",
      "515/515 [==============================] - 0s 771us/step - loss: 6.9460 - mae: 6.9460 - val_loss: 6.9404 - val_mae: 6.9404\n",
      "Epoch 226/300\n",
      "515/515 [==============================] - 0s 774us/step - loss: 6.9271 - mae: 6.9271 - val_loss: 6.9263 - val_mae: 6.9263\n",
      "Epoch 227/300\n",
      "515/515 [==============================] - 0s 766us/step - loss: 6.9332 - mae: 6.9332 - val_loss: 6.9676 - val_mae: 6.9676\n",
      "Epoch 228/300\n",
      "515/515 [==============================] - 0s 770us/step - loss: 6.9361 - mae: 6.9361 - val_loss: 6.9506 - val_mae: 6.9506\n",
      "Epoch 229/300\n",
      "515/515 [==============================] - 0s 765us/step - loss: 6.9267 - mae: 6.9267 - val_loss: 6.9448 - val_mae: 6.9448\n",
      "Epoch 230/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 6.9336 - mae: 6.9336 - val_loss: 6.9997 - val_mae: 6.9997\n",
      "Epoch 231/300\n",
      "515/515 [==============================] - 0s 778us/step - loss: 6.9333 - mae: 6.9333 - val_loss: 6.9660 - val_mae: 6.9660\n",
      "Epoch 232/300\n",
      "515/515 [==============================] - 0s 774us/step - loss: 6.9365 - mae: 6.9365 - val_loss: 6.9406 - val_mae: 6.9406\n",
      "Epoch 233/300\n",
      "515/515 [==============================] - 0s 776us/step - loss: 6.9367 - mae: 6.9367 - val_loss: 6.9385 - val_mae: 6.9385\n",
      "Epoch 234/300\n",
      "515/515 [==============================] - 0s 770us/step - loss: 6.9362 - mae: 6.9362 - val_loss: 6.9995 - val_mae: 6.9995\n",
      "Epoch 235/300\n",
      "515/515 [==============================] - 0s 790us/step - loss: 6.9445 - mae: 6.9445 - val_loss: 6.9525 - val_mae: 6.9525\n",
      "Epoch 236/300\n",
      "515/515 [==============================] - 0s 780us/step - loss: 6.9350 - mae: 6.9350 - val_loss: 6.9856 - val_mae: 6.9856\n",
      "Epoch 237/300\n",
      "515/515 [==============================] - 0s 761us/step - loss: 6.9319 - mae: 6.9319 - val_loss: 6.9356 - val_mae: 6.9356\n",
      "Epoch 238/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 6.9221 - mae: 6.9221 - val_loss: 6.9485 - val_mae: 6.9485\n",
      "Epoch 239/300\n",
      "515/515 [==============================] - 0s 893us/step - loss: 6.9243 - mae: 6.9243 - val_loss: 6.9641 - val_mae: 6.9641\n",
      "Epoch 240/300\n",
      "515/515 [==============================] - 0s 835us/step - loss: 6.9349 - mae: 6.9349 - val_loss: 6.9182 - val_mae: 6.9182\n",
      "Epoch 241/300\n",
      "515/515 [==============================] - 0s 864us/step - loss: 6.9346 - mae: 6.9346 - val_loss: 6.9537 - val_mae: 6.9537\n",
      "Epoch 242/300\n",
      "515/515 [==============================] - 0s 879us/step - loss: 6.9299 - mae: 6.9299 - val_loss: 6.9255 - val_mae: 6.9255\n",
      "Epoch 243/300\n",
      "515/515 [==============================] - 0s 941us/step - loss: 6.9300 - mae: 6.9300 - val_loss: 6.9971 - val_mae: 6.9971\n",
      "Epoch 244/300\n",
      "515/515 [==============================] - 0s 903us/step - loss: 6.9328 - mae: 6.9328 - val_loss: 6.9283 - val_mae: 6.9283\n",
      "Epoch 245/300\n",
      "515/515 [==============================] - 0s 895us/step - loss: 6.9265 - mae: 6.9265 - val_loss: 6.9525 - val_mae: 6.9525\n",
      "Epoch 246/300\n",
      "515/515 [==============================] - 0s 835us/step - loss: 6.9288 - mae: 6.9288 - val_loss: 6.9013 - val_mae: 6.9013\n",
      "Epoch 247/300\n",
      "515/515 [==============================] - 0s 870us/step - loss: 6.9186 - mae: 6.9186 - val_loss: 6.9245 - val_mae: 6.9245\n",
      "Epoch 248/300\n",
      "515/515 [==============================] - 0s 804us/step - loss: 6.9354 - mae: 6.9354 - val_loss: 6.9691 - val_mae: 6.9691\n",
      "Epoch 249/300\n",
      "515/515 [==============================] - 0s 801us/step - loss: 6.9211 - mae: 6.9211 - val_loss: 6.9872 - val_mae: 6.9872\n",
      "Epoch 250/300\n",
      "515/515 [==============================] - 0s 814us/step - loss: 6.9274 - mae: 6.9274 - val_loss: 7.0000 - val_mae: 7.0000\n",
      "Epoch 251/300\n",
      "515/515 [==============================] - 0s 880us/step - loss: 6.9294 - mae: 6.9294 - val_loss: 6.9821 - val_mae: 6.9821\n",
      "Epoch 252/300\n",
      "515/515 [==============================] - 0s 769us/step - loss: 6.9259 - mae: 6.9259 - val_loss: 6.9312 - val_mae: 6.9312\n",
      "Epoch 253/300\n",
      "515/515 [==============================] - 0s 768us/step - loss: 6.9205 - mae: 6.9205 - val_loss: 6.9334 - val_mae: 6.9334\n",
      "Epoch 254/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 6.9284 - mae: 6.9284 - val_loss: 6.9514 - val_mae: 6.9514\n",
      "Epoch 255/300\n",
      "515/515 [==============================] - 0s 769us/step - loss: 6.9275 - mae: 6.9275 - val_loss: 6.9445 - val_mae: 6.9445\n",
      "Epoch 256/300\n",
      "515/515 [==============================] - 0s 779us/step - loss: 6.9218 - mae: 6.9218 - val_loss: 6.9166 - val_mae: 6.9166\n",
      "Epoch 257/300\n",
      "515/515 [==============================] - 0s 781us/step - loss: 6.9340 - mae: 6.9340 - val_loss: 6.9105 - val_mae: 6.9105\n",
      "Epoch 258/300\n",
      "515/515 [==============================] - 0s 820us/step - loss: 6.9172 - mae: 6.9172 - val_loss: 6.9536 - val_mae: 6.9536\n",
      "Epoch 259/300\n",
      "515/515 [==============================] - 0s 968us/step - loss: 6.9257 - mae: 6.9257 - val_loss: 6.9832 - val_mae: 6.9832\n",
      "Epoch 260/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.9346 - mae: 6.9346 - val_loss: 6.9397 - val_mae: 6.9397\n",
      "Epoch 261/300\n",
      "515/515 [==============================] - 0s 867us/step - loss: 6.9146 - mae: 6.9146 - val_loss: 6.9696 - val_mae: 6.9696\n",
      "Epoch 262/300\n",
      "515/515 [==============================] - 0s 867us/step - loss: 6.9205 - mae: 6.9205 - val_loss: 6.9092 - val_mae: 6.9092\n",
      "Epoch 263/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.9217 - mae: 6.9217 - val_loss: 6.9279 - val_mae: 6.9279\n",
      "Epoch 264/300\n",
      "515/515 [==============================] - 0s 947us/step - loss: 6.9205 - mae: 6.9205 - val_loss: 6.9452 - val_mae: 6.9452\n",
      "Epoch 265/300\n",
      "515/515 [==============================] - 0s 855us/step - loss: 6.9223 - mae: 6.9223 - val_loss: 6.9206 - val_mae: 6.9206\n",
      "Epoch 266/300\n",
      "515/515 [==============================] - 0s 869us/step - loss: 6.9110 - mae: 6.9110 - val_loss: 6.9231 - val_mae: 6.9231\n",
      "Epoch 267/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.9129 - mae: 6.9129 - val_loss: 6.9281 - val_mae: 6.9281\n",
      "Epoch 268/300\n",
      "515/515 [==============================] - 0s 879us/step - loss: 6.9023 - mae: 6.9023 - val_loss: 6.9719 - val_mae: 6.9719\n",
      "Epoch 269/300\n",
      "515/515 [==============================] - 0s 947us/step - loss: 6.9136 - mae: 6.9136 - val_loss: 6.9341 - val_mae: 6.9341\n",
      "Epoch 270/300\n",
      "515/515 [==============================] - 0s 782us/step - loss: 6.9096 - mae: 6.9096 - val_loss: 6.9822 - val_mae: 6.9822\n",
      "Epoch 271/300\n",
      "515/515 [==============================] - 0s 875us/step - loss: 6.9135 - mae: 6.9135 - val_loss: 6.9480 - val_mae: 6.9480\n",
      "Epoch 272/300\n",
      "515/515 [==============================] - 0s 837us/step - loss: 6.9157 - mae: 6.9157 - val_loss: 6.9565 - val_mae: 6.9565\n",
      "Epoch 273/300\n",
      "515/515 [==============================] - 0s 781us/step - loss: 6.9208 - mae: 6.9208 - val_loss: 6.9227 - val_mae: 6.9227\n",
      "Epoch 274/300\n",
      "515/515 [==============================] - 0s 773us/step - loss: 6.9167 - mae: 6.9167 - val_loss: 6.9870 - val_mae: 6.9870\n",
      "Epoch 275/300\n",
      "515/515 [==============================] - 0s 763us/step - loss: 6.9124 - mae: 6.9124 - val_loss: 6.9120 - val_mae: 6.9120\n",
      "Epoch 276/300\n",
      "515/515 [==============================] - 0s 782us/step - loss: 6.9050 - mae: 6.9050 - val_loss: 6.9701 - val_mae: 6.9701\n",
      "Epoch 277/300\n",
      "515/515 [==============================] - 0s 865us/step - loss: 6.9191 - mae: 6.9191 - val_loss: 6.9594 - val_mae: 6.9594\n",
      "Epoch 278/300\n",
      "515/515 [==============================] - 0s 827us/step - loss: 6.9150 - mae: 6.9150 - val_loss: 6.9083 - val_mae: 6.9083\n",
      "Epoch 279/300\n",
      "515/515 [==============================] - 0s 867us/step - loss: 6.9221 - mae: 6.9221 - val_loss: 6.9111 - val_mae: 6.9111\n",
      "Epoch 280/300\n",
      "515/515 [==============================] - 0s 805us/step - loss: 6.9157 - mae: 6.9157 - val_loss: 6.9672 - val_mae: 6.9672\n",
      "Epoch 281/300\n",
      "515/515 [==============================] - 0s 921us/step - loss: 6.9120 - mae: 6.9120 - val_loss: 6.9618 - val_mae: 6.9618\n",
      "Epoch 282/300\n",
      "515/515 [==============================] - 0s 801us/step - loss: 6.9052 - mae: 6.9052 - val_loss: 6.9606 - val_mae: 6.9606\n",
      "Epoch 283/300\n",
      "515/515 [==============================] - 0s 829us/step - loss: 6.9118 - mae: 6.9118 - val_loss: 6.8975 - val_mae: 6.8975\n",
      "Epoch 284/300\n",
      "515/515 [==============================] - 0s 829us/step - loss: 6.9146 - mae: 6.9146 - val_loss: 6.9163 - val_mae: 6.9163\n",
      "Epoch 285/300\n",
      "515/515 [==============================] - 0s 828us/step - loss: 6.9102 - mae: 6.9102 - val_loss: 6.9090 - val_mae: 6.9090\n",
      "Epoch 286/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.9074 - mae: 6.9074 - val_loss: 6.9304 - val_mae: 6.9304\n",
      "Epoch 287/300\n",
      "515/515 [==============================] - 0s 914us/step - loss: 6.9088 - mae: 6.9088 - val_loss: 6.9529 - val_mae: 6.9529\n",
      "Epoch 288/300\n",
      "515/515 [==============================] - 0s 903us/step - loss: 6.9191 - mae: 6.9191 - val_loss: 6.9034 - val_mae: 6.9034\n",
      "Epoch 289/300\n",
      "515/515 [==============================] - 0s 885us/step - loss: 6.9149 - mae: 6.9149 - val_loss: 6.9226 - val_mae: 6.9226\n",
      "Epoch 290/300\n",
      "515/515 [==============================] - 0s 952us/step - loss: 6.8979 - mae: 6.8979 - val_loss: 6.8789 - val_mae: 6.8789\n",
      "Epoch 291/300\n",
      "515/515 [==============================] - 0s 953us/step - loss: 6.9106 - mae: 6.9106 - val_loss: 6.9565 - val_mae: 6.9565\n",
      "Epoch 292/300\n",
      "515/515 [==============================] - 0s 874us/step - loss: 6.8919 - mae: 6.8919 - val_loss: 7.0170 - val_mae: 7.0170\n",
      "Epoch 293/300\n",
      "515/515 [==============================] - 0s 811us/step - loss: 6.9193 - mae: 6.9193 - val_loss: 6.9759 - val_mae: 6.9759\n",
      "Epoch 294/300\n",
      "515/515 [==============================] - 0s 782us/step - loss: 6.9053 - mae: 6.9053 - val_loss: 6.9091 - val_mae: 6.9091\n",
      "Epoch 295/300\n",
      "515/515 [==============================] - 0s 798us/step - loss: 6.9021 - mae: 6.9021 - val_loss: 6.9480 - val_mae: 6.9480\n",
      "Epoch 296/300\n",
      "515/515 [==============================] - 0s 857us/step - loss: 6.9076 - mae: 6.9076 - val_loss: 6.9510 - val_mae: 6.9510\n",
      "Epoch 297/300\n",
      "515/515 [==============================] - 0s 819us/step - loss: 6.9270 - mae: 6.9270 - val_loss: 6.9158 - val_mae: 6.9158\n",
      "Epoch 298/300\n",
      "515/515 [==============================] - 0s 778us/step - loss: 6.8923 - mae: 6.8923 - val_loss: 6.9552 - val_mae: 6.9552\n",
      "Epoch 299/300\n",
      "515/515 [==============================] - 0s 796us/step - loss: 6.9089 - mae: 6.9089 - val_loss: 6.9270 - val_mae: 6.9270\n",
      "Epoch 300/300\n",
      "515/515 [==============================] - 0s 798us/step - loss: 6.9068 - mae: 6.9068 - val_loss: 6.9139 - val_mae: 6.9139\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils.vis_utils import plot_model\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 10, restore_best_weights = True)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "model.compile(optimizer='adam', \n",
    "              loss= 'mae',\n",
    "              metrics=['mae'])\n",
    "\n",
    "history = model.fit(force_train, theta_z_train, epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (force_test, theta_z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(len(training_loss))\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Angle (degree)')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prediction = model.predict(force_test)\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (20,5)\n",
    "plt.plot(theta_z_test)\n",
    "plt.plot(y_prediction,'--')\n",
    "plt.legend(['Ground Truth', 'Prediction'])\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Angle (degree)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.913944966483415"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(theta_z_test, y_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
