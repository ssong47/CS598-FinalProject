{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib as mpl\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading output signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read video frame\n",
    "def dep_cam_reduced(dep_v_name):\n",
    "    dep_v = cv2.VideoCapture(dep_v_name)\n",
    "    ret, frame = dep_v.read()\n",
    "    counter=0\n",
    "\n",
    "    frame_count = int(dep_v.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "#     frame_height = int(frame.shape[0]/5)\n",
    "#     frame_width = int(frame.shape[1]/5)\n",
    "#     frame_height = frame.shape[0]\n",
    "#     frame_width = frame.shape[1]\n",
    "    frame_height = 30\n",
    "    frame_width = 40\n",
    "    depth_frames = np.empty((frame_count, frame_height, frame_width))\n",
    "\n",
    "    while(dep_v.isOpened()):\n",
    "        ret, frame = dep_v.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        if ret == True:\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray_frame = cv2.resize(gray_frame, (frame_width, frame_height), interpolation = cv2.INTER_AREA)\n",
    "            depth_frames[counter] = gray_frame\n",
    "            counter+=1\n",
    "\n",
    "    dep_v.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return depth_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read input depth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read output depth images data with reduced dimension\n",
    "#left 32 as fresh unseen data\n",
    "foldername = r'Test_Subject_Leo/'\n",
    "test_folder = ['test24', 'test30', 'test31','test33', 'test35' ]\n",
    "test_num = ['24', '30', '31', '33', '35']\n",
    "sub_name = foldername + test_folder[0]\n",
    "dep_name = sub_name + r'/depth_processed_leo_test' + test_num[0] + '.avi';\n",
    "depth =  dep_cam_reduced(dep_name)/255.0\n",
    "for i in range(1, 5):\n",
    "    subfolder_name = foldername + test_folder[i]\n",
    "    dep_video_name = subfolder_name + r'/depth_processed_leo_test' + test_num[i] + '.avi'\n",
    "    #print(dep_video_name) \n",
    "    dep_v_temp =  dep_cam_reduced(dep_video_name)/255.0\n",
    "    depth = np.concatenate((depth, dep_v_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = r'Test_Subject_Leo/'\n",
    "test_folder = ['test24', 'test30', 'test31','test33', 'test35' ]\n",
    "test_num = ['24', '30', '31', '33', '35']\n",
    "subfolder_name = foldername + test_folder[0]\n",
    "qtm_file = subfolder_name + r'/qtm_processed_leo_test' + test_num[0] + '_' + '11_15_2020' + '.txt'\n",
    "theta_z = pd.read_csv(qtm_file)\n",
    "theta_z = theta_z.iloc[:,0].values\n",
    "for i in range(1,5):\n",
    "    subfolder_name = foldername + test_folder[i]\n",
    "    if test_folder[i] == 'test30' or test_folder[i] == 'test31':\n",
    "        qtm_file = subfolder_name + r'/qtm_processed_leo_test' + test_num[i] + '_' + '11_24_2020' + '.txt'\n",
    "    else: \n",
    "        qtm_file = subfolder_name + r'/qtm_processed_leo_test' + test_num[i] + '_' + '11_25_2020' + '.txt'\n",
    "    dataset_y =  pd.read_csv(qtm_file)\n",
    "    theta_z_temp = dataset_y.iloc[:,0].values\n",
    "    theta_z = np.concatenate((theta_z, theta_z_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization of output data (theta z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saturate(theta, min_val, max_val):\n",
    "    for i in range(len(theta)):\n",
    "        if theta[i] < min_val:\n",
    "            theta[i] = min_val\n",
    "            continue\n",
    "        if theta[i] > max_val:\n",
    "            theta[i] = max_val\n",
    "            continue\n",
    "    return theta           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates label based on number of classes. Given theta_z, the goal is to put each angle to a certain class or bin. \n",
    "# each class will have min_\n",
    "\n",
    "def create_label(n_class, theta_z, min_val, max_val):\n",
    "    \n",
    "\n",
    "    labels = []\n",
    "    class_list = []\n",
    "\n",
    "    # interval of each class\n",
    "    interval = (max_val - min_val) / n_class \n",
    "    print(interval)\n",
    "\n",
    "    # create a list containing min and max bound of each class. This way we don't have to have a lot of if statements\n",
    "    for j in range(n_class):\n",
    "        min_class = min_val + (j) * interval # min_class is the minimum bound of each class\n",
    "\n",
    "        max_class = min_class + interval # max_class is the maximum bound of each class\n",
    "\n",
    "        class_list.append([min_class, max_class])\n",
    "\n",
    "\n",
    "    # Go through each theta and assign a label. The final labels will have same number of elements as \n",
    "    for i in range(len(theta_z)):\n",
    "        for j in range (len(class_list)):\n",
    "            class_range = class_list[j]    \n",
    "            if class_range[0] <= theta_z[i] < class_range[1]:\n",
    "                labels.append(j)\n",
    "                break\n",
    "                \n",
    "       \n",
    "    return(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n"
     ]
    }
   ],
   "source": [
    "# try different number of classes\n",
    "n_class = 5\n",
    "min_val = -50 \n",
    "max_val = 50\n",
    "\n",
    "sat_theta_z = saturate(theta_z, min_val, max_val)\n",
    "labeled_z = create_label(n_class, theta_z, min_val, max_val)\n",
    "\n",
    "# plt.plot(sat_theta_z)\n",
    "# plt.plot(labeled_z,'--')\n",
    "# plt.legend(['Ground Truth', 'Discretized'])\n",
    "# plt.xlabel('Sample', fontsize=18)\n",
    "# plt.ylabel('Angle (degree)', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read force data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(labeled_z))\n",
    "print(sat_theta_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder_name = foldername + test_folder[0]\n",
    "force_file = subfolder_name + r'/fcss_processed_leo_test' + test_num[0] + '_' + '11_15_2020' + '.txt'\n",
    "force = pd.read_csv(force_file)\n",
    "force = force.iloc[:,:].values\n",
    "for i in range(1,5):\n",
    "    subfolder_name = foldername + test_folder[i]\n",
    "    if test_folder[i] == 'test30' or test_folder[i] == 'test31':\n",
    "        force_file = subfolder_name + r'/fcss_processed_leo_test' + test_num[i] + '_' + '11_24_2020' + '.txt'\n",
    "    else: \n",
    "        force_file = subfolder_name + r'/fcss_processed_leo_test' + test_num[i] + '_' + '11_25_2020' + '.txt'\n",
    "    dataset_y =  pd.read_csv(force_file)\n",
    "    force_temp = dataset_y.iloc[:,:].values\n",
    "    force = np.concatenate((force, force_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data with Leo's BMI\n",
    "weight = 67\n",
    "height = 1.74\n",
    "BMI = weight/(height**2)\n",
    "force = force/BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = depth[0:len(labeled_z)]\n",
    "\n",
    "force = force[0:len(labeled_z)]\n",
    "labeled_z = np.array(labeled_z)\n",
    "depth_train, depth_test, force_train, force_test, theta_z_train, theta_z_test = train_test_split(depth, force, labeled_z, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Activation\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.8976 - accuracy: 0.6369 - val_loss: 0.8144 - val_accuracy: 0.6560\n",
      "Epoch 2/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.8121 - accuracy: 0.6520 - val_loss: 0.7726 - val_accuracy: 0.6669\n",
      "Epoch 3/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.7659 - accuracy: 0.6615 - val_loss: 0.7903 - val_accuracy: 0.6727\n",
      "Epoch 4/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.7255 - accuracy: 0.6781 - val_loss: 0.7011 - val_accuracy: 0.6937\n",
      "Epoch 5/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.6904 - val_loss: 0.6740 - val_accuracy: 0.6993\n",
      "Epoch 6/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.6623 - accuracy: 0.7064 - val_loss: 0.6508 - val_accuracy: 0.7100\n",
      "Epoch 7/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.6362 - accuracy: 0.7179 - val_loss: 0.6448 - val_accuracy: 0.7142\n",
      "Epoch 8/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.6113 - accuracy: 0.7281 - val_loss: 0.6199 - val_accuracy: 0.7270\n",
      "Epoch 9/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.5885 - accuracy: 0.7382 - val_loss: 0.5751 - val_accuracy: 0.7489\n",
      "Epoch 10/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.5643 - accuracy: 0.7517 - val_loss: 0.5485 - val_accuracy: 0.7601\n",
      "Epoch 11/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.5474 - accuracy: 0.7598 - val_loss: 0.5602 - val_accuracy: 0.7581\n",
      "Epoch 12/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.5287 - accuracy: 0.7668 - val_loss: 0.5156 - val_accuracy: 0.7786\n",
      "Epoch 13/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.5088 - accuracy: 0.7759 - val_loss: 0.5165 - val_accuracy: 0.7737\n",
      "Epoch 14/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.4961 - accuracy: 0.7836 - val_loss: 0.5222 - val_accuracy: 0.7759\n",
      "Epoch 15/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.4817 - accuracy: 0.7893 - val_loss: 0.4884 - val_accuracy: 0.7897\n",
      "Epoch 16/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.4691 - accuracy: 0.7953 - val_loss: 0.4853 - val_accuracy: 0.7911\n",
      "Epoch 17/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.4536 - accuracy: 0.8024 - val_loss: 0.4612 - val_accuracy: 0.7997\n",
      "Epoch 18/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.4453 - accuracy: 0.8061 - val_loss: 0.4562 - val_accuracy: 0.8021\n",
      "Epoch 19/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.4301 - accuracy: 0.8138 - val_loss: 0.4435 - val_accuracy: 0.8097\n",
      "Epoch 20/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.4153 - accuracy: 0.8206 - val_loss: 0.4473 - val_accuracy: 0.8078\n",
      "Epoch 21/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.4077 - accuracy: 0.8243 - val_loss: 0.4412 - val_accuracy: 0.8074\n",
      "Epoch 22/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.3953 - accuracy: 0.8294 - val_loss: 0.4281 - val_accuracy: 0.8175\n",
      "Epoch 23/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.3917 - accuracy: 0.8320 - val_loss: 0.4168 - val_accuracy: 0.8225\n",
      "Epoch 24/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.3795 - accuracy: 0.8369 - val_loss: 0.4327 - val_accuracy: 0.8187\n",
      "Epoch 25/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.3707 - accuracy: 0.8404 - val_loss: 0.4025 - val_accuracy: 0.8275\n",
      "Epoch 26/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.3668 - accuracy: 0.8433 - val_loss: 0.4223 - val_accuracy: 0.8210\n",
      "Epoch 27/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.3550 - accuracy: 0.8484 - val_loss: 0.4073 - val_accuracy: 0.8277\n",
      "Epoch 28/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.3489 - accuracy: 0.8502 - val_loss: 0.3856 - val_accuracy: 0.8393\n",
      "Epoch 29/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8518 - val_loss: 0.3799 - val_accuracy: 0.8398\n",
      "Epoch 30/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.3350 - accuracy: 0.8579 - val_loss: 0.3745 - val_accuracy: 0.8427\n",
      "Epoch 31/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8612 - val_loss: 0.3607 - val_accuracy: 0.8510\n",
      "Epoch 32/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8619 - val_loss: 0.3914 - val_accuracy: 0.8375\n",
      "Epoch 33/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.3178 - accuracy: 0.8639 - val_loss: 0.4004 - val_accuracy: 0.8381\n",
      "Epoch 34/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.3161 - accuracy: 0.8659 - val_loss: 0.4111 - val_accuracy: 0.8296\n",
      "Epoch 35/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.3076 - accuracy: 0.8702 - val_loss: 0.3393 - val_accuracy: 0.8608\n",
      "Epoch 36/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.3047 - accuracy: 0.8711 - val_loss: 0.3662 - val_accuracy: 0.8510\n",
      "Epoch 37/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.2986 - accuracy: 0.8737 - val_loss: 0.3672 - val_accuracy: 0.8480\n",
      "Epoch 38/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.2974 - accuracy: 0.8739 - val_loss: 0.3418 - val_accuracy: 0.8609\n",
      "Epoch 39/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2880 - accuracy: 0.8785 - val_loss: 0.3614 - val_accuracy: 0.8555\n",
      "Epoch 40/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2841 - accuracy: 0.8805 - val_loss: 0.3411 - val_accuracy: 0.8583\n",
      "Epoch 41/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.8825 - val_loss: 0.3647 - val_accuracy: 0.8449\n",
      "Epoch 42/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2741 - accuracy: 0.8848 - val_loss: 0.3408 - val_accuracy: 0.8620\n",
      "Epoch 43/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2754 - accuracy: 0.8845 - val_loss: 0.3486 - val_accuracy: 0.8621\n",
      "Epoch 44/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.2684 - accuracy: 0.8888 - val_loss: 0.3349 - val_accuracy: 0.8631\n",
      "Epoch 45/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.2655 - accuracy: 0.8898 - val_loss: 0.3338 - val_accuracy: 0.8635\n",
      "Epoch 46/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.2641 - accuracy: 0.8906 - val_loss: 0.3546 - val_accuracy: 0.8536\n",
      "Epoch 47/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2571 - accuracy: 0.8920 - val_loss: 0.3334 - val_accuracy: 0.8649\n",
      "Epoch 48/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2571 - accuracy: 0.8928 - val_loss: 0.3361 - val_accuracy: 0.8666\n",
      "Epoch 49/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.2531 - accuracy: 0.8950 - val_loss: 0.3284 - val_accuracy: 0.8708\n",
      "Epoch 50/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2544 - accuracy: 0.8954 - val_loss: 0.3463 - val_accuracy: 0.8612\n",
      "Epoch 51/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2433 - accuracy: 0.8994 - val_loss: 0.3382 - val_accuracy: 0.8682\n",
      "Epoch 52/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2414 - accuracy: 0.9006 - val_loss: 0.3356 - val_accuracy: 0.8731\n",
      "Epoch 53/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.2428 - accuracy: 0.8983 - val_loss: 0.3329 - val_accuracy: 0.8674\n",
      "Epoch 54/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.2406 - accuracy: 0.9011 - val_loss: 0.3139 - val_accuracy: 0.8776\n",
      "Epoch 55/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.2357 - accuracy: 0.9024 - val_loss: 0.3314 - val_accuracy: 0.8692\n",
      "Epoch 56/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.2368 - accuracy: 0.9027 - val_loss: 0.3282 - val_accuracy: 0.8715\n",
      "Epoch 57/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2267 - accuracy: 0.9073 - val_loss: 0.3392 - val_accuracy: 0.8654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2270 - accuracy: 0.9072 - val_loss: 0.3130 - val_accuracy: 0.8786\n",
      "Epoch 59/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2276 - accuracy: 0.9062 - val_loss: 0.3301 - val_accuracy: 0.8698\n",
      "Epoch 60/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2294 - accuracy: 0.9063 - val_loss: 0.3062 - val_accuracy: 0.8793\n",
      "Epoch 61/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2179 - accuracy: 0.9105 - val_loss: 0.3423 - val_accuracy: 0.8678\n",
      "Epoch 62/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2220 - accuracy: 0.9094 - val_loss: 0.3209 - val_accuracy: 0.8784\n",
      "Epoch 63/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.2178 - accuracy: 0.9100 - val_loss: 0.3166 - val_accuracy: 0.8804\n",
      "Epoch 64/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.2180 - accuracy: 0.9108 - val_loss: 0.3250 - val_accuracy: 0.8786\n",
      "Epoch 65/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.2156 - accuracy: 0.9123 - val_loss: 0.3113 - val_accuracy: 0.8841\n",
      "Epoch 66/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.2121 - accuracy: 0.9129 - val_loss: 0.2984 - val_accuracy: 0.8881\n",
      "Epoch 67/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2093 - accuracy: 0.9157 - val_loss: 0.3280 - val_accuracy: 0.8789\n",
      "Epoch 68/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2094 - accuracy: 0.9156 - val_loss: 0.3155 - val_accuracy: 0.8819\n",
      "Epoch 69/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2075 - accuracy: 0.9164 - val_loss: 0.3092 - val_accuracy: 0.8834\n",
      "Epoch 70/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2031 - accuracy: 0.9167 - val_loss: 0.3170 - val_accuracy: 0.8839\n",
      "Epoch 71/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2018 - accuracy: 0.9182 - val_loss: 0.3215 - val_accuracy: 0.8809\n",
      "Epoch 72/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2006 - accuracy: 0.9187 - val_loss: 0.3093 - val_accuracy: 0.8834\n",
      "Epoch 73/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1972 - accuracy: 0.9194 - val_loss: 0.3086 - val_accuracy: 0.8862\n",
      "Epoch 74/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.2038 - accuracy: 0.9175 - val_loss: 0.3120 - val_accuracy: 0.8831\n",
      "Epoch 75/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1968 - accuracy: 0.9203 - val_loss: 0.3188 - val_accuracy: 0.8832\n",
      "Epoch 76/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2003 - accuracy: 0.9187 - val_loss: 0.3150 - val_accuracy: 0.8793\n",
      "Epoch 77/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1935 - accuracy: 0.9211 - val_loss: 0.3094 - val_accuracy: 0.8859\n",
      "Epoch 78/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1938 - accuracy: 0.9224 - val_loss: 0.3115 - val_accuracy: 0.8873\n",
      "Epoch 79/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1895 - accuracy: 0.9247 - val_loss: 0.3034 - val_accuracy: 0.8903\n",
      "Epoch 80/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1909 - accuracy: 0.9238 - val_loss: 0.3136 - val_accuracy: 0.8846\n",
      "Epoch 81/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1862 - accuracy: 0.9235 - val_loss: 0.3491 - val_accuracy: 0.8751\n",
      "Epoch 82/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1865 - accuracy: 0.9237 - val_loss: 0.3007 - val_accuracy: 0.8909\n",
      "Epoch 83/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1879 - accuracy: 0.9243 - val_loss: 0.3063 - val_accuracy: 0.8900\n",
      "Epoch 84/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1809 - accuracy: 0.9271 - val_loss: 0.3147 - val_accuracy: 0.8882\n",
      "Epoch 85/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1798 - accuracy: 0.9285 - val_loss: 0.3138 - val_accuracy: 0.8874\n",
      "Epoch 86/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1793 - accuracy: 0.9276 - val_loss: 0.3201 - val_accuracy: 0.8870\n",
      "Epoch 87/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.9259 - val_loss: 0.3339 - val_accuracy: 0.8811\n",
      "Epoch 88/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.9276 - val_loss: 0.3061 - val_accuracy: 0.8869\n",
      "Epoch 89/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1739 - accuracy: 0.9301 - val_loss: 0.3124 - val_accuracy: 0.8888\n",
      "Epoch 90/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.9307 - val_loss: 0.3195 - val_accuracy: 0.8867\n",
      "Epoch 91/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1728 - accuracy: 0.9302 - val_loss: 0.3016 - val_accuracy: 0.8926\n",
      "Epoch 92/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1751 - accuracy: 0.9294 - val_loss: 0.3087 - val_accuracy: 0.8876\n",
      "Epoch 93/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1709 - accuracy: 0.9306 - val_loss: 0.2907 - val_accuracy: 0.8943\n",
      "Epoch 94/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1724 - accuracy: 0.9301 - val_loss: 0.3038 - val_accuracy: 0.8954\n",
      "Epoch 95/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1730 - accuracy: 0.9292 - val_loss: 0.3176 - val_accuracy: 0.8891\n",
      "Epoch 96/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1711 - accuracy: 0.9319 - val_loss: 0.2980 - val_accuracy: 0.8960\n",
      "Epoch 97/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1625 - accuracy: 0.9342 - val_loss: 0.3104 - val_accuracy: 0.8912\n",
      "Epoch 98/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1661 - accuracy: 0.9341 - val_loss: 0.3096 - val_accuracy: 0.8932\n",
      "Epoch 99/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1643 - accuracy: 0.9339 - val_loss: 0.3358 - val_accuracy: 0.8851\n",
      "Epoch 100/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1661 - accuracy: 0.9338 - val_loss: 0.3172 - val_accuracy: 0.8922\n",
      "Epoch 101/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1642 - accuracy: 0.9352 - val_loss: 0.3070 - val_accuracy: 0.8903\n",
      "Epoch 102/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1602 - accuracy: 0.9356 - val_loss: 0.3216 - val_accuracy: 0.8896\n",
      "Epoch 103/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1577 - accuracy: 0.9377 - val_loss: 0.3125 - val_accuracy: 0.8928\n",
      "Epoch 104/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.9372 - val_loss: 0.3007 - val_accuracy: 0.8968\n",
      "Epoch 105/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1617 - accuracy: 0.9357 - val_loss: 0.3250 - val_accuracy: 0.8934\n",
      "Epoch 106/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1560 - accuracy: 0.9387 - val_loss: 0.2958 - val_accuracy: 0.8981\n",
      "Epoch 107/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1534 - accuracy: 0.9388 - val_loss: 0.3097 - val_accuracy: 0.8975\n",
      "Epoch 108/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1603 - accuracy: 0.9362 - val_loss: 0.3123 - val_accuracy: 0.8964\n",
      "Epoch 109/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1515 - accuracy: 0.9408 - val_loss: 0.3190 - val_accuracy: 0.8921\n",
      "Epoch 110/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1577 - accuracy: 0.9376 - val_loss: 0.3206 - val_accuracy: 0.8895\n",
      "Epoch 111/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1550 - accuracy: 0.9391 - val_loss: 0.3032 - val_accuracy: 0.8974\n",
      "Epoch 112/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1544 - accuracy: 0.9379 - val_loss: 0.2991 - val_accuracy: 0.8993\n",
      "Epoch 113/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1534 - accuracy: 0.9400 - val_loss: 0.3168 - val_accuracy: 0.8986\n",
      "Epoch 114/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1558 - accuracy: 0.9385 - val_loss: 0.3289 - val_accuracy: 0.8943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1512 - accuracy: 0.9409 - val_loss: 0.3112 - val_accuracy: 0.8989\n",
      "Epoch 116/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1535 - accuracy: 0.9397 - val_loss: 0.3225 - val_accuracy: 0.8942\n",
      "Epoch 117/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1512 - accuracy: 0.9393 - val_loss: 0.3293 - val_accuracy: 0.8896\n",
      "Epoch 118/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1478 - accuracy: 0.9413 - val_loss: 0.3193 - val_accuracy: 0.8976\n",
      "Epoch 119/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1456 - accuracy: 0.9418 - val_loss: 0.3236 - val_accuracy: 0.8901\n",
      "Epoch 120/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1495 - accuracy: 0.9419 - val_loss: 0.3102 - val_accuracy: 0.8989\n",
      "Epoch 121/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1481 - accuracy: 0.9403 - val_loss: 0.3263 - val_accuracy: 0.8945\n",
      "Epoch 122/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1481 - accuracy: 0.9419 - val_loss: 0.3159 - val_accuracy: 0.8965\n",
      "Epoch 123/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1433 - accuracy: 0.9436 - val_loss: 0.3192 - val_accuracy: 0.8963\n",
      "Epoch 124/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1444 - accuracy: 0.9430 - val_loss: 0.3086 - val_accuracy: 0.9014\n",
      "Epoch 125/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1424 - accuracy: 0.9439 - val_loss: 0.3253 - val_accuracy: 0.8976\n",
      "Epoch 126/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1440 - accuracy: 0.9431 - val_loss: 0.3265 - val_accuracy: 0.9001\n",
      "Epoch 127/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1449 - accuracy: 0.9424 - val_loss: 0.3177 - val_accuracy: 0.8976\n",
      "Epoch 128/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1438 - accuracy: 0.9436 - val_loss: 0.3057 - val_accuracy: 0.8998\n",
      "Epoch 129/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1388 - accuracy: 0.9458 - val_loss: 0.3033 - val_accuracy: 0.9027\n",
      "Epoch 130/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1356 - accuracy: 0.9468 - val_loss: 0.3410 - val_accuracy: 0.8911\n",
      "Epoch 131/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1470 - accuracy: 0.9417 - val_loss: 0.3132 - val_accuracy: 0.8985\n",
      "Epoch 132/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1406 - accuracy: 0.9451 - val_loss: 0.3417 - val_accuracy: 0.8917\n",
      "Epoch 133/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1346 - accuracy: 0.9472 - val_loss: 0.3344 - val_accuracy: 0.8965\n",
      "Epoch 134/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1380 - accuracy: 0.9458 - val_loss: 0.3202 - val_accuracy: 0.9006\n",
      "Epoch 135/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1367 - accuracy: 0.9460 - val_loss: 0.3078 - val_accuracy: 0.8995\n",
      "Epoch 136/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1362 - accuracy: 0.9467 - val_loss: 0.3178 - val_accuracy: 0.9014\n",
      "Epoch 137/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1364 - accuracy: 0.9474 - val_loss: 0.3162 - val_accuracy: 0.8973\n",
      "Epoch 138/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1328 - accuracy: 0.9477 - val_loss: 0.3386 - val_accuracy: 0.8929\n",
      "Epoch 139/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1369 - accuracy: 0.9462 - val_loss: 0.3041 - val_accuracy: 0.8999\n",
      "Epoch 140/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1338 - accuracy: 0.9479 - val_loss: 0.3280 - val_accuracy: 0.8956\n",
      "Epoch 141/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1350 - accuracy: 0.9468 - val_loss: 0.3135 - val_accuracy: 0.9025\n",
      "Epoch 142/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1291 - accuracy: 0.9496 - val_loss: 0.3246 - val_accuracy: 0.9019\n",
      "Epoch 143/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1289 - accuracy: 0.9490 - val_loss: 0.3465 - val_accuracy: 0.8939\n",
      "Epoch 144/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1357 - accuracy: 0.9466 - val_loss: 0.3191 - val_accuracy: 0.8983\n",
      "Epoch 145/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1310 - accuracy: 0.9492 - val_loss: 0.3330 - val_accuracy: 0.8991\n",
      "Epoch 146/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1352 - accuracy: 0.9472 - val_loss: 0.3179 - val_accuracy: 0.9017\n",
      "Epoch 147/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1293 - accuracy: 0.9490 - val_loss: 0.3263 - val_accuracy: 0.8989\n",
      "Epoch 148/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1279 - accuracy: 0.9500 - val_loss: 0.3374 - val_accuracy: 0.8970\n",
      "Epoch 149/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1303 - accuracy: 0.9493 - val_loss: 0.3229 - val_accuracy: 0.8974\n",
      "Epoch 150/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1284 - accuracy: 0.9492 - val_loss: 0.3104 - val_accuracy: 0.9011\n",
      "Epoch 151/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1267 - accuracy: 0.9506 - val_loss: 0.3037 - val_accuracy: 0.9029\n",
      "Epoch 152/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1268 - accuracy: 0.9493 - val_loss: 0.3205 - val_accuracy: 0.9020\n",
      "Epoch 153/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1293 - accuracy: 0.9492 - val_loss: 0.3395 - val_accuracy: 0.8968\n",
      "Epoch 154/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1306 - accuracy: 0.9492 - val_loss: 0.3444 - val_accuracy: 0.8944\n",
      "Epoch 155/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1264 - accuracy: 0.9509 - val_loss: 0.3275 - val_accuracy: 0.9016\n",
      "Epoch 156/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1244 - accuracy: 0.9523 - val_loss: 0.3153 - val_accuracy: 0.9001\n",
      "Epoch 157/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1221 - accuracy: 0.9517 - val_loss: 0.3198 - val_accuracy: 0.8961\n",
      "Epoch 158/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1238 - accuracy: 0.9512 - val_loss: 0.3470 - val_accuracy: 0.8936\n",
      "Epoch 159/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1210 - accuracy: 0.9525 - val_loss: 0.3471 - val_accuracy: 0.8967\n",
      "Epoch 160/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1273 - accuracy: 0.9516 - val_loss: 0.3189 - val_accuracy: 0.9034\n",
      "Epoch 161/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1170 - accuracy: 0.9546 - val_loss: 0.3262 - val_accuracy: 0.9041\n",
      "Epoch 162/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1213 - accuracy: 0.9535 - val_loss: 0.3263 - val_accuracy: 0.8969\n",
      "Epoch 163/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1252 - accuracy: 0.9516 - val_loss: 0.3131 - val_accuracy: 0.9046\n",
      "Epoch 164/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1226 - accuracy: 0.9522 - val_loss: 0.3402 - val_accuracy: 0.8994\n",
      "Epoch 165/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1173 - accuracy: 0.9542 - val_loss: 0.3276 - val_accuracy: 0.9022\n",
      "Epoch 166/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1227 - accuracy: 0.9526 - val_loss: 0.3222 - val_accuracy: 0.9029\n",
      "Epoch 167/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1181 - accuracy: 0.9540 - val_loss: 0.3181 - val_accuracy: 0.9021\n",
      "Epoch 168/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1145 - accuracy: 0.9555 - val_loss: 0.3101 - val_accuracy: 0.9072\n",
      "Epoch 169/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1176 - accuracy: 0.9541 - val_loss: 0.3129 - val_accuracy: 0.9026\n",
      "Epoch 170/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1162 - accuracy: 0.9549 - val_loss: 0.3305 - val_accuracy: 0.9019\n",
      "Epoch 171/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1215 - accuracy: 0.9534 - val_loss: 0.3740 - val_accuracy: 0.8913\n",
      "Epoch 172/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1201 - accuracy: 0.9529 - val_loss: 0.3294 - val_accuracy: 0.9061\n",
      "Epoch 173/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1143 - accuracy: 0.9552 - val_loss: 0.3324 - val_accuracy: 0.9020\n",
      "Epoch 174/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1146 - accuracy: 0.9560 - val_loss: 0.3381 - val_accuracy: 0.9006\n",
      "Epoch 175/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1137 - accuracy: 0.9566 - val_loss: 0.3197 - val_accuracy: 0.9045\n",
      "Epoch 176/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1154 - accuracy: 0.9555 - val_loss: 0.3153 - val_accuracy: 0.9105\n",
      "Epoch 177/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1170 - accuracy: 0.9546 - val_loss: 0.3498 - val_accuracy: 0.9017\n",
      "Epoch 178/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1127 - accuracy: 0.9558 - val_loss: 0.3589 - val_accuracy: 0.8996\n",
      "Epoch 179/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1166 - accuracy: 0.9548 - val_loss: 0.3299 - val_accuracy: 0.9074\n",
      "Epoch 180/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1133 - accuracy: 0.9556 - val_loss: 0.3239 - val_accuracy: 0.9039\n",
      "Epoch 181/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1161 - accuracy: 0.9556 - val_loss: 0.3371 - val_accuracy: 0.8971\n",
      "Epoch 182/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1118 - accuracy: 0.9563 - val_loss: 0.3166 - val_accuracy: 0.9090\n",
      "Epoch 183/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1189 - accuracy: 0.9558 - val_loss: 0.3186 - val_accuracy: 0.9057\n",
      "Epoch 184/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1103 - accuracy: 0.9574 - val_loss: 0.3324 - val_accuracy: 0.9036\n",
      "Epoch 185/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1131 - accuracy: 0.9565 - val_loss: 0.3270 - val_accuracy: 0.9057\n",
      "Epoch 186/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1123 - accuracy: 0.9560 - val_loss: 0.3151 - val_accuracy: 0.9049\n",
      "Epoch 187/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1064 - accuracy: 0.9587 - val_loss: 0.3402 - val_accuracy: 0.8975\n",
      "Epoch 188/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1147 - accuracy: 0.9551 - val_loss: 0.3296 - val_accuracy: 0.9047\n",
      "Epoch 189/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1092 - accuracy: 0.9576 - val_loss: 0.3330 - val_accuracy: 0.9007\n",
      "Epoch 190/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1108 - accuracy: 0.9573 - val_loss: 0.3147 - val_accuracy: 0.9086\n",
      "Epoch 191/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1062 - accuracy: 0.9592 - val_loss: 0.3466 - val_accuracy: 0.9050\n",
      "Epoch 192/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1116 - accuracy: 0.9567 - val_loss: 0.3189 - val_accuracy: 0.9066\n",
      "Epoch 193/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1101 - accuracy: 0.9577 - val_loss: 0.3157 - val_accuracy: 0.9040\n",
      "Epoch 194/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1077 - accuracy: 0.9583 - val_loss: 0.3197 - val_accuracy: 0.9049\n",
      "Epoch 195/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1152 - accuracy: 0.9553 - val_loss: 0.3321 - val_accuracy: 0.9005\n",
      "Epoch 196/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1057 - accuracy: 0.9590 - val_loss: 0.3201 - val_accuracy: 0.9077\n",
      "Epoch 197/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1043 - accuracy: 0.9592 - val_loss: 0.3479 - val_accuracy: 0.9034\n",
      "Epoch 198/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1135 - accuracy: 0.9566 - val_loss: 0.3152 - val_accuracy: 0.9084\n",
      "Epoch 199/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1102 - accuracy: 0.9576 - val_loss: 0.3079 - val_accuracy: 0.9077\n",
      "Epoch 200/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1114 - accuracy: 0.9572 - val_loss: 0.3182 - val_accuracy: 0.9050\n",
      "Epoch 201/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1023 - accuracy: 0.9604 - val_loss: 0.3381 - val_accuracy: 0.9049\n",
      "Epoch 202/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1095 - accuracy: 0.9583 - val_loss: 0.3125 - val_accuracy: 0.9079\n",
      "Epoch 203/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1045 - accuracy: 0.9581 - val_loss: 0.3285 - val_accuracy: 0.9062\n",
      "Epoch 204/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1022 - accuracy: 0.9604 - val_loss: 0.3352 - val_accuracy: 0.9054\n",
      "Epoch 205/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1096 - accuracy: 0.9578 - val_loss: 0.3196 - val_accuracy: 0.9109\n",
      "Epoch 206/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1024 - accuracy: 0.9607 - val_loss: 0.3060 - val_accuracy: 0.9090\n",
      "Epoch 207/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.9616 - val_loss: 0.3385 - val_accuracy: 0.9058\n",
      "Epoch 208/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1075 - accuracy: 0.9600 - val_loss: 0.3294 - val_accuracy: 0.9051\n",
      "Epoch 209/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1030 - accuracy: 0.9610 - val_loss: 0.3166 - val_accuracy: 0.9066\n",
      "Epoch 210/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1008 - accuracy: 0.9613 - val_loss: 0.3070 - val_accuracy: 0.9116\n",
      "Epoch 211/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1041 - accuracy: 0.9607 - val_loss: 0.3239 - val_accuracy: 0.9072\n",
      "Epoch 212/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0993 - accuracy: 0.9613 - val_loss: 0.3286 - val_accuracy: 0.9063\n",
      "Epoch 213/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1031 - accuracy: 0.9599 - val_loss: 0.3311 - val_accuracy: 0.9002\n",
      "Epoch 214/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1062 - accuracy: 0.9601 - val_loss: 0.3196 - val_accuracy: 0.9085\n",
      "Epoch 215/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9606 - val_loss: 0.3217 - val_accuracy: 0.9071\n",
      "Epoch 216/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1022 - accuracy: 0.9596 - val_loss: 0.3228 - val_accuracy: 0.9091\n",
      "Epoch 217/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1008 - accuracy: 0.9617 - val_loss: 0.3479 - val_accuracy: 0.9030\n",
      "Epoch 218/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1055 - accuracy: 0.9593 - val_loss: 0.3273 - val_accuracy: 0.9067\n",
      "Epoch 219/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1011 - accuracy: 0.9604 - val_loss: 0.3070 - val_accuracy: 0.9100\n",
      "Epoch 220/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.1034 - accuracy: 0.9596 - val_loss: 0.3353 - val_accuracy: 0.9059\n",
      "Epoch 221/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0992 - accuracy: 0.9617 - val_loss: 0.3361 - val_accuracy: 0.9070\n",
      "Epoch 222/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0980 - accuracy: 0.9640 - val_loss: 0.3346 - val_accuracy: 0.9054\n",
      "Epoch 223/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9642 - val_loss: 0.3529 - val_accuracy: 0.9033\n",
      "Epoch 224/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1013 - accuracy: 0.9600 - val_loss: 0.3343 - val_accuracy: 0.9054\n",
      "Epoch 225/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9629 - val_loss: 0.3302 - val_accuracy: 0.9105\n",
      "Epoch 226/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0943 - accuracy: 0.9645 - val_loss: 0.3381 - val_accuracy: 0.9056\n",
      "Epoch 227/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9630 - val_loss: 0.3509 - val_accuracy: 0.9054\n",
      "Epoch 228/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1012 - accuracy: 0.9614 - val_loss: 0.3510 - val_accuracy: 0.9042\n",
      "Epoch 229/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0982 - accuracy: 0.9630 - val_loss: 0.3286 - val_accuracy: 0.9126\n",
      "Epoch 230/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0933 - accuracy: 0.9639 - val_loss: 0.3384 - val_accuracy: 0.9075\n",
      "Epoch 231/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0992 - accuracy: 0.9621 - val_loss: 0.3326 - val_accuracy: 0.9087\n",
      "Epoch 232/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0994 - accuracy: 0.9619 - val_loss: 0.3530 - val_accuracy: 0.9043\n",
      "Epoch 233/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9624 - val_loss: 0.3416 - val_accuracy: 0.9062\n",
      "Epoch 234/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9651 - val_loss: 0.3377 - val_accuracy: 0.9080\n",
      "Epoch 235/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9619 - val_loss: 0.3533 - val_accuracy: 0.9055\n",
      "Epoch 236/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9657 - val_loss: 0.3308 - val_accuracy: 0.9095\n",
      "Epoch 237/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9644 - val_loss: 0.3400 - val_accuracy: 0.9078\n",
      "Epoch 238/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9634 - val_loss: 0.3220 - val_accuracy: 0.9117\n",
      "Epoch 239/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0985 - accuracy: 0.9628 - val_loss: 0.3814 - val_accuracy: 0.9017\n",
      "Epoch 240/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9637 - val_loss: 0.3370 - val_accuracy: 0.9089\n",
      "Epoch 241/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0936 - accuracy: 0.9647 - val_loss: 0.3520 - val_accuracy: 0.9036\n",
      "Epoch 242/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0923 - accuracy: 0.9655 - val_loss: 0.3499 - val_accuracy: 0.9028\n",
      "Epoch 243/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9644 - val_loss: 0.3494 - val_accuracy: 0.9069\n",
      "Epoch 244/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9648 - val_loss: 0.3405 - val_accuracy: 0.9091\n",
      "Epoch 245/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.9660 - val_loss: 0.3494 - val_accuracy: 0.9074\n",
      "Epoch 246/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9649 - val_loss: 0.3450 - val_accuracy: 0.9037\n",
      "Epoch 247/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0952 - accuracy: 0.9638 - val_loss: 0.3230 - val_accuracy: 0.9116\n",
      "Epoch 248/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9629 - val_loss: 0.3343 - val_accuracy: 0.9101\n",
      "Epoch 249/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0920 - accuracy: 0.9650 - val_loss: 0.3467 - val_accuracy: 0.9066\n",
      "Epoch 250/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0923 - accuracy: 0.9643 - val_loss: 0.3369 - val_accuracy: 0.9112\n",
      "Epoch 251/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0988 - accuracy: 0.9634 - val_loss: 0.3712 - val_accuracy: 0.9021\n",
      "Epoch 252/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1030 - accuracy: 0.9613 - val_loss: 0.3470 - val_accuracy: 0.9095\n",
      "Epoch 253/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0878 - accuracy: 0.9666 - val_loss: 0.3303 - val_accuracy: 0.9132\n",
      "Epoch 254/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9660 - val_loss: 0.3619 - val_accuracy: 0.9033\n",
      "Epoch 255/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9646 - val_loss: 0.3896 - val_accuracy: 0.9000\n",
      "Epoch 256/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9640 - val_loss: 0.3524 - val_accuracy: 0.9124\n",
      "Epoch 257/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0911 - accuracy: 0.9654 - val_loss: 0.3500 - val_accuracy: 0.9080\n",
      "Epoch 258/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0913 - accuracy: 0.9652 - val_loss: 0.3665 - val_accuracy: 0.9059\n",
      "Epoch 259/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0888 - accuracy: 0.9668 - val_loss: 0.3616 - val_accuracy: 0.9072\n",
      "Epoch 260/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0877 - accuracy: 0.9667 - val_loss: 0.3519 - val_accuracy: 0.9121\n",
      "Epoch 261/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0863 - accuracy: 0.9668 - val_loss: 0.3711 - val_accuracy: 0.9049\n",
      "Epoch 262/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0961 - accuracy: 0.9640 - val_loss: 0.3307 - val_accuracy: 0.9144\n",
      "Epoch 263/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0875 - accuracy: 0.9665 - val_loss: 0.3325 - val_accuracy: 0.9127\n",
      "Epoch 264/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9638 - val_loss: 0.3403 - val_accuracy: 0.9103\n",
      "Epoch 265/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0866 - accuracy: 0.9673 - val_loss: 0.3378 - val_accuracy: 0.9117\n",
      "Epoch 266/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.9656 - val_loss: 0.3430 - val_accuracy: 0.9102\n",
      "Epoch 267/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0860 - accuracy: 0.9677 - val_loss: 0.3658 - val_accuracy: 0.9094\n",
      "Epoch 268/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9636 - val_loss: 0.3407 - val_accuracy: 0.9079\n",
      "Epoch 269/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0817 - accuracy: 0.9685 - val_loss: 0.3511 - val_accuracy: 0.9066\n",
      "Epoch 270/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0886 - accuracy: 0.9668 - val_loss: 0.3567 - val_accuracy: 0.9076\n",
      "Epoch 271/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9654 - val_loss: 0.3416 - val_accuracy: 0.9100\n",
      "Epoch 272/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0867 - accuracy: 0.9672 - val_loss: 0.3586 - val_accuracy: 0.9077\n",
      "Epoch 273/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.9668 - val_loss: 0.3323 - val_accuracy: 0.9082\n",
      "Epoch 274/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.9665 - val_loss: 0.3413 - val_accuracy: 0.9084\n",
      "Epoch 275/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0840 - accuracy: 0.9678 - val_loss: 0.3443 - val_accuracy: 0.9090\n",
      "Epoch 276/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0864 - accuracy: 0.9676 - val_loss: 0.3513 - val_accuracy: 0.9112\n",
      "Epoch 277/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0880 - accuracy: 0.9665 - val_loss: 0.3396 - val_accuracy: 0.9131\n",
      "Epoch 278/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0867 - accuracy: 0.9678 - val_loss: 0.3641 - val_accuracy: 0.9066\n",
      "Epoch 279/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0888 - accuracy: 0.9661 - val_loss: 0.3666 - val_accuracy: 0.9065\n",
      "Epoch 280/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0885 - accuracy: 0.9669 - val_loss: 0.3668 - val_accuracy: 0.9087\n",
      "Epoch 281/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0846 - accuracy: 0.9684 - val_loss: 0.3487 - val_accuracy: 0.9094\n",
      "Epoch 282/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0852 - accuracy: 0.9681 - val_loss: 0.3602 - val_accuracy: 0.9069\n",
      "Epoch 283/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0856 - accuracy: 0.9687 - val_loss: 0.3578 - val_accuracy: 0.9075\n",
      "Epoch 284/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0841 - accuracy: 0.9681 - val_loss: 0.3698 - val_accuracy: 0.9067\n",
      "Epoch 285/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0897 - accuracy: 0.9663 - val_loss: 0.3507 - val_accuracy: 0.9080\n",
      "Epoch 286/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0867 - accuracy: 0.9677 - val_loss: 0.3772 - val_accuracy: 0.9077\n",
      "Epoch 287/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0823 - accuracy: 0.9689 - val_loss: 0.3619 - val_accuracy: 0.9079\n",
      "Epoch 288/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0859 - accuracy: 0.9683 - val_loss: 0.3379 - val_accuracy: 0.9104\n",
      "Epoch 289/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0838 - accuracy: 0.9689 - val_loss: 0.3500 - val_accuracy: 0.9087\n",
      "Epoch 290/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0802 - accuracy: 0.9698 - val_loss: 0.3528 - val_accuracy: 0.9124\n",
      "Epoch 291/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0871 - accuracy: 0.9669 - val_loss: 0.3505 - val_accuracy: 0.9086\n",
      "Epoch 292/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0857 - accuracy: 0.9673 - val_loss: 0.3460 - val_accuracy: 0.9093\n",
      "Epoch 293/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0839 - accuracy: 0.9681 - val_loss: 0.3343 - val_accuracy: 0.9114\n",
      "Epoch 294/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0834 - accuracy: 0.9688 - val_loss: 0.3493 - val_accuracy: 0.9088\n",
      "Epoch 295/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0794 - accuracy: 0.9697 - val_loss: 0.3700 - val_accuracy: 0.9055\n",
      "Epoch 296/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0864 - accuracy: 0.9674 - val_loss: 0.3466 - val_accuracy: 0.9113\n",
      "Epoch 297/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0817 - accuracy: 0.9688 - val_loss: 0.3417 - val_accuracy: 0.9137\n",
      "Epoch 298/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0833 - accuracy: 0.9680 - val_loss: 0.3826 - val_accuracy: 0.9089\n",
      "Epoch 299/300\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0840 - accuracy: 0.9683 - val_loss: 0.3588 - val_accuracy: 0.9098\n",
      "Epoch 300/300\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.0846 - accuracy: 0.9668 - val_loss: 0.3750 - val_accuracy: 0.9033\n"
     ]
    }
   ],
   "source": [
    "input_depth = layers.Input(shape = (30, 40))\n",
    "input_force = layers.Input(shape = (6, ))\n",
    "\n",
    "# first branch\n",
    "x = layers.Flatten(input_shape=(30, 40))(input_depth)\n",
    "x = layers.Dense(units=200, activation='relu')(x)\n",
    "x = layers.Dense(units=200, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(100, activation='relu')(x)\n",
    "x = tf.keras.Model(inputs= input_depth, outputs = x)\n",
    "\n",
    "# second branch\n",
    "y = layers.Dense(units=200, activation='relu')(input_force)\n",
    "y = layers.Dense(units=200, activation='relu')(y)\n",
    "y = layers.Dropout(0.2)(y)\n",
    "y = layers.Dense(100, activation='relu')(y)\n",
    "y = tf.keras.Model(inputs= input_force, outputs = y)\n",
    "\n",
    "# combine two branches\n",
    "combined = layers.concatenate([x.output, y.output])\n",
    "\n",
    "# regression to one output\n",
    "z = layers.Dense(units=100, activation='relu')(combined)\n",
    "z = layers.Dropout(0.2)(z)\n",
    "z = layers.Dense(units=100, activation='relu')(combined)\n",
    "z = layers.Dense(units = 5, activation = 'linear')(z)\n",
    "\n",
    "model_fd = tf.keras.Model(inputs = [x.input, y.input], outputs = z)\n",
    "\n",
    "model_fd.compile(optimizer='adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "history = model_fd.fit([depth_train, force_train],theta_z_train, verbose = 1, epochs = 300, batch_size = 128,\n",
    "                   validation_data = ([depth_test, force_test], theta_z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13991,)\n"
     ]
    }
   ],
   "source": [
    "# probability_model = tf.keras.Sequential([model_dp, tf.keras.layers.Softmax()])\n",
    "predictions = model_fd.predict([depth_test, force_test])\n",
    "y_predictions = np.argmax(predictions, axis = 1)\n",
    "print(y_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9032949753412909\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(theta_z_test, y_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model_fd.save('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model')\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as mpl\n",
    "# mpl.rcParams['figure.figsize'] = (20,7)\n",
    "# mpl.rc('xtick', labelsize=18) \n",
    "# mpl.rc('ytick', labelsize=18)\n",
    "# plt.plot(theta_z_test[0:100])\n",
    "# plt.plot(y_predictions[0:100],'--')\n",
    "# plt.legend(['Ground Truth', 'Prediction'])\n",
    "# plt.xlabel('Sample', fontsize=18)\n",
    "# plt.ylabel('Angle (degree)', fontsize=18)\n",
    "# plt.show()\n",
    "# #plt.savefig('ground_v_prediction_zoomed in.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n"
     ]
    }
   ],
   "source": [
    "foldername = r'Test_Subject_Leo/'\n",
    "sub_name = foldername + 'test32'\n",
    "dep_name = sub_name + r'/depth_processed_leo_test' + '32' + '.avi';\n",
    "depth_fresh =  dep_cam_reduced(dep_name)/255.0\n",
    "\n",
    "\n",
    "qtm_file = sub_name + r'/qtm_processed_leo_test' + '32' + '_' + '11_25_2020' + '.txt'\n",
    "theta_z = pd.read_csv(qtm_file)\n",
    "theta_z_fresh = theta_z.iloc[:,0].values\n",
    "n_class = 5\n",
    "min_val = -50 \n",
    "max_val = 50\n",
    "\n",
    "sat_theta_z = saturate(theta_z_fresh, min_val, max_val)\n",
    "labeled_z_fresh = create_label(n_class, sat_theta_z, min_val, max_val)\n",
    "\n",
    "force_file = sub_name + r'/fcss_processed_leo_test' + '32' + '_' + '11_25_2020' + '.txt'\n",
    "force_fresh = pd.read_csv(force_file)\n",
    "force_fresh = force_fresh/BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_fresh = depth_fresh[0:len(labeled_z_fresh)]\n",
    "\n",
    "force_fresh = force_fresh[0:len(labeled_z_fresh)]\n",
    "\n",
    "y_predic_unseen = model_fd.predict([depth_fresh, force_fresh])\n",
    "y_predic_unseen = np.argmax(y_predic_unseen, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5469126568603009"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(labeled_z_fresh, y_predic_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5338652040222721"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(labeled_z_fresh, y_predic_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_absolute_error(theta_z_test, y_prediction)\n",
    "# mpl.rcParams['figure.figsize'] = (10,7)\n",
    "# mpl.rc('xtick', labelsize=18) \n",
    "# mpl.rc('ytick', labelsize=18)\n",
    "# plt.plot(labeled_z_fresh)\n",
    "# plt.plot(y_predic_unseen,'--')\n",
    "# plt.legend(['Ground Truth', 'Prediction'])\n",
    "# plt.xlabel('Sample', fontsize=18)\n",
    "# plt.ylabel('Angle (degree)', fontsize=18)\n",
    "# plt.show()\n",
    "# #plt.savefig('ground_v_prediction_zoomed in.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
