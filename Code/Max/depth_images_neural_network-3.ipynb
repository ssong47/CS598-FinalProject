{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read input data (depth camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read video frame\n",
    "def dep_cam(dep_v_name):\n",
    "    dep_v = cv2.VideoCapture(dep_v_name)\n",
    "    ret, frame = dep_v.read()\n",
    "    counter=0\n",
    "\n",
    "    frame_count = int(dep_v.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # frame_height = int(frame.shape[0]/5)\n",
    "    # frame_width = int(frame.shape[1]/5)\n",
    "    frame_height = frame.shape[0]\n",
    "    frame_width = frame.shape[1]\n",
    "    depth_frames = np.empty((frame_count, frame_height, frame_width))\n",
    "\n",
    "    while(dep_v.isOpened()):\n",
    "        ret, frame = dep_v.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        if ret == True:\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray_frame = cv2.resize(gray_frame, (frame_width, frame_height), interpolation = cv2.INTER_AREA)\n",
    "            depth_frames[counter] = gray_frame\n",
    "            counter+=1\n",
    "\n",
    "    dep_v.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return depth_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read input depth data (test folder 13, 14, 15, 16, 24 from Preliminary result v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read output angle data\n",
    "# ignore\n",
    "foldername = r'Test_Subject_Leo_Preliminary_v4/'\n",
    "test_folder = ['test13', 'test14', 'test15', 'test16', 'test24' ]\n",
    "test_num = ['13', '14', '15', '16', '24']\n",
    "sub_name = foldername + test_folder[4]\n",
    "dep_name = sub_name + r'/depth_processed_leo_test' + test_num[4] + '.avi';\n",
    "depth =  dep_cam(dep_name)\n",
    "for i in range(4):\n",
    "    subfolder_name = foldername + test_folder[i]\n",
    "    dep_video_name = subfolder_name + r'/depth_processed_leo_test' + test_num[i] + '.avi'\n",
    "    dep_v_temp =  dep_cam(dep_video_name)\n",
    "    depth = np.concatenate((dep_v_temp, depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read input depth data (test folder 24, 30, 31, 32, 33, 35 from Preliminary result v5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read output angle data\n",
    "foldername = r'Test_Subject_Leo/'\n",
    "test_folder = ['test24', 'test30', 'test31', 'test32','test33', 'test35' ]\n",
    "test_num = ['24', '30', '31', '32', '33', '35']\n",
    "sub_name = foldername + test_folder[0]\n",
    "dep_name = sub_name + r'/depth_processed_leo_test' + test_num[0] + '.avi';\n",
    "depth =  dep_cam(dep_name)\n",
    "for i in range(1, 6):\n",
    "    subfolder_name = foldername + test_folder[i]\n",
    "    dep_video_name = subfolder_name + r'/depth_processed_leo_test' + test_num[i] + '.avi'\n",
    "    #print(dep_video_name)\n",
    "    dep_v_temp =  dep_cam(dep_video_name)\n",
    "    depth = np.concatenate((depth, dep_v_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(depth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot one single frame\n",
    "# plt.imshow(depth[5000], interpolation='nearest')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read output data (angle) in test_folder 13, 14, 15, 16, 24 from Preliminary v4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder_name = foldername + test_folder[4]\n",
    "qtm_file = subfolder_name + r'/qtm_processed_leo_test' + test_num[4] + '_' + '11_15_2020' + '.txt'\n",
    "theta_z = pd.read_csv(qtm_file)\n",
    "theta_z = theta_z.iloc[:,0].values\n",
    "for i in range(4):\n",
    "    subfolder_name = foldername + test_folder[i]\n",
    "#     if test_folder[i] == 'test24':\n",
    "#         qtm_file = subfolder_name + r'/qtm_processed_leo_test' + test_num[i] + '_' + '11_15_2020' + '.txt'\n",
    "#     else: \n",
    "    qtm_file = subfolder_name + r'/qtm_processed_leo_test' + test_num[i] + '_' + '11_11_2020' + '.txt'\n",
    "    dataset_y =  pd.read_csv(qtm_file)\n",
    "    theta_z_temp = dataset_y.iloc[:,0].values\n",
    "    theta_z = np.concatenate((theta_z, theta_z_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read output angle data (test folder 24, 30, 31, 32, 33, 35 from Preliminary result v5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = r'Test_Subject_Leo/'\n",
    "test_folder = ['test24', 'test30', 'test31', 'test32','test33', 'test35' ]\n",
    "test_num = ['24', '30', '31', '32', '33', '35']\n",
    "subfolder_name = foldername + test_folder[0]\n",
    "qtm_file = subfolder_name + r'/qtm_processed_leo_test' + test_num[0] + '_' + '11_15_2020' + '.txt'\n",
    "theta_z = pd.read_csv(qtm_file)\n",
    "theta_z = theta_z.iloc[:,0].values\n",
    "for i in range(1,6):\n",
    "    subfolder_name = foldername + test_folder[i]\n",
    "    if test_folder[i] == 'test30' or test_folder[i] == 'test31':\n",
    "        qtm_file = subfolder_name + r'/qtm_processed_leo_test' + test_num[i] + '_' + '11_24_2020' + '.txt'\n",
    "    else: \n",
    "        qtm_file = subfolder_name + r'/qtm_processed_leo_test' + test_num[i] + '_' + '11_25_2020' + '.txt'\n",
    "    dataset_y =  pd.read_csv(qtm_file)\n",
    "    theta_z_temp = dataset_y.iloc[:,0].values\n",
    "    theta_z = np.concatenate((theta_z, theta_z_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(theta_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_flatten = depth.reshape(19200, 82381).T\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_sk, X_test_sk, y_train_sk, y_test_sk = train_test_split(depth_flatten, theta_z, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use scikit learn builtin neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sklearn MLPRegressor\n",
    "model_sk = MLPRegressor(hidden_layer_sizes = (200, ), activation = 'relu', learning_rate = 'constant',\n",
    "                        random_state = 1, max_iter = 500, early_stopping = True, verbose = True).fit(X_train_sk, y_train_sk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_prediction_sk = model_sk.predict(X_test_sk)\n",
    "mean_absolute_error(y_test_sk, y_prediction_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (20,5)\n",
    "plt.plot(y_test)\n",
    "plt.plot(y_prediction_sk,'--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# sc.fit(X_train)\n",
    "# Xtrain = sc.transform(X_train)\n",
    "# Xtest = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sklearn MLPRegressor\n",
    "model_sk = MLPRegressor(hidden_layer_sizes = (100, ), activation = 'relu', learning_rate = 'constant',\n",
    "                        random_state = 1, max_iter = 500, early_stopping = True, verbose = True).fit(X_train_sk, y_train_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_prediction_sk = model_sk.predict(X_test_sk)\n",
    "mean_absolute_error(y_test_sk, y_prediction_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tensorflow NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(depth, theta_z, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 10, restore_best_weights = True)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(120, 160)),\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=192, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss= 'mae',\n",
    "              metrics=['mae'])\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "model.fit(X_train_tf, y_train_tf, epochs=3,callbacks = [tensorboard_callback], \n",
    "                    batch_size = 128, validation_data = (X_test_tf, y_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(len(training_loss))\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction_tf = model.predict(X_test_tf)\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (20,5)\n",
    "plt.plot(y_test)\n",
    "plt.plot(y_prediction_tf,'--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction_tf = model.predict(X_test_tf)\n",
    "mean_absolute_error(y_test_tf, y_prediction_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the dimension of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read video frame\n",
    "def dep_cam_reduced(dep_v_name):\n",
    "    dep_v = cv2.VideoCapture(dep_v_name)\n",
    "    ret, frame = dep_v.read()\n",
    "    counter=0\n",
    "\n",
    "    frame_count = int(dep_v.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "#     frame_height = int(frame.shape[0]/5)\n",
    "#     frame_width = int(frame.shape[1]/5)\n",
    "#     frame_height = frame.shape[0]\n",
    "#     frame_width = frame.shape[1]\n",
    "    frame_height = 30\n",
    "    frame_width = 40\n",
    "    depth_frames = np.empty((frame_count, frame_height, frame_width))\n",
    "\n",
    "    while(dep_v.isOpened()):\n",
    "        ret, frame = dep_v.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        if ret == True:\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray_frame = cv2.resize(gray_frame, (frame_width, frame_height), interpolation = cv2.INTER_AREA)\n",
    "            depth_frames[counter] = gray_frame\n",
    "            counter+=1\n",
    "\n",
    "    dep_v.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return depth_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read output depth images data\n",
    "foldername = r'Test_Subject_Leo/'\n",
    "test_folder = ['test24', 'test30', 'test31', 'test32','test33', 'test35' ]\n",
    "test_num = ['24', '30', '31', '32', '33', '35']\n",
    "sub_name = foldername + test_folder[0]\n",
    "dep_name = sub_name + r'/depth_processed_leo_test' + test_num[0] + '.avi';\n",
    "depth =  dep_cam_reduced(dep_name)\n",
    "for i in range(1, 6):\n",
    "    subfolder_name = foldername + test_folder[i]\n",
    "    dep_video_name = subfolder_name + r'/depth_processed_leo_test' + test_num[i] + '.avi'\n",
    "    #print(dep_video_name)\n",
    "    dep_v_temp =  dep_cam_reduced(dep_video_name)/255.0\n",
    "    depth = np.concatenate((depth, dep_v_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(depth.shape)\n",
    "print(theta_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(depth, theta_z, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3, restore_best_weights = True)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(30, 40)),\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=192, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss= 'mae',\n",
    "              metrics=['mae'])\n",
    "\n",
    "history = model.fit(X_train_tf, y_train_tf, epochs=250, callbacks = [callback], batch_size = 128, \n",
    "                    verbose = 1, validation_data = (X_test_tf, y_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(len(training_loss))\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(X_test_tf)\n",
    "\n",
    "import matplotlib as mpl\n",
    "%matplotlib tk\n",
    "mpl.rcParams['figure.figsize'] = (20,5)\n",
    "plt.plot(y_test_tf)\n",
    "plt.plot(y_prediction,'--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test_tf, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using tanh as activation function\n",
    "import tensorflow as tf\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(120, 160)),\n",
    "    tf.keras.layers.Dense(units=256, activation='tanh'),\n",
    "    tf.keras.layers.Dense(units=192, activation='tanh'),\n",
    "    tf.keras.layers.Dense(units=128, activation='tanh'),\n",
    "    tf.keras.layers.Dense(1, activation = 'linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss= 'mae',\n",
    "              metrics=['mae'])\n",
    "\n",
    "model.fit(X_train, y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(X_test)\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (20,5)\n",
    "plt.plot(y_test)\n",
    "plt.plot(y_prediction,'--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try use sigmoid as activation function\n",
    "import tensorflow as tf\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(120, 160)),\n",
    "    tf.keras.layers.Dense(units=256, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(units=192, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(units=128, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss= 'mae',\n",
    "              metrics=['mae'])\n",
    "\n",
    "model.fit(X_train, y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Observation: Comparing to the NN that uses tanh and sigmoid activation function, the rectified linear unit fucntion seemed to have better performance (lower mae) when the layers number are the same. Also, the choice of metrics of model evaluation seemed to be important (mse is quite large compared to mae). But I wonder what happened to my plots ;(     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Also, right now I am using a dimension of 120 * 160, performing a dimensionality reduction could be helpful for extracting necessary features. A longer epoch time may also improve performance. Tried sklearn neural network MLPRegressor but does not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add dropout to the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(depth, theta_z, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 10, restore_best_weights = True)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(120, 160)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=192, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss= 'mae',\n",
    "              metrics=['mae'])\n",
    "\n",
    "history = model.fit(X_train_tf, y_train_tf, epochs=1000,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (X_test_tf, y_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(X_test_tf)\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (20,5)\n",
    "plt.plot(y_test)\n",
    "plt.plot(y_prediction,'--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(len(training_loss))\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN with reduced dimensionality and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout at visible layer\n",
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(depth, theta_z, test_size = 0.2, random_state = 0)\n",
    "import tensorflow as tf\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 10, restore_best_weights = True)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(30, 40)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=192, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss= 'mae',\n",
    "              metrics=['mae'])\n",
    "\n",
    "history = model.fit(X_train_tf, y_train_tf, epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (X_test_tf, y_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(len(training_loss))\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout at both visible layer and hidden layer\n",
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(depth, theta_z, test_size = 0.2, random_state = 0)\n",
    "import tensorflow as tf\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 10, restore_best_weights = True)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(30, 40)),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss= 'mae',\n",
    "              metrics=['mae'])\n",
    "\n",
    "history = model.fit(X_train_tf, y_train_tf, epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (X_test_tf, y_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(len(training_loss))\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_prediction = model.predict(X_test_tf)\n",
    "\n",
    "import matplotlib as mpl\n",
    "%matplotlib tk\n",
    "mpl.rcParams['figure.figsize'] = (20,5)\n",
    "plt.plot(y_test_tf)\n",
    "plt.plot(y_prediction,'--')\n",
    "plt.legend(['Ground Truth', 'Prediction'])\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Angle (degree)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred = model.predict(X_test_tf)\n",
    "mean_absolute_error(y_test_tf, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize input signal (depth images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_z_temp = theta_z.reshape(-1,1)\n",
    "trans = KBinsDiscretizer(n_bins=40, encode='onehot-dense', strategy='quantile')\n",
    "data = trans.fit_transform(theta_z_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(theta_z, 'r--')\n",
    "plt.plot(data,'b-')\n",
    "plt.legend(['Continuous', 'Discrete'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Angle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mulitple inputs in neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read foce data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder_name = foldername + test_folder[0]\n",
    "force_file = subfolder_name + r'/fcss_processed_leo_test' + test_num[0] + '_' + '11_15_2020' + '.txt'\n",
    "force = pd.read_csv(force_file)\n",
    "force = force.iloc[:,:].values\n",
    "for i in range(1,6):\n",
    "    subfolder_name = foldername + test_folder[i]\n",
    "    if test_folder[i] == 'test30' or test_folder[i] == 'test31':\n",
    "        force_file = subfolder_name + r'/fcss_processed_leo_test' + test_num[i] + '_' + '11_24_2020' + '.txt'\n",
    "    else: \n",
    "        force_file = subfolder_name + r'/fcss_processed_leo_test' + test_num[i] + '_' + '11_25_2020' + '.txt'\n",
    "    dataset_y =  pd.read_csv(force_file)\n",
    "    force_temp = dataset_y.iloc[:,:].values\n",
    "    force = np.concatenate((force, force_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(force.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "depth_train, depth_test, force_train, force_test, theta_z_train, theta_z_test = train_test_split(depth, force, theta_z, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "input_depth = layers.Input(shape = (30, 40))\n",
    "input_force = layers.Input(shape = (6, ))\n",
    "\n",
    "# first branch\n",
    "x = layers.Flatten(input_shape=(30, 40))(input_depth)\n",
    "x = layers.Dense(units=128, activation='relu')(x)\n",
    "x = layers.Dense(units=64, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "x = tf.keras.Model(inputs= input_depth, outputs = x)\n",
    "\n",
    "# second branch\n",
    "y = layers.Dense(units=128, activation='relu')(input_force)\n",
    "y = layers.Dense(units=64, activation='relu')(y)\n",
    "y = layers.Dense(32, activation='relu')(y)\n",
    "y = layers.Dropout(0.2)(y)\n",
    "y = tf.keras.Model(inputs= input_force, outputs = y)\n",
    "\n",
    "# combine two branches\n",
    "combined = layers.concatenate([x.output, y.output])\n",
    "\n",
    "# regression to one output\n",
    "z = layers.Dense(units=32, activation='relu')(combined)\n",
    "z = layers.Dropout(0.2)(z)\n",
    "z = layers.Dense(units=16, activation='relu')(combined)\n",
    "z = layers.Dense(1, activation='linear')(z)\n",
    "model = tf.keras.Model(inputs = [x.input, y.input], outputs = z)\n",
    "\n",
    "#tf.keras.utils.plot_model(model, to_file = 'model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 8.3145 - mae: 8.3145 - val_loss: 7.2741 - val_mae: 7.2741\n",
      "Epoch 2/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.1364 - mae: 7.1364 - val_loss: 6.7326 - val_mae: 6.7326\n",
      "Epoch 3/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.5907 - mae: 6.5907 - val_loss: 6.2742 - val_mae: 6.2742\n",
      "Epoch 4/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.1415 - mae: 6.1415 - val_loss: 5.9257 - val_mae: 5.9257\n",
      "Epoch 5/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.8203 - mae: 5.8203 - val_loss: 5.6613 - val_mae: 5.6613\n",
      "Epoch 6/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.6211 - mae: 5.6211 - val_loss: 5.5527 - val_mae: 5.5527\n",
      "Epoch 7/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 5.5462 - mae: 5.5462 - val_loss: 5.5380 - val_mae: 5.5380\n",
      "Epoch 8/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 5.3819 - mae: 5.3819 - val_loss: 5.2563 - val_mae: 5.2563\n",
      "Epoch 9/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.2914 - mae: 5.2914 - val_loss: 5.4441 - val_mae: 5.4441\n",
      "Epoch 10/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 5.1857 - mae: 5.1857 - val_loss: 5.1627 - val_mae: 5.1627\n",
      "Epoch 11/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.0945 - mae: 5.0945 - val_loss: 5.2140 - val_mae: 5.2140\n",
      "Epoch 12/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 5.0372 - mae: 5.0372 - val_loss: 5.0749 - val_mae: 5.0749\n",
      "Epoch 13/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.9485 - mae: 4.9485 - val_loss: 5.0023 - val_mae: 5.0023\n",
      "Epoch 14/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.8745 - mae: 4.8745 - val_loss: 4.8436 - val_mae: 4.8436\n",
      "Epoch 15/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.7877 - mae: 4.7877 - val_loss: 4.8040 - val_mae: 4.8040\n",
      "Epoch 16/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.7590 - mae: 4.7590 - val_loss: 4.7784 - val_mae: 4.7784\n",
      "Epoch 17/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.7182 - mae: 4.7182 - val_loss: 4.7501 - val_mae: 4.7501\n",
      "Epoch 18/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.6917 - mae: 4.6917 - val_loss: 4.6539 - val_mae: 4.6539\n",
      "Epoch 19/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.6354 - mae: 4.6354 - val_loss: 4.6712 - val_mae: 4.6712\n",
      "Epoch 20/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 4.5479 - mae: 4.5479 - val_loss: 4.6115 - val_mae: 4.6115\n",
      "Epoch 21/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.5075 - mae: 4.5075 - val_loss: 4.7212 - val_mae: 4.7212\n",
      "Epoch 22/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 4.4626 - mae: 4.4626 - val_loss: 4.5372 - val_mae: 4.5372\n",
      "Epoch 23/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.4200 - mae: 4.4200 - val_loss: 4.5037 - val_mae: 4.5037\n",
      "Epoch 24/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.3754 - mae: 4.3754 - val_loss: 4.4154 - val_mae: 4.4154\n",
      "Epoch 25/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.3204 - mae: 4.3204 - val_loss: 4.4757 - val_mae: 4.4757\n",
      "Epoch 26/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.2663 - mae: 4.2663 - val_loss: 4.4558 - val_mae: 4.4558\n",
      "Epoch 27/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.2547 - mae: 4.2547 - val_loss: 4.5127 - val_mae: 4.5127\n",
      "Epoch 28/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.2284 - mae: 4.2284 - val_loss: 4.4310 - val_mae: 4.4310\n",
      "Epoch 29/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.1977 - mae: 4.1977 - val_loss: 4.3554 - val_mae: 4.3554\n",
      "Epoch 30/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.1459 - mae: 4.1459 - val_loss: 4.2443 - val_mae: 4.2443\n",
      "Epoch 31/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.0948 - mae: 4.0948 - val_loss: 4.2184 - val_mae: 4.2184\n",
      "Epoch 32/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.1225 - mae: 4.1225 - val_loss: 4.2667 - val_mae: 4.2667\n",
      "Epoch 33/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.0894 - mae: 4.0894 - val_loss: 4.2414 - val_mae: 4.2414\n",
      "Epoch 34/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.0433 - mae: 4.0433 - val_loss: 4.1633 - val_mae: 4.1633\n",
      "Epoch 35/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.0046 - mae: 4.0046 - val_loss: 4.1406 - val_mae: 4.1406\n",
      "Epoch 36/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.9688 - mae: 3.9688 - val_loss: 4.0363 - val_mae: 4.0363\n",
      "Epoch 37/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.9812 - mae: 3.9812 - val_loss: 4.2622 - val_mae: 4.2622\n",
      "Epoch 38/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.9722 - mae: 3.9722 - val_loss: 4.1584 - val_mae: 4.1584\n",
      "Epoch 39/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.9355 - mae: 3.9355 - val_loss: 4.1244 - val_mae: 4.1244\n",
      "Epoch 40/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.9093 - mae: 3.9093 - val_loss: 4.0286 - val_mae: 4.0286\n",
      "Epoch 41/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.8915 - mae: 3.8915 - val_loss: 4.3047 - val_mae: 4.3047\n",
      "Epoch 42/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.8663 - mae: 3.8663 - val_loss: 4.2979 - val_mae: 4.2979\n",
      "Epoch 43/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.8660 - mae: 3.8660 - val_loss: 3.9866 - val_mae: 3.9866\n",
      "Epoch 44/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.8380 - mae: 3.8380 - val_loss: 3.9454 - val_mae: 3.9454\n",
      "Epoch 45/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.8329 - mae: 3.8329 - val_loss: 3.9862 - val_mae: 3.9862\n",
      "Epoch 46/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.8052 - mae: 3.8052 - val_loss: 3.9267 - val_mae: 3.9267\n",
      "Epoch 47/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7910 - mae: 3.7910 - val_loss: 4.0280 - val_mae: 4.0280\n",
      "Epoch 48/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7756 - mae: 3.7756 - val_loss: 3.9212 - val_mae: 3.9212\n",
      "Epoch 49/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7626 - mae: 3.7626 - val_loss: 3.9553 - val_mae: 3.9553\n",
      "Epoch 50/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7339 - mae: 3.7339 - val_loss: 4.0301 - val_mae: 4.0301\n",
      "Epoch 51/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7140 - mae: 3.7140 - val_loss: 3.9870 - val_mae: 3.9870\n",
      "Epoch 52/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7161 - mae: 3.7161 - val_loss: 3.8601 - val_mae: 3.8601\n",
      "Epoch 53/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6926 - mae: 3.6926 - val_loss: 3.9203 - val_mae: 3.9203\n",
      "Epoch 54/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6711 - mae: 3.6711 - val_loss: 3.9765 - val_mae: 3.9765\n",
      "Epoch 55/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6940 - mae: 3.6940 - val_loss: 3.9870 - val_mae: 3.9870\n",
      "Epoch 56/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6580 - mae: 3.6580 - val_loss: 3.8430 - val_mae: 3.8430\n",
      "Epoch 57/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6403 - mae: 3.6403 - val_loss: 3.8962 - val_mae: 3.8962\n",
      "Epoch 58/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6236 - mae: 3.6236 - val_loss: 3.8896 - val_mae: 3.8896\n",
      "Epoch 59/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5703 - mae: 3.5703 - val_loss: 3.7679 - val_mae: 3.7679\n",
      "Epoch 60/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5466 - mae: 3.5466 - val_loss: 3.7178 - val_mae: 3.7178\n",
      "Epoch 61/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5203 - mae: 3.5203 - val_loss: 3.7656 - val_mae: 3.7656\n",
      "Epoch 62/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5290 - mae: 3.5290 - val_loss: 3.8298 - val_mae: 3.8298\n",
      "Epoch 63/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5180 - mae: 3.5180 - val_loss: 3.6987 - val_mae: 3.6987\n",
      "Epoch 64/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4925 - mae: 3.4925 - val_loss: 3.5943 - val_mae: 3.5943\n",
      "Epoch 65/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4628 - mae: 3.4628 - val_loss: 3.6770 - val_mae: 3.6770\n",
      "Epoch 66/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4648 - mae: 3.4648 - val_loss: 3.7312 - val_mae: 3.7312\n",
      "Epoch 67/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4609 - mae: 3.4609 - val_loss: 3.7004 - val_mae: 3.7004\n",
      "Epoch 68/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4496 - mae: 3.4496 - val_loss: 3.7238 - val_mae: 3.7238\n",
      "Epoch 69/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4347 - mae: 3.4347 - val_loss: 3.6587 - val_mae: 3.6587\n",
      "Epoch 70/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4465 - mae: 3.4465 - val_loss: 3.7527 - val_mae: 3.7527\n",
      "Epoch 71/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4201 - mae: 3.4201 - val_loss: 3.5990 - val_mae: 3.5990\n",
      "Epoch 72/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3951 - mae: 3.3951 - val_loss: 3.6022 - val_mae: 3.6022\n",
      "Epoch 73/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4320 - mae: 3.4320 - val_loss: 3.6888 - val_mae: 3.6888\n",
      "Epoch 74/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3710 - mae: 3.3710 - val_loss: 3.5649 - val_mae: 3.5649\n",
      "Epoch 75/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3838 - mae: 3.3838 - val_loss: 3.6054 - val_mae: 3.6054\n",
      "Epoch 76/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3621 - mae: 3.3621 - val_loss: 3.5603 - val_mae: 3.5603\n",
      "Epoch 77/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3693 - mae: 3.3693 - val_loss: 3.6560 - val_mae: 3.6560\n",
      "Epoch 78/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3655 - mae: 3.3655 - val_loss: 3.6094 - val_mae: 3.6094\n",
      "Epoch 79/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3559 - mae: 3.3559 - val_loss: 3.6540 - val_mae: 3.6540\n",
      "Epoch 80/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3358 - mae: 3.3358 - val_loss: 3.6632 - val_mae: 3.6632\n",
      "Epoch 81/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3327 - mae: 3.3327 - val_loss: 3.5195 - val_mae: 3.5195\n",
      "Epoch 82/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3018 - mae: 3.3018 - val_loss: 3.4736 - val_mae: 3.4736\n",
      "Epoch 83/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3137 - mae: 3.3137 - val_loss: 3.5985 - val_mae: 3.5985\n",
      "Epoch 84/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2829 - mae: 3.2829 - val_loss: 3.5920 - val_mae: 3.5920\n",
      "Epoch 85/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2924 - mae: 3.2924 - val_loss: 3.5558 - val_mae: 3.5558\n",
      "Epoch 86/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2883 - mae: 3.2883 - val_loss: 3.4524 - val_mae: 3.4524\n",
      "Epoch 87/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2707 - mae: 3.2707 - val_loss: 3.5825 - val_mae: 3.5825\n",
      "Epoch 88/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2536 - mae: 3.2536 - val_loss: 3.6389 - val_mae: 3.6389\n",
      "Epoch 89/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2455 - mae: 3.2455 - val_loss: 3.4090 - val_mae: 3.4090\n",
      "Epoch 90/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2522 - mae: 3.2522 - val_loss: 3.6266 - val_mae: 3.6266\n",
      "Epoch 91/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2708 - mae: 3.2708 - val_loss: 3.6182 - val_mae: 3.6182\n",
      "Epoch 92/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2255 - mae: 3.2255 - val_loss: 3.5803 - val_mae: 3.5803\n",
      "Epoch 93/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2827 - mae: 3.2827 - val_loss: 3.5092 - val_mae: 3.5092\n",
      "Epoch 94/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2303 - mae: 3.2303 - val_loss: 3.6004 - val_mae: 3.6004\n",
      "Epoch 95/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2143 - mae: 3.2143 - val_loss: 3.3795 - val_mae: 3.3795\n",
      "Epoch 96/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2072 - mae: 3.2072 - val_loss: 3.4042 - val_mae: 3.4042\n",
      "Epoch 97/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2015 - mae: 3.2015 - val_loss: 3.4576 - val_mae: 3.4576\n",
      "Epoch 98/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2152 - mae: 3.2152 - val_loss: 3.5476 - val_mae: 3.5476\n",
      "Epoch 99/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1817 - mae: 3.1817 - val_loss: 3.5073 - val_mae: 3.5073\n",
      "Epoch 100/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1670 - mae: 3.1670 - val_loss: 3.6174 - val_mae: 3.6174\n",
      "Epoch 101/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1859 - mae: 3.1859 - val_loss: 3.3748 - val_mae: 3.3748\n",
      "Epoch 102/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1477 - mae: 3.1477 - val_loss: 3.4680 - val_mae: 3.4680\n",
      "Epoch 103/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1656 - mae: 3.1656 - val_loss: 3.3641 - val_mae: 3.3641\n",
      "Epoch 104/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1613 - mae: 3.1613 - val_loss: 3.6102 - val_mae: 3.6102\n",
      "Epoch 105/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1628 - mae: 3.1628 - val_loss: 3.4115 - val_mae: 3.4115\n",
      "Epoch 106/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1549 - mae: 3.1549 - val_loss: 3.3277 - val_mae: 3.3277\n",
      "Epoch 107/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1250 - mae: 3.1250 - val_loss: 3.4028 - val_mae: 3.4028\n",
      "Epoch 108/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1366 - mae: 3.1366 - val_loss: 3.3475 - val_mae: 3.3475\n",
      "Epoch 109/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1088 - mae: 3.1088 - val_loss: 3.4095 - val_mae: 3.4095\n",
      "Epoch 110/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1147 - mae: 3.1147 - val_loss: 3.4193 - val_mae: 3.4193\n",
      "Epoch 111/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1026 - mae: 3.1026 - val_loss: 3.3400 - val_mae: 3.3400\n",
      "Epoch 112/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0919 - mae: 3.0919 - val_loss: 3.3118 - val_mae: 3.3118\n",
      "Epoch 113/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0897 - mae: 3.0897 - val_loss: 3.3839 - val_mae: 3.3839\n",
      "Epoch 114/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0683 - mae: 3.0683 - val_loss: 3.3636 - val_mae: 3.3636\n",
      "Epoch 115/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0990 - mae: 3.0990 - val_loss: 3.3652 - val_mae: 3.3652\n",
      "Epoch 116/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0560 - mae: 3.0560 - val_loss: 3.3150 - val_mae: 3.3150\n",
      "Epoch 117/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0835 - mae: 3.0835 - val_loss: 3.3626 - val_mae: 3.3626\n",
      "Epoch 118/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0638 - mae: 3.0638 - val_loss: 3.2831 - val_mae: 3.2831\n",
      "Epoch 119/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0401 - mae: 3.0401 - val_loss: 3.5210 - val_mae: 3.5210\n",
      "Epoch 120/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0526 - mae: 3.0526 - val_loss: 3.4113 - val_mae: 3.4113\n",
      "Epoch 121/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0308 - mae: 3.0308 - val_loss: 3.3015 - val_mae: 3.3015\n",
      "Epoch 122/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0259 - mae: 3.0259 - val_loss: 3.3985 - val_mae: 3.3985\n",
      "Epoch 123/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0586 - mae: 3.0586 - val_loss: 3.2252 - val_mae: 3.2252\n",
      "Epoch 124/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0144 - mae: 3.0144 - val_loss: 3.3710 - val_mae: 3.3710\n",
      "Epoch 125/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0306 - mae: 3.0306 - val_loss: 3.4031 - val_mae: 3.4031\n",
      "Epoch 126/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0067 - mae: 3.0067 - val_loss: 3.4799 - val_mae: 3.4799\n",
      "Epoch 127/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9873 - mae: 2.9873 - val_loss: 3.3884 - val_mae: 3.3884\n",
      "Epoch 128/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0159 - mae: 3.0159 - val_loss: 3.3963 - val_mae: 3.3963\n",
      "Epoch 129/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9799 - mae: 2.9799 - val_loss: 3.3145 - val_mae: 3.3145\n",
      "Epoch 130/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9919 - mae: 2.9919 - val_loss: 3.3079 - val_mae: 3.3079\n",
      "Epoch 131/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9983 - mae: 2.9983 - val_loss: 3.3394 - val_mae: 3.3394\n",
      "Epoch 132/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9570 - mae: 2.9570 - val_loss: 3.3112 - val_mae: 3.3112\n",
      "Epoch 133/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9850 - mae: 2.9850 - val_loss: 3.4820 - val_mae: 3.4820\n",
      "Epoch 134/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9701 - mae: 2.9701 - val_loss: 3.3919 - val_mae: 3.3919\n",
      "Epoch 135/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9757 - mae: 2.9757 - val_loss: 3.3700 - val_mae: 3.3700\n",
      "Epoch 136/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9547 - mae: 2.9547 - val_loss: 3.2977 - val_mae: 3.2977\n",
      "Epoch 137/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9540 - mae: 2.9540 - val_loss: 3.3738 - val_mae: 3.3738\n",
      "Epoch 138/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9519 - mae: 2.9519 - val_loss: 3.3680 - val_mae: 3.3680\n",
      "Epoch 139/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9434 - mae: 2.9434 - val_loss: 3.3045 - val_mae: 3.3045\n",
      "Epoch 140/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9658 - mae: 2.9658 - val_loss: 3.3717 - val_mae: 3.3717\n",
      "Epoch 141/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9569 - mae: 2.9569 - val_loss: 3.5065 - val_mae: 3.5065\n",
      "Epoch 142/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9435 - mae: 2.9435 - val_loss: 3.2690 - val_mae: 3.2690\n",
      "Epoch 143/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9335 - mae: 2.9335 - val_loss: 3.3246 - val_mae: 3.3246\n",
      "Epoch 144/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9384 - mae: 2.9384 - val_loss: 3.2381 - val_mae: 3.2381\n",
      "Epoch 145/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9362 - mae: 2.9362 - val_loss: 3.2912 - val_mae: 3.2912\n",
      "Epoch 146/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9251 - mae: 2.9251 - val_loss: 3.2488 - val_mae: 3.2488\n",
      "Epoch 147/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9238 - mae: 2.9238 - val_loss: 3.1754 - val_mae: 3.1754\n",
      "Epoch 148/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9420 - mae: 2.9420 - val_loss: 3.3488 - val_mae: 3.3488\n",
      "Epoch 149/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8934 - mae: 2.8934 - val_loss: 3.3063 - val_mae: 3.3063\n",
      "Epoch 150/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8806 - mae: 2.8806 - val_loss: 3.3118 - val_mae: 3.3118\n",
      "Epoch 151/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8717 - mae: 2.8717 - val_loss: 3.2758 - val_mae: 3.2758\n",
      "Epoch 152/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8808 - mae: 2.8808 - val_loss: 3.4326 - val_mae: 3.4326\n",
      "Epoch 153/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8957 - mae: 2.8957 - val_loss: 3.3404 - val_mae: 3.3404\n",
      "Epoch 154/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8630 - mae: 2.8630 - val_loss: 3.2875 - val_mae: 3.2875\n",
      "Epoch 155/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8724 - mae: 2.8724 - val_loss: 3.2294 - val_mae: 3.2294\n",
      "Epoch 156/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8841 - mae: 2.8841 - val_loss: 3.2025 - val_mae: 3.2025\n",
      "Epoch 157/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8726 - mae: 2.8726 - val_loss: 3.2041 - val_mae: 3.2041\n",
      "Epoch 158/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8729 - mae: 2.8729 - val_loss: 3.2352 - val_mae: 3.2352\n",
      "Epoch 159/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8679 - mae: 2.8679 - val_loss: 3.2400 - val_mae: 3.2400\n",
      "Epoch 160/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8641 - mae: 2.8641 - val_loss: 3.2480 - val_mae: 3.2480\n",
      "Epoch 161/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8763 - mae: 2.8763 - val_loss: 3.2641 - val_mae: 3.2641\n",
      "Epoch 162/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8416 - mae: 2.8416 - val_loss: 3.1692 - val_mae: 3.1692\n",
      "Epoch 163/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8580 - mae: 2.8580 - val_loss: 3.1989 - val_mae: 3.1989\n",
      "Epoch 164/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8283 - mae: 2.8283 - val_loss: 3.2124 - val_mae: 3.2124\n",
      "Epoch 165/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8643 - mae: 2.8643 - val_loss: 3.1780 - val_mae: 3.1780\n",
      "Epoch 166/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8543 - mae: 2.8543 - val_loss: 3.2653 - val_mae: 3.2653\n",
      "Epoch 167/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8316 - mae: 2.8316 - val_loss: 3.2265 - val_mae: 3.2265\n",
      "Epoch 168/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8367 - mae: 2.8367 - val_loss: 3.2608 - val_mae: 3.2608\n",
      "Epoch 169/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8223 - mae: 2.8223 - val_loss: 3.2907 - val_mae: 3.2907\n",
      "Epoch 170/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8179 - mae: 2.8179 - val_loss: 3.3773 - val_mae: 3.3773\n",
      "Epoch 171/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8252 - mae: 2.8252 - val_loss: 3.2921 - val_mae: 3.2921\n",
      "Epoch 172/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8205 - mae: 2.8205 - val_loss: 3.2766 - val_mae: 3.2766\n",
      "Epoch 173/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8124 - mae: 2.8124 - val_loss: 3.2224 - val_mae: 3.2224\n",
      "Epoch 174/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8225 - mae: 2.8225 - val_loss: 3.2443 - val_mae: 3.2443\n",
      "Epoch 175/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8239 - mae: 2.8239 - val_loss: 3.3713 - val_mae: 3.3713\n",
      "Epoch 176/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7986 - mae: 2.7986 - val_loss: 3.2568 - val_mae: 3.2568\n",
      "Epoch 177/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7910 - mae: 2.7910 - val_loss: 3.1357 - val_mae: 3.1357\n",
      "Epoch 178/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7865 - mae: 2.7865 - val_loss: 3.2103 - val_mae: 3.2103\n",
      "Epoch 179/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7960 - mae: 2.7960 - val_loss: 3.2332 - val_mae: 3.2332\n",
      "Epoch 180/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7673 - mae: 2.7673 - val_loss: 3.2642 - val_mae: 3.2642\n",
      "Epoch 181/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7985 - mae: 2.7985 - val_loss: 3.2915 - val_mae: 3.2915\n",
      "Epoch 182/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7685 - mae: 2.7685 - val_loss: 3.2736 - val_mae: 3.2736\n",
      "Epoch 183/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7816 - mae: 2.7816 - val_loss: 3.1749 - val_mae: 3.1749\n",
      "Epoch 184/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7656 - mae: 2.7656 - val_loss: 3.2932 - val_mae: 3.2932\n",
      "Epoch 185/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7712 - mae: 2.7712 - val_loss: 3.1970 - val_mae: 3.1970\n",
      "Epoch 186/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7675 - mae: 2.7675 - val_loss: 3.1675 - val_mae: 3.1675\n",
      "Epoch 187/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7509 - mae: 2.7509 - val_loss: 3.1820 - val_mae: 3.1820\n",
      "Epoch 188/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7543 - mae: 2.7543 - val_loss: 3.1572 - val_mae: 3.1572\n",
      "Epoch 189/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7491 - mae: 2.7491 - val_loss: 3.3639 - val_mae: 3.3639\n",
      "Epoch 190/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7480 - mae: 2.7480 - val_loss: 3.2221 - val_mae: 3.2221\n",
      "Epoch 191/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7534 - mae: 2.7534 - val_loss: 3.1213 - val_mae: 3.1213\n",
      "Epoch 192/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7485 - mae: 2.7485 - val_loss: 3.2304 - val_mae: 3.2304\n",
      "Epoch 193/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7360 - mae: 2.7360 - val_loss: 3.1049 - val_mae: 3.1049\n",
      "Epoch 194/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7453 - mae: 2.7453 - val_loss: 3.1727 - val_mae: 3.1727\n",
      "Epoch 195/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7297 - mae: 2.7297 - val_loss: 3.2344 - val_mae: 3.2344\n",
      "Epoch 196/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7345 - mae: 2.7345 - val_loss: 3.2151 - val_mae: 3.2151\n",
      "Epoch 197/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7274 - mae: 2.7274 - val_loss: 3.1189 - val_mae: 3.1189\n",
      "Epoch 198/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7246 - mae: 2.7246 - val_loss: 3.2106 - val_mae: 3.2106\n",
      "Epoch 199/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7267 - mae: 2.7267 - val_loss: 3.1084 - val_mae: 3.1084\n",
      "Epoch 200/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7283 - mae: 2.7283 - val_loss: 3.2345 - val_mae: 3.2345\n",
      "Epoch 201/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7473 - mae: 2.7473 - val_loss: 3.0852 - val_mae: 3.0852\n",
      "Epoch 202/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7060 - mae: 2.7060 - val_loss: 3.2062 - val_mae: 3.2062\n",
      "Epoch 203/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7458 - mae: 2.7458 - val_loss: 3.2039 - val_mae: 3.2039\n",
      "Epoch 204/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7134 - mae: 2.7134 - val_loss: 3.1600 - val_mae: 3.1600\n",
      "Epoch 205/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6956 - mae: 2.6956 - val_loss: 3.2353 - val_mae: 3.2353\n",
      "Epoch 206/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7192 - mae: 2.7192 - val_loss: 3.1161 - val_mae: 3.1161\n",
      "Epoch 207/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6889 - mae: 2.6889 - val_loss: 3.1154 - val_mae: 3.1154\n",
      "Epoch 208/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7251 - mae: 2.7251 - val_loss: 3.2248 - val_mae: 3.2248\n",
      "Epoch 209/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6884 - mae: 2.6884 - val_loss: 3.3314 - val_mae: 3.3314\n",
      "Epoch 210/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8468 - mae: 2.8468 - val_loss: 3.2766 - val_mae: 3.2766\n",
      "Epoch 211/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7480 - mae: 2.7480 - val_loss: 3.2753 - val_mae: 3.2753\n",
      "Epoch 212/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7184 - mae: 2.7184 - val_loss: 3.1744 - val_mae: 3.1744\n",
      "Epoch 213/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6845 - mae: 2.6845 - val_loss: 3.2338 - val_mae: 3.2338\n",
      "Epoch 214/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6903 - mae: 2.6903 - val_loss: 3.1844 - val_mae: 3.1844\n",
      "Epoch 215/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6967 - mae: 2.6967 - val_loss: 3.1726 - val_mae: 3.1726\n",
      "Epoch 216/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6792 - mae: 2.6792 - val_loss: 3.2410 - val_mae: 3.2410\n",
      "Epoch 217/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6873 - mae: 2.6873 - val_loss: 3.0869 - val_mae: 3.0869\n",
      "Epoch 218/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6661 - mae: 2.6661 - val_loss: 3.1582 - val_mae: 3.1582\n",
      "Epoch 219/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6678 - mae: 2.6678 - val_loss: 3.1335 - val_mae: 3.1335\n",
      "Epoch 220/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6664 - mae: 2.6664 - val_loss: 3.2297 - val_mae: 3.2297\n",
      "Epoch 221/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6874 - mae: 2.6874 - val_loss: 3.1913 - val_mae: 3.1913\n",
      "Epoch 222/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6727 - mae: 2.6727 - val_loss: 3.1555 - val_mae: 3.1555\n",
      "Epoch 223/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6564 - mae: 2.6564 - val_loss: 3.0745 - val_mae: 3.0745\n",
      "Epoch 224/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6689 - mae: 2.6689 - val_loss: 3.1394 - val_mae: 3.1394\n",
      "Epoch 225/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6534 - mae: 2.6534 - val_loss: 3.1688 - val_mae: 3.1688\n",
      "Epoch 226/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6624 - mae: 2.6624 - val_loss: 3.2013 - val_mae: 3.2013\n",
      "Epoch 227/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6442 - mae: 2.6442 - val_loss: 3.0821 - val_mae: 3.0821\n",
      "Epoch 228/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6677 - mae: 2.6677 - val_loss: 3.1605 - val_mae: 3.1605\n",
      "Epoch 229/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6552 - mae: 2.6552 - val_loss: 3.1390 - val_mae: 3.1390\n",
      "Epoch 230/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6411 - mae: 2.6411 - val_loss: 3.1134 - val_mae: 3.1134\n",
      "Epoch 231/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6625 - mae: 2.6625 - val_loss: 3.1789 - val_mae: 3.1789\n",
      "Epoch 232/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6411 - mae: 2.6411 - val_loss: 3.1226 - val_mae: 3.1226\n",
      "Epoch 233/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6311 - mae: 2.6311 - val_loss: 3.1291 - val_mae: 3.1291\n",
      "Epoch 234/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6420 - mae: 2.6420 - val_loss: 3.1150 - val_mae: 3.1150\n",
      "Epoch 235/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6298 - mae: 2.6298 - val_loss: 3.0928 - val_mae: 3.0928\n",
      "Epoch 236/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6358 - mae: 2.6358 - val_loss: 3.1296 - val_mae: 3.1296\n",
      "Epoch 237/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6335 - mae: 2.6335 - val_loss: 3.2105 - val_mae: 3.2105\n",
      "Epoch 238/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6445 - mae: 2.6445 - val_loss: 3.1359 - val_mae: 3.1359\n",
      "Epoch 239/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6246 - mae: 2.6246 - val_loss: 3.1063 - val_mae: 3.1063\n",
      "Epoch 240/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6187 - mae: 2.6187 - val_loss: 3.0964 - val_mae: 3.0964\n",
      "Epoch 241/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6393 - mae: 2.6393 - val_loss: 3.1543 - val_mae: 3.1543\n",
      "Epoch 242/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6332 - mae: 2.6332 - val_loss: 3.1703 - val_mae: 3.1703\n",
      "Epoch 243/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6295 - mae: 2.6295 - val_loss: 3.1821 - val_mae: 3.1821\n",
      "Epoch 244/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5988 - mae: 2.5988 - val_loss: 3.0746 - val_mae: 3.0746\n",
      "Epoch 245/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5996 - mae: 2.5996 - val_loss: 3.2345 - val_mae: 3.2345\n",
      "Epoch 246/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6179 - mae: 2.6179 - val_loss: 3.1597 - val_mae: 3.1597\n",
      "Epoch 247/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6024 - mae: 2.6024 - val_loss: 3.1654 - val_mae: 3.1654\n",
      "Epoch 248/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6056 - mae: 2.6056 - val_loss: 3.1468 - val_mae: 3.1468\n",
      "Epoch 249/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6015 - mae: 2.6015 - val_loss: 3.2377 - val_mae: 3.2377\n",
      "Epoch 250/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5971 - mae: 2.5971 - val_loss: 3.1962 - val_mae: 3.1962\n",
      "Epoch 251/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6015 - mae: 2.6015 - val_loss: 3.1347 - val_mae: 3.1347\n",
      "Epoch 252/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5935 - mae: 2.5935 - val_loss: 3.1059 - val_mae: 3.1059\n",
      "Epoch 253/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6086 - mae: 2.6086 - val_loss: 3.1927 - val_mae: 3.1927\n",
      "Epoch 254/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5984 - mae: 2.5984 - val_loss: 3.0646 - val_mae: 3.0646\n",
      "Epoch 255/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5745 - mae: 2.5745 - val_loss: 3.1598 - val_mae: 3.1598\n",
      "Epoch 256/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5883 - mae: 2.5883 - val_loss: 3.1719 - val_mae: 3.1719\n",
      "Epoch 257/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5801 - mae: 2.5801 - val_loss: 3.0739 - val_mae: 3.0739\n",
      "Epoch 258/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6179 - mae: 2.6179 - val_loss: 3.1095 - val_mae: 3.1095\n",
      "Epoch 259/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5609 - mae: 2.5609 - val_loss: 3.0436 - val_mae: 3.0436\n",
      "Epoch 260/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5803 - mae: 2.5803 - val_loss: 3.1874 - val_mae: 3.1874\n",
      "Epoch 261/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5894 - mae: 2.5894 - val_loss: 3.0884 - val_mae: 3.0884\n",
      "Epoch 262/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5908 - mae: 2.5908 - val_loss: 3.1580 - val_mae: 3.1580\n",
      "Epoch 263/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5770 - mae: 2.5770 - val_loss: 3.0579 - val_mae: 3.0579\n",
      "Epoch 264/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5803 - mae: 2.5803 - val_loss: 3.1832 - val_mae: 3.1832\n",
      "Epoch 265/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5907 - mae: 2.5907 - val_loss: 3.1825 - val_mae: 3.1825\n",
      "Epoch 266/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5887 - mae: 2.5887 - val_loss: 3.1338 - val_mae: 3.1338\n",
      "Epoch 267/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5598 - mae: 2.5598 - val_loss: 3.1516 - val_mae: 3.1516\n",
      "Epoch 268/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5540 - mae: 2.5540 - val_loss: 3.1165 - val_mae: 3.1165\n",
      "Epoch 269/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5794 - mae: 2.5794 - val_loss: 3.1676 - val_mae: 3.1676\n",
      "Epoch 270/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5636 - mae: 2.5636 - val_loss: 3.0849 - val_mae: 3.0849\n",
      "Epoch 271/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5447 - mae: 2.5447 - val_loss: 3.0162 - val_mae: 3.0162\n",
      "Epoch 272/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5519 - mae: 2.5519 - val_loss: 3.1478 - val_mae: 3.1478\n",
      "Epoch 273/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5493 - mae: 2.5493 - val_loss: 3.1701 - val_mae: 3.1701\n",
      "Epoch 274/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5653 - mae: 2.5653 - val_loss: 3.0590 - val_mae: 3.0590\n",
      "Epoch 275/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5587 - mae: 2.5587 - val_loss: 3.1524 - val_mae: 3.1524\n",
      "Epoch 276/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5483 - mae: 2.5483 - val_loss: 3.1037 - val_mae: 3.1037\n",
      "Epoch 277/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5517 - mae: 2.5517 - val_loss: 3.0579 - val_mae: 3.0579\n",
      "Epoch 278/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5385 - mae: 2.5385 - val_loss: 3.0610 - val_mae: 3.0610\n",
      "Epoch 279/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5470 - mae: 2.5470 - val_loss: 3.1574 - val_mae: 3.1574\n",
      "Epoch 280/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5416 - mae: 2.5416 - val_loss: 3.0980 - val_mae: 3.0980\n",
      "Epoch 281/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5323 - mae: 2.5323 - val_loss: 3.1080 - val_mae: 3.1080\n",
      "Epoch 282/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5533 - mae: 2.5533 - val_loss: 3.1362 - val_mae: 3.1362\n",
      "Epoch 283/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5403 - mae: 2.5403 - val_loss: 3.1117 - val_mae: 3.1117\n",
      "Epoch 284/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5704 - mae: 2.5704 - val_loss: 3.0693 - val_mae: 3.0693\n",
      "Epoch 285/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5354 - mae: 2.5354 - val_loss: 3.0873 - val_mae: 3.0873\n",
      "Epoch 286/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5156 - mae: 2.5156 - val_loss: 3.0770 - val_mae: 3.0770\n",
      "Epoch 287/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5470 - mae: 2.5470 - val_loss: 3.0365 - val_mae: 3.0365\n",
      "Epoch 288/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5448 - mae: 2.5448 - val_loss: 3.2246 - val_mae: 3.2246\n",
      "Epoch 289/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5326 - mae: 2.5326 - val_loss: 3.1014 - val_mae: 3.1014\n",
      "Epoch 290/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5423 - mae: 2.5423 - val_loss: 3.0673 - val_mae: 3.0673\n",
      "Epoch 291/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5270 - mae: 2.5270 - val_loss: 3.1544 - val_mae: 3.1544\n",
      "Epoch 292/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5564 - mae: 2.5564 - val_loss: 3.1811 - val_mae: 3.1811\n",
      "Epoch 293/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5295 - mae: 2.5295 - val_loss: 3.2660 - val_mae: 3.2660\n",
      "Epoch 294/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5450 - mae: 2.5450 - val_loss: 3.1526 - val_mae: 3.1526\n",
      "Epoch 295/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5265 - mae: 2.5265 - val_loss: 3.1033 - val_mae: 3.1033\n",
      "Epoch 296/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5293 - mae: 2.5293 - val_loss: 3.0840 - val_mae: 3.0840\n",
      "Epoch 297/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5118 - mae: 2.5118 - val_loss: 3.0504 - val_mae: 3.0504\n",
      "Epoch 298/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5009 - mae: 2.5009 - val_loss: 3.0840 - val_mae: 3.0840\n",
      "Epoch 299/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4941 - mae: 2.4941 - val_loss: 3.0733 - val_mae: 3.0733\n",
      "Epoch 300/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5239 - mae: 2.5239 - val_loss: 3.0195 - val_mae: 3.0195\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss= 'mae', metrics=['mae'])\n",
    "\n",
    "history = model.fit([depth_train, force_train],theta_z_train, verbose = 1, epochs = 300, batch_size = 128,\n",
    "                   validation_data = ([depth_test, force_test], theta_z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(len(training_loss))\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict([depth_test, force_test])\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (20,5)\n",
    "plt.plot(theta_z_test)\n",
    "plt.plot(y_prediction,'--')\n",
    "plt.legend(['Ground Truth', 'Prediction'])\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Angle (degree)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_prediction, theta_z_test)\n",
    "plt.xlabel('Prediction angle')\n",
    "plt.ylabel('Ground angle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed only force data to the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils.vis_utils import plot_model\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 100, restore_best_weights = True)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "model.compile(optimizer='adam', \n",
    "              loss= 'mae',\n",
    "              metrics=['mae'])\n",
    "\n",
    "history = model.fit(force_train, theta_z_train, epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (force_test, theta_z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(len(training_loss))\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(force_test)\n",
    "\n",
    "import matplotlib as mpl\n",
    "%matplotlib tk\n",
    "mpl.rcParams['figure.figsize'] = (20,5)\n",
    "plt.plot(theta_z_test)\n",
    "plt.plot(y_prediction,'--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retry Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "# fc = StandardScaler()\n",
    "# sc_y = StandardScaler()\n",
    "\n",
    "# force_train = fc.fit_transform(force_train)\n",
    "# force_test = fc.transform(force_test)\n",
    "\n",
    "# theta_z_train = theta_z_train.reshape(-1,1)\n",
    "# theta_z_train = sc_y.fit_transform(theta_z_train)\n",
    "# theta_z_train = theta_z_train.ravel()\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 2)\n",
    "regressor.fit(force_train, theta_z_train)\n",
    "\n",
    "#y_pred = sc_y.inverse_transform(regressor.predict(force_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred = regressor.predict(force_test)\n",
    "mean_absolute_error(theta_z_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.score(force_test,theta_z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (15,10)\n",
    "plt.plot(theta_z_test,'-')\n",
    "plt.plot(y_pred,'--')\n",
    "\n",
    "plt.title('Random Forest Regression')\n",
    "plt.ylabel('Angle (deg)')\n",
    "plt.xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_z = theta_z.reshape(-1, 1)\n",
    "trans = KBinsDiscretizer(n_bins=200, encode='ordinal', strategy='uniform')\n",
    "theta_z_disc = trans.fit_transform(theta_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "%matplotlib tk\n",
    "mpl.rcParams['figure.figsize'] = (20,5)\n",
    "plt.plot(theta_z, 'r--')\n",
    "plt.plot(theta_z_disc,'b-')\n",
    "plt.legend(['Continuous', 'Discrete'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Angle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = theta_z_disc[0]-theta_z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_z_disc = theta_z_disc - error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one single frame\n",
    "cv2.imshow('image', depth[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "clt = MiniBatchKMeans(n_clusters = 4)\n",
    "labels = clt.fit_predict(depth[5000])\n",
    "quant = clt.cluster_centers_[labels]\n",
    "cv2.imshow('image',quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization for depth images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(image):\n",
    "    clt = MiniBatchKMeans(n_clusters = 4)\n",
    "    labels = clt.fit_predict(image)\n",
    "    quant_image = clt.cluster_centers_[labels]\n",
    "    return quant_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "depth_quantized = np.empty((depth.shape[0],depth.shape[1],depth.shape[2]))\n",
    "for i in range(depth.shape[0]):\n",
    "    depth_quantized[i] = quantize(depth[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Image',depth_quantized[200])\n",
    "cv2.imshow('Image', depth[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "depth_train, depth_test, force_train, force_test, theta_z_train, theta_z_test = train_test_split(depth_quantized, force, theta_z_disc, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "input_depth = layers.Input(shape = (30, 40))\n",
    "input_force = layers.Input(shape = (6, ))\n",
    "\n",
    "# first branch\n",
    "x = layers.Flatten(input_shape=(30, 40))(input_depth)\n",
    "x = layers.Dense(units=128, activation='relu')(x)\n",
    "x = layers.Dense(units=64, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "x = tf.keras.Model(inputs= input_depth, outputs = x)\n",
    "\n",
    "# second branch\n",
    "y = layers.Dense(units=128, activation='relu')(input_force)\n",
    "y = layers.Dense(units=64, activation='relu')(y)\n",
    "y = layers.Dense(32, activation='relu')(y)\n",
    "y = layers.Dropout(0.2)(y)\n",
    "y = tf.keras.Model(inputs= input_force, outputs = y)\n",
    "\n",
    "# combine two branches\n",
    "combined = layers.concatenate([x.output, y.output])\n",
    "\n",
    "# regression to one output\n",
    "z = layers.Dense(units=32, activation='relu')(combined)\n",
    "z = layers.Dropout(0.2)(z)\n",
    "z = layers.Dense(units=16, activation='relu')(combined)\n",
    "z = layers.Dense(1, activation='linear')(z)\n",
    "model = tf.keras.Model(inputs = [x.input, y.input], outputs = z)\n",
    "\n",
    "#tf.keras.utils.plot_model(model, to_file = 'model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.7041 - mae: 6.7041 - val_loss: 5.9654 - val_mae: 5.9654\n",
      "Epoch 2/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.8554 - mae: 5.8554 - val_loss: 5.5684 - val_mae: 5.5684\n",
      "Epoch 3/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.5466 - mae: 5.5466 - val_loss: 5.2943 - val_mae: 5.2943\n",
      "Epoch 4/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.2659 - mae: 5.2659 - val_loss: 4.9893 - val_mae: 4.9893\n",
      "Epoch 5/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.9619 - mae: 4.9619 - val_loss: 4.8505 - val_mae: 4.8505\n",
      "Epoch 6/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.8140 - mae: 4.8140 - val_loss: 4.7246 - val_mae: 4.7246\n",
      "Epoch 7/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.7189 - mae: 4.7189 - val_loss: 4.6052 - val_mae: 4.6052\n",
      "Epoch 8/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 4.6443 - mae: 4.6443 - val_loss: 4.5936 - val_mae: 4.5936\n",
      "Epoch 9/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 4.5230 - mae: 4.5230 - val_loss: 4.4989 - val_mae: 4.4989\n",
      "Epoch 10/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 4.4788 - mae: 4.4788 - val_loss: 4.4133 - val_mae: 4.4133\n",
      "Epoch 11/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.4164 - mae: 4.4164 - val_loss: 4.3759 - val_mae: 4.3759\n",
      "Epoch 12/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.3589 - mae: 4.3589 - val_loss: 4.3245 - val_mae: 4.3245\n",
      "Epoch 13/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 4.3016 - mae: 4.3016 - val_loss: 4.2739 - val_mae: 4.2739\n",
      "Epoch 14/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.2827 - mae: 4.2827 - val_loss: 4.3186 - val_mae: 4.3186\n",
      "Epoch 15/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.2699 - mae: 4.2699 - val_loss: 4.3589 - val_mae: 4.3589\n",
      "Epoch 16/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.2067 - mae: 4.2067 - val_loss: 4.2766 - val_mae: 4.2766\n",
      "Epoch 17/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.1829 - mae: 4.1829 - val_loss: 4.1846 - val_mae: 4.1846\n",
      "Epoch 18/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.1392 - mae: 4.1392 - val_loss: 4.2422 - val_mae: 4.2422\n",
      "Epoch 19/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.1024 - mae: 4.1024 - val_loss: 4.2076 - val_mae: 4.2076\n",
      "Epoch 20/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 4.0813 - mae: 4.0813 - val_loss: 4.0721 - val_mae: 4.0721\n",
      "Epoch 21/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 4.0530 - mae: 4.0530 - val_loss: 4.0611 - val_mae: 4.0611\n",
      "Epoch 22/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 4.0780 - mae: 4.0780 - val_loss: 4.1427 - val_mae: 4.1427\n",
      "Epoch 23/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.0074 - mae: 4.0074 - val_loss: 3.9919 - val_mae: 3.9919\n",
      "Epoch 24/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 3.9643 - mae: 3.9643 - val_loss: 4.0026 - val_mae: 4.0026\n",
      "Epoch 25/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 3.9564 - mae: 3.9564 - val_loss: 4.0550 - val_mae: 4.0550\n",
      "Epoch 26/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 3.9418 - mae: 3.9418 - val_loss: 4.0381 - val_mae: 4.0381\n",
      "Epoch 27/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.9287 - mae: 3.9287 - val_loss: 3.9690 - val_mae: 3.9690\n",
      "Epoch 28/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.9157 - mae: 3.9157 - val_loss: 3.9199 - val_mae: 3.9199\n",
      "Epoch 29/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.8712 - mae: 3.8712 - val_loss: 3.9487 - val_mae: 3.9487\n",
      "Epoch 30/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.8334 - mae: 3.8334 - val_loss: 3.8780 - val_mae: 3.8780\n",
      "Epoch 31/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7686 - mae: 3.7686 - val_loss: 3.9071 - val_mae: 3.9071\n",
      "Epoch 32/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7819 - mae: 3.7819 - val_loss: 3.8331 - val_mae: 3.8331\n",
      "Epoch 33/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7207 - mae: 3.7207 - val_loss: 3.8016 - val_mae: 3.8016\n",
      "Epoch 34/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 3.7182 - mae: 3.7182 - val_loss: 3.8038 - val_mae: 3.8038\n",
      "Epoch 35/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 3.6854 - mae: 3.6854 - val_loss: 3.6970 - val_mae: 3.6970\n",
      "Epoch 36/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6573 - mae: 3.6573 - val_loss: 3.7348 - val_mae: 3.7348\n",
      "Epoch 37/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6616 - mae: 3.6616 - val_loss: 3.7474 - val_mae: 3.7474\n",
      "Epoch 38/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6534 - mae: 3.6534 - val_loss: 3.7726 - val_mae: 3.7726\n",
      "Epoch 39/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6470 - mae: 3.6470 - val_loss: 3.6795 - val_mae: 3.6795\n",
      "Epoch 40/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6434 - mae: 3.6434 - val_loss: 3.7517 - val_mae: 3.7517\n",
      "Epoch 41/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5910 - mae: 3.5910 - val_loss: 3.7126 - val_mae: 3.7126\n",
      "Epoch 42/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5792 - mae: 3.5792 - val_loss: 3.6518 - val_mae: 3.6518\n",
      "Epoch 43/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5676 - mae: 3.5676 - val_loss: 3.6541 - val_mae: 3.6541\n",
      "Epoch 44/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5524 - mae: 3.5524 - val_loss: 3.6794 - val_mae: 3.6794\n",
      "Epoch 45/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5500 - mae: 3.5500 - val_loss: 3.6768 - val_mae: 3.6768\n",
      "Epoch 46/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5179 - mae: 3.5179 - val_loss: 3.6396 - val_mae: 3.6396\n",
      "Epoch 47/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5168 - mae: 3.5168 - val_loss: 3.6359 - val_mae: 3.6359\n",
      "Epoch 48/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4934 - mae: 3.4934 - val_loss: 3.5565 - val_mae: 3.5565\n",
      "Epoch 49/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4747 - mae: 3.4747 - val_loss: 3.5493 - val_mae: 3.5493\n",
      "Epoch 50/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4830 - mae: 3.4830 - val_loss: 3.5781 - val_mae: 3.5781\n",
      "Epoch 51/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4727 - mae: 3.4727 - val_loss: 3.5586 - val_mae: 3.5586\n",
      "Epoch 52/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4606 - mae: 3.4606 - val_loss: 3.5732 - val_mae: 3.5732\n",
      "Epoch 53/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4254 - mae: 3.4254 - val_loss: 3.5543 - val_mae: 3.5543\n",
      "Epoch 54/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4554 - mae: 3.4554 - val_loss: 3.5777 - val_mae: 3.5777\n",
      "Epoch 55/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4449 - mae: 3.4449 - val_loss: 3.4717 - val_mae: 3.4717\n",
      "Epoch 56/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4068 - mae: 3.4068 - val_loss: 3.5946 - val_mae: 3.5946\n",
      "Epoch 57/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4160 - mae: 3.4160 - val_loss: 3.5430 - val_mae: 3.5430\n",
      "Epoch 58/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4069 - mae: 3.4069 - val_loss: 3.6111 - val_mae: 3.6111\n",
      "Epoch 59/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3707 - mae: 3.3707 - val_loss: 3.4514 - val_mae: 3.4514\n",
      "Epoch 60/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4020 - mae: 3.4020 - val_loss: 3.5486 - val_mae: 3.5486\n",
      "Epoch 61/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3869 - mae: 3.3869 - val_loss: 3.4606 - val_mae: 3.4606\n",
      "Epoch 62/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3506 - mae: 3.3506 - val_loss: 3.4677 - val_mae: 3.4677\n",
      "Epoch 63/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3636 - mae: 3.3636 - val_loss: 3.4393 - val_mae: 3.4393\n",
      "Epoch 64/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 3.3345 - mae: 3.3345 - val_loss: 3.5126 - val_mae: 3.5126\n",
      "Epoch 65/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3459 - mae: 3.3459 - val_loss: 3.5214 - val_mae: 3.5214\n",
      "Epoch 66/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3547 - mae: 3.3547 - val_loss: 3.5519 - val_mae: 3.5519\n",
      "Epoch 67/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3287 - mae: 3.3287 - val_loss: 3.4986 - val_mae: 3.4986\n",
      "Epoch 68/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3147 - mae: 3.3147 - val_loss: 3.5216 - val_mae: 3.5216\n",
      "Epoch 69/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3087 - mae: 3.3087 - val_loss: 3.4284 - val_mae: 3.4284\n",
      "Epoch 70/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2982 - mae: 3.2982 - val_loss: 3.4954 - val_mae: 3.4954\n",
      "Epoch 71/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2991 - mae: 3.2991 - val_loss: 3.4491 - val_mae: 3.4491\n",
      "Epoch 72/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3209 - mae: 3.3209 - val_loss: 3.4679 - val_mae: 3.4679\n",
      "Epoch 73/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2675 - mae: 3.2675 - val_loss: 3.4768 - val_mae: 3.4768\n",
      "Epoch 74/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2829 - mae: 3.2829 - val_loss: 3.4389 - val_mae: 3.4389\n",
      "Epoch 75/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 3.2643 - mae: 3.2643 - val_loss: 3.4780 - val_mae: 3.4780\n",
      "Epoch 76/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2575 - mae: 3.2575 - val_loss: 3.3786 - val_mae: 3.3786\n",
      "Epoch 77/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2916 - mae: 3.2916 - val_loss: 3.4004 - val_mae: 3.4004\n",
      "Epoch 78/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2911 - mae: 3.2911 - val_loss: 3.4346 - val_mae: 3.4346\n",
      "Epoch 79/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2747 - mae: 3.2747 - val_loss: 3.3618 - val_mae: 3.3618\n",
      "Epoch 80/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2566 - mae: 3.2566 - val_loss: 3.4512 - val_mae: 3.4512\n",
      "Epoch 81/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2752 - mae: 3.2752 - val_loss: 3.4392 - val_mae: 3.4392\n",
      "Epoch 82/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2470 - mae: 3.2470 - val_loss: 3.3984 - val_mae: 3.3984\n",
      "Epoch 83/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2156 - mae: 3.2156 - val_loss: 3.3760 - val_mae: 3.3760\n",
      "Epoch 84/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2355 - mae: 3.2355 - val_loss: 3.4030 - val_mae: 3.4030\n",
      "Epoch 85/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2352 - mae: 3.2352 - val_loss: 3.3712 - val_mae: 3.3712\n",
      "Epoch 86/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2183 - mae: 3.2183 - val_loss: 3.4521 - val_mae: 3.4521\n",
      "Epoch 87/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2114 - mae: 3.2114 - val_loss: 3.4400 - val_mae: 3.4400\n",
      "Epoch 88/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1900 - mae: 3.1900 - val_loss: 3.3897 - val_mae: 3.3897\n",
      "Epoch 89/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 3.1916 - mae: 3.1916 - val_loss: 3.3508 - val_mae: 3.3508\n",
      "Epoch 90/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 3.1952 - mae: 3.1952 - val_loss: 3.5089 - val_mae: 3.5089\n",
      "Epoch 91/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2974 - mae: 3.2974 - val_loss: 3.4119 - val_mae: 3.4119\n",
      "Epoch 92/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2039 - mae: 3.2039 - val_loss: 3.2770 - val_mae: 3.2770\n",
      "Epoch 93/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1883 - mae: 3.1883 - val_loss: 3.3382 - val_mae: 3.3382\n",
      "Epoch 94/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1728 - mae: 3.1728 - val_loss: 3.3215 - val_mae: 3.3215\n",
      "Epoch 95/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1522 - mae: 3.1522 - val_loss: 3.3197 - val_mae: 3.3197\n",
      "Epoch 96/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1702 - mae: 3.1702 - val_loss: 3.3257 - val_mae: 3.3257\n",
      "Epoch 97/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1442 - mae: 3.1442 - val_loss: 3.3648 - val_mae: 3.3648\n",
      "Epoch 98/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1723 - mae: 3.1723 - val_loss: 3.4056 - val_mae: 3.4056\n",
      "Epoch 99/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 3.1488 - mae: 3.1488 - val_loss: 3.3932 - val_mae: 3.3932\n",
      "Epoch 100/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1658 - mae: 3.1658 - val_loss: 3.3073 - val_mae: 3.3073\n",
      "Epoch 101/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1364 - mae: 3.1364 - val_loss: 3.4449 - val_mae: 3.4449\n",
      "Epoch 102/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1584 - mae: 3.1584 - val_loss: 3.3114 - val_mae: 3.3114\n",
      "Epoch 103/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1722 - mae: 3.1722 - val_loss: 3.5029 - val_mae: 3.5029\n",
      "Epoch 104/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1455 - mae: 3.1455 - val_loss: 3.3543 - val_mae: 3.3543\n",
      "Epoch 105/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1196 - mae: 3.1196 - val_loss: 3.3404 - val_mae: 3.3404\n",
      "Epoch 106/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1392 - mae: 3.1392 - val_loss: 3.3607 - val_mae: 3.3607\n",
      "Epoch 107/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1600 - mae: 3.1600 - val_loss: 3.3439 - val_mae: 3.3439\n",
      "Epoch 108/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1653 - mae: 3.1653 - val_loss: 3.3919 - val_mae: 3.3919\n",
      "Epoch 109/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1421 - mae: 3.1421 - val_loss: 3.3940 - val_mae: 3.3940\n",
      "Epoch 110/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1609 - mae: 3.1609 - val_loss: 3.3656 - val_mae: 3.3656\n",
      "Epoch 111/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1309 - mae: 3.1309 - val_loss: 3.3376 - val_mae: 3.3376\n",
      "Epoch 112/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1210 - mae: 3.1210 - val_loss: 3.3266 - val_mae: 3.3266\n",
      "Epoch 113/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0971 - mae: 3.0971 - val_loss: 3.3022 - val_mae: 3.3022\n",
      "Epoch 114/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1470 - mae: 3.1470 - val_loss: 3.3804 - val_mae: 3.3804\n",
      "Epoch 115/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1055 - mae: 3.1055 - val_loss: 3.3112 - val_mae: 3.3112\n",
      "Epoch 116/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0908 - mae: 3.0908 - val_loss: 3.2886 - val_mae: 3.2886\n",
      "Epoch 117/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1067 - mae: 3.1067 - val_loss: 3.4111 - val_mae: 3.4111\n",
      "Epoch 118/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0987 - mae: 3.0987 - val_loss: 3.5228 - val_mae: 3.5228\n",
      "Epoch 119/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0794 - mae: 3.0794 - val_loss: 3.4339 - val_mae: 3.4339\n",
      "Epoch 120/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0898 - mae: 3.0898 - val_loss: 3.3166 - val_mae: 3.3166\n",
      "Epoch 121/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0627 - mae: 3.0627 - val_loss: 3.3452 - val_mae: 3.3452\n",
      "Epoch 122/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0762 - mae: 3.0762 - val_loss: 3.3393 - val_mae: 3.3393\n",
      "Epoch 123/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0763 - mae: 3.0763 - val_loss: 3.2693 - val_mae: 3.2693\n",
      "Epoch 124/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1025 - mae: 3.1025 - val_loss: 3.2708 - val_mae: 3.2708\n",
      "Epoch 125/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0797 - mae: 3.0797 - val_loss: 3.2466 - val_mae: 3.2466\n",
      "Epoch 126/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1280 - mae: 3.1280 - val_loss: 3.3629 - val_mae: 3.3629\n",
      "Epoch 127/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0902 - mae: 3.0902 - val_loss: 3.3337 - val_mae: 3.3337\n",
      "Epoch 128/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0790 - mae: 3.0790 - val_loss: 3.2711 - val_mae: 3.2711\n",
      "Epoch 129/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0559 - mae: 3.0559 - val_loss: 3.2972 - val_mae: 3.2972\n",
      "Epoch 130/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0736 - mae: 3.0736 - val_loss: 3.2534 - val_mae: 3.2534\n",
      "Epoch 131/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0440 - mae: 3.0440 - val_loss: 3.3425 - val_mae: 3.3425\n",
      "Epoch 132/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0294 - mae: 3.0294 - val_loss: 3.3256 - val_mae: 3.3256\n",
      "Epoch 133/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0360 - mae: 3.0360 - val_loss: 3.2502 - val_mae: 3.2502\n",
      "Epoch 134/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0353 - mae: 3.0353 - val_loss: 3.3254 - val_mae: 3.3254\n",
      "Epoch 135/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0395 - mae: 3.0395 - val_loss: 3.3249 - val_mae: 3.3249\n",
      "Epoch 136/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0300 - mae: 3.0300 - val_loss: 3.3418 - val_mae: 3.3418\n",
      "Epoch 137/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0426 - mae: 3.0426 - val_loss: 3.2742 - val_mae: 3.2742\n",
      "Epoch 138/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0247 - mae: 3.0247 - val_loss: 3.3011 - val_mae: 3.3011\n",
      "Epoch 139/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 3.0269 - mae: 3.0269 - val_loss: 3.2674 - val_mae: 3.2674\n",
      "Epoch 140/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0415 - mae: 3.0415 - val_loss: 3.3152 - val_mae: 3.3152\n",
      "Epoch 141/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0077 - mae: 3.0077 - val_loss: 3.2799 - val_mae: 3.2799\n",
      "Epoch 142/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0258 - mae: 3.0258 - val_loss: 3.2654 - val_mae: 3.2654\n",
      "Epoch 143/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0165 - mae: 3.0165 - val_loss: 3.3301 - val_mae: 3.3301\n",
      "Epoch 144/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0249 - mae: 3.0249 - val_loss: 3.3489 - val_mae: 3.3489\n",
      "Epoch 145/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0174 - mae: 3.0174 - val_loss: 3.3783 - val_mae: 3.3783\n",
      "Epoch 146/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.9938 - mae: 2.9938 - val_loss: 3.2106 - val_mae: 3.2106\n",
      "Epoch 147/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.9932 - mae: 2.9932 - val_loss: 3.2904 - val_mae: 3.2904\n",
      "Epoch 148/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0007 - mae: 3.0007 - val_loss: 3.2835 - val_mae: 3.2835\n",
      "Epoch 149/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0147 - mae: 3.0147 - val_loss: 3.2730 - val_mae: 3.2730\n",
      "Epoch 150/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.9905 - mae: 2.9905 - val_loss: 3.3061 - val_mae: 3.3061\n",
      "Epoch 151/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.9883 - mae: 2.9883 - val_loss: 3.2751 - val_mae: 3.2751\n",
      "Epoch 152/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.9681 - mae: 2.9681 - val_loss: 3.2579 - val_mae: 3.2579\n",
      "Epoch 153/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9699 - mae: 2.9699 - val_loss: 3.3185 - val_mae: 3.3185\n",
      "Epoch 154/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9765 - mae: 2.9765 - val_loss: 3.2906 - val_mae: 3.2906\n",
      "Epoch 155/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9909 - mae: 2.9909 - val_loss: 3.3227 - val_mae: 3.3227\n",
      "Epoch 156/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9766 - mae: 2.9766 - val_loss: 3.2837 - val_mae: 3.2837\n",
      "Epoch 157/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9711 - mae: 2.9711 - val_loss: 3.2643 - val_mae: 3.2643\n",
      "Epoch 158/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9671 - mae: 2.9671 - val_loss: 3.2679 - val_mae: 3.2679\n",
      "Epoch 159/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.9588 - mae: 2.9588 - val_loss: 3.2303 - val_mae: 3.2303\n",
      "Epoch 160/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.9671 - mae: 2.9671 - val_loss: 3.3116 - val_mae: 3.3116\n",
      "Epoch 161/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.9643 - mae: 2.9643 - val_loss: 3.3526 - val_mae: 3.3526\n",
      "Epoch 162/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 3.0100 - mae: 3.0100 - val_loss: 3.3288 - val_mae: 3.3288\n",
      "Epoch 163/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9815 - mae: 2.9815 - val_loss: 3.2466 - val_mae: 3.2466\n",
      "Epoch 164/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9606 - mae: 2.9606 - val_loss: 3.2811 - val_mae: 3.2811\n",
      "Epoch 165/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.9571 - mae: 2.9571 - val_loss: 3.2539 - val_mae: 3.2539\n",
      "Epoch 166/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9466 - mae: 2.9466 - val_loss: 3.2779 - val_mae: 3.2779\n",
      "Epoch 167/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9346 - mae: 2.9346 - val_loss: 3.2613 - val_mae: 3.2613\n",
      "Epoch 168/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9420 - mae: 2.9420 - val_loss: 3.2896 - val_mae: 3.2896\n",
      "Epoch 169/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9570 - mae: 2.9570 - val_loss: 3.2379 - val_mae: 3.2379\n",
      "Epoch 170/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9387 - mae: 2.9387 - val_loss: 3.2241 - val_mae: 3.2241\n",
      "Epoch 171/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9305 - mae: 2.9305 - val_loss: 3.2321 - val_mae: 3.2321\n",
      "Epoch 172/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9226 - mae: 2.9226 - val_loss: 3.2547 - val_mae: 3.2547\n",
      "Epoch 173/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9334 - mae: 2.9334 - val_loss: 3.2808 - val_mae: 3.2808\n",
      "Epoch 174/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9969 - mae: 2.9969 - val_loss: 3.3401 - val_mae: 3.3401\n",
      "Epoch 175/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9657 - mae: 2.9657 - val_loss: 3.2378 - val_mae: 3.2378\n",
      "Epoch 176/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9435 - mae: 2.9435 - val_loss: 3.3278 - val_mae: 3.3278\n",
      "Epoch 177/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9627 - mae: 2.9627 - val_loss: 3.2388 - val_mae: 3.2388\n",
      "Epoch 178/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9285 - mae: 2.9285 - val_loss: 3.2011 - val_mae: 3.2011\n",
      "Epoch 179/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9064 - mae: 2.9064 - val_loss: 3.2427 - val_mae: 3.2427\n",
      "Epoch 180/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9303 - mae: 2.9303 - val_loss: 3.2639 - val_mae: 3.2639\n",
      "Epoch 181/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9266 - mae: 2.9266 - val_loss: 3.2687 - val_mae: 3.2687\n",
      "Epoch 182/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9179 - mae: 2.9179 - val_loss: 3.2428 - val_mae: 3.2428\n",
      "Epoch 183/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9278 - mae: 2.9278 - val_loss: 3.2116 - val_mae: 3.2116\n",
      "Epoch 184/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9100 - mae: 2.9100 - val_loss: 3.2202 - val_mae: 3.2202\n",
      "Epoch 185/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.9175 - mae: 2.9175 - val_loss: 3.2460 - val_mae: 3.2460\n",
      "Epoch 186/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.9328 - mae: 2.9328 - val_loss: 3.2358 - val_mae: 3.2358\n",
      "Epoch 187/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9108 - mae: 2.9108 - val_loss: 3.3407 - val_mae: 3.3407\n",
      "Epoch 188/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.8927 - mae: 2.8927 - val_loss: 3.2391 - val_mae: 3.2391\n",
      "Epoch 189/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.8955 - mae: 2.8955 - val_loss: 3.2048 - val_mae: 3.2048\n",
      "Epoch 190/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.9003 - mae: 2.9003 - val_loss: 3.1999 - val_mae: 3.1999\n",
      "Epoch 191/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8831 - mae: 2.8831 - val_loss: 3.2794 - val_mae: 3.2794\n",
      "Epoch 192/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9191 - mae: 2.9191 - val_loss: 3.2118 - val_mae: 3.2118\n",
      "Epoch 193/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9009 - mae: 2.9009 - val_loss: 3.1879 - val_mae: 3.1879\n",
      "Epoch 194/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8867 - mae: 2.8867 - val_loss: 3.2441 - val_mae: 3.2441\n",
      "Epoch 195/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8782 - mae: 2.8782 - val_loss: 3.2110 - val_mae: 3.2110\n",
      "Epoch 196/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8619 - mae: 2.8619 - val_loss: 3.2790 - val_mae: 3.2790\n",
      "Epoch 197/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9134 - mae: 2.9134 - val_loss: 3.2654 - val_mae: 3.2654\n",
      "Epoch 198/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9057 - mae: 2.9057 - val_loss: 3.2271 - val_mae: 3.2271\n",
      "Epoch 199/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8842 - mae: 2.8842 - val_loss: 3.2738 - val_mae: 3.2738\n",
      "Epoch 200/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8780 - mae: 2.8780 - val_loss: 3.2330 - val_mae: 3.2330\n",
      "Epoch 201/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8935 - mae: 2.8935 - val_loss: 3.2589 - val_mae: 3.2589\n",
      "Epoch 202/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8758 - mae: 2.8758 - val_loss: 3.2512 - val_mae: 3.2512\n",
      "Epoch 203/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8864 - mae: 2.8864 - val_loss: 3.2445 - val_mae: 3.2445\n",
      "Epoch 204/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8976 - mae: 2.8976 - val_loss: 3.2310 - val_mae: 3.2310\n",
      "Epoch 205/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8643 - mae: 2.8643 - val_loss: 3.2159 - val_mae: 3.2159\n",
      "Epoch 206/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9833 - mae: 2.9833 - val_loss: 3.2462 - val_mae: 3.2462\n",
      "Epoch 207/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8803 - mae: 2.8803 - val_loss: 3.2605 - val_mae: 3.2605\n",
      "Epoch 208/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8800 - mae: 2.8800 - val_loss: 3.2938 - val_mae: 3.2938\n",
      "Epoch 209/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8778 - mae: 2.8778 - val_loss: 3.2435 - val_mae: 3.2435\n",
      "Epoch 210/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8920 - mae: 2.8920 - val_loss: 3.2145 - val_mae: 3.2145\n",
      "Epoch 211/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8911 - mae: 2.8911 - val_loss: 3.2411 - val_mae: 3.2411\n",
      "Epoch 212/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8587 - mae: 2.8587 - val_loss: 3.1776 - val_mae: 3.1776\n",
      "Epoch 213/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8517 - mae: 2.8517 - val_loss: 3.2256 - val_mae: 3.2256\n",
      "Epoch 214/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8642 - mae: 2.8642 - val_loss: 3.1947 - val_mae: 3.1947\n",
      "Epoch 215/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8466 - mae: 2.8466 - val_loss: 3.1442 - val_mae: 3.1442\n",
      "Epoch 216/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8623 - mae: 2.8623 - val_loss: 3.2403 - val_mae: 3.2403\n",
      "Epoch 217/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8675 - mae: 2.8675 - val_loss: 3.2469 - val_mae: 3.2469\n",
      "Epoch 218/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8494 - mae: 2.8494 - val_loss: 3.1803 - val_mae: 3.1803\n",
      "Epoch 219/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8355 - mae: 2.8355 - val_loss: 3.2038 - val_mae: 3.2038\n",
      "Epoch 220/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8433 - mae: 2.8433 - val_loss: 3.2425 - val_mae: 3.2425\n",
      "Epoch 221/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8882 - mae: 2.8882 - val_loss: 3.1893 - val_mae: 3.1893\n",
      "Epoch 222/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8643 - mae: 2.8643 - val_loss: 3.2014 - val_mae: 3.2014\n",
      "Epoch 223/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8448 - mae: 2.8448 - val_loss: 3.2203 - val_mae: 3.2203\n",
      "Epoch 224/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8851 - mae: 2.8851 - val_loss: 3.3853 - val_mae: 3.3853\n",
      "Epoch 225/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9103 - mae: 2.9103 - val_loss: 3.2754 - val_mae: 3.2754\n",
      "Epoch 226/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8577 - mae: 2.8577 - val_loss: 3.3098 - val_mae: 3.3098\n",
      "Epoch 227/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8510 - mae: 2.8510 - val_loss: 3.1829 - val_mae: 3.1829\n",
      "Epoch 228/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8886 - mae: 2.8886 - val_loss: 3.3166 - val_mae: 3.3166\n",
      "Epoch 229/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8440 - mae: 2.8440 - val_loss: 3.2628 - val_mae: 3.2628\n",
      "Epoch 230/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8447 - mae: 2.8447 - val_loss: 3.2051 - val_mae: 3.2051\n",
      "Epoch 231/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8401 - mae: 2.8401 - val_loss: 3.2594 - val_mae: 3.2594\n",
      "Epoch 232/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8536 - mae: 2.8536 - val_loss: 3.2188 - val_mae: 3.2188\n",
      "Epoch 233/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8269 - mae: 2.8269 - val_loss: 3.2018 - val_mae: 3.2018\n",
      "Epoch 234/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.8805 - mae: 2.8805 - val_loss: 3.2258 - val_mae: 3.2258\n",
      "Epoch 235/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8200 - mae: 2.8200 - val_loss: 3.1754 - val_mae: 3.1754\n",
      "Epoch 236/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8168 - mae: 2.8168 - val_loss: 3.2550 - val_mae: 3.2550\n",
      "Epoch 237/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8457 - mae: 2.8457 - val_loss: 3.1760 - val_mae: 3.1760\n",
      "Epoch 238/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8577 - mae: 2.8577 - val_loss: 3.1829 - val_mae: 3.1829\n",
      "Epoch 239/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8192 - mae: 2.8192 - val_loss: 3.2476 - val_mae: 3.2476\n",
      "Epoch 240/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8625 - mae: 2.8625 - val_loss: 3.2643 - val_mae: 3.2643\n",
      "Epoch 241/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8059 - mae: 2.8059 - val_loss: 3.2380 - val_mae: 3.2380\n",
      "Epoch 242/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8079 - mae: 2.8079 - val_loss: 3.2999 - val_mae: 3.2999\n",
      "Epoch 243/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8065 - mae: 2.8065 - val_loss: 3.2226 - val_mae: 3.2226\n",
      "Epoch 244/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8253 - mae: 2.8253 - val_loss: 3.2289 - val_mae: 3.2289\n",
      "Epoch 245/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.8151 - mae: 2.8151 - val_loss: 3.2274 - val_mae: 3.2274\n",
      "Epoch 246/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.8224 - mae: 2.8224 - val_loss: 3.2062 - val_mae: 3.2062\n",
      "Epoch 247/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.8067 - mae: 2.8067 - val_loss: 3.2067 - val_mae: 3.2067\n",
      "Epoch 248/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7934 - mae: 2.7934 - val_loss: 3.1845 - val_mae: 3.1845\n",
      "Epoch 249/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7943 - mae: 2.7943 - val_loss: 3.2138 - val_mae: 3.2138\n",
      "Epoch 250/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.8105 - mae: 2.8105 - val_loss: 3.2039 - val_mae: 3.2039\n",
      "Epoch 251/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7938 - mae: 2.7938 - val_loss: 3.2413 - val_mae: 3.2413\n",
      "Epoch 252/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.8034 - mae: 2.8034 - val_loss: 3.2382 - val_mae: 3.2382\n",
      "Epoch 253/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8085 - mae: 2.8085 - val_loss: 3.2139 - val_mae: 3.2139\n",
      "Epoch 254/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7848 - mae: 2.7848 - val_loss: 3.1815 - val_mae: 3.1815\n",
      "Epoch 255/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7770 - mae: 2.7770 - val_loss: 3.2475 - val_mae: 3.2475\n",
      "Epoch 256/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8074 - mae: 2.8074 - val_loss: 3.1647 - val_mae: 3.1647\n",
      "Epoch 257/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7867 - mae: 2.7867 - val_loss: 3.1494 - val_mae: 3.1494\n",
      "Epoch 258/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7803 - mae: 2.7803 - val_loss: 3.1675 - val_mae: 3.1675\n",
      "Epoch 259/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7912 - mae: 2.7912 - val_loss: 3.1465 - val_mae: 3.1465\n",
      "Epoch 260/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7911 - mae: 2.7911 - val_loss: 3.1545 - val_mae: 3.1545\n",
      "Epoch 261/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7953 - mae: 2.7953 - val_loss: 3.2552 - val_mae: 3.2552\n",
      "Epoch 262/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.8176 - mae: 2.8176 - val_loss: 3.1924 - val_mae: 3.1924\n",
      "Epoch 263/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7829 - mae: 2.7829 - val_loss: 3.2648 - val_mae: 3.2648\n",
      "Epoch 264/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7744 - mae: 2.7744 - val_loss: 3.2026 - val_mae: 3.2026\n",
      "Epoch 265/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7694 - mae: 2.7694 - val_loss: 3.1732 - val_mae: 3.1732\n",
      "Epoch 266/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7824 - mae: 2.7824 - val_loss: 3.1999 - val_mae: 3.1999\n",
      "Epoch 267/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7771 - mae: 2.7771 - val_loss: 3.1370 - val_mae: 3.1370\n",
      "Epoch 268/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7386 - mae: 2.7386 - val_loss: 3.2149 - val_mae: 3.2149\n",
      "Epoch 269/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7765 - mae: 2.7765 - val_loss: 3.2016 - val_mae: 3.2016\n",
      "Epoch 270/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7769 - mae: 2.7769 - val_loss: 3.1900 - val_mae: 3.1900\n",
      "Epoch 271/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7683 - mae: 2.7683 - val_loss: 3.2032 - val_mae: 3.2032\n",
      "Epoch 272/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7825 - mae: 2.7825 - val_loss: 3.1535 - val_mae: 3.1535\n",
      "Epoch 273/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7979 - mae: 2.7979 - val_loss: 3.1831 - val_mae: 3.1831\n",
      "Epoch 274/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7791 - mae: 2.7791 - val_loss: 3.1741 - val_mae: 3.1741\n",
      "Epoch 275/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7652 - mae: 2.7652 - val_loss: 3.2033 - val_mae: 3.2033\n",
      "Epoch 276/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7541 - mae: 2.7541 - val_loss: 3.1598 - val_mae: 3.1598\n",
      "Epoch 277/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7388 - mae: 2.7388 - val_loss: 3.1943 - val_mae: 3.1943\n",
      "Epoch 278/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7797 - mae: 2.7797 - val_loss: 3.1459 - val_mae: 3.1459\n",
      "Epoch 279/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7357 - mae: 2.7357 - val_loss: 3.1644 - val_mae: 3.1644\n",
      "Epoch 280/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7538 - mae: 2.7538 - val_loss: 3.2157 - val_mae: 3.2157\n",
      "Epoch 281/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7525 - mae: 2.7525 - val_loss: 3.1152 - val_mae: 3.1152\n",
      "Epoch 282/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7407 - mae: 2.7407 - val_loss: 3.1531 - val_mae: 3.1531\n",
      "Epoch 283/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7751 - mae: 2.7751 - val_loss: 3.1183 - val_mae: 3.1183\n",
      "Epoch 284/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7517 - mae: 2.7517 - val_loss: 3.2195 - val_mae: 3.2195\n",
      "Epoch 285/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7514 - mae: 2.7514 - val_loss: 3.2257 - val_mae: 3.2257\n",
      "Epoch 286/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7577 - mae: 2.7577 - val_loss: 3.1424 - val_mae: 3.1424\n",
      "Epoch 287/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7445 - mae: 2.7445 - val_loss: 3.1937 - val_mae: 3.1937\n",
      "Epoch 288/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7341 - mae: 2.7341 - val_loss: 3.2166 - val_mae: 3.2166\n",
      "Epoch 289/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7487 - mae: 2.7487 - val_loss: 3.1638 - val_mae: 3.1638\n",
      "Epoch 290/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7617 - mae: 2.7617 - val_loss: 3.1417 - val_mae: 3.1417\n",
      "Epoch 291/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7339 - mae: 2.7339 - val_loss: 3.1570 - val_mae: 3.1570\n",
      "Epoch 292/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7445 - mae: 2.7445 - val_loss: 3.2498 - val_mae: 3.2498\n",
      "Epoch 293/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7296 - mae: 2.7296 - val_loss: 3.1777 - val_mae: 3.1777\n",
      "Epoch 294/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7639 - mae: 2.7639 - val_loss: 3.1659 - val_mae: 3.1659\n",
      "Epoch 295/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7315 - mae: 2.7315 - val_loss: 3.1581 - val_mae: 3.1581\n",
      "Epoch 296/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7407 - mae: 2.7407 - val_loss: 3.1342 - val_mae: 3.1342\n",
      "Epoch 297/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7628 - mae: 2.7628 - val_loss: 3.1227 - val_mae: 3.1227\n",
      "Epoch 298/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7576 - mae: 2.7576 - val_loss: 3.1643 - val_mae: 3.1643\n",
      "Epoch 299/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7383 - mae: 2.7383 - val_loss: 3.1795 - val_mae: 3.1795\n",
      "Epoch 300/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.7417 - mae: 2.7417 - val_loss: 3.1882 - val_mae: 3.1882\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss= 'mae', metrics=['mae'])\n",
    "\n",
    "history = model.fit([depth_train, force_train],theta_z_train, verbose = 1, epochs = 300, batch_size = 128,\n",
    "                   validation_data = ([depth_test, force_test], theta_z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_23\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 30, 40)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1200)         0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 128)          153728      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 128)          896         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 64)           8256        dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 64)           8256        dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 64)           0           dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 32)           2080        dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 32)           2080        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32)           0           dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64)           0           dense_32[0][0]                   \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 16)           1040        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 1)            17          dense_37[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 176,353\n",
      "Trainable params: 176,353\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_train, depth_test, force_train, force_test, theta_z_train, theta_z_test = train_test_split(depth, force, theta_z_disc, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.4728 - mae: 6.4728 - val_loss: 5.7229 - val_mae: 5.7229\n",
      "Epoch 2/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.6974 - mae: 5.6974 - val_loss: 5.3898 - val_mae: 5.3898\n",
      "Epoch 3/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 5.2905 - mae: 5.2905 - val_loss: 4.9091 - val_mae: 4.9091\n",
      "Epoch 4/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.8886 - mae: 4.8886 - val_loss: 4.6913 - val_mae: 4.6913\n",
      "Epoch 5/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.6739 - mae: 4.6739 - val_loss: 4.4580 - val_mae: 4.4580\n",
      "Epoch 6/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 4.5751 - mae: 4.5751 - val_loss: 4.3827 - val_mae: 4.3827\n",
      "Epoch 7/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.4253 - mae: 4.4253 - val_loss: 4.3367 - val_mae: 4.3367\n",
      "Epoch 8/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.3095 - mae: 4.3095 - val_loss: 4.2625 - val_mae: 4.2625\n",
      "Epoch 9/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.2196 - mae: 4.2196 - val_loss: 4.1633 - val_mae: 4.1633\n",
      "Epoch 10/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.1781 - mae: 4.1781 - val_loss: 4.2334 - val_mae: 4.2334\n",
      "Epoch 11/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.0910 - mae: 4.0910 - val_loss: 4.0245 - val_mae: 4.0245\n",
      "Epoch 12/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 4.0120 - mae: 4.0120 - val_loss: 3.9416 - val_mae: 3.9416\n",
      "Epoch 13/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.9636 - mae: 3.9636 - val_loss: 3.9799 - val_mae: 3.9799\n",
      "Epoch 14/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.9103 - mae: 3.9103 - val_loss: 3.8441 - val_mae: 3.8441\n",
      "Epoch 15/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.8384 - mae: 3.8384 - val_loss: 3.9870 - val_mae: 3.9870\n",
      "Epoch 16/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7786 - mae: 3.7786 - val_loss: 3.6939 - val_mae: 3.6939\n",
      "Epoch 17/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.7251 - mae: 3.7251 - val_loss: 3.6486 - val_mae: 3.6486\n",
      "Epoch 18/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6533 - mae: 3.6533 - val_loss: 3.6339 - val_mae: 3.6339\n",
      "Epoch 19/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.6074 - mae: 3.6074 - val_loss: 3.5414 - val_mae: 3.5414\n",
      "Epoch 20/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5764 - mae: 3.5764 - val_loss: 3.6400 - val_mae: 3.6400\n",
      "Epoch 21/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 3.5862 - mae: 3.5862 - val_loss: 3.6134 - val_mae: 3.6134\n",
      "Epoch 22/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5198 - mae: 3.5198 - val_loss: 3.4626 - val_mae: 3.4626\n",
      "Epoch 23/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.5236 - mae: 3.5236 - val_loss: 3.4436 - val_mae: 3.4436\n",
      "Epoch 24/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4299 - mae: 3.4299 - val_loss: 3.5458 - val_mae: 3.5458\n",
      "Epoch 25/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.4331 - mae: 3.4331 - val_loss: 3.4276 - val_mae: 3.4276\n",
      "Epoch 26/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3669 - mae: 3.3669 - val_loss: 3.4371 - val_mae: 3.4371\n",
      "Epoch 27/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3423 - mae: 3.3423 - val_loss: 3.3793 - val_mae: 3.3793\n",
      "Epoch 28/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3288 - mae: 3.3288 - val_loss: 3.3996 - val_mae: 3.3996\n",
      "Epoch 29/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.3098 - mae: 3.3098 - val_loss: 3.3427 - val_mae: 3.3427\n",
      "Epoch 30/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2669 - mae: 3.2669 - val_loss: 3.3657 - val_mae: 3.3657\n",
      "Epoch 31/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2721 - mae: 3.2721 - val_loss: 3.2441 - val_mae: 3.2441\n",
      "Epoch 32/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2251 - mae: 3.2251 - val_loss: 3.2754 - val_mae: 3.2754\n",
      "Epoch 33/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.2027 - mae: 3.2027 - val_loss: 3.3377 - val_mae: 3.3377\n",
      "Epoch 34/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1868 - mae: 3.1868 - val_loss: 3.2893 - val_mae: 3.2893\n",
      "Epoch 35/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1836 - mae: 3.1836 - val_loss: 3.3038 - val_mae: 3.3038\n",
      "Epoch 36/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1455 - mae: 3.1455 - val_loss: 3.2203 - val_mae: 3.2203\n",
      "Epoch 37/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1246 - mae: 3.1246 - val_loss: 3.1765 - val_mae: 3.1765\n",
      "Epoch 38/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.1347 - mae: 3.1347 - val_loss: 3.1797 - val_mae: 3.1797\n",
      "Epoch 39/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0971 - mae: 3.0971 - val_loss: 3.2924 - val_mae: 3.2924\n",
      "Epoch 40/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0789 - mae: 3.0789 - val_loss: 3.2393 - val_mae: 3.2393\n",
      "Epoch 41/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0713 - mae: 3.0713 - val_loss: 3.3136 - val_mae: 3.3136\n",
      "Epoch 42/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0499 - mae: 3.0499 - val_loss: 3.2268 - val_mae: 3.2268\n",
      "Epoch 43/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0350 - mae: 3.0350 - val_loss: 3.1914 - val_mae: 3.1914\n",
      "Epoch 44/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0139 - mae: 3.0139 - val_loss: 3.1528 - val_mae: 3.1528\n",
      "Epoch 45/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0087 - mae: 3.0087 - val_loss: 3.0676 - val_mae: 3.0676\n",
      "Epoch 46/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 3.0329 - mae: 3.0329 - val_loss: 3.1574 - val_mae: 3.1574\n",
      "Epoch 47/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9948 - mae: 2.9948 - val_loss: 3.1579 - val_mae: 3.1579\n",
      "Epoch 48/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9608 - mae: 2.9608 - val_loss: 3.0483 - val_mae: 3.0483\n",
      "Epoch 49/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9441 - mae: 2.9441 - val_loss: 2.9782 - val_mae: 2.9782\n",
      "Epoch 50/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9547 - mae: 2.9547 - val_loss: 3.0913 - val_mae: 3.0913\n",
      "Epoch 51/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9360 - mae: 2.9360 - val_loss: 3.1189 - val_mae: 3.1189\n",
      "Epoch 52/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9464 - mae: 2.9464 - val_loss: 2.9908 - val_mae: 2.9908\n",
      "Epoch 53/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8880 - mae: 2.8880 - val_loss: 3.0903 - val_mae: 3.0903\n",
      "Epoch 54/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.9022 - mae: 2.9022 - val_loss: 3.1114 - val_mae: 3.1114\n",
      "Epoch 55/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8912 - mae: 2.8912 - val_loss: 3.0196 - val_mae: 3.0196\n",
      "Epoch 56/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8687 - mae: 2.8687 - val_loss: 3.0414 - val_mae: 3.0414\n",
      "Epoch 57/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8588 - mae: 2.8588 - val_loss: 2.9821 - val_mae: 2.9821\n",
      "Epoch 58/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8460 - mae: 2.8460 - val_loss: 3.0211 - val_mae: 3.0211\n",
      "Epoch 59/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8443 - mae: 2.8443 - val_loss: 2.9954 - val_mae: 2.9954\n",
      "Epoch 60/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8393 - mae: 2.8393 - val_loss: 3.0555 - val_mae: 3.0555\n",
      "Epoch 61/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8445 - mae: 2.8445 - val_loss: 3.0085 - val_mae: 3.0085\n",
      "Epoch 62/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8175 - mae: 2.8175 - val_loss: 2.9815 - val_mae: 2.9815\n",
      "Epoch 63/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7957 - mae: 2.7957 - val_loss: 3.0057 - val_mae: 3.0057\n",
      "Epoch 64/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.8024 - mae: 2.8024 - val_loss: 2.9449 - val_mae: 2.9449\n",
      "Epoch 65/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7941 - mae: 2.7941 - val_loss: 3.0162 - val_mae: 3.0162\n",
      "Epoch 66/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7866 - mae: 2.7866 - val_loss: 2.8904 - val_mae: 2.8904\n",
      "Epoch 67/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7612 - mae: 2.7612 - val_loss: 2.9538 - val_mae: 2.9538\n",
      "Epoch 68/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7687 - mae: 2.7687 - val_loss: 2.9797 - val_mae: 2.9797\n",
      "Epoch 69/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7454 - mae: 2.7454 - val_loss: 2.8377 - val_mae: 2.8377\n",
      "Epoch 70/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7367 - mae: 2.7367 - val_loss: 2.9774 - val_mae: 2.9774\n",
      "Epoch 71/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7660 - mae: 2.7660 - val_loss: 2.9669 - val_mae: 2.9669\n",
      "Epoch 72/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7139 - mae: 2.7139 - val_loss: 2.9063 - val_mae: 2.9063\n",
      "Epoch 73/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6935 - mae: 2.6935 - val_loss: 2.9050 - val_mae: 2.9050\n",
      "Epoch 74/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7238 - mae: 2.7238 - val_loss: 2.8976 - val_mae: 2.8976\n",
      "Epoch 75/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.7105 - mae: 2.7105 - val_loss: 2.8185 - val_mae: 2.8185\n",
      "Epoch 76/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6943 - mae: 2.6943 - val_loss: 2.9006 - val_mae: 2.9006\n",
      "Epoch 77/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6913 - mae: 2.6913 - val_loss: 2.8317 - val_mae: 2.8317\n",
      "Epoch 78/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6675 - mae: 2.6675 - val_loss: 3.1004 - val_mae: 3.1004\n",
      "Epoch 79/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6867 - mae: 2.6867 - val_loss: 2.8822 - val_mae: 2.8822\n",
      "Epoch 80/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6474 - mae: 2.6474 - val_loss: 2.9196 - val_mae: 2.9196\n",
      "Epoch 81/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6628 - mae: 2.6628 - val_loss: 2.8208 - val_mae: 2.8208\n",
      "Epoch 82/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6540 - mae: 2.6540 - val_loss: 2.8261 - val_mae: 2.8261\n",
      "Epoch 83/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6479 - mae: 2.6479 - val_loss: 2.8615 - val_mae: 2.8615\n",
      "Epoch 84/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6590 - mae: 2.6590 - val_loss: 2.9542 - val_mae: 2.9542\n",
      "Epoch 85/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6443 - mae: 2.6443 - val_loss: 2.8625 - val_mae: 2.8625\n",
      "Epoch 86/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6064 - mae: 2.6064 - val_loss: 2.8990 - val_mae: 2.8990\n",
      "Epoch 87/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.6279 - mae: 2.6279 - val_loss: 2.8276 - val_mae: 2.8276\n",
      "Epoch 88/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6059 - mae: 2.6059 - val_loss: 2.8024 - val_mae: 2.8024\n",
      "Epoch 89/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5916 - mae: 2.5916 - val_loss: 2.8717 - val_mae: 2.8717\n",
      "Epoch 90/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5889 - mae: 2.5889 - val_loss: 2.7349 - val_mae: 2.7349\n",
      "Epoch 91/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6085 - mae: 2.6085 - val_loss: 2.8715 - val_mae: 2.8715\n",
      "Epoch 92/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5853 - mae: 2.5853 - val_loss: 2.7792 - val_mae: 2.7792\n",
      "Epoch 93/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5728 - mae: 2.5728 - val_loss: 2.7133 - val_mae: 2.7133\n",
      "Epoch 94/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.6032 - mae: 2.6032 - val_loss: 2.8689 - val_mae: 2.8689\n",
      "Epoch 95/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5805 - mae: 2.5805 - val_loss: 2.8062 - val_mae: 2.8062\n",
      "Epoch 96/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5766 - mae: 2.5766 - val_loss: 2.8370 - val_mae: 2.8370\n",
      "Epoch 97/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5741 - mae: 2.5741 - val_loss: 2.8599 - val_mae: 2.8599\n",
      "Epoch 98/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5479 - mae: 2.5479 - val_loss: 2.7862 - val_mae: 2.7862\n",
      "Epoch 99/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5527 - mae: 2.5527 - val_loss: 2.8143 - val_mae: 2.8143\n",
      "Epoch 100/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5480 - mae: 2.5480 - val_loss: 2.7435 - val_mae: 2.7435\n",
      "Epoch 101/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5347 - mae: 2.5347 - val_loss: 2.7035 - val_mae: 2.7035\n",
      "Epoch 102/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5362 - mae: 2.5362 - val_loss: 2.7118 - val_mae: 2.7118\n",
      "Epoch 103/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5226 - mae: 2.5226 - val_loss: 2.8086 - val_mae: 2.8086\n",
      "Epoch 104/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5457 - mae: 2.5457 - val_loss: 2.9095 - val_mae: 2.9095\n",
      "Epoch 105/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5201 - mae: 2.5201 - val_loss: 2.7013 - val_mae: 2.7013\n",
      "Epoch 106/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5094 - mae: 2.5094 - val_loss: 2.9539 - val_mae: 2.9539\n",
      "Epoch 107/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5243 - mae: 2.5243 - val_loss: 2.7912 - val_mae: 2.7912\n",
      "Epoch 108/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4923 - mae: 2.4923 - val_loss: 2.7441 - val_mae: 2.7441\n",
      "Epoch 109/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5235 - mae: 2.5235 - val_loss: 2.7341 - val_mae: 2.7341\n",
      "Epoch 110/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5079 - mae: 2.5079 - val_loss: 2.7490 - val_mae: 2.7490\n",
      "Epoch 111/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.5133 - mae: 2.5133 - val_loss: 2.7858 - val_mae: 2.7858\n",
      "Epoch 112/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4854 - mae: 2.4854 - val_loss: 2.7486 - val_mae: 2.7486\n",
      "Epoch 113/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4920 - mae: 2.4920 - val_loss: 2.8198 - val_mae: 2.8198\n",
      "Epoch 114/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4777 - mae: 2.4777 - val_loss: 2.7439 - val_mae: 2.7439\n",
      "Epoch 115/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4780 - mae: 2.4780 - val_loss: 2.7094 - val_mae: 2.7094\n",
      "Epoch 116/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4542 - mae: 2.4542 - val_loss: 2.7480 - val_mae: 2.7480\n",
      "Epoch 117/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4916 - mae: 2.4916 - val_loss: 2.6990 - val_mae: 2.6990\n",
      "Epoch 118/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4506 - mae: 2.4506 - val_loss: 2.7244 - val_mae: 2.7244\n",
      "Epoch 119/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4544 - mae: 2.4544 - val_loss: 2.6952 - val_mae: 2.6952\n",
      "Epoch 120/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4503 - mae: 2.4503 - val_loss: 2.6977 - val_mae: 2.6977\n",
      "Epoch 121/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4324 - mae: 2.4324 - val_loss: 2.7557 - val_mae: 2.7557\n",
      "Epoch 122/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4496 - mae: 2.4496 - val_loss: 2.7128 - val_mae: 2.7128\n",
      "Epoch 123/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4145 - mae: 2.4145 - val_loss: 2.7045 - val_mae: 2.7045\n",
      "Epoch 124/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.4315 - mae: 2.4315 - val_loss: 2.6601 - val_mae: 2.6601\n",
      "Epoch 125/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4406 - mae: 2.4406 - val_loss: 2.7471 - val_mae: 2.7471\n",
      "Epoch 126/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4215 - mae: 2.4215 - val_loss: 2.7291 - val_mae: 2.7291\n",
      "Epoch 127/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4213 - mae: 2.4213 - val_loss: 2.7278 - val_mae: 2.7278\n",
      "Epoch 128/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4059 - mae: 2.4059 - val_loss: 2.7064 - val_mae: 2.7064\n",
      "Epoch 129/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3931 - mae: 2.3931 - val_loss: 2.7631 - val_mae: 2.7631\n",
      "Epoch 130/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4303 - mae: 2.4303 - val_loss: 2.6768 - val_mae: 2.6768\n",
      "Epoch 131/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4085 - mae: 2.4085 - val_loss: 2.7691 - val_mae: 2.7691\n",
      "Epoch 132/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3997 - mae: 2.3997 - val_loss: 2.7985 - val_mae: 2.7985\n",
      "Epoch 133/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3938 - mae: 2.3938 - val_loss: 2.6950 - val_mae: 2.6950\n",
      "Epoch 134/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3777 - mae: 2.3777 - val_loss: 2.7450 - val_mae: 2.7450\n",
      "Epoch 135/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4008 - mae: 2.4008 - val_loss: 2.8168 - val_mae: 2.8168\n",
      "Epoch 136/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4469 - mae: 2.4469 - val_loss: 2.6703 - val_mae: 2.6703\n",
      "Epoch 137/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3738 - mae: 2.3738 - val_loss: 2.7348 - val_mae: 2.7348\n",
      "Epoch 138/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3665 - mae: 2.3665 - val_loss: 2.6597 - val_mae: 2.6597\n",
      "Epoch 139/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.3682 - mae: 2.3682 - val_loss: 2.7142 - val_mae: 2.7142\n",
      "Epoch 140/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.4323 - mae: 2.4323 - val_loss: 2.6730 - val_mae: 2.6730\n",
      "Epoch 141/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3810 - mae: 2.3810 - val_loss: 2.5828 - val_mae: 2.5828\n",
      "Epoch 142/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3389 - mae: 2.3389 - val_loss: 2.7287 - val_mae: 2.7287\n",
      "Epoch 143/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3596 - mae: 2.3596 - val_loss: 2.6472 - val_mae: 2.6472\n",
      "Epoch 144/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3618 - mae: 2.3618 - val_loss: 2.6864 - val_mae: 2.6864\n",
      "Epoch 145/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3456 - mae: 2.3456 - val_loss: 2.6953 - val_mae: 2.6953\n",
      "Epoch 146/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3611 - mae: 2.3611 - val_loss: 2.6421 - val_mae: 2.6421\n",
      "Epoch 147/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3287 - mae: 2.3287 - val_loss: 2.6201 - val_mae: 2.6201\n",
      "Epoch 148/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3554 - mae: 2.3554 - val_loss: 2.6021 - val_mae: 2.6021\n",
      "Epoch 149/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3690 - mae: 2.3690 - val_loss: 2.6867 - val_mae: 2.6867\n",
      "Epoch 150/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3349 - mae: 2.3349 - val_loss: 2.7361 - val_mae: 2.7361\n",
      "Epoch 151/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3148 - mae: 2.3148 - val_loss: 2.6226 - val_mae: 2.6226\n",
      "Epoch 152/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3212 - mae: 2.3212 - val_loss: 2.6173 - val_mae: 2.6173\n",
      "Epoch 153/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3365 - mae: 2.3365 - val_loss: 2.6479 - val_mae: 2.6479\n",
      "Epoch 154/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3347 - mae: 2.3347 - val_loss: 2.6566 - val_mae: 2.6566\n",
      "Epoch 155/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3044 - mae: 2.3044 - val_loss: 2.6078 - val_mae: 2.6078\n",
      "Epoch 156/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3022 - mae: 2.3022 - val_loss: 2.6590 - val_mae: 2.6590\n",
      "Epoch 157/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2991 - mae: 2.2991 - val_loss: 2.6246 - val_mae: 2.6246\n",
      "Epoch 158/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.3167 - mae: 2.3167 - val_loss: 2.7495 - val_mae: 2.7495\n",
      "Epoch 159/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2977 - mae: 2.2977 - val_loss: 2.5879 - val_mae: 2.5879\n",
      "Epoch 160/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2912 - mae: 2.2912 - val_loss: 2.6443 - val_mae: 2.6443\n",
      "Epoch 161/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2866 - mae: 2.2866 - val_loss: 2.7078 - val_mae: 2.7078\n",
      "Epoch 162/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2859 - mae: 2.2859 - val_loss: 2.7392 - val_mae: 2.7392\n",
      "Epoch 163/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2985 - mae: 2.2985 - val_loss: 2.7536 - val_mae: 2.7536\n",
      "Epoch 164/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2711 - mae: 2.2711 - val_loss: 2.6203 - val_mae: 2.6203\n",
      "Epoch 165/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2751 - mae: 2.2751 - val_loss: 2.6426 - val_mae: 2.6426\n",
      "Epoch 166/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2718 - mae: 2.2718 - val_loss: 2.6782 - val_mae: 2.6782\n",
      "Epoch 167/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2650 - mae: 2.2650 - val_loss: 2.6500 - val_mae: 2.6500\n",
      "Epoch 168/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2865 - mae: 2.2865 - val_loss: 2.6959 - val_mae: 2.6959\n",
      "Epoch 169/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2768 - mae: 2.2768 - val_loss: 2.6595 - val_mae: 2.6595\n",
      "Epoch 170/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2890 - mae: 2.2890 - val_loss: 2.6239 - val_mae: 2.6239\n",
      "Epoch 171/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2675 - mae: 2.2675 - val_loss: 2.7256 - val_mae: 2.7256\n",
      "Epoch 172/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2448 - mae: 2.2448 - val_loss: 2.6153 - val_mae: 2.6153\n",
      "Epoch 173/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2627 - mae: 2.2627 - val_loss: 2.6760 - val_mae: 2.6760\n",
      "Epoch 174/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2598 - mae: 2.2598 - val_loss: 2.6138 - val_mae: 2.6138\n",
      "Epoch 175/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2510 - mae: 2.2510 - val_loss: 2.6137 - val_mae: 2.6137\n",
      "Epoch 176/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2304 - mae: 2.2304 - val_loss: 2.6648 - val_mae: 2.6648\n",
      "Epoch 177/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2557 - mae: 2.2557 - val_loss: 2.6491 - val_mae: 2.6491\n",
      "Epoch 178/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2717 - mae: 2.2717 - val_loss: 2.7708 - val_mae: 2.7708\n",
      "Epoch 179/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2807 - mae: 2.2807 - val_loss: 2.8366 - val_mae: 2.8366\n",
      "Epoch 180/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2339 - mae: 2.2339 - val_loss: 2.5632 - val_mae: 2.5632\n",
      "Epoch 181/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2765 - mae: 2.2765 - val_loss: 2.6492 - val_mae: 2.6492\n",
      "Epoch 182/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2282 - mae: 2.2282 - val_loss: 2.6858 - val_mae: 2.6858\n",
      "Epoch 183/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2295 - mae: 2.2295 - val_loss: 2.5894 - val_mae: 2.5894\n",
      "Epoch 184/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2309 - mae: 2.2309 - val_loss: 2.6954 - val_mae: 2.6954\n",
      "Epoch 185/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2176 - mae: 2.2176 - val_loss: 2.6258 - val_mae: 2.6258\n",
      "Epoch 186/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.2153 - mae: 2.2153 - val_loss: 2.5942 - val_mae: 2.5942\n",
      "Epoch 187/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1865 - mae: 2.1865 - val_loss: 2.5300 - val_mae: 2.5300\n",
      "Epoch 188/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2059 - mae: 2.2059 - val_loss: 2.6096 - val_mae: 2.6096\n",
      "Epoch 189/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2382 - mae: 2.2382 - val_loss: 2.6293 - val_mae: 2.6293\n",
      "Epoch 190/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2007 - mae: 2.2007 - val_loss: 2.5842 - val_mae: 2.5842\n",
      "Epoch 191/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.2138 - mae: 2.2138 - val_loss: 2.6245 - val_mae: 2.6245\n",
      "Epoch 192/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1954 - mae: 2.1954 - val_loss: 2.5018 - val_mae: 2.5018\n",
      "Epoch 193/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1931 - mae: 2.1931 - val_loss: 2.6603 - val_mae: 2.6603\n",
      "Epoch 194/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1847 - mae: 2.1847 - val_loss: 2.6596 - val_mae: 2.6596\n",
      "Epoch 195/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1932 - mae: 2.1932 - val_loss: 2.6691 - val_mae: 2.6691\n",
      "Epoch 196/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.1801 - mae: 2.1801 - val_loss: 2.6542 - val_mae: 2.6542\n",
      "Epoch 197/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1829 - mae: 2.1829 - val_loss: 2.5627 - val_mae: 2.5627\n",
      "Epoch 198/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1657 - mae: 2.1657 - val_loss: 2.5785 - val_mae: 2.5785\n",
      "Epoch 199/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1969 - mae: 2.1969 - val_loss: 2.6323 - val_mae: 2.6323\n",
      "Epoch 200/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1845 - mae: 2.1845 - val_loss: 2.6121 - val_mae: 2.6121\n",
      "Epoch 201/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1722 - mae: 2.1722 - val_loss: 2.5284 - val_mae: 2.5284\n",
      "Epoch 202/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1495 - mae: 2.1495 - val_loss: 2.5629 - val_mae: 2.5629\n",
      "Epoch 203/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1839 - mae: 2.1839 - val_loss: 2.6365 - val_mae: 2.6365\n",
      "Epoch 204/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1622 - mae: 2.1622 - val_loss: 2.5627 - val_mae: 2.5627\n",
      "Epoch 205/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1563 - mae: 2.1563 - val_loss: 2.5722 - val_mae: 2.5722\n",
      "Epoch 206/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1511 - mae: 2.1511 - val_loss: 2.6092 - val_mae: 2.6092\n",
      "Epoch 207/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1701 - mae: 2.1701 - val_loss: 2.5587 - val_mae: 2.5587\n",
      "Epoch 208/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1597 - mae: 2.1597 - val_loss: 2.5514 - val_mae: 2.5514\n",
      "Epoch 209/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1801 - mae: 2.1801 - val_loss: 2.6204 - val_mae: 2.6204\n",
      "Epoch 210/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1470 - mae: 2.1470 - val_loss: 2.6238 - val_mae: 2.6238\n",
      "Epoch 211/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1360 - mae: 2.1360 - val_loss: 2.6313 - val_mae: 2.6313\n",
      "Epoch 212/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1722 - mae: 2.1722 - val_loss: 2.6642 - val_mae: 2.6642\n",
      "Epoch 213/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1439 - mae: 2.1439 - val_loss: 2.6048 - val_mae: 2.6048\n",
      "Epoch 214/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1454 - mae: 2.1454 - val_loss: 2.6332 - val_mae: 2.6332\n",
      "Epoch 215/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1650 - mae: 2.1650 - val_loss: 2.5926 - val_mae: 2.5926\n",
      "Epoch 216/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1903 - mae: 2.1903 - val_loss: 2.5433 - val_mae: 2.5433\n",
      "Epoch 217/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1519 - mae: 2.1519 - val_loss: 2.6062 - val_mae: 2.6062\n",
      "Epoch 218/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1314 - mae: 2.1314 - val_loss: 2.5832 - val_mae: 2.5832\n",
      "Epoch 219/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1510 - mae: 2.1510 - val_loss: 2.5831 - val_mae: 2.5831\n",
      "Epoch 220/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1351 - mae: 2.1351 - val_loss: 2.5806 - val_mae: 2.5806\n",
      "Epoch 221/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1298 - mae: 2.1298 - val_loss: 2.5939 - val_mae: 2.5939\n",
      "Epoch 222/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1173 - mae: 2.1173 - val_loss: 2.6414 - val_mae: 2.6414\n",
      "Epoch 223/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1140 - mae: 2.1140 - val_loss: 2.5844 - val_mae: 2.5844\n",
      "Epoch 224/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1297 - mae: 2.1297 - val_loss: 2.6223 - val_mae: 2.6223\n",
      "Epoch 225/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1373 - mae: 2.1373 - val_loss: 2.6032 - val_mae: 2.6032\n",
      "Epoch 226/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1219 - mae: 2.1219 - val_loss: 2.6196 - val_mae: 2.6196\n",
      "Epoch 227/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1377 - mae: 2.1377 - val_loss: 2.5817 - val_mae: 2.5817\n",
      "Epoch 228/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1155 - mae: 2.1155 - val_loss: 2.5625 - val_mae: 2.5625\n",
      "Epoch 229/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1010 - mae: 2.1010 - val_loss: 2.5605 - val_mae: 2.5605\n",
      "Epoch 230/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1186 - mae: 2.1186 - val_loss: 2.6614 - val_mae: 2.6614\n",
      "Epoch 231/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1247 - mae: 2.1247 - val_loss: 2.5077 - val_mae: 2.5077\n",
      "Epoch 232/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1118 - mae: 2.1118 - val_loss: 2.5953 - val_mae: 2.5953\n",
      "Epoch 233/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0886 - mae: 2.0886 - val_loss: 2.5824 - val_mae: 2.5824\n",
      "Epoch 234/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1002 - mae: 2.1002 - val_loss: 2.5498 - val_mae: 2.5498\n",
      "Epoch 235/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0869 - mae: 2.0869 - val_loss: 2.6266 - val_mae: 2.6266\n",
      "Epoch 236/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1484 - mae: 2.1484 - val_loss: 2.5417 - val_mae: 2.5417\n",
      "Epoch 237/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1015 - mae: 2.1015 - val_loss: 2.5433 - val_mae: 2.5433\n",
      "Epoch 238/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1003 - mae: 2.1003 - val_loss: 2.6354 - val_mae: 2.6354\n",
      "Epoch 239/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1051 - mae: 2.1051 - val_loss: 2.7046 - val_mae: 2.7046\n",
      "Epoch 240/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1046 - mae: 2.1046 - val_loss: 2.5410 - val_mae: 2.5410\n",
      "Epoch 241/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0848 - mae: 2.0848 - val_loss: 2.5282 - val_mae: 2.5282\n",
      "Epoch 242/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0801 - mae: 2.0801 - val_loss: 2.5741 - val_mae: 2.5741\n",
      "Epoch 243/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0722 - mae: 2.0722 - val_loss: 2.5370 - val_mae: 2.5370\n",
      "Epoch 244/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0638 - mae: 2.0638 - val_loss: 2.6210 - val_mae: 2.6210\n",
      "Epoch 245/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0760 - mae: 2.0760 - val_loss: 2.5625 - val_mae: 2.5625\n",
      "Epoch 246/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1067 - mae: 2.1067 - val_loss: 2.5124 - val_mae: 2.5124\n",
      "Epoch 247/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1323 - mae: 2.1323 - val_loss: 2.6430 - val_mae: 2.6430\n",
      "Epoch 248/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0740 - mae: 2.0740 - val_loss: 2.5242 - val_mae: 2.5242\n",
      "Epoch 249/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.0923 - mae: 2.0923 - val_loss: 2.5403 - val_mae: 2.5403\n",
      "Epoch 250/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.0866 - mae: 2.0866 - val_loss: 2.5424 - val_mae: 2.5424\n",
      "Epoch 251/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.1077 - mae: 2.1077 - val_loss: 2.5508 - val_mae: 2.5508\n",
      "Epoch 252/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.0559 - mae: 2.0559 - val_loss: 2.5245 - val_mae: 2.5245\n",
      "Epoch 253/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0807 - mae: 2.0807 - val_loss: 2.5086 - val_mae: 2.5086\n",
      "Epoch 254/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0644 - mae: 2.0644 - val_loss: 2.5409 - val_mae: 2.5409\n",
      "Epoch 255/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0652 - mae: 2.0652 - val_loss: 2.5222 - val_mae: 2.5222\n",
      "Epoch 256/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0522 - mae: 2.0522 - val_loss: 2.5040 - val_mae: 2.5040\n",
      "Epoch 257/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0565 - mae: 2.0565 - val_loss: 2.5055 - val_mae: 2.5055\n",
      "Epoch 258/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0655 - mae: 2.0655 - val_loss: 2.5870 - val_mae: 2.5870\n",
      "Epoch 259/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0632 - mae: 2.0632 - val_loss: 2.5927 - val_mae: 2.5927\n",
      "Epoch 260/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.1091 - mae: 2.1091 - val_loss: 2.6854 - val_mae: 2.6854\n",
      "Epoch 261/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.0392 - mae: 2.0392 - val_loss: 2.5644 - val_mae: 2.5644\n",
      "Epoch 262/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0873 - mae: 2.0873 - val_loss: 2.5754 - val_mae: 2.5754\n",
      "Epoch 263/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0671 - mae: 2.0671 - val_loss: 2.5889 - val_mae: 2.5889\n",
      "Epoch 264/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0547 - mae: 2.0547 - val_loss: 2.5815 - val_mae: 2.5815\n",
      "Epoch 265/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0514 - mae: 2.0514 - val_loss: 2.5595 - val_mae: 2.5595\n",
      "Epoch 266/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0467 - mae: 2.0467 - val_loss: 2.5161 - val_mae: 2.5161\n",
      "Epoch 267/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0469 - mae: 2.0469 - val_loss: 2.6282 - val_mae: 2.6282\n",
      "Epoch 268/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0506 - mae: 2.0506 - val_loss: 2.5421 - val_mae: 2.5421\n",
      "Epoch 269/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0555 - mae: 2.0555 - val_loss: 2.5473 - val_mae: 2.5473\n",
      "Epoch 270/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0297 - mae: 2.0297 - val_loss: 2.5332 - val_mae: 2.5332\n",
      "Epoch 271/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0702 - mae: 2.0702 - val_loss: 2.5512 - val_mae: 2.5512\n",
      "Epoch 272/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0774 - mae: 2.0774 - val_loss: 2.5538 - val_mae: 2.5538\n",
      "Epoch 273/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0545 - mae: 2.0545 - val_loss: 2.5449 - val_mae: 2.5449\n",
      "Epoch 274/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0506 - mae: 2.0506 - val_loss: 2.5373 - val_mae: 2.5373\n",
      "Epoch 275/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0291 - mae: 2.0291 - val_loss: 2.5023 - val_mae: 2.5023\n",
      "Epoch 276/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0427 - mae: 2.0427 - val_loss: 2.4982 - val_mae: 2.4982\n",
      "Epoch 277/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0169 - mae: 2.0169 - val_loss: 2.6250 - val_mae: 2.6250\n",
      "Epoch 278/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0195 - mae: 2.0195 - val_loss: 2.5810 - val_mae: 2.5810\n",
      "Epoch 279/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0331 - mae: 2.0331 - val_loss: 2.6089 - val_mae: 2.6089\n",
      "Epoch 280/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0456 - mae: 2.0456 - val_loss: 2.5612 - val_mae: 2.5612\n",
      "Epoch 281/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0337 - mae: 2.0337 - val_loss: 2.5230 - val_mae: 2.5230\n",
      "Epoch 282/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0644 - mae: 2.0644 - val_loss: 2.5757 - val_mae: 2.5757\n",
      "Epoch 283/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0630 - mae: 2.0630 - val_loss: 2.5793 - val_mae: 2.5793\n",
      "Epoch 284/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0399 - mae: 2.0399 - val_loss: 2.5459 - val_mae: 2.5459\n",
      "Epoch 285/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 1.9987 - mae: 1.9987 - val_loss: 2.5014 - val_mae: 2.5014\n",
      "Epoch 286/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0114 - mae: 2.0114 - val_loss: 2.5124 - val_mae: 2.5124\n",
      "Epoch 287/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0200 - mae: 2.0200 - val_loss: 2.6720 - val_mae: 2.6720\n",
      "Epoch 288/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0494 - mae: 2.0494 - val_loss: 2.5176 - val_mae: 2.5176\n",
      "Epoch 289/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0101 - mae: 2.0101 - val_loss: 2.4891 - val_mae: 2.4891\n",
      "Epoch 290/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0262 - mae: 2.0262 - val_loss: 2.5754 - val_mae: 2.5754\n",
      "Epoch 291/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0376 - mae: 2.0376 - val_loss: 2.5167 - val_mae: 2.5167\n",
      "Epoch 292/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 2.0142 - mae: 2.0142 - val_loss: 2.4943 - val_mae: 2.4943\n",
      "Epoch 293/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0098 - mae: 2.0098 - val_loss: 2.5072 - val_mae: 2.5072\n",
      "Epoch 294/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0090 - mae: 2.0090 - val_loss: 2.5608 - val_mae: 2.5608\n",
      "Epoch 295/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0510 - mae: 2.0510 - val_loss: 2.5221 - val_mae: 2.5221\n",
      "Epoch 296/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0039 - mae: 2.0039 - val_loss: 2.5444 - val_mae: 2.5444\n",
      "Epoch 297/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0008 - mae: 2.0008 - val_loss: 2.5336 - val_mae: 2.5336\n",
      "Epoch 298/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0302 - mae: 2.0302 - val_loss: 2.5294 - val_mae: 2.5294\n",
      "Epoch 299/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 2.0185 - mae: 2.0185 - val_loss: 2.4870 - val_mae: 2.4870\n",
      "Epoch 300/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 1.9956 - mae: 1.9956 - val_loss: 2.5635 - val_mae: 2.5635\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "input_depth = layers.Input(shape = (30, 40))\n",
    "input_force = layers.Input(shape = (6, ))\n",
    "\n",
    "# first branch\n",
    "x = layers.Flatten(input_shape=(30, 40))(input_depth)\n",
    "x = layers.Dense(units=128, activation='relu')(x)\n",
    "x = layers.Dense(units=64, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "x = tf.keras.Model(inputs= input_depth, outputs = x)\n",
    "\n",
    "# second branch\n",
    "y = layers.Dense(units=128, activation='relu')(input_force)\n",
    "y = layers.Dense(units=64, activation='relu')(y)\n",
    "y = layers.Dense(32, activation='relu')(y)\n",
    "y = layers.Dropout(0.2)(y)\n",
    "y = tf.keras.Model(inputs= input_force, outputs = y)\n",
    "\n",
    "# combine two branches\n",
    "combined = layers.concatenate([x.output, y.output])\n",
    "\n",
    "# regression to one output\n",
    "z = layers.Dense(units=32, activation='relu')(combined)\n",
    "z = layers.Dropout(0.2)(z)\n",
    "z = layers.Dense(units=16, activation='relu')(combined)\n",
    "z = layers.Dense(1, activation='linear')(z)\n",
    "model = tf.keras.Model(inputs = [x.input, y.input], outputs = z)\n",
    "\n",
    "#tf.keras.utils.plot_model(model, to_file = 'model.png')\n",
    "model.compile(optimizer='adam', loss= 'mae', metrics=['mae'])\n",
    "\n",
    "history = model.fit([depth_train, force_train],theta_z_train, verbose = 1, epochs = 300, batch_size = 128,\n",
    "                   validation_data = ([depth_test, force_test], theta_z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.8862 - mae: 7.8862 - val_loss: 7.5961 - val_mae: 7.5961\n",
      "Epoch 2/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.5531 - mae: 7.5531 - val_loss: 7.5408 - val_mae: 7.5408\n",
      "Epoch 3/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.4656 - mae: 7.4656 - val_loss: 7.3679 - val_mae: 7.3679\n",
      "Epoch 4/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 7.3643 - mae: 7.3643 - val_loss: 7.2519 - val_mae: 7.2519\n",
      "Epoch 5/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.3073 - mae: 7.3073 - val_loss: 7.1640 - val_mae: 7.1640\n",
      "Epoch 6/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.2836 - mae: 7.2836 - val_loss: 7.2576 - val_mae: 7.2576\n",
      "Epoch 7/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.2511 - mae: 7.2511 - val_loss: 7.1030 - val_mae: 7.1030\n",
      "Epoch 8/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.2064 - mae: 7.2064 - val_loss: 7.0497 - val_mae: 7.0497\n",
      "Epoch 9/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.0869 - mae: 7.0869 - val_loss: 6.9600 - val_mae: 6.9600\n",
      "Epoch 10/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.0863 - mae: 7.0863 - val_loss: 7.0303 - val_mae: 7.0303\n",
      "Epoch 11/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 7.0272 - mae: 7.0272 - val_loss: 6.8074 - val_mae: 6.8074\n",
      "Epoch 12/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.9214 - mae: 6.9214 - val_loss: 6.8432 - val_mae: 6.8432\n",
      "Epoch 13/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.9788 - mae: 6.9788 - val_loss: 6.8864 - val_mae: 6.8864\n",
      "Epoch 14/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.9180 - mae: 6.9180 - val_loss: 6.7471 - val_mae: 6.7471\n",
      "Epoch 15/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.7833 - mae: 6.7833 - val_loss: 6.7091 - val_mae: 6.7091\n",
      "Epoch 16/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.7292 - mae: 6.7292 - val_loss: 6.6028 - val_mae: 6.6028\n",
      "Epoch 17/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.6568 - mae: 6.6568 - val_loss: 6.5667 - val_mae: 6.5667\n",
      "Epoch 18/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.6969 - mae: 6.6969 - val_loss: 6.5670 - val_mae: 6.5670\n",
      "Epoch 19/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.6610 - mae: 6.6610 - val_loss: 6.5217 - val_mae: 6.5217\n",
      "Epoch 20/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.6509 - mae: 6.6509 - val_loss: 6.4880 - val_mae: 6.4880\n",
      "Epoch 21/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.5578 - mae: 6.5578 - val_loss: 6.4368 - val_mae: 6.4368\n",
      "Epoch 22/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.5804 - mae: 6.5804 - val_loss: 6.4279 - val_mae: 6.4279\n",
      "Epoch 23/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.5314 - mae: 6.5314 - val_loss: 6.3870 - val_mae: 6.3870\n",
      "Epoch 24/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.5373 - mae: 6.5373 - val_loss: 6.4097 - val_mae: 6.4097\n",
      "Epoch 25/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.4872 - mae: 6.4872 - val_loss: 6.3331 - val_mae: 6.3331\n",
      "Epoch 26/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.4534 - mae: 6.4534 - val_loss: 6.3772 - val_mae: 6.3772\n",
      "Epoch 27/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.4616 - mae: 6.4616 - val_loss: 6.3217 - val_mae: 6.3217\n",
      "Epoch 28/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.2306 - val_mae: 6.2306\n",
      "Epoch 29/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.3388 - mae: 6.3388 - val_loss: 6.1994 - val_mae: 6.1994\n",
      "Epoch 30/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.3210 - mae: 6.3210 - val_loss: 6.1987 - val_mae: 6.1987\n",
      "Epoch 31/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.2865 - mae: 6.2865 - val_loss: 6.1170 - val_mae: 6.1170\n",
      "Epoch 32/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.2761 - mae: 6.2761 - val_loss: 6.1368 - val_mae: 6.1368\n",
      "Epoch 33/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.2703 - mae: 6.2703 - val_loss: 6.1438 - val_mae: 6.1438\n",
      "Epoch 34/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.3277 - mae: 6.3277 - val_loss: 6.2939 - val_mae: 6.2939\n",
      "Epoch 35/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.2853 - mae: 6.2853 - val_loss: 6.1353 - val_mae: 6.1353\n",
      "Epoch 36/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.2768 - mae: 6.2768 - val_loss: 6.1762 - val_mae: 6.1762\n",
      "Epoch 37/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.3079 - mae: 6.3079 - val_loss: 6.2063 - val_mae: 6.2063\n",
      "Epoch 38/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.3201 - mae: 6.3201 - val_loss: 6.2757 - val_mae: 6.2757\n",
      "Epoch 39/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.4056 - mae: 6.4056 - val_loss: 6.2180 - val_mae: 6.2180\n",
      "Epoch 40/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.3285 - mae: 6.3285 - val_loss: 6.1375 - val_mae: 6.1375\n",
      "Epoch 41/300\n",
      "515/515 [==============================] - 1s 1ms/step - loss: 6.3725 - mae: 6.3725 - val_loss: 6.2772 - val_mae: 6.2772\n",
      "Epoch 42/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.3735 - mae: 6.3735 - val_loss: 6.2379 - val_mae: 6.2379\n",
      "Epoch 43/300\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 6.2880 - mae: 6.2880 - val_loss: 6.1579 - val_mae: 6.1579\n"
     ]
    }
   ],
   "source": [
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(depth_quantized, theta_z_disc, test_size = 0.2, random_state = 0)\n",
    "import tensorflow as tf\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 10, restore_best_weights = True)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(30, 40)),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss= 'mae',\n",
    "              metrics=['mae'])\n",
    "\n",
    "history = model.fit(X_train_tf, y_train_tf, epochs=300,callbacks = [callback], \n",
    "                    batch_size = 128, validation_data = (X_test_tf, y_test_tf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
